I0824 09:20:24.232116      14 e2e.go:116] Starting e2e run "e1f158d7-4c48-4d0f-8c7b-65e2c1188e50" on Ginkgo node 1
Aug 24 09:20:24.271: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1661332823 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Aug 24 09:20:24.460: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 09:20:24.465: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 24 09:20:24.497: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 24 09:20:24.547: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 24 09:20:24.547: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Aug 24 09:20:24.548: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 24 09:20:24.557: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 24 09:20:24.557: INFO: e2e test version: v1.25.0
Aug 24 09:20:24.559: INFO: kube-apiserver version: v1.25.0
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Aug 24 09:20:24.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 09:20:24.567: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.108 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 24 09:20:24.460: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 09:20:24.465: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Aug 24 09:20:24.497: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Aug 24 09:20:24.547: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Aug 24 09:20:24.547: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
    Aug 24 09:20:24.548: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Aug 24 09:20:24.557: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Aug 24 09:20:24.557: INFO: e2e test version: v1.25.0
    Aug 24 09:20:24.559: INFO: kube-apiserver version: v1.25.0
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 24 09:20:24.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 09:20:24.567: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:20:24.608
Aug 24 09:20:24.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:20:24.61
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:24.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:24.651
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-dab09c8d-8312-458c-9a71-c5398a5d9bb3 08/24/22 09:20:24.656
STEP: Creating a pod to test consume configMaps 08/24/22 09:20:24.668
Aug 24 09:20:24.693: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0" in namespace "projected-3434" to be "Succeeded or Failed"
Aug 24 09:20:24.712: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.388617ms
Aug 24 09:20:26.720: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026537338s
Aug 24 09:20:28.726: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032215047s
Aug 24 09:20:30.724: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030233449s
Aug 24 09:20:32.721: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027674251s
Aug 24 09:20:34.721: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.027778598s
Aug 24 09:20:36.718: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.02484856s
STEP: Saw pod success 08/24/22 09:20:36.718
Aug 24 09:20:36.720: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0" satisfied condition "Succeeded or Failed"
Aug 24 09:20:36.727: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 09:20:36.767
Aug 24 09:20:36.787: INFO: Waiting for pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 to disappear
Aug 24 09:20:36.791: INFO: Pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 09:20:36.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3434" for this suite. 08/24/22 09:20:36.798
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":1,"skipped":9,"failed":0}
------------------------------
• [SLOW TEST] [12.201 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:20:24.608
    Aug 24 09:20:24.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:20:24.61
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:24.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:24.651
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-dab09c8d-8312-458c-9a71-c5398a5d9bb3 08/24/22 09:20:24.656
    STEP: Creating a pod to test consume configMaps 08/24/22 09:20:24.668
    Aug 24 09:20:24.693: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0" in namespace "projected-3434" to be "Succeeded or Failed"
    Aug 24 09:20:24.712: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.388617ms
    Aug 24 09:20:26.720: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026537338s
    Aug 24 09:20:28.726: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032215047s
    Aug 24 09:20:30.724: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030233449s
    Aug 24 09:20:32.721: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027674251s
    Aug 24 09:20:34.721: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.027778598s
    Aug 24 09:20:36.718: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.02484856s
    STEP: Saw pod success 08/24/22 09:20:36.718
    Aug 24 09:20:36.720: INFO: Pod "pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0" satisfied condition "Succeeded or Failed"
    Aug 24 09:20:36.727: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 09:20:36.767
    Aug 24 09:20:36.787: INFO: Waiting for pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 to disappear
    Aug 24 09:20:36.791: INFO: Pod pod-projected-configmaps-c4b94e37-5c09-4574-a7c0-a026cbbb32e0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 09:20:36.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3434" for this suite. 08/24/22 09:20:36.798
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:20:36.816
Aug 24 09:20:36.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename prestop 08/24/22 09:20:36.819
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:36.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:36.849
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-7802 08/24/22 09:20:36.853
STEP: Waiting for pods to come up. 08/24/22 09:20:36.867
Aug 24 09:20:36.867: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7802" to be "running"
Aug 24 09:20:36.873: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951701ms
Aug 24 09:20:38.878: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.010608089s
Aug 24 09:20:38.879: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-7802 08/24/22 09:20:38.889
Aug 24 09:20:38.901: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7802" to be "running"
Aug 24 09:20:38.910: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 8.70135ms
Aug 24 09:20:40.919: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017908056s
Aug 24 09:20:42.916: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015198256s
Aug 24 09:20:44.918: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 6.017174776s
Aug 24 09:20:44.918: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 08/24/22 09:20:44.918
Aug 24 09:20:49.943: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 08/24/22 09:20:49.943
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Aug 24 09:20:49.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7802" for this suite. 08/24/22 09:20:49.977
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":2,"skipped":25,"failed":0}
------------------------------
• [SLOW TEST] [13.171 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:20:36.816
    Aug 24 09:20:36.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename prestop 08/24/22 09:20:36.819
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:36.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:36.849
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-7802 08/24/22 09:20:36.853
    STEP: Waiting for pods to come up. 08/24/22 09:20:36.867
    Aug 24 09:20:36.867: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7802" to be "running"
    Aug 24 09:20:36.873: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951701ms
    Aug 24 09:20:38.878: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.010608089s
    Aug 24 09:20:38.879: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-7802 08/24/22 09:20:38.889
    Aug 24 09:20:38.901: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7802" to be "running"
    Aug 24 09:20:38.910: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 8.70135ms
    Aug 24 09:20:40.919: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017908056s
    Aug 24 09:20:42.916: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015198256s
    Aug 24 09:20:44.918: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 6.017174776s
    Aug 24 09:20:44.918: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 08/24/22 09:20:44.918
    Aug 24 09:20:49.943: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 08/24/22 09:20:49.943
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Aug 24 09:20:49.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-7802" for this suite. 08/24/22 09:20:49.977
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:20:49.998
Aug 24 09:20:49.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 09:20:50.005
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:50.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:50.043
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/24/22 09:20:50.048
Aug 24 09:20:50.066: INFO: Waiting up to 5m0s for pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427" in namespace "emptydir-6955" to be "Succeeded or Failed"
Aug 24 09:20:50.073: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Pending", Reason="", readiness=false. Elapsed: 6.823089ms
Aug 24 09:20:52.084: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018185224s
Aug 24 09:20:54.081: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014528647s
STEP: Saw pod success 08/24/22 09:20:54.081
Aug 24 09:20:54.083: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427" satisfied condition "Succeeded or Failed"
Aug 24 09:20:54.091: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 container test-container: <nil>
STEP: delete the pod 08/24/22 09:20:54.113
Aug 24 09:20:54.149: INFO: Waiting for pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 to disappear
Aug 24 09:20:54.155: INFO: Pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 09:20:54.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6955" for this suite. 08/24/22 09:20:54.166
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":3,"skipped":57,"failed":0}
------------------------------
• [4.179 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:20:49.998
    Aug 24 09:20:49.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 09:20:50.005
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:50.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:50.043
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/24/22 09:20:50.048
    Aug 24 09:20:50.066: INFO: Waiting up to 5m0s for pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427" in namespace "emptydir-6955" to be "Succeeded or Failed"
    Aug 24 09:20:50.073: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Pending", Reason="", readiness=false. Elapsed: 6.823089ms
    Aug 24 09:20:52.084: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018185224s
    Aug 24 09:20:54.081: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014528647s
    STEP: Saw pod success 08/24/22 09:20:54.081
    Aug 24 09:20:54.083: INFO: Pod "pod-7abcf484-d400-4983-bd7f-b134dd83a427" satisfied condition "Succeeded or Failed"
    Aug 24 09:20:54.091: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 container test-container: <nil>
    STEP: delete the pod 08/24/22 09:20:54.113
    Aug 24 09:20:54.149: INFO: Waiting for pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 to disappear
    Aug 24 09:20:54.155: INFO: Pod pod-7abcf484-d400-4983-bd7f-b134dd83a427 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 09:20:54.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6955" for this suite. 08/24/22 09:20:54.166
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:20:54.178
Aug 24 09:20:54.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 09:20:54.185
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:54.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:54.224
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 08/24/22 09:20:54.229
STEP: Ensuring active pods == parallelism 08/24/22 09:20:54.245
STEP: delete a job 08/24/22 09:20:56.257
STEP: deleting Job.batch foo in namespace job-4006, will wait for the garbage collector to delete the pods 08/24/22 09:20:56.258
Aug 24 09:20:56.329: INFO: Deleting Job.batch foo took: 13.797617ms
Aug 24 09:20:56.430: INFO: Terminating Job.batch foo pods took: 101.266625ms
STEP: Ensuring job was deleted 08/24/22 09:21:29.331
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 09:21:29.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4006" for this suite. 08/24/22 09:21:29.361
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":4,"skipped":57,"failed":0}
------------------------------
• [SLOW TEST] [35.204 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:20:54.178
    Aug 24 09:20:54.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 09:20:54.185
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:20:54.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:20:54.224
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 08/24/22 09:20:54.229
    STEP: Ensuring active pods == parallelism 08/24/22 09:20:54.245
    STEP: delete a job 08/24/22 09:20:56.257
    STEP: deleting Job.batch foo in namespace job-4006, will wait for the garbage collector to delete the pods 08/24/22 09:20:56.258
    Aug 24 09:20:56.329: INFO: Deleting Job.batch foo took: 13.797617ms
    Aug 24 09:20:56.430: INFO: Terminating Job.batch foo pods took: 101.266625ms
    STEP: Ensuring job was deleted 08/24/22 09:21:29.331
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 09:21:29.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4006" for this suite. 08/24/22 09:21:29.361
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:21:29.383
Aug 24 09:21:29.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 09:21:29.391
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:29.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:29.444
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 08/24/22 09:21:29.485
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:21:29.504
Aug 24 09:21:29.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:29.521: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:30.540: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:30.540: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:31.536: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:31.536: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:32.540: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:32.540: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:33.537: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:33.537: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:34.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:34.539: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:35.534: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:35.534: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:36.545: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:36.545: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:37.533: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:37.533: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:38.538: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:38.538: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:39.549: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 09:21:39.549: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:40.537: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 09:21:40.537: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:21:41.535: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 09:21:41.535: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/24/22 09:21:41.542
Aug 24 09:21:41.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 09:21:41.599: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 08/24/22 09:21:41.599
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:21:41.64
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7721, will wait for the garbage collector to delete the pods 08/24/22 09:21:41.641
Aug 24 09:21:41.715: INFO: Deleting DaemonSet.extensions daemon-set took: 10.739285ms
Aug 24 09:21:41.819: INFO: Terminating DaemonSet.extensions daemon-set pods took: 104.566612ms
Aug 24 09:21:44.026: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:21:44.026: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 09:21:44.039: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3848"},"items":null}

Aug 24 09:21:44.067: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3848"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:21:44.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7721" for this suite. 08/24/22 09:21:44.116
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":5,"skipped":59,"failed":0}
------------------------------
• [SLOW TEST] [14.744 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:21:29.383
    Aug 24 09:21:29.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 09:21:29.391
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:29.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:29.444
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 08/24/22 09:21:29.485
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:21:29.504
    Aug 24 09:21:29.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:29.521: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:30.540: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:30.540: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:31.536: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:31.536: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:32.540: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:32.540: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:33.537: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:33.537: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:34.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:34.539: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:35.534: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:35.534: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:36.545: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:36.545: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:37.533: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:37.533: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:38.538: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:38.538: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:39.549: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 09:21:39.549: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:40.537: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 09:21:40.537: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:21:41.535: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 09:21:41.535: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/24/22 09:21:41.542
    Aug 24 09:21:41.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 09:21:41.599: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 08/24/22 09:21:41.599
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:21:41.64
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7721, will wait for the garbage collector to delete the pods 08/24/22 09:21:41.641
    Aug 24 09:21:41.715: INFO: Deleting DaemonSet.extensions daemon-set took: 10.739285ms
    Aug 24 09:21:41.819: INFO: Terminating DaemonSet.extensions daemon-set pods took: 104.566612ms
    Aug 24 09:21:44.026: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:21:44.026: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 09:21:44.039: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3848"},"items":null}

    Aug 24 09:21:44.067: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3848"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:21:44.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7721" for this suite. 08/24/22 09:21:44.116
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:21:44.136
Aug 24 09:21:44.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 09:21:44.138
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:44.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:44.18
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:21:44.184
Aug 24 09:21:44.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61" in namespace "downward-api-7382" to be "Succeeded or Failed"
Aug 24 09:21:44.207: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Pending", Reason="", readiness=false. Elapsed: 6.731367ms
Aug 24 09:21:46.220: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019013816s
Aug 24 09:21:48.222: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0215201s
STEP: Saw pod success 08/24/22 09:21:48.224
Aug 24 09:21:48.225: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61" satisfied condition "Succeeded or Failed"
Aug 24 09:21:48.232: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 container client-container: <nil>
STEP: delete the pod 08/24/22 09:21:48.247
Aug 24 09:21:48.270: INFO: Waiting for pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 to disappear
Aug 24 09:21:48.275: INFO: Pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 09:21:48.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7382" for this suite. 08/24/22 09:21:48.282
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":6,"skipped":92,"failed":0}
------------------------------
• [4.158 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:21:44.136
    Aug 24 09:21:44.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 09:21:44.138
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:44.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:44.18
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:21:44.184
    Aug 24 09:21:44.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61" in namespace "downward-api-7382" to be "Succeeded or Failed"
    Aug 24 09:21:44.207: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Pending", Reason="", readiness=false. Elapsed: 6.731367ms
    Aug 24 09:21:46.220: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019013816s
    Aug 24 09:21:48.222: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0215201s
    STEP: Saw pod success 08/24/22 09:21:48.224
    Aug 24 09:21:48.225: INFO: Pod "downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61" satisfied condition "Succeeded or Failed"
    Aug 24 09:21:48.232: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 container client-container: <nil>
    STEP: delete the pod 08/24/22 09:21:48.247
    Aug 24 09:21:48.270: INFO: Waiting for pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 to disappear
    Aug 24 09:21:48.275: INFO: Pod downwardapi-volume-ea920469-2541-4fcb-bc77-a659e6f77b61 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 09:21:48.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7382" for this suite. 08/24/22 09:21:48.282
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:21:48.295
Aug 24 09:21:48.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 09:21:48.299
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:48.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:48.337
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f in namespace container-probe-4422 08/24/22 09:21:48.343
Aug 24 09:21:48.369: INFO: Waiting up to 5m0s for pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f" in namespace "container-probe-4422" to be "not pending"
Aug 24 09:21:48.378: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051664ms
Aug 24 09:21:50.387: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.017800788s
Aug 24 09:21:50.388: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f" satisfied condition "not pending"
Aug 24 09:21:50.388: INFO: Started pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f in namespace container-probe-4422
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:21:50.388
Aug 24 09:21:50.395: INFO: Initial restart count of pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f is 0
STEP: deleting the pod 08/24/22 09:25:51.535
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 09:25:51.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4422" for this suite. 08/24/22 09:25:51.588
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":7,"skipped":98,"failed":0}
------------------------------
• [SLOW TEST] [243.310 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:21:48.295
    Aug 24 09:21:48.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 09:21:48.299
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:21:48.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:21:48.337
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f in namespace container-probe-4422 08/24/22 09:21:48.343
    Aug 24 09:21:48.369: INFO: Waiting up to 5m0s for pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f" in namespace "container-probe-4422" to be "not pending"
    Aug 24 09:21:48.378: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051664ms
    Aug 24 09:21:50.387: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.017800788s
    Aug 24 09:21:50.388: INFO: Pod "busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f" satisfied condition "not pending"
    Aug 24 09:21:50.388: INFO: Started pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f in namespace container-probe-4422
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:21:50.388
    Aug 24 09:21:50.395: INFO: Initial restart count of pod busybox-024f5ffa-ac49-42a2-8019-5ede24443b9f is 0
    STEP: deleting the pod 08/24/22 09:25:51.535
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 09:25:51.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4422" for this suite. 08/24/22 09:25:51.588
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:25:51.608
Aug 24 09:25:51.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 09:25:51.615
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:25:51.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:25:51.651
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 08/24/22 09:26:08.662
STEP: Creating a ResourceQuota 08/24/22 09:26:13.67
STEP: Ensuring resource quota status is calculated 08/24/22 09:26:13.681
STEP: Creating a ConfigMap 08/24/22 09:26:15.689
STEP: Ensuring resource quota status captures configMap creation 08/24/22 09:26:15.712
STEP: Deleting a ConfigMap 08/24/22 09:26:17.719
STEP: Ensuring resource quota status released usage 08/24/22 09:26:17.73
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 09:26:19.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9431" for this suite. 08/24/22 09:26:19.744
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":8,"skipped":127,"failed":0}
------------------------------
• [SLOW TEST] [28.150 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:25:51.608
    Aug 24 09:25:51.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 09:25:51.615
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:25:51.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:25:51.651
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 08/24/22 09:26:08.662
    STEP: Creating a ResourceQuota 08/24/22 09:26:13.67
    STEP: Ensuring resource quota status is calculated 08/24/22 09:26:13.681
    STEP: Creating a ConfigMap 08/24/22 09:26:15.689
    STEP: Ensuring resource quota status captures configMap creation 08/24/22 09:26:15.712
    STEP: Deleting a ConfigMap 08/24/22 09:26:17.719
    STEP: Ensuring resource quota status released usage 08/24/22 09:26:17.73
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 09:26:19.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9431" for this suite. 08/24/22 09:26:19.744
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:19.766
Aug 24 09:26:19.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:26:19.768
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:19.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:19.801
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 08/24/22 09:26:19.806
Aug 24 09:26:19.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3094 create -f -'
Aug 24 09:26:21.451: INFO: stderr: ""
Aug 24 09:26:21.451: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/24/22 09:26:21.451
Aug 24 09:26:22.460: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 09:26:22.460: INFO: Found 1 / 1
Aug 24 09:26:22.460: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 08/24/22 09:26:22.46
Aug 24 09:26:22.464: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 09:26:22.464: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 09:26:22.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3094 patch pod agnhost-primary-jmt9f -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 24 09:26:22.635: INFO: stderr: ""
Aug 24 09:26:22.635: INFO: stdout: "pod/agnhost-primary-jmt9f patched\n"
STEP: checking annotations 08/24/22 09:26:22.635
Aug 24 09:26:22.641: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 09:26:22.641: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:26:22.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3094" for this suite. 08/24/22 09:26:22.647
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":9,"skipped":143,"failed":0}
------------------------------
• [2.890 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:19.766
    Aug 24 09:26:19.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:26:19.768
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:19.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:19.801
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 08/24/22 09:26:19.806
    Aug 24 09:26:19.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3094 create -f -'
    Aug 24 09:26:21.451: INFO: stderr: ""
    Aug 24 09:26:21.451: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/24/22 09:26:21.451
    Aug 24 09:26:22.460: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 09:26:22.460: INFO: Found 1 / 1
    Aug 24 09:26:22.460: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 08/24/22 09:26:22.46
    Aug 24 09:26:22.464: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 09:26:22.464: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 24 09:26:22.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3094 patch pod agnhost-primary-jmt9f -p {"metadata":{"annotations":{"x":"y"}}}'
    Aug 24 09:26:22.635: INFO: stderr: ""
    Aug 24 09:26:22.635: INFO: stdout: "pod/agnhost-primary-jmt9f patched\n"
    STEP: checking annotations 08/24/22 09:26:22.635
    Aug 24 09:26:22.641: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 09:26:22.641: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:26:22.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3094" for this suite. 08/24/22 09:26:22.647
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:22.659
Aug 24 09:26:22.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 09:26:22.664
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.718
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 08/24/22 09:26:22.722
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/24/22 09:26:22.723
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/24/22 09:26:22.723
STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/24/22 09:26:22.723
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/24/22 09:26:22.724
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/24/22 09:26:22.724
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/24/22 09:26:22.726
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:26:22.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4247" for this suite. 08/24/22 09:26:22.731
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":10,"skipped":184,"failed":0}
------------------------------
• [0.082 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:22.659
    Aug 24 09:26:22.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 09:26:22.664
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.718
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 08/24/22 09:26:22.722
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/24/22 09:26:22.723
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/24/22 09:26:22.723
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/24/22 09:26:22.723
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/24/22 09:26:22.724
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/24/22 09:26:22.724
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/24/22 09:26:22.726
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:26:22.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4247" for this suite. 08/24/22 09:26:22.731
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:22.742
Aug 24 09:26:22.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename podtemplate 08/24/22 09:26:22.744
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.78
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 24 09:26:22.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-660" for this suite. 08/24/22 09:26:22.835
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":11,"skipped":190,"failed":0}
------------------------------
• [0.103 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:22.742
    Aug 24 09:26:22.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename podtemplate 08/24/22 09:26:22.744
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.78
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 24 09:26:22.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-660" for this suite. 08/24/22 09:26:22.835
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:22.85
Aug 24 09:26:22.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 09:26:22.852
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.883
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-c052db07-b706-4066-849e-b1d76b0c89cf 08/24/22 09:26:22.897
STEP: Creating the pod 08/24/22 09:26:22.905
Aug 24 09:26:22.929: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade" in namespace "configmap-2769" to be "running"
Aug 24 09:26:22.936: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade": Phase="Pending", Reason="", readiness=false. Elapsed: 6.377059ms
Aug 24 09:26:24.946: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade": Phase="Running", Reason="", readiness=false. Elapsed: 2.016669428s
Aug 24 09:26:24.947: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade" satisfied condition "running"
STEP: Waiting for pod with text data 08/24/22 09:26:24.947
STEP: Waiting for pod with binary data 08/24/22 09:26:24.98
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 09:26:24.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2769" for this suite. 08/24/22 09:26:24.998
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":12,"skipped":201,"failed":0}
------------------------------
• [2.163 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:22.85
    Aug 24 09:26:22.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 09:26:22.852
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:22.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:22.883
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-c052db07-b706-4066-849e-b1d76b0c89cf 08/24/22 09:26:22.897
    STEP: Creating the pod 08/24/22 09:26:22.905
    Aug 24 09:26:22.929: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade" in namespace "configmap-2769" to be "running"
    Aug 24 09:26:22.936: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade": Phase="Pending", Reason="", readiness=false. Elapsed: 6.377059ms
    Aug 24 09:26:24.946: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade": Phase="Running", Reason="", readiness=false. Elapsed: 2.016669428s
    Aug 24 09:26:24.947: INFO: Pod "pod-configmaps-5c41d92f-49bc-4e1c-9df0-835d2a946ade" satisfied condition "running"
    STEP: Waiting for pod with text data 08/24/22 09:26:24.947
    STEP: Waiting for pod with binary data 08/24/22 09:26:24.98
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 09:26:24.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2769" for this suite. 08/24/22 09:26:24.998
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:25.017
Aug 24 09:26:25.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 09:26:25.021
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:25.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:25.063
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7358 08/24/22 09:26:25.068
STEP: changing the ExternalName service to type=ClusterIP 08/24/22 09:26:25.077
STEP: creating replication controller externalname-service in namespace services-7358 08/24/22 09:26:25.101
I0824 09:26:25.117374      14 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7358, replica count: 2
I0824 09:26:28.169048      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:26:31.169894      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:26:34.170725      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 09:26:34.170: INFO: Creating new exec pod
Aug 24 09:26:34.184: INFO: Waiting up to 5m0s for pod "execpodwhxrg" in namespace "services-7358" to be "running"
Aug 24 09:26:34.189: INFO: Pod "execpodwhxrg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.833477ms
Aug 24 09:26:36.194: INFO: Pod "execpodwhxrg": Phase="Running", Reason="", readiness=true. Elapsed: 2.010556504s
Aug 24 09:26:36.195: INFO: Pod "execpodwhxrg" satisfied condition "running"
Aug 24 09:26:37.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 09:26:37.465: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 09:26:37.465: INFO: stdout: ""
Aug 24 09:26:38.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 09:26:38.701: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 09:26:38.701: INFO: stdout: "externalname-service-jk86f"
Aug 24 09:26:38.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.60.242 80'
Aug 24 09:26:38.954: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.60.242 80\nConnection to 10.233.60.242 80 port [tcp/http] succeeded!\n"
Aug 24 09:26:38.954: INFO: stdout: "externalname-service-jk86f"
Aug 24 09:26:38.954: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 09:26:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7358" for this suite. 08/24/22 09:26:38.997
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":13,"skipped":212,"failed":0}
------------------------------
• [SLOW TEST] [13.992 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:25.017
    Aug 24 09:26:25.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 09:26:25.021
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:25.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:25.063
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-7358 08/24/22 09:26:25.068
    STEP: changing the ExternalName service to type=ClusterIP 08/24/22 09:26:25.077
    STEP: creating replication controller externalname-service in namespace services-7358 08/24/22 09:26:25.101
    I0824 09:26:25.117374      14 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7358, replica count: 2
    I0824 09:26:28.169048      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:26:31.169894      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:26:34.170725      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 09:26:34.170: INFO: Creating new exec pod
    Aug 24 09:26:34.184: INFO: Waiting up to 5m0s for pod "execpodwhxrg" in namespace "services-7358" to be "running"
    Aug 24 09:26:34.189: INFO: Pod "execpodwhxrg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.833477ms
    Aug 24 09:26:36.194: INFO: Pod "execpodwhxrg": Phase="Running", Reason="", readiness=true. Elapsed: 2.010556504s
    Aug 24 09:26:36.195: INFO: Pod "execpodwhxrg" satisfied condition "running"
    Aug 24 09:26:37.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 24 09:26:37.465: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 24 09:26:37.465: INFO: stdout: ""
    Aug 24 09:26:38.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 24 09:26:38.701: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 24 09:26:38.701: INFO: stdout: "externalname-service-jk86f"
    Aug 24 09:26:38.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7358 exec execpodwhxrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.60.242 80'
    Aug 24 09:26:38.954: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.60.242 80\nConnection to 10.233.60.242 80 port [tcp/http] succeeded!\n"
    Aug 24 09:26:38.954: INFO: stdout: "externalname-service-jk86f"
    Aug 24 09:26:38.954: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 09:26:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7358" for this suite. 08/24/22 09:26:38.997
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:39.019
Aug 24 09:26:39.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:26:39.023
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:39.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:39.067
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 08/24/22 09:26:39.071
Aug 24 09:26:39.073: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-23 proxy --unix-socket=/tmp/kubectl-proxy-unix3134568763/test'
STEP: retrieving proxy /api/ output 08/24/22 09:26:39.171
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:26:39.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-23" for this suite. 08/24/22 09:26:39.182
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":14,"skipped":218,"failed":0}
------------------------------
• [0.181 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:39.019
    Aug 24 09:26:39.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:26:39.023
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:39.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:39.067
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 08/24/22 09:26:39.071
    Aug 24 09:26:39.073: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-23 proxy --unix-socket=/tmp/kubectl-proxy-unix3134568763/test'
    STEP: retrieving proxy /api/ output 08/24/22 09:26:39.171
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:26:39.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-23" for this suite. 08/24/22 09:26:39.182
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:26:39.223
Aug 24 09:26:39.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename cronjob 08/24/22 09:26:39.227
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:39.251
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:39.255
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 08/24/22 09:26:39.259
STEP: Ensuring a job is scheduled 08/24/22 09:26:39.271
STEP: Ensuring exactly one is scheduled 08/24/22 09:27:01.283
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/24/22 09:27:01.288
STEP: Ensuring no more jobs are scheduled 08/24/22 09:27:01.294
STEP: Removing cronjob 08/24/22 09:32:01.309
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 24 09:32:01.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9524" for this suite. 08/24/22 09:32:01.327
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":15,"skipped":253,"failed":0}
------------------------------
• [SLOW TEST] [322.116 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:26:39.223
    Aug 24 09:26:39.224: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename cronjob 08/24/22 09:26:39.227
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:26:39.251
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:26:39.255
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 08/24/22 09:26:39.259
    STEP: Ensuring a job is scheduled 08/24/22 09:26:39.271
    STEP: Ensuring exactly one is scheduled 08/24/22 09:27:01.283
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/24/22 09:27:01.288
    STEP: Ensuring no more jobs are scheduled 08/24/22 09:27:01.294
    STEP: Removing cronjob 08/24/22 09:32:01.309
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 24 09:32:01.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9524" for this suite. 08/24/22 09:32:01.327
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:01.353
Aug 24 09:32:01.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 09:32:01.356
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.39
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 08/24/22 09:32:01.395
Aug 24 09:32:01.396: INFO: Creating e2e-svc-a-cq4bj
Aug 24 09:32:01.423: INFO: Creating e2e-svc-b-z8w4l
Aug 24 09:32:01.442: INFO: Creating e2e-svc-c-xn6h5
STEP: deleting service collection 08/24/22 09:32:01.47
Aug 24 09:32:01.535: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 09:32:01.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2368" for this suite. 08/24/22 09:32:01.552
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":16,"skipped":264,"failed":0}
------------------------------
• [0.214 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:01.353
    Aug 24 09:32:01.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 09:32:01.356
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.39
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 08/24/22 09:32:01.395
    Aug 24 09:32:01.396: INFO: Creating e2e-svc-a-cq4bj
    Aug 24 09:32:01.423: INFO: Creating e2e-svc-b-z8w4l
    Aug 24 09:32:01.442: INFO: Creating e2e-svc-c-xn6h5
    STEP: deleting service collection 08/24/22 09:32:01.47
    Aug 24 09:32:01.535: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 09:32:01.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2368" for this suite. 08/24/22 09:32:01.552
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:01.571
Aug 24 09:32:01.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 09:32:01.575
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.62
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 09:32:01.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6732" for this suite. 08/24/22 09:32:01.739
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":17,"skipped":291,"failed":0}
------------------------------
• [0.182 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:01.571
    Aug 24 09:32:01.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 09:32:01.575
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.62
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 09:32:01.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6732" for this suite. 08/24/22 09:32:01.739
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:01.755
Aug 24 09:32:01.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replication-controller 08/24/22 09:32:01.759
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.799
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 08/24/22 09:32:01.81
STEP: waiting for RC to be added 08/24/22 09:32:01.828
STEP: waiting for available Replicas 08/24/22 09:32:01.829
STEP: patching ReplicationController 08/24/22 09:32:07.453
STEP: waiting for RC to be modified 08/24/22 09:32:07.469
STEP: patching ReplicationController status 08/24/22 09:32:07.47
STEP: waiting for RC to be modified 08/24/22 09:32:07.481
STEP: waiting for available Replicas 08/24/22 09:32:07.482
STEP: fetching ReplicationController status 08/24/22 09:32:07.492
STEP: patching ReplicationController scale 08/24/22 09:32:07.498
STEP: waiting for RC to be modified 08/24/22 09:32:07.509
STEP: waiting for ReplicationController's scale to be the max amount 08/24/22 09:32:07.509
STEP: fetching ReplicationController; ensuring that it's patched 08/24/22 09:32:12.833
STEP: updating ReplicationController status 08/24/22 09:32:12.844
STEP: waiting for RC to be modified 08/24/22 09:32:12.857
STEP: listing all ReplicationControllers 08/24/22 09:32:12.858
STEP: checking that ReplicationController has expected values 08/24/22 09:32:12.865
STEP: deleting ReplicationControllers by collection 08/24/22 09:32:12.865
STEP: waiting for ReplicationController to have a DELETED watchEvent 08/24/22 09:32:12.886
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 24 09:32:12.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-518" for this suite. 08/24/22 09:32:12.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":18,"skipped":300,"failed":0}
------------------------------
• [SLOW TEST] [11.225 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:01.755
    Aug 24 09:32:01.756: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replication-controller 08/24/22 09:32:01.759
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:01.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:01.799
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 08/24/22 09:32:01.81
    STEP: waiting for RC to be added 08/24/22 09:32:01.828
    STEP: waiting for available Replicas 08/24/22 09:32:01.829
    STEP: patching ReplicationController 08/24/22 09:32:07.453
    STEP: waiting for RC to be modified 08/24/22 09:32:07.469
    STEP: patching ReplicationController status 08/24/22 09:32:07.47
    STEP: waiting for RC to be modified 08/24/22 09:32:07.481
    STEP: waiting for available Replicas 08/24/22 09:32:07.482
    STEP: fetching ReplicationController status 08/24/22 09:32:07.492
    STEP: patching ReplicationController scale 08/24/22 09:32:07.498
    STEP: waiting for RC to be modified 08/24/22 09:32:07.509
    STEP: waiting for ReplicationController's scale to be the max amount 08/24/22 09:32:07.509
    STEP: fetching ReplicationController; ensuring that it's patched 08/24/22 09:32:12.833
    STEP: updating ReplicationController status 08/24/22 09:32:12.844
    STEP: waiting for RC to be modified 08/24/22 09:32:12.857
    STEP: listing all ReplicationControllers 08/24/22 09:32:12.858
    STEP: checking that ReplicationController has expected values 08/24/22 09:32:12.865
    STEP: deleting ReplicationControllers by collection 08/24/22 09:32:12.865
    STEP: waiting for ReplicationController to have a DELETED watchEvent 08/24/22 09:32:12.886
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 24 09:32:12.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-518" for this suite. 08/24/22 09:32:12.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:12.982
Aug 24 09:32:12.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-pred 08/24/22 09:32:12.988
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:13.013
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:13.018
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 24 09:32:13.023: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 09:32:13.039: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 09:32:13.045: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
Aug 24 09:32:13.078: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.078: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:13.078: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.078: INFO: 	Container coredns ready: true, restart count 1
Aug 24 09:32:13.078: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.079: INFO: 	Container coredns ready: true, restart count 1
Aug 24 09:32:13.079: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.079: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 09:32:13.079: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.079: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 09:32:13.079: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.079: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 09:32:13.080: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.080: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:13.080: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.080: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 09:32:13.080: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:13.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:13.081: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 09:32:13.081: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
Aug 24 09:32:13.099: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:13.099: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 09:32:13.099: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 09:32:13.099: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 09:32:13.099: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:13.099: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 09:32:13.099: INFO: rc-test-f6mmn from replication-controller-518 started at 2022-08-24 09:32:07 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container rc-test ready: true, restart count 0
Aug 24 09:32:13.099: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:13.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:13.099: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 09:32:13.099: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
Aug 24 09:32:13.110: INFO: kube-flannel-ds-q5hr7 from kube-flannel started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:13.110: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:13.110: INFO: rc-test-m72dv from replication-controller-518 started at 2022-08-24 09:32:01 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container rc-test ready: true, restart count 0
Aug 24 09:32:13.110: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 09:32:13.110: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container e2e ready: true, restart count 0
Aug 24 09:32:13.110: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:13.110: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:13.110: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:13.110: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 08/24/22 09:32:13.111
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.170e3e0bd90bd8a0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 08/24/22 09:32:13.161
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:32:14.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2929" for this suite. 08/24/22 09:32:14.174
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":19,"skipped":304,"failed":0}
------------------------------
• [1.206 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:12.982
    Aug 24 09:32:12.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-pred 08/24/22 09:32:12.988
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:13.013
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:13.018
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 24 09:32:13.023: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 24 09:32:13.039: INFO: Waiting for terminating namespaces to be deleted...
    Aug 24 09:32:13.045: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
    Aug 24 09:32:13.078: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.078: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:13.078: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.078: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 09:32:13.078: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.079: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 09:32:13.079: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.079: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 09:32:13.079: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.079: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 09:32:13.079: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.079: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 09:32:13.080: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.080: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:13.080: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.080: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 09:32:13.080: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:13.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:13.081: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 09:32:13.081: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
    Aug 24 09:32:13.099: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 09:32:13.099: INFO: rc-test-f6mmn from replication-controller-518 started at 2022-08-24 09:32:07 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container rc-test ready: true, restart count 0
    Aug 24 09:32:13.099: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:13.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:13.099: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 09:32:13.099: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
    Aug 24 09:32:13.110: INFO: kube-flannel-ds-q5hr7 from kube-flannel started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:13.110: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:13.110: INFO: rc-test-m72dv from replication-controller-518 started at 2022-08-24 09:32:01 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container rc-test ready: true, restart count 0
    Aug 24 09:32:13.110: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 24 09:32:13.110: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container e2e ready: true, restart count 0
    Aug 24 09:32:13.110: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:13.110: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:13.110: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:13.110: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 08/24/22 09:32:13.111
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.170e3e0bd90bd8a0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 08/24/22 09:32:13.161
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:32:14.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2929" for this suite. 08/24/22 09:32:14.174
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:14.198
Aug 24 09:32:14.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-pred 08/24/22 09:32:14.201
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:14.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:14.234
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 24 09:32:14.240: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 09:32:14.255: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 09:32:14.260: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
Aug 24 09:32:14.274: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.275: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:14.275: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.275: INFO: 	Container coredns ready: true, restart count 1
Aug 24 09:32:14.275: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.275: INFO: 	Container coredns ready: true, restart count 1
Aug 24 09:32:14.275: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.275: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 09:32:14.275: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.275: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 09:32:14.275: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.276: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 09:32:14.276: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.276: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:14.276: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.276: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 09:32:14.276: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:14.276: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:14.276: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 09:32:14.276: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
Aug 24 09:32:14.290: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:14.290: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 09:32:14.290: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 09:32:14.290: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 09:32:14.290: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:14.290: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 09:32:14.290: INFO: rc-test-f6mmn from replication-controller-518 started at 2022-08-24 09:32:07 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container rc-test ready: true, restart count 0
Aug 24 09:32:14.290: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:14.290: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:14.290: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 09:32:14.290: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
Aug 24 09:32:14.302: INFO: kube-flannel-ds-q5hr7 from kube-flannel started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 09:32:14.302: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 09:32:14.302: INFO: rc-test-m72dv from replication-controller-518 started at 2022-08-24 09:32:01 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container rc-test ready: true, restart count 0
Aug 24 09:32:14.302: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 09:32:14.302: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container e2e ready: true, restart count 0
Aug 24 09:32:14.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:14.302: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 09:32:14.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 09:32:14.302: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node kah9uighaagh-1 08/24/22 09:32:20.427
STEP: verifying the node has the label node kah9uighaagh-2 08/24/22 09:32:20.466
STEP: verifying the node has the label node kah9uighaagh-3 08/24/22 09:32:20.515
Aug 24 09:32:20.536: INFO: Pod kube-flannel-ds-q5hr7 requesting resource cpu=100m on Node kah9uighaagh-3
Aug 24 09:32:20.537: INFO: Pod kube-flannel-ds-v9ltq requesting resource cpu=100m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-flannel-ds-xn6l2 requesting resource cpu=100m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod coredns-565d847f94-l25vk requesting resource cpu=100m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod coredns-565d847f94-l5p5g requesting resource cpu=100m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-addon-manager-kah9uighaagh-1 requesting resource cpu=5m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-addon-manager-kah9uighaagh-2 requesting resource cpu=5m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod kube-apiserver-kah9uighaagh-1 requesting resource cpu=250m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-apiserver-kah9uighaagh-2 requesting resource cpu=250m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod kube-controller-manager-kah9uighaagh-1 requesting resource cpu=200m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-controller-manager-kah9uighaagh-2 requesting resource cpu=200m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod kube-proxy-thfcl requesting resource cpu=0m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-proxy-v9kb2 requesting resource cpu=0m on Node kah9uighaagh-3
Aug 24 09:32:20.537: INFO: Pod kube-proxy-w2mv4 requesting resource cpu=0m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod kube-scheduler-kah9uighaagh-1 requesting resource cpu=100m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod kube-scheduler-kah9uighaagh-2 requesting resource cpu=100m on Node kah9uighaagh-2
Aug 24 09:32:20.537: INFO: Pod sonobuoy requesting resource cpu=0m on Node kah9uighaagh-3
Aug 24 09:32:20.537: INFO: Pod sonobuoy-e2e-job-3c870a7ae8ea444b requesting resource cpu=0m on Node kah9uighaagh-3
Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 requesting resource cpu=0m on Node kah9uighaagh-1
Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 requesting resource cpu=0m on Node kah9uighaagh-3
Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 requesting resource cpu=0m on Node kah9uighaagh-2
STEP: Starting Pods to consume most of the cluster CPU. 08/24/22 09:32:20.537
Aug 24 09:32:20.537: INFO: Creating a pod which consumes cpu=521m on Node kah9uighaagh-1
Aug 24 09:32:20.557: INFO: Creating a pod which consumes cpu=661m on Node kah9uighaagh-2
Aug 24 09:32:20.570: INFO: Creating a pod which consumes cpu=1050m on Node kah9uighaagh-3
Aug 24 09:32:20.580: INFO: Waiting up to 5m0s for pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be" in namespace "sched-pred-4755" to be "running"
Aug 24 09:32:20.586: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Pending", Reason="", readiness=false. Elapsed: 5.896389ms
Aug 24 09:32:22.593: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013641621s
Aug 24 09:32:24.595: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Running", Reason="", readiness=true. Elapsed: 4.015462128s
Aug 24 09:32:24.595: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be" satisfied condition "running"
Aug 24 09:32:24.595: INFO: Waiting up to 5m0s for pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6" in namespace "sched-pred-4755" to be "running"
Aug 24 09:32:24.601: INFO: Pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6": Phase="Running", Reason="", readiness=true. Elapsed: 5.590778ms
Aug 24 09:32:24.601: INFO: Pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6" satisfied condition "running"
Aug 24 09:32:24.601: INFO: Waiting up to 5m0s for pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9" in namespace "sched-pred-4755" to be "running"
Aug 24 09:32:24.607: INFO: Pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9": Phase="Running", Reason="", readiness=true. Elapsed: 6.020389ms
Aug 24 09:32:24.607: INFO: Pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 08/24/22 09:32:24.608
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0d9735158e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be to kah9uighaagh-1] 08/24/22 09:32:24.616
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0de883ebb9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.616
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0df22d1458], Reason = [Created], Message = [Created container filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be] 08/24/22 09:32:24.616
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0df427e3f5], Reason = [Started], Message = [Started container filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0d97c2e081], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9 to kah9uighaagh-3] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0db69fcc88], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0dbeec8474], Reason = [Created], Message = [Created container filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0dc029b669], Reason = [Started], Message = [Started container filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0d973f97bf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6 to kah9uighaagh-2] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0db30cfbee], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.617
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0dbb968a4f], Reason = [Created], Message = [Created container filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6] 08/24/22 09:32:24.618
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0dbd767bef], Reason = [Started], Message = [Started container filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6] 08/24/22 09:32:24.618
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.170e3e0e8529d2a1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 08/24/22 09:32:24.643
STEP: removing the label node off the node kah9uighaagh-1 08/24/22 09:32:25.644
STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.667
STEP: removing the label node off the node kah9uighaagh-2 08/24/22 09:32:25.674
STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.706
STEP: removing the label node off the node kah9uighaagh-3 08/24/22 09:32:25.718
STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.745
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:32:25.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4755" for this suite. 08/24/22 09:32:25.765
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":20,"skipped":343,"failed":0}
------------------------------
• [SLOW TEST] [11.580 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:14.198
    Aug 24 09:32:14.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-pred 08/24/22 09:32:14.201
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:14.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:14.234
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 24 09:32:14.240: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 24 09:32:14.255: INFO: Waiting for terminating namespaces to be deleted...
    Aug 24 09:32:14.260: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
    Aug 24 09:32:14.274: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.275: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:14.275: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.275: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 09:32:14.275: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.275: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 09:32:14.275: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.275: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 09:32:14.275: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.275: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 09:32:14.275: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.276: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 09:32:14.276: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.276: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:14.276: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.276: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 09:32:14.276: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:14.276: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:14.276: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 09:32:14.276: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
    Aug 24 09:32:14.290: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 09:32:14.290: INFO: rc-test-f6mmn from replication-controller-518 started at 2022-08-24 09:32:07 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container rc-test ready: true, restart count 0
    Aug 24 09:32:14.290: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:14.290: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:14.290: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 09:32:14.290: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
    Aug 24 09:32:14.302: INFO: kube-flannel-ds-q5hr7 from kube-flannel started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 09:32:14.302: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 09:32:14.302: INFO: rc-test-m72dv from replication-controller-518 started at 2022-08-24 09:32:01 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container rc-test ready: true, restart count 0
    Aug 24 09:32:14.302: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 24 09:32:14.302: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container e2e ready: true, restart count 0
    Aug 24 09:32:14.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:14.302: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 09:32:14.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 09:32:14.302: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node kah9uighaagh-1 08/24/22 09:32:20.427
    STEP: verifying the node has the label node kah9uighaagh-2 08/24/22 09:32:20.466
    STEP: verifying the node has the label node kah9uighaagh-3 08/24/22 09:32:20.515
    Aug 24 09:32:20.536: INFO: Pod kube-flannel-ds-q5hr7 requesting resource cpu=100m on Node kah9uighaagh-3
    Aug 24 09:32:20.537: INFO: Pod kube-flannel-ds-v9ltq requesting resource cpu=100m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-flannel-ds-xn6l2 requesting resource cpu=100m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod coredns-565d847f94-l25vk requesting resource cpu=100m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod coredns-565d847f94-l5p5g requesting resource cpu=100m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-addon-manager-kah9uighaagh-1 requesting resource cpu=5m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-addon-manager-kah9uighaagh-2 requesting resource cpu=5m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod kube-apiserver-kah9uighaagh-1 requesting resource cpu=250m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-apiserver-kah9uighaagh-2 requesting resource cpu=250m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod kube-controller-manager-kah9uighaagh-1 requesting resource cpu=200m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-controller-manager-kah9uighaagh-2 requesting resource cpu=200m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod kube-proxy-thfcl requesting resource cpu=0m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-proxy-v9kb2 requesting resource cpu=0m on Node kah9uighaagh-3
    Aug 24 09:32:20.537: INFO: Pod kube-proxy-w2mv4 requesting resource cpu=0m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod kube-scheduler-kah9uighaagh-1 requesting resource cpu=100m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod kube-scheduler-kah9uighaagh-2 requesting resource cpu=100m on Node kah9uighaagh-2
    Aug 24 09:32:20.537: INFO: Pod sonobuoy requesting resource cpu=0m on Node kah9uighaagh-3
    Aug 24 09:32:20.537: INFO: Pod sonobuoy-e2e-job-3c870a7ae8ea444b requesting resource cpu=0m on Node kah9uighaagh-3
    Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 requesting resource cpu=0m on Node kah9uighaagh-1
    Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 requesting resource cpu=0m on Node kah9uighaagh-3
    Aug 24 09:32:20.537: INFO: Pod sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 requesting resource cpu=0m on Node kah9uighaagh-2
    STEP: Starting Pods to consume most of the cluster CPU. 08/24/22 09:32:20.537
    Aug 24 09:32:20.537: INFO: Creating a pod which consumes cpu=521m on Node kah9uighaagh-1
    Aug 24 09:32:20.557: INFO: Creating a pod which consumes cpu=661m on Node kah9uighaagh-2
    Aug 24 09:32:20.570: INFO: Creating a pod which consumes cpu=1050m on Node kah9uighaagh-3
    Aug 24 09:32:20.580: INFO: Waiting up to 5m0s for pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be" in namespace "sched-pred-4755" to be "running"
    Aug 24 09:32:20.586: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Pending", Reason="", readiness=false. Elapsed: 5.896389ms
    Aug 24 09:32:22.593: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013641621s
    Aug 24 09:32:24.595: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be": Phase="Running", Reason="", readiness=true. Elapsed: 4.015462128s
    Aug 24 09:32:24.595: INFO: Pod "filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be" satisfied condition "running"
    Aug 24 09:32:24.595: INFO: Waiting up to 5m0s for pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6" in namespace "sched-pred-4755" to be "running"
    Aug 24 09:32:24.601: INFO: Pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6": Phase="Running", Reason="", readiness=true. Elapsed: 5.590778ms
    Aug 24 09:32:24.601: INFO: Pod "filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6" satisfied condition "running"
    Aug 24 09:32:24.601: INFO: Waiting up to 5m0s for pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9" in namespace "sched-pred-4755" to be "running"
    Aug 24 09:32:24.607: INFO: Pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9": Phase="Running", Reason="", readiness=true. Elapsed: 6.020389ms
    Aug 24 09:32:24.607: INFO: Pod "filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 08/24/22 09:32:24.608
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0d9735158e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be to kah9uighaagh-1] 08/24/22 09:32:24.616
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0de883ebb9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.616
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0df22d1458], Reason = [Created], Message = [Created container filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be] 08/24/22 09:32:24.616
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be.170e3e0df427e3f5], Reason = [Started], Message = [Started container filler-pod-1ad8bb3d-8633-44d0-8204-99652cdf58be] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0d97c2e081], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9 to kah9uighaagh-3] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0db69fcc88], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0dbeec8474], Reason = [Created], Message = [Created container filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9.170e3e0dc029b669], Reason = [Started], Message = [Started container filler-pod-1e4a06d6-8190-4757-82c4-604a0bd06ad9] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0d973f97bf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4755/filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6 to kah9uighaagh-2] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0db30cfbee], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/24/22 09:32:24.617
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0dbb968a4f], Reason = [Created], Message = [Created container filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6] 08/24/22 09:32:24.618
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6.170e3e0dbd767bef], Reason = [Started], Message = [Started container filler-pod-ba2226db-c8ae-4fd2-abab-54eabb30f6b6] 08/24/22 09:32:24.618
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.170e3e0e8529d2a1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 08/24/22 09:32:24.643
    STEP: removing the label node off the node kah9uighaagh-1 08/24/22 09:32:25.644
    STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.667
    STEP: removing the label node off the node kah9uighaagh-2 08/24/22 09:32:25.674
    STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.706
    STEP: removing the label node off the node kah9uighaagh-3 08/24/22 09:32:25.718
    STEP: verifying the node doesn't have the label node 08/24/22 09:32:25.745
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:32:25.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4755" for this suite. 08/24/22 09:32:25.765
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:25.779
Aug 24 09:32:25.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 09:32:25.781
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:25.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:25.824
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-72939405-2779-4661-9ce3-a4f4443cd01b 08/24/22 09:32:25.829
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 09:32:25.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2926" for this suite. 08/24/22 09:32:25.842
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":21,"skipped":344,"failed":0}
------------------------------
• [0.077 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:25.779
    Aug 24 09:32:25.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 09:32:25.781
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:25.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:25.824
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-72939405-2779-4661-9ce3-a4f4443cd01b 08/24/22 09:32:25.829
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 09:32:25.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2926" for this suite. 08/24/22 09:32:25.842
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:25.857
Aug 24 09:32:25.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 09:32:25.861
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:25.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:25.893
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 08/24/22 09:32:25.906
STEP: create the rc2 08/24/22 09:32:25.918
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/24/22 09:32:30.944
STEP: delete the rc simpletest-rc-to-be-deleted 08/24/22 09:32:33.21
STEP: wait for the rc to be deleted 08/24/22 09:32:33.362
Aug 24 09:32:38.406: INFO: 64 pods remaining
Aug 24 09:32:38.406: INFO: 64 pods has nil DeletionTimestamp
Aug 24 09:32:38.406: INFO: 
STEP: Gathering metrics 08/24/22 09:32:43.421
Aug 24 09:32:43.836: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 09:32:43.845: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.611047ms
Aug 24 09:32:43.846: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 09:32:43.846: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 09:32:44.304: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 24 09:32:44.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jfkk" in namespace "gc-2550"
Aug 24 09:32:44.329: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lcqn" in namespace "gc-2550"
Aug 24 09:32:44.369: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ppzz" in namespace "gc-2550"
Aug 24 09:32:44.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-2rtmf" in namespace "gc-2550"
Aug 24 09:32:44.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zg2h" in namespace "gc-2550"
Aug 24 09:32:44.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-4h9t6" in namespace "gc-2550"
Aug 24 09:32:44.546: INFO: Deleting pod "simpletest-rc-to-be-deleted-4lcph" in namespace "gc-2550"
Aug 24 09:32:44.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fbtq" in namespace "gc-2550"
Aug 24 09:32:44.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-5g72s" in namespace "gc-2550"
Aug 24 09:32:44.754: INFO: Deleting pod "simpletest-rc-to-be-deleted-65cqr" in namespace "gc-2550"
Aug 24 09:32:44.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-67vfl" in namespace "gc-2550"
Aug 24 09:32:44.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-6frnx" in namespace "gc-2550"
Aug 24 09:32:44.879: INFO: Deleting pod "simpletest-rc-to-be-deleted-6z2gg" in namespace "gc-2550"
Aug 24 09:32:44.914: INFO: Deleting pod "simpletest-rc-to-be-deleted-79zcb" in namespace "gc-2550"
Aug 24 09:32:44.951: INFO: Deleting pod "simpletest-rc-to-be-deleted-7gdr4" in namespace "gc-2550"
Aug 24 09:32:44.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-7k6qt" in namespace "gc-2550"
Aug 24 09:32:45.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-7t5nd" in namespace "gc-2550"
Aug 24 09:32:45.125: INFO: Deleting pod "simpletest-rc-to-be-deleted-8d4xc" in namespace "gc-2550"
Aug 24 09:32:45.206: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dmcr" in namespace "gc-2550"
Aug 24 09:32:45.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jtwm" in namespace "gc-2550"
Aug 24 09:32:45.344: INFO: Deleting pod "simpletest-rc-to-be-deleted-8v55n" in namespace "gc-2550"
Aug 24 09:32:45.410: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dpcm" in namespace "gc-2550"
Aug 24 09:32:45.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dvxb" in namespace "gc-2550"
Aug 24 09:32:45.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-9h4l7" in namespace "gc-2550"
Aug 24 09:32:45.739: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xcrl" in namespace "gc-2550"
Aug 24 09:32:45.810: INFO: Deleting pod "simpletest-rc-to-be-deleted-b5pvk" in namespace "gc-2550"
Aug 24 09:32:45.905: INFO: Deleting pod "simpletest-rc-to-be-deleted-bdklx" in namespace "gc-2550"
Aug 24 09:32:45.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-bq6sf" in namespace "gc-2550"
Aug 24 09:32:45.968: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwhb5" in namespace "gc-2550"
Aug 24 09:32:46.001: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8frb" in namespace "gc-2550"
Aug 24 09:32:46.040: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmw78" in namespace "gc-2550"
Aug 24 09:32:46.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4bhk" in namespace "gc-2550"
Aug 24 09:32:46.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-d66lf" in namespace "gc-2550"
Aug 24 09:32:46.146: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk6bc" in namespace "gc-2550"
Aug 24 09:32:46.185: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkflw" in namespace "gc-2550"
Aug 24 09:32:46.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnkgs" in namespace "gc-2550"
Aug 24 09:32:46.325: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx58q" in namespace "gc-2550"
Aug 24 09:32:46.355: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxcvs" in namespace "gc-2550"
Aug 24 09:32:46.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj7t8" in namespace "gc-2550"
Aug 24 09:32:46.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-fn928" in namespace "gc-2550"
Aug 24 09:32:46.470: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpvz9" in namespace "gc-2550"
Aug 24 09:32:46.536: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxqc5" in namespace "gc-2550"
Aug 24 09:32:46.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-g4kkh" in namespace "gc-2550"
Aug 24 09:32:46.627: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwl7d" in namespace "gc-2550"
Aug 24 09:32:46.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-hdgcx" in namespace "gc-2550"
Aug 24 09:32:46.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-htsb9" in namespace "gc-2550"
Aug 24 09:32:46.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-hw875" in namespace "gc-2550"
Aug 24 09:32:46.909: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4cqw" in namespace "gc-2550"
Aug 24 09:32:46.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-jhj2p" in namespace "gc-2550"
Aug 24 09:32:46.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-jv74w" in namespace "gc-2550"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 09:32:47.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2550" for this suite. 08/24/22 09:32:47.033
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":22,"skipped":346,"failed":0}
------------------------------
• [SLOW TEST] [21.220 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:25.857
    Aug 24 09:32:25.857: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 09:32:25.861
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:25.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:25.893
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 08/24/22 09:32:25.906
    STEP: create the rc2 08/24/22 09:32:25.918
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/24/22 09:32:30.944
    STEP: delete the rc simpletest-rc-to-be-deleted 08/24/22 09:32:33.21
    STEP: wait for the rc to be deleted 08/24/22 09:32:33.362
    Aug 24 09:32:38.406: INFO: 64 pods remaining
    Aug 24 09:32:38.406: INFO: 64 pods has nil DeletionTimestamp
    Aug 24 09:32:38.406: INFO: 
    STEP: Gathering metrics 08/24/22 09:32:43.421
    Aug 24 09:32:43.836: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 09:32:43.845: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.611047ms
    Aug 24 09:32:43.846: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 09:32:43.846: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 09:32:44.304: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 24 09:32:44.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jfkk" in namespace "gc-2550"
    Aug 24 09:32:44.329: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lcqn" in namespace "gc-2550"
    Aug 24 09:32:44.369: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ppzz" in namespace "gc-2550"
    Aug 24 09:32:44.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-2rtmf" in namespace "gc-2550"
    Aug 24 09:32:44.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zg2h" in namespace "gc-2550"
    Aug 24 09:32:44.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-4h9t6" in namespace "gc-2550"
    Aug 24 09:32:44.546: INFO: Deleting pod "simpletest-rc-to-be-deleted-4lcph" in namespace "gc-2550"
    Aug 24 09:32:44.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fbtq" in namespace "gc-2550"
    Aug 24 09:32:44.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-5g72s" in namespace "gc-2550"
    Aug 24 09:32:44.754: INFO: Deleting pod "simpletest-rc-to-be-deleted-65cqr" in namespace "gc-2550"
    Aug 24 09:32:44.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-67vfl" in namespace "gc-2550"
    Aug 24 09:32:44.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-6frnx" in namespace "gc-2550"
    Aug 24 09:32:44.879: INFO: Deleting pod "simpletest-rc-to-be-deleted-6z2gg" in namespace "gc-2550"
    Aug 24 09:32:44.914: INFO: Deleting pod "simpletest-rc-to-be-deleted-79zcb" in namespace "gc-2550"
    Aug 24 09:32:44.951: INFO: Deleting pod "simpletest-rc-to-be-deleted-7gdr4" in namespace "gc-2550"
    Aug 24 09:32:44.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-7k6qt" in namespace "gc-2550"
    Aug 24 09:32:45.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-7t5nd" in namespace "gc-2550"
    Aug 24 09:32:45.125: INFO: Deleting pod "simpletest-rc-to-be-deleted-8d4xc" in namespace "gc-2550"
    Aug 24 09:32:45.206: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dmcr" in namespace "gc-2550"
    Aug 24 09:32:45.292: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jtwm" in namespace "gc-2550"
    Aug 24 09:32:45.344: INFO: Deleting pod "simpletest-rc-to-be-deleted-8v55n" in namespace "gc-2550"
    Aug 24 09:32:45.410: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dpcm" in namespace "gc-2550"
    Aug 24 09:32:45.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dvxb" in namespace "gc-2550"
    Aug 24 09:32:45.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-9h4l7" in namespace "gc-2550"
    Aug 24 09:32:45.739: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xcrl" in namespace "gc-2550"
    Aug 24 09:32:45.810: INFO: Deleting pod "simpletest-rc-to-be-deleted-b5pvk" in namespace "gc-2550"
    Aug 24 09:32:45.905: INFO: Deleting pod "simpletest-rc-to-be-deleted-bdklx" in namespace "gc-2550"
    Aug 24 09:32:45.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-bq6sf" in namespace "gc-2550"
    Aug 24 09:32:45.968: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwhb5" in namespace "gc-2550"
    Aug 24 09:32:46.001: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8frb" in namespace "gc-2550"
    Aug 24 09:32:46.040: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmw78" in namespace "gc-2550"
    Aug 24 09:32:46.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4bhk" in namespace "gc-2550"
    Aug 24 09:32:46.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-d66lf" in namespace "gc-2550"
    Aug 24 09:32:46.146: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk6bc" in namespace "gc-2550"
    Aug 24 09:32:46.185: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkflw" in namespace "gc-2550"
    Aug 24 09:32:46.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnkgs" in namespace "gc-2550"
    Aug 24 09:32:46.325: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx58q" in namespace "gc-2550"
    Aug 24 09:32:46.355: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxcvs" in namespace "gc-2550"
    Aug 24 09:32:46.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj7t8" in namespace "gc-2550"
    Aug 24 09:32:46.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-fn928" in namespace "gc-2550"
    Aug 24 09:32:46.470: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpvz9" in namespace "gc-2550"
    Aug 24 09:32:46.536: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxqc5" in namespace "gc-2550"
    Aug 24 09:32:46.591: INFO: Deleting pod "simpletest-rc-to-be-deleted-g4kkh" in namespace "gc-2550"
    Aug 24 09:32:46.627: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwl7d" in namespace "gc-2550"
    Aug 24 09:32:46.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-hdgcx" in namespace "gc-2550"
    Aug 24 09:32:46.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-htsb9" in namespace "gc-2550"
    Aug 24 09:32:46.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-hw875" in namespace "gc-2550"
    Aug 24 09:32:46.909: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4cqw" in namespace "gc-2550"
    Aug 24 09:32:46.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-jhj2p" in namespace "gc-2550"
    Aug 24 09:32:46.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-jv74w" in namespace "gc-2550"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 09:32:47.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2550" for this suite. 08/24/22 09:32:47.033
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:32:47.082
Aug 24 09:32:47.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 09:32:47.089
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:47.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:47.154
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-dbad7b0b-9d9b-4333-b991-477535fc94cd 08/24/22 09:32:47.183
STEP: Creating configMap with name cm-test-opt-upd-2b750e60-71f5-4c65-a3c6-12fb686b2b87 08/24/22 09:32:47.193
STEP: Creating the pod 08/24/22 09:32:47.209
Aug 24 09:32:47.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2" in namespace "configmap-4793" to be "running and ready"
Aug 24 09:32:47.244: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.210698ms
Aug 24 09:32:47.244: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:32:49.252: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021057011s
Aug 24 09:32:49.252: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:32:51.253: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Running", Reason="", readiness=true. Elapsed: 4.022158119s
Aug 24 09:32:51.253: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Running (Ready = true)
Aug 24 09:32:51.253: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-dbad7b0b-9d9b-4333-b991-477535fc94cd 08/24/22 09:32:51.34
STEP: Updating configmap cm-test-opt-upd-2b750e60-71f5-4c65-a3c6-12fb686b2b87 08/24/22 09:32:51.356
STEP: Creating configMap with name cm-test-opt-create-bb004911-2ff6-4ad2-a745-d91ee53f764f 08/24/22 09:32:51.368
STEP: waiting to observe update in volume 08/24/22 09:32:51.375
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 09:34:08.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4793" for this suite. 08/24/22 09:34:08.181
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":23,"skipped":377,"failed":0}
------------------------------
• [SLOW TEST] [81.111 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:32:47.082
    Aug 24 09:32:47.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 09:32:47.089
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:32:47.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:32:47.154
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-dbad7b0b-9d9b-4333-b991-477535fc94cd 08/24/22 09:32:47.183
    STEP: Creating configMap with name cm-test-opt-upd-2b750e60-71f5-4c65-a3c6-12fb686b2b87 08/24/22 09:32:47.193
    STEP: Creating the pod 08/24/22 09:32:47.209
    Aug 24 09:32:47.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2" in namespace "configmap-4793" to be "running and ready"
    Aug 24 09:32:47.244: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.210698ms
    Aug 24 09:32:47.244: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:32:49.252: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021057011s
    Aug 24 09:32:49.252: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:32:51.253: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2": Phase="Running", Reason="", readiness=true. Elapsed: 4.022158119s
    Aug 24 09:32:51.253: INFO: The phase of Pod pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2 is Running (Ready = true)
    Aug 24 09:32:51.253: INFO: Pod "pod-configmaps-a2e3005e-6c2c-4265-9d3c-e85c4ee942a2" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-dbad7b0b-9d9b-4333-b991-477535fc94cd 08/24/22 09:32:51.34
    STEP: Updating configmap cm-test-opt-upd-2b750e60-71f5-4c65-a3c6-12fb686b2b87 08/24/22 09:32:51.356
    STEP: Creating configMap with name cm-test-opt-create-bb004911-2ff6-4ad2-a745-d91ee53f764f 08/24/22 09:32:51.368
    STEP: waiting to observe update in volume 08/24/22 09:32:51.375
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 09:34:08.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4793" for this suite. 08/24/22 09:34:08.181
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:34:08.196
Aug 24 09:34:08.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 09:34:08.201
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:08.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:08.237
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-5054/configmap-test-d9e3f061-056b-4c23-bc18-5a230c16cacc 08/24/22 09:34:08.241
STEP: Creating a pod to test consume configMaps 08/24/22 09:34:08.248
Aug 24 09:34:08.260: INFO: Waiting up to 5m0s for pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215" in namespace "configmap-5054" to be "Succeeded or Failed"
Aug 24 09:34:08.265: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Pending", Reason="", readiness=false. Elapsed: 4.300596ms
Aug 24 09:34:10.273: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012139273s
Aug 24 09:34:12.272: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011727794s
STEP: Saw pod success 08/24/22 09:34:12.272
Aug 24 09:34:12.273: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215" satisfied condition "Succeeded or Failed"
Aug 24 09:34:12.278: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 container env-test: <nil>
STEP: delete the pod 08/24/22 09:34:12.288
Aug 24 09:34:12.308: INFO: Waiting for pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 to disappear
Aug 24 09:34:12.314: INFO: Pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 09:34:12.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5054" for this suite. 08/24/22 09:34:12.322
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":24,"skipped":378,"failed":0}
------------------------------
• [4.136 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:34:08.196
    Aug 24 09:34:08.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 09:34:08.201
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:08.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:08.237
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-5054/configmap-test-d9e3f061-056b-4c23-bc18-5a230c16cacc 08/24/22 09:34:08.241
    STEP: Creating a pod to test consume configMaps 08/24/22 09:34:08.248
    Aug 24 09:34:08.260: INFO: Waiting up to 5m0s for pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215" in namespace "configmap-5054" to be "Succeeded or Failed"
    Aug 24 09:34:08.265: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Pending", Reason="", readiness=false. Elapsed: 4.300596ms
    Aug 24 09:34:10.273: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012139273s
    Aug 24 09:34:12.272: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011727794s
    STEP: Saw pod success 08/24/22 09:34:12.272
    Aug 24 09:34:12.273: INFO: Pod "pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215" satisfied condition "Succeeded or Failed"
    Aug 24 09:34:12.278: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 container env-test: <nil>
    STEP: delete the pod 08/24/22 09:34:12.288
    Aug 24 09:34:12.308: INFO: Waiting for pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 to disappear
    Aug 24 09:34:12.314: INFO: Pod pod-configmaps-21e1eed2-ac81-48f3-9fb6-5da891dd7215 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 09:34:12.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5054" for this suite. 08/24/22 09:34:12.322
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:34:12.348
Aug 24 09:34:12.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 09:34:12.349
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:12.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:12.401
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 08/24/22 09:34:12.405
STEP: Ensuring ResourceQuota status is calculated 08/24/22 09:34:12.413
STEP: Creating a ResourceQuota with not best effort scope 08/24/22 09:34:14.423
STEP: Ensuring ResourceQuota status is calculated 08/24/22 09:34:14.432
STEP: Creating a best-effort pod 08/24/22 09:34:16.439
STEP: Ensuring resource quota with best effort scope captures the pod usage 08/24/22 09:34:16.461
STEP: Ensuring resource quota with not best effort ignored the pod usage 08/24/22 09:34:18.467
STEP: Deleting the pod 08/24/22 09:34:20.476
STEP: Ensuring resource quota status released the pod usage 08/24/22 09:34:20.509
STEP: Creating a not best-effort pod 08/24/22 09:34:22.525
STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/24/22 09:34:22.555
STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/24/22 09:34:24.566
STEP: Deleting the pod 08/24/22 09:34:26.611
STEP: Ensuring resource quota status released the pod usage 08/24/22 09:34:26.644
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 09:34:28.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5153" for this suite. 08/24/22 09:34:28.663
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":25,"skipped":437,"failed":0}
------------------------------
• [SLOW TEST] [16.328 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:34:12.348
    Aug 24 09:34:12.348: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 09:34:12.349
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:12.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:12.401
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 08/24/22 09:34:12.405
    STEP: Ensuring ResourceQuota status is calculated 08/24/22 09:34:12.413
    STEP: Creating a ResourceQuota with not best effort scope 08/24/22 09:34:14.423
    STEP: Ensuring ResourceQuota status is calculated 08/24/22 09:34:14.432
    STEP: Creating a best-effort pod 08/24/22 09:34:16.439
    STEP: Ensuring resource quota with best effort scope captures the pod usage 08/24/22 09:34:16.461
    STEP: Ensuring resource quota with not best effort ignored the pod usage 08/24/22 09:34:18.467
    STEP: Deleting the pod 08/24/22 09:34:20.476
    STEP: Ensuring resource quota status released the pod usage 08/24/22 09:34:20.509
    STEP: Creating a not best-effort pod 08/24/22 09:34:22.525
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/24/22 09:34:22.555
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/24/22 09:34:24.566
    STEP: Deleting the pod 08/24/22 09:34:26.611
    STEP: Ensuring resource quota status released the pod usage 08/24/22 09:34:26.644
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 09:34:28.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5153" for this suite. 08/24/22 09:34:28.663
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:34:28.681
Aug 24 09:34:28.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 09:34:28.685
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:28.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:28.723
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 08/24/22 09:34:28.741
STEP: delete the rc 08/24/22 09:34:33.774
STEP: wait for the rc to be deleted 08/24/22 09:34:33.799
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/24/22 09:34:38.861
STEP: Gathering metrics 08/24/22 09:35:08.895
Aug 24 09:35:08.942: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 09:35:08.949: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.643956ms
Aug 24 09:35:08.949: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 09:35:08.949: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 09:35:09.064: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 24 09:35:09.064: INFO: Deleting pod "simpletest.rc-22dc5" in namespace "gc-5573"
Aug 24 09:35:09.109: INFO: Deleting pod "simpletest.rc-2mvrn" in namespace "gc-5573"
Aug 24 09:35:09.176: INFO: Deleting pod "simpletest.rc-2nlrz" in namespace "gc-5573"
Aug 24 09:35:09.205: INFO: Deleting pod "simpletest.rc-2rprq" in namespace "gc-5573"
Aug 24 09:35:09.264: INFO: Deleting pod "simpletest.rc-44sv5" in namespace "gc-5573"
Aug 24 09:35:09.320: INFO: Deleting pod "simpletest.rc-4jsck" in namespace "gc-5573"
Aug 24 09:35:09.394: INFO: Deleting pod "simpletest.rc-54wdf" in namespace "gc-5573"
Aug 24 09:35:09.491: INFO: Deleting pod "simpletest.rc-57b74" in namespace "gc-5573"
Aug 24 09:35:09.564: INFO: Deleting pod "simpletest.rc-5dv9g" in namespace "gc-5573"
Aug 24 09:35:09.655: INFO: Deleting pod "simpletest.rc-5pxxp" in namespace "gc-5573"
Aug 24 09:35:09.717: INFO: Deleting pod "simpletest.rc-6f4qm" in namespace "gc-5573"
Aug 24 09:35:09.775: INFO: Deleting pod "simpletest.rc-6lrls" in namespace "gc-5573"
Aug 24 09:35:09.874: INFO: Deleting pod "simpletest.rc-6nr5r" in namespace "gc-5573"
Aug 24 09:35:09.921: INFO: Deleting pod "simpletest.rc-6tm2z" in namespace "gc-5573"
Aug 24 09:35:09.979: INFO: Deleting pod "simpletest.rc-6zk9p" in namespace "gc-5573"
Aug 24 09:35:10.020: INFO: Deleting pod "simpletest.rc-79jfq" in namespace "gc-5573"
Aug 24 09:35:10.077: INFO: Deleting pod "simpletest.rc-7jw48" in namespace "gc-5573"
Aug 24 09:35:10.145: INFO: Deleting pod "simpletest.rc-7tvgm" in namespace "gc-5573"
Aug 24 09:35:10.270: INFO: Deleting pod "simpletest.rc-8kg5v" in namespace "gc-5573"
Aug 24 09:35:10.319: INFO: Deleting pod "simpletest.rc-8pzfm" in namespace "gc-5573"
Aug 24 09:35:10.471: INFO: Deleting pod "simpletest.rc-96g5l" in namespace "gc-5573"
Aug 24 09:35:10.575: INFO: Deleting pod "simpletest.rc-97qmx" in namespace "gc-5573"
Aug 24 09:35:10.646: INFO: Deleting pod "simpletest.rc-9lwl4" in namespace "gc-5573"
Aug 24 09:35:10.842: INFO: Deleting pod "simpletest.rc-9xk58" in namespace "gc-5573"
Aug 24 09:35:10.915: INFO: Deleting pod "simpletest.rc-9xzj9" in namespace "gc-5573"
Aug 24 09:35:10.947: INFO: Deleting pod "simpletest.rc-b5jx8" in namespace "gc-5573"
Aug 24 09:35:10.986: INFO: Deleting pod "simpletest.rc-b9f85" in namespace "gc-5573"
Aug 24 09:35:11.033: INFO: Deleting pod "simpletest.rc-blzsc" in namespace "gc-5573"
Aug 24 09:35:11.085: INFO: Deleting pod "simpletest.rc-c5k7p" in namespace "gc-5573"
Aug 24 09:35:11.135: INFO: Deleting pod "simpletest.rc-cjrf7" in namespace "gc-5573"
Aug 24 09:35:11.221: INFO: Deleting pod "simpletest.rc-d64m7" in namespace "gc-5573"
Aug 24 09:35:11.433: INFO: Deleting pod "simpletest.rc-d74zg" in namespace "gc-5573"
Aug 24 09:35:11.534: INFO: Deleting pod "simpletest.rc-dgvdh" in namespace "gc-5573"
Aug 24 09:35:11.739: INFO: Deleting pod "simpletest.rc-dl72l" in namespace "gc-5573"
Aug 24 09:35:11.858: INFO: Deleting pod "simpletest.rc-dnx8m" in namespace "gc-5573"
Aug 24 09:35:11.925: INFO: Deleting pod "simpletest.rc-dw6sj" in namespace "gc-5573"
Aug 24 09:35:11.956: INFO: Deleting pod "simpletest.rc-f6dzn" in namespace "gc-5573"
Aug 24 09:35:11.993: INFO: Deleting pod "simpletest.rc-ffxm4" in namespace "gc-5573"
Aug 24 09:35:12.081: INFO: Deleting pod "simpletest.rc-g6bhk" in namespace "gc-5573"
Aug 24 09:35:12.158: INFO: Deleting pod "simpletest.rc-gknnl" in namespace "gc-5573"
Aug 24 09:35:12.257: INFO: Deleting pod "simpletest.rc-gnmvf" in namespace "gc-5573"
Aug 24 09:35:12.290: INFO: Deleting pod "simpletest.rc-gsczd" in namespace "gc-5573"
Aug 24 09:35:12.380: INFO: Deleting pod "simpletest.rc-gzqhk" in namespace "gc-5573"
Aug 24 09:35:12.475: INFO: Deleting pod "simpletest.rc-hpb6f" in namespace "gc-5573"
Aug 24 09:35:12.515: INFO: Deleting pod "simpletest.rc-hzc9h" in namespace "gc-5573"
Aug 24 09:35:12.573: INFO: Deleting pod "simpletest.rc-j8kjt" in namespace "gc-5573"
Aug 24 09:35:12.629: INFO: Deleting pod "simpletest.rc-jbsw9" in namespace "gc-5573"
Aug 24 09:35:12.704: INFO: Deleting pod "simpletest.rc-jhk5h" in namespace "gc-5573"
Aug 24 09:35:12.757: INFO: Deleting pod "simpletest.rc-jltd5" in namespace "gc-5573"
Aug 24 09:35:12.802: INFO: Deleting pod "simpletest.rc-jrbnr" in namespace "gc-5573"
Aug 24 09:35:12.823: INFO: Deleting pod "simpletest.rc-jxd6b" in namespace "gc-5573"
Aug 24 09:35:12.856: INFO: Deleting pod "simpletest.rc-jzgbf" in namespace "gc-5573"
Aug 24 09:35:12.885: INFO: Deleting pod "simpletest.rc-jzxlg" in namespace "gc-5573"
Aug 24 09:35:12.929: INFO: Deleting pod "simpletest.rc-k2pg2" in namespace "gc-5573"
Aug 24 09:35:13.055: INFO: Deleting pod "simpletest.rc-k6rkh" in namespace "gc-5573"
Aug 24 09:35:13.093: INFO: Deleting pod "simpletest.rc-kqxns" in namespace "gc-5573"
Aug 24 09:35:13.126: INFO: Deleting pod "simpletest.rc-l8np2" in namespace "gc-5573"
Aug 24 09:35:13.266: INFO: Deleting pod "simpletest.rc-lqjv4" in namespace "gc-5573"
Aug 24 09:35:13.306: INFO: Deleting pod "simpletest.rc-m5dvh" in namespace "gc-5573"
Aug 24 09:35:13.343: INFO: Deleting pod "simpletest.rc-mbqmz" in namespace "gc-5573"
Aug 24 09:35:13.384: INFO: Deleting pod "simpletest.rc-mdl4r" in namespace "gc-5573"
Aug 24 09:35:13.637: INFO: Deleting pod "simpletest.rc-mvrpt" in namespace "gc-5573"
Aug 24 09:35:13.682: INFO: Deleting pod "simpletest.rc-n5pp2" in namespace "gc-5573"
Aug 24 09:35:13.730: INFO: Deleting pod "simpletest.rc-ndkvh" in namespace "gc-5573"
Aug 24 09:35:13.795: INFO: Deleting pod "simpletest.rc-nhbpw" in namespace "gc-5573"
Aug 24 09:35:13.862: INFO: Deleting pod "simpletest.rc-nzsk4" in namespace "gc-5573"
Aug 24 09:35:13.899: INFO: Deleting pod "simpletest.rc-p46dg" in namespace "gc-5573"
Aug 24 09:35:13.945: INFO: Deleting pod "simpletest.rc-p9c9r" in namespace "gc-5573"
Aug 24 09:35:14.029: INFO: Deleting pod "simpletest.rc-pf8ht" in namespace "gc-5573"
Aug 24 09:35:14.085: INFO: Deleting pod "simpletest.rc-pw98h" in namespace "gc-5573"
Aug 24 09:35:14.111: INFO: Deleting pod "simpletest.rc-q55w6" in namespace "gc-5573"
Aug 24 09:35:14.139: INFO: Deleting pod "simpletest.rc-r5wng" in namespace "gc-5573"
Aug 24 09:35:14.196: INFO: Deleting pod "simpletest.rc-rb49n" in namespace "gc-5573"
Aug 24 09:35:14.262: INFO: Deleting pod "simpletest.rc-rchpz" in namespace "gc-5573"
Aug 24 09:35:14.314: INFO: Deleting pod "simpletest.rc-rmjkm" in namespace "gc-5573"
Aug 24 09:35:14.410: INFO: Deleting pod "simpletest.rc-s5tfs" in namespace "gc-5573"
Aug 24 09:35:14.507: INFO: Deleting pod "simpletest.rc-sg7dk" in namespace "gc-5573"
Aug 24 09:35:14.545: INFO: Deleting pod "simpletest.rc-sh479" in namespace "gc-5573"
Aug 24 09:35:14.608: INFO: Deleting pod "simpletest.rc-snx8r" in namespace "gc-5573"
Aug 24 09:35:14.650: INFO: Deleting pod "simpletest.rc-szzwr" in namespace "gc-5573"
Aug 24 09:35:14.726: INFO: Deleting pod "simpletest.rc-tclzp" in namespace "gc-5573"
Aug 24 09:35:14.885: INFO: Deleting pod "simpletest.rc-tdgb4" in namespace "gc-5573"
Aug 24 09:35:14.939: INFO: Deleting pod "simpletest.rc-tmhpz" in namespace "gc-5573"
Aug 24 09:35:14.978: INFO: Deleting pod "simpletest.rc-tqbxk" in namespace "gc-5573"
Aug 24 09:35:15.022: INFO: Deleting pod "simpletest.rc-trrjj" in namespace "gc-5573"
Aug 24 09:35:15.076: INFO: Deleting pod "simpletest.rc-ttb5f" in namespace "gc-5573"
Aug 24 09:35:15.131: INFO: Deleting pod "simpletest.rc-v7vtn" in namespace "gc-5573"
Aug 24 09:35:15.194: INFO: Deleting pod "simpletest.rc-v87q4" in namespace "gc-5573"
Aug 24 09:35:15.249: INFO: Deleting pod "simpletest.rc-vbzlx" in namespace "gc-5573"
Aug 24 09:35:15.307: INFO: Deleting pod "simpletest.rc-vhtms" in namespace "gc-5573"
Aug 24 09:35:15.422: INFO: Deleting pod "simpletest.rc-w4js5" in namespace "gc-5573"
Aug 24 09:35:15.534: INFO: Deleting pod "simpletest.rc-wfcwk" in namespace "gc-5573"
Aug 24 09:35:15.574: INFO: Deleting pod "simpletest.rc-wgn9p" in namespace "gc-5573"
Aug 24 09:35:15.821: INFO: Deleting pod "simpletest.rc-wjjhw" in namespace "gc-5573"
Aug 24 09:35:15.872: INFO: Deleting pod "simpletest.rc-x75wj" in namespace "gc-5573"
Aug 24 09:35:15.912: INFO: Deleting pod "simpletest.rc-x9527" in namespace "gc-5573"
Aug 24 09:35:15.948: INFO: Deleting pod "simpletest.rc-xtbff" in namespace "gc-5573"
Aug 24 09:35:15.989: INFO: Deleting pod "simpletest.rc-zqsqk" in namespace "gc-5573"
Aug 24 09:35:16.029: INFO: Deleting pod "simpletest.rc-zxpk9" in namespace "gc-5573"
Aug 24 09:35:16.083: INFO: Deleting pod "simpletest.rc-zzvwf" in namespace "gc-5573"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 09:35:16.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5573" for this suite. 08/24/22 09:35:16.234
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":26,"skipped":469,"failed":0}
------------------------------
• [SLOW TEST] [47.572 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:34:28.681
    Aug 24 09:34:28.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 09:34:28.685
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:34:28.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:34:28.723
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 08/24/22 09:34:28.741
    STEP: delete the rc 08/24/22 09:34:33.774
    STEP: wait for the rc to be deleted 08/24/22 09:34:33.799
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/24/22 09:34:38.861
    STEP: Gathering metrics 08/24/22 09:35:08.895
    Aug 24 09:35:08.942: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 09:35:08.949: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.643956ms
    Aug 24 09:35:08.949: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 09:35:08.949: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 09:35:09.064: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 24 09:35:09.064: INFO: Deleting pod "simpletest.rc-22dc5" in namespace "gc-5573"
    Aug 24 09:35:09.109: INFO: Deleting pod "simpletest.rc-2mvrn" in namespace "gc-5573"
    Aug 24 09:35:09.176: INFO: Deleting pod "simpletest.rc-2nlrz" in namespace "gc-5573"
    Aug 24 09:35:09.205: INFO: Deleting pod "simpletest.rc-2rprq" in namespace "gc-5573"
    Aug 24 09:35:09.264: INFO: Deleting pod "simpletest.rc-44sv5" in namespace "gc-5573"
    Aug 24 09:35:09.320: INFO: Deleting pod "simpletest.rc-4jsck" in namespace "gc-5573"
    Aug 24 09:35:09.394: INFO: Deleting pod "simpletest.rc-54wdf" in namespace "gc-5573"
    Aug 24 09:35:09.491: INFO: Deleting pod "simpletest.rc-57b74" in namespace "gc-5573"
    Aug 24 09:35:09.564: INFO: Deleting pod "simpletest.rc-5dv9g" in namespace "gc-5573"
    Aug 24 09:35:09.655: INFO: Deleting pod "simpletest.rc-5pxxp" in namespace "gc-5573"
    Aug 24 09:35:09.717: INFO: Deleting pod "simpletest.rc-6f4qm" in namespace "gc-5573"
    Aug 24 09:35:09.775: INFO: Deleting pod "simpletest.rc-6lrls" in namespace "gc-5573"
    Aug 24 09:35:09.874: INFO: Deleting pod "simpletest.rc-6nr5r" in namespace "gc-5573"
    Aug 24 09:35:09.921: INFO: Deleting pod "simpletest.rc-6tm2z" in namespace "gc-5573"
    Aug 24 09:35:09.979: INFO: Deleting pod "simpletest.rc-6zk9p" in namespace "gc-5573"
    Aug 24 09:35:10.020: INFO: Deleting pod "simpletest.rc-79jfq" in namespace "gc-5573"
    Aug 24 09:35:10.077: INFO: Deleting pod "simpletest.rc-7jw48" in namespace "gc-5573"
    Aug 24 09:35:10.145: INFO: Deleting pod "simpletest.rc-7tvgm" in namespace "gc-5573"
    Aug 24 09:35:10.270: INFO: Deleting pod "simpletest.rc-8kg5v" in namespace "gc-5573"
    Aug 24 09:35:10.319: INFO: Deleting pod "simpletest.rc-8pzfm" in namespace "gc-5573"
    Aug 24 09:35:10.471: INFO: Deleting pod "simpletest.rc-96g5l" in namespace "gc-5573"
    Aug 24 09:35:10.575: INFO: Deleting pod "simpletest.rc-97qmx" in namespace "gc-5573"
    Aug 24 09:35:10.646: INFO: Deleting pod "simpletest.rc-9lwl4" in namespace "gc-5573"
    Aug 24 09:35:10.842: INFO: Deleting pod "simpletest.rc-9xk58" in namespace "gc-5573"
    Aug 24 09:35:10.915: INFO: Deleting pod "simpletest.rc-9xzj9" in namespace "gc-5573"
    Aug 24 09:35:10.947: INFO: Deleting pod "simpletest.rc-b5jx8" in namespace "gc-5573"
    Aug 24 09:35:10.986: INFO: Deleting pod "simpletest.rc-b9f85" in namespace "gc-5573"
    Aug 24 09:35:11.033: INFO: Deleting pod "simpletest.rc-blzsc" in namespace "gc-5573"
    Aug 24 09:35:11.085: INFO: Deleting pod "simpletest.rc-c5k7p" in namespace "gc-5573"
    Aug 24 09:35:11.135: INFO: Deleting pod "simpletest.rc-cjrf7" in namespace "gc-5573"
    Aug 24 09:35:11.221: INFO: Deleting pod "simpletest.rc-d64m7" in namespace "gc-5573"
    Aug 24 09:35:11.433: INFO: Deleting pod "simpletest.rc-d74zg" in namespace "gc-5573"
    Aug 24 09:35:11.534: INFO: Deleting pod "simpletest.rc-dgvdh" in namespace "gc-5573"
    Aug 24 09:35:11.739: INFO: Deleting pod "simpletest.rc-dl72l" in namespace "gc-5573"
    Aug 24 09:35:11.858: INFO: Deleting pod "simpletest.rc-dnx8m" in namespace "gc-5573"
    Aug 24 09:35:11.925: INFO: Deleting pod "simpletest.rc-dw6sj" in namespace "gc-5573"
    Aug 24 09:35:11.956: INFO: Deleting pod "simpletest.rc-f6dzn" in namespace "gc-5573"
    Aug 24 09:35:11.993: INFO: Deleting pod "simpletest.rc-ffxm4" in namespace "gc-5573"
    Aug 24 09:35:12.081: INFO: Deleting pod "simpletest.rc-g6bhk" in namespace "gc-5573"
    Aug 24 09:35:12.158: INFO: Deleting pod "simpletest.rc-gknnl" in namespace "gc-5573"
    Aug 24 09:35:12.257: INFO: Deleting pod "simpletest.rc-gnmvf" in namespace "gc-5573"
    Aug 24 09:35:12.290: INFO: Deleting pod "simpletest.rc-gsczd" in namespace "gc-5573"
    Aug 24 09:35:12.380: INFO: Deleting pod "simpletest.rc-gzqhk" in namespace "gc-5573"
    Aug 24 09:35:12.475: INFO: Deleting pod "simpletest.rc-hpb6f" in namespace "gc-5573"
    Aug 24 09:35:12.515: INFO: Deleting pod "simpletest.rc-hzc9h" in namespace "gc-5573"
    Aug 24 09:35:12.573: INFO: Deleting pod "simpletest.rc-j8kjt" in namespace "gc-5573"
    Aug 24 09:35:12.629: INFO: Deleting pod "simpletest.rc-jbsw9" in namespace "gc-5573"
    Aug 24 09:35:12.704: INFO: Deleting pod "simpletest.rc-jhk5h" in namespace "gc-5573"
    Aug 24 09:35:12.757: INFO: Deleting pod "simpletest.rc-jltd5" in namespace "gc-5573"
    Aug 24 09:35:12.802: INFO: Deleting pod "simpletest.rc-jrbnr" in namespace "gc-5573"
    Aug 24 09:35:12.823: INFO: Deleting pod "simpletest.rc-jxd6b" in namespace "gc-5573"
    Aug 24 09:35:12.856: INFO: Deleting pod "simpletest.rc-jzgbf" in namespace "gc-5573"
    Aug 24 09:35:12.885: INFO: Deleting pod "simpletest.rc-jzxlg" in namespace "gc-5573"
    Aug 24 09:35:12.929: INFO: Deleting pod "simpletest.rc-k2pg2" in namespace "gc-5573"
    Aug 24 09:35:13.055: INFO: Deleting pod "simpletest.rc-k6rkh" in namespace "gc-5573"
    Aug 24 09:35:13.093: INFO: Deleting pod "simpletest.rc-kqxns" in namespace "gc-5573"
    Aug 24 09:35:13.126: INFO: Deleting pod "simpletest.rc-l8np2" in namespace "gc-5573"
    Aug 24 09:35:13.266: INFO: Deleting pod "simpletest.rc-lqjv4" in namespace "gc-5573"
    Aug 24 09:35:13.306: INFO: Deleting pod "simpletest.rc-m5dvh" in namespace "gc-5573"
    Aug 24 09:35:13.343: INFO: Deleting pod "simpletest.rc-mbqmz" in namespace "gc-5573"
    Aug 24 09:35:13.384: INFO: Deleting pod "simpletest.rc-mdl4r" in namespace "gc-5573"
    Aug 24 09:35:13.637: INFO: Deleting pod "simpletest.rc-mvrpt" in namespace "gc-5573"
    Aug 24 09:35:13.682: INFO: Deleting pod "simpletest.rc-n5pp2" in namespace "gc-5573"
    Aug 24 09:35:13.730: INFO: Deleting pod "simpletest.rc-ndkvh" in namespace "gc-5573"
    Aug 24 09:35:13.795: INFO: Deleting pod "simpletest.rc-nhbpw" in namespace "gc-5573"
    Aug 24 09:35:13.862: INFO: Deleting pod "simpletest.rc-nzsk4" in namespace "gc-5573"
    Aug 24 09:35:13.899: INFO: Deleting pod "simpletest.rc-p46dg" in namespace "gc-5573"
    Aug 24 09:35:13.945: INFO: Deleting pod "simpletest.rc-p9c9r" in namespace "gc-5573"
    Aug 24 09:35:14.029: INFO: Deleting pod "simpletest.rc-pf8ht" in namespace "gc-5573"
    Aug 24 09:35:14.085: INFO: Deleting pod "simpletest.rc-pw98h" in namespace "gc-5573"
    Aug 24 09:35:14.111: INFO: Deleting pod "simpletest.rc-q55w6" in namespace "gc-5573"
    Aug 24 09:35:14.139: INFO: Deleting pod "simpletest.rc-r5wng" in namespace "gc-5573"
    Aug 24 09:35:14.196: INFO: Deleting pod "simpletest.rc-rb49n" in namespace "gc-5573"
    Aug 24 09:35:14.262: INFO: Deleting pod "simpletest.rc-rchpz" in namespace "gc-5573"
    Aug 24 09:35:14.314: INFO: Deleting pod "simpletest.rc-rmjkm" in namespace "gc-5573"
    Aug 24 09:35:14.410: INFO: Deleting pod "simpletest.rc-s5tfs" in namespace "gc-5573"
    Aug 24 09:35:14.507: INFO: Deleting pod "simpletest.rc-sg7dk" in namespace "gc-5573"
    Aug 24 09:35:14.545: INFO: Deleting pod "simpletest.rc-sh479" in namespace "gc-5573"
    Aug 24 09:35:14.608: INFO: Deleting pod "simpletest.rc-snx8r" in namespace "gc-5573"
    Aug 24 09:35:14.650: INFO: Deleting pod "simpletest.rc-szzwr" in namespace "gc-5573"
    Aug 24 09:35:14.726: INFO: Deleting pod "simpletest.rc-tclzp" in namespace "gc-5573"
    Aug 24 09:35:14.885: INFO: Deleting pod "simpletest.rc-tdgb4" in namespace "gc-5573"
    Aug 24 09:35:14.939: INFO: Deleting pod "simpletest.rc-tmhpz" in namespace "gc-5573"
    Aug 24 09:35:14.978: INFO: Deleting pod "simpletest.rc-tqbxk" in namespace "gc-5573"
    Aug 24 09:35:15.022: INFO: Deleting pod "simpletest.rc-trrjj" in namespace "gc-5573"
    Aug 24 09:35:15.076: INFO: Deleting pod "simpletest.rc-ttb5f" in namespace "gc-5573"
    Aug 24 09:35:15.131: INFO: Deleting pod "simpletest.rc-v7vtn" in namespace "gc-5573"
    Aug 24 09:35:15.194: INFO: Deleting pod "simpletest.rc-v87q4" in namespace "gc-5573"
    Aug 24 09:35:15.249: INFO: Deleting pod "simpletest.rc-vbzlx" in namespace "gc-5573"
    Aug 24 09:35:15.307: INFO: Deleting pod "simpletest.rc-vhtms" in namespace "gc-5573"
    Aug 24 09:35:15.422: INFO: Deleting pod "simpletest.rc-w4js5" in namespace "gc-5573"
    Aug 24 09:35:15.534: INFO: Deleting pod "simpletest.rc-wfcwk" in namespace "gc-5573"
    Aug 24 09:35:15.574: INFO: Deleting pod "simpletest.rc-wgn9p" in namespace "gc-5573"
    Aug 24 09:35:15.821: INFO: Deleting pod "simpletest.rc-wjjhw" in namespace "gc-5573"
    Aug 24 09:35:15.872: INFO: Deleting pod "simpletest.rc-x75wj" in namespace "gc-5573"
    Aug 24 09:35:15.912: INFO: Deleting pod "simpletest.rc-x9527" in namespace "gc-5573"
    Aug 24 09:35:15.948: INFO: Deleting pod "simpletest.rc-xtbff" in namespace "gc-5573"
    Aug 24 09:35:15.989: INFO: Deleting pod "simpletest.rc-zqsqk" in namespace "gc-5573"
    Aug 24 09:35:16.029: INFO: Deleting pod "simpletest.rc-zxpk9" in namespace "gc-5573"
    Aug 24 09:35:16.083: INFO: Deleting pod "simpletest.rc-zzvwf" in namespace "gc-5573"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 09:35:16.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5573" for this suite. 08/24/22 09:35:16.234
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:16.259
Aug 24 09:35:16.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-runtime 08/24/22 09:35:16.27
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:16.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:16.329
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/24/22 09:35:16.359
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/24/22 09:35:32.525
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/24/22 09:35:32.534
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/24/22 09:35:32.548
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/24/22 09:35:32.549
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/24/22 09:35:32.603
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/24/22 09:35:35.639
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/24/22 09:35:37.663
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/24/22 09:35:37.672
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/24/22 09:35:37.672
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/24/22 09:35:37.709
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/24/22 09:35:38.726
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/24/22 09:35:41.759
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/24/22 09:35:41.769
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/24/22 09:35:41.769
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 24 09:35:41.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7477" for this suite. 08/24/22 09:35:41.82
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":27,"skipped":497,"failed":0}
------------------------------
• [SLOW TEST] [25.570 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:16.259
    Aug 24 09:35:16.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-runtime 08/24/22 09:35:16.27
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:16.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:16.329
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/24/22 09:35:16.359
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/24/22 09:35:32.525
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/24/22 09:35:32.534
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/24/22 09:35:32.548
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/24/22 09:35:32.549
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/24/22 09:35:32.603
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/24/22 09:35:35.639
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/24/22 09:35:37.663
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/24/22 09:35:37.672
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/24/22 09:35:37.672
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/24/22 09:35:37.709
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/24/22 09:35:38.726
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/24/22 09:35:41.759
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/24/22 09:35:41.769
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/24/22 09:35:41.769
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 24 09:35:41.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7477" for this suite. 08/24/22 09:35:41.82
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:41.838
Aug 24 09:35:41.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:35:41.842
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:41.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:41.873
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 08/24/22 09:35:41.876
Aug 24 09:35:41.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5783 api-versions'
Aug 24 09:35:42.015: INFO: stderr: ""
Aug 24 09:35:42.015: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:35:42.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5783" for this suite. 08/24/22 09:35:42.03
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":28,"skipped":511,"failed":0}
------------------------------
• [0.206 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:41.838
    Aug 24 09:35:41.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:35:41.842
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:41.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:41.873
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 08/24/22 09:35:41.876
    Aug 24 09:35:41.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5783 api-versions'
    Aug 24 09:35:42.015: INFO: stderr: ""
    Aug 24 09:35:42.015: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:35:42.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5783" for this suite. 08/24/22 09:35:42.03
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:42.05
Aug 24 09:35:42.050: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubelet-test 08/24/22 09:35:42.053
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:42.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:42.087
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Aug 24 09:35:42.105: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00" in namespace "kubelet-test-7862" to be "running and ready"
Aug 24 09:35:42.116: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00": Phase="Pending", Reason="", readiness=false. Elapsed: 11.240536ms
Aug 24 09:35:42.116: INFO: The phase of Pod busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:35:44.123: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00": Phase="Running", Reason="", readiness=true. Elapsed: 2.01746757s
Aug 24 09:35:44.123: INFO: The phase of Pod busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00 is Running (Ready = true)
Aug 24 09:35:44.123: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 24 09:35:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7862" for this suite. 08/24/22 09:35:44.161
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":29,"skipped":525,"failed":0}
------------------------------
• [2.124 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:42.05
    Aug 24 09:35:42.050: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubelet-test 08/24/22 09:35:42.053
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:42.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:42.087
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Aug 24 09:35:42.105: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00" in namespace "kubelet-test-7862" to be "running and ready"
    Aug 24 09:35:42.116: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00": Phase="Pending", Reason="", readiness=false. Elapsed: 11.240536ms
    Aug 24 09:35:42.116: INFO: The phase of Pod busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:35:44.123: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00": Phase="Running", Reason="", readiness=true. Elapsed: 2.01746757s
    Aug 24 09:35:44.123: INFO: The phase of Pod busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00 is Running (Ready = true)
    Aug 24 09:35:44.123: INFO: Pod "busybox-readonly-fsa141d7df-07af-4667-9fc2-c1a696545e00" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 24 09:35:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7862" for this suite. 08/24/22 09:35:44.161
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:44.179
Aug 24 09:35:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 09:35:44.182
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:44.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:44.214
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 09:35:44.251
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:35:45.366
STEP: Deploying the webhook pod 08/24/22 09:35:45.38
STEP: Wait for the deployment to be ready 08/24/22 09:35:45.429
Aug 24 09:35:45.452: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 09:35:47.471
STEP: Verifying the service has paired with the endpoint 08/24/22 09:35:47.494
Aug 24 09:35:48.494: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 08/24/22 09:35:48.661
STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 09:35:48.751
STEP: Deleting the collection of validation webhooks 08/24/22 09:35:48.802
STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 09:35:48.932
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:35:48.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5595" for this suite. 08/24/22 09:35:48.961
STEP: Destroying namespace "webhook-5595-markers" for this suite. 08/24/22 09:35:48.975
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":30,"skipped":534,"failed":0}
------------------------------
• [4.923 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:44.179
    Aug 24 09:35:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 09:35:44.182
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:44.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:44.214
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 09:35:44.251
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:35:45.366
    STEP: Deploying the webhook pod 08/24/22 09:35:45.38
    STEP: Wait for the deployment to be ready 08/24/22 09:35:45.429
    Aug 24 09:35:45.452: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 09:35:47.471
    STEP: Verifying the service has paired with the endpoint 08/24/22 09:35:47.494
    Aug 24 09:35:48.494: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 08/24/22 09:35:48.661
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 09:35:48.751
    STEP: Deleting the collection of validation webhooks 08/24/22 09:35:48.802
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 09:35:48.932
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:35:48.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5595" for this suite. 08/24/22 09:35:48.961
    STEP: Destroying namespace "webhook-5595-markers" for this suite. 08/24/22 09:35:48.975
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:49.103
Aug 24 09:35:49.104: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sysctl 08/24/22 09:35:49.107
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:49.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:49.153
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 08/24/22 09:35:49.158
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 09:35:49.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-768" for this suite. 08/24/22 09:35:49.175
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":31,"skipped":536,"failed":0}
------------------------------
• [0.086 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:49.103
    Aug 24 09:35:49.104: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sysctl 08/24/22 09:35:49.107
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:49.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:49.153
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 08/24/22 09:35:49.158
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 09:35:49.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-768" for this suite. 08/24/22 09:35:49.175
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:49.192
Aug 24 09:35:49.192: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:35:49.197
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:49.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:49.293
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:35:49.3
Aug 24 09:35:49.335: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154" in namespace "projected-4313" to be "Succeeded or Failed"
Aug 24 09:35:49.349: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Pending", Reason="", readiness=false. Elapsed: 14.175288ms
Aug 24 09:35:51.364: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Running", Reason="", readiness=false. Elapsed: 2.028597233s
Aug 24 09:35:53.361: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025599784s
STEP: Saw pod success 08/24/22 09:35:53.361
Aug 24 09:35:53.361: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154" satisfied condition "Succeeded or Failed"
Aug 24 09:35:53.366: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 container client-container: <nil>
STEP: delete the pod 08/24/22 09:35:53.378
Aug 24 09:35:53.447: INFO: Waiting for pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 to disappear
Aug 24 09:35:53.453: INFO: Pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 09:35:53.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4313" for this suite. 08/24/22 09:35:53.462
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":32,"skipped":543,"failed":0}
------------------------------
• [4.284 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:49.192
    Aug 24 09:35:49.192: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:35:49.197
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:49.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:49.293
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:35:49.3
    Aug 24 09:35:49.335: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154" in namespace "projected-4313" to be "Succeeded or Failed"
    Aug 24 09:35:49.349: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Pending", Reason="", readiness=false. Elapsed: 14.175288ms
    Aug 24 09:35:51.364: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Running", Reason="", readiness=false. Elapsed: 2.028597233s
    Aug 24 09:35:53.361: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025599784s
    STEP: Saw pod success 08/24/22 09:35:53.361
    Aug 24 09:35:53.361: INFO: Pod "downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154" satisfied condition "Succeeded or Failed"
    Aug 24 09:35:53.366: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 container client-container: <nil>
    STEP: delete the pod 08/24/22 09:35:53.378
    Aug 24 09:35:53.447: INFO: Waiting for pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 to disappear
    Aug 24 09:35:53.453: INFO: Pod downwardapi-volume-35f72a45-d7fb-4d0d-91fa-f7f0a110c154 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 09:35:53.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4313" for this suite. 08/24/22 09:35:53.462
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:53.481
Aug 24 09:35:53.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename events 08/24/22 09:35:53.483
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:53.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:53.523
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 08/24/22 09:35:53.528
STEP: get a list of Events with a label in the current namespace 08/24/22 09:35:53.56
STEP: delete a list of events 08/24/22 09:35:53.57
Aug 24 09:35:53.570: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/24/22 09:35:53.626
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 24 09:35:53.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2458" for this suite. 08/24/22 09:35:53.643
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":33,"skipped":566,"failed":0}
------------------------------
• [0.176 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:53.481
    Aug 24 09:35:53.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename events 08/24/22 09:35:53.483
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:53.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:53.523
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 08/24/22 09:35:53.528
    STEP: get a list of Events with a label in the current namespace 08/24/22 09:35:53.56
    STEP: delete a list of events 08/24/22 09:35:53.57
    Aug 24 09:35:53.570: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/24/22 09:35:53.626
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 24 09:35:53.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-2458" for this suite. 08/24/22 09:35:53.643
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:53.657
Aug 24 09:35:53.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 09:35:53.662
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:53.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:53.707
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:35:53.711
Aug 24 09:35:53.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f" in namespace "downward-api-5444" to be "Succeeded or Failed"
Aug 24 09:35:53.754: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.64102ms
Aug 24 09:35:55.766: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037261967s
Aug 24 09:35:57.770: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041444041s
STEP: Saw pod success 08/24/22 09:35:57.771
Aug 24 09:35:57.771: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f" satisfied condition "Succeeded or Failed"
Aug 24 09:35:57.778: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f container client-container: <nil>
STEP: delete the pod 08/24/22 09:35:57.79
Aug 24 09:35:57.825: INFO: Waiting for pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f to disappear
Aug 24 09:35:57.834: INFO: Pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 09:35:57.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5444" for this suite. 08/24/22 09:35:57.848
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":34,"skipped":568,"failed":0}
------------------------------
• [4.208 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:53.657
    Aug 24 09:35:53.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 09:35:53.662
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:53.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:53.707
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:35:53.711
    Aug 24 09:35:53.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f" in namespace "downward-api-5444" to be "Succeeded or Failed"
    Aug 24 09:35:53.754: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.64102ms
    Aug 24 09:35:55.766: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037261967s
    Aug 24 09:35:57.770: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041444041s
    STEP: Saw pod success 08/24/22 09:35:57.771
    Aug 24 09:35:57.771: INFO: Pod "downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f" satisfied condition "Succeeded or Failed"
    Aug 24 09:35:57.778: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f container client-container: <nil>
    STEP: delete the pod 08/24/22 09:35:57.79
    Aug 24 09:35:57.825: INFO: Waiting for pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f to disappear
    Aug 24 09:35:57.834: INFO: Pod downwardapi-volume-e888fe0c-d637-445b-b9e1-4d9c1404a23f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 09:35:57.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5444" for this suite. 08/24/22 09:35:57.848
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:35:57.867
Aug 24 09:35:57.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-runtime 08/24/22 09:35:57.877
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:57.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:57.922
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 08/24/22 09:35:57.927
STEP: wait for the container to reach Succeeded 08/24/22 09:35:57.942
STEP: get the container status 08/24/22 09:36:01.982
STEP: the container should be terminated 08/24/22 09:36:01.986
STEP: the termination message should be set 08/24/22 09:36:01.987
Aug 24 09:36:01.987: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/24/22 09:36:01.987
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 24 09:36:02.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8608" for this suite. 08/24/22 09:36:02.018
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":35,"skipped":571,"failed":0}
------------------------------
• [4.165 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:35:57.867
    Aug 24 09:35:57.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-runtime 08/24/22 09:35:57.877
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:35:57.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:35:57.922
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 08/24/22 09:35:57.927
    STEP: wait for the container to reach Succeeded 08/24/22 09:35:57.942
    STEP: get the container status 08/24/22 09:36:01.982
    STEP: the container should be terminated 08/24/22 09:36:01.986
    STEP: the termination message should be set 08/24/22 09:36:01.987
    Aug 24 09:36:01.987: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/24/22 09:36:01.987
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 24 09:36:02.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8608" for this suite. 08/24/22 09:36:02.018
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:36:02.036
Aug 24 09:36:02.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 09:36:02.038
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:36:02.069
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:36:02.073
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-2242 08/24/22 09:36:02.078
STEP: creating service affinity-clusterip-transition in namespace services-2242 08/24/22 09:36:02.078
STEP: creating replication controller affinity-clusterip-transition in namespace services-2242 08/24/22 09:36:02.093
I0824 09:36:02.110415      14 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2242, replica count: 3
I0824 09:36:05.162550      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:36:08.163198      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:36:11.163566      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:36:14.164777      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:36:17.165778      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 09:36:17.187: INFO: Creating new exec pod
Aug 24 09:36:17.210: INFO: Waiting up to 5m0s for pod "execpod-affinityp252d" in namespace "services-2242" to be "running"
Aug 24 09:36:17.216: INFO: Pod "execpod-affinityp252d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.696828ms
Aug 24 09:36:19.229: INFO: Pod "execpod-affinityp252d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018476399s
Aug 24 09:36:19.229: INFO: Pod "execpod-affinityp252d" satisfied condition "running"
Aug 24 09:36:20.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Aug 24 09:36:20.647: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug 24 09:36:20.649: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:36:20.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.33.216 80'
Aug 24 09:36:20.963: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.33.216 80\nConnection to 10.233.33.216 80 port [tcp/http] succeeded!\n"
Aug 24 09:36:20.963: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:36:20.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.33.216:80/ ; done'
Aug 24 09:36:21.702: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n"
Aug 24 09:36:21.702: INFO: stdout: "\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-qkwj2\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-qkwj2\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr"
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-qkwj2
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-qkwj2
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
Aug 24 09:36:21.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.33.216:80/ ; done'
Aug 24 09:36:22.267: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n"
Aug 24 09:36:22.267: INFO: stdout: "\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4"
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
Aug 24 09:36:22.268: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2242, will wait for the garbage collector to delete the pods 08/24/22 09:36:22.304
Aug 24 09:36:22.375: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.719309ms
Aug 24 09:36:22.575: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.46438ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 09:36:25.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2242" for this suite. 08/24/22 09:36:25.336
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":36,"skipped":588,"failed":0}
------------------------------
• [SLOW TEST] [23.318 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:36:02.036
    Aug 24 09:36:02.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 09:36:02.038
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:36:02.069
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:36:02.073
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-2242 08/24/22 09:36:02.078
    STEP: creating service affinity-clusterip-transition in namespace services-2242 08/24/22 09:36:02.078
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2242 08/24/22 09:36:02.093
    I0824 09:36:02.110415      14 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2242, replica count: 3
    I0824 09:36:05.162550      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:36:08.163198      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:36:11.163566      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:36:14.164777      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:36:17.165778      14 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 09:36:17.187: INFO: Creating new exec pod
    Aug 24 09:36:17.210: INFO: Waiting up to 5m0s for pod "execpod-affinityp252d" in namespace "services-2242" to be "running"
    Aug 24 09:36:17.216: INFO: Pod "execpod-affinityp252d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.696828ms
    Aug 24 09:36:19.229: INFO: Pod "execpod-affinityp252d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018476399s
    Aug 24 09:36:19.229: INFO: Pod "execpod-affinityp252d" satisfied condition "running"
    Aug 24 09:36:20.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Aug 24 09:36:20.647: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Aug 24 09:36:20.649: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:36:20.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.33.216 80'
    Aug 24 09:36:20.963: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.33.216 80\nConnection to 10.233.33.216 80 port [tcp/http] succeeded!\n"
    Aug 24 09:36:20.963: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:36:20.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.33.216:80/ ; done'
    Aug 24 09:36:21.702: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n"
    Aug 24 09:36:21.702: INFO: stdout: "\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-qkwj2\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-qkwj2\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-wgfrr"
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-qkwj2
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-qkwj2
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:21.702: INFO: Received response from host: affinity-clusterip-transition-wgfrr
    Aug 24 09:36:21.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2242 exec execpod-affinityp252d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.33.216:80/ ; done'
    Aug 24 09:36:22.267: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.33.216:80/\n"
    Aug 24 09:36:22.267: INFO: stdout: "\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4\naffinity-clusterip-transition-nbng4"
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Received response from host: affinity-clusterip-transition-nbng4
    Aug 24 09:36:22.268: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2242, will wait for the garbage collector to delete the pods 08/24/22 09:36:22.304
    Aug 24 09:36:22.375: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.719309ms
    Aug 24 09:36:22.575: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.46438ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 09:36:25.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2242" for this suite. 08/24/22 09:36:25.336
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:36:25.361
Aug 24 09:36:25.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename cronjob 08/24/22 09:36:25.372
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:36:25.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:36:25.434
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 08/24/22 09:36:25.447
STEP: Ensuring more than one job is running at a time 08/24/22 09:36:25.482
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/24/22 09:38:01.493
STEP: Removing cronjob 08/24/22 09:38:01.507
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 24 09:38:01.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7622" for this suite. 08/24/22 09:38:01.574
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":37,"skipped":605,"failed":0}
------------------------------
• [SLOW TEST] [96.247 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:36:25.361
    Aug 24 09:36:25.362: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename cronjob 08/24/22 09:36:25.372
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:36:25.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:36:25.434
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 08/24/22 09:36:25.447
    STEP: Ensuring more than one job is running at a time 08/24/22 09:36:25.482
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/24/22 09:38:01.493
    STEP: Removing cronjob 08/24/22 09:38:01.507
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 24 09:38:01.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7622" for this suite. 08/24/22 09:38:01.574
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:01.609
Aug 24 09:38:01.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 09:38:01.612
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:01.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:01.683
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Aug 24 09:38:01.719: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 09:38:06.729: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 09:38:06.729
STEP: Scaling up "test-rs" replicaset  08/24/22 09:38:06.729
Aug 24 09:38:06.751: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 08/24/22 09:38:06.751
W0824 09:38:06.772725      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 24 09:38:06.776: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 09:38:06.810: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 09:38:06.875: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 09:38:06.899: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 09:38:08.181: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 2, AvailableReplicas 2
Aug 24 09:38:08.667: INFO: observed Replicaset test-rs in namespace replicaset-7832 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 09:38:08.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7832" for this suite. 08/24/22 09:38:08.681
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":38,"skipped":617,"failed":0}
------------------------------
• [SLOW TEST] [7.084 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:01.609
    Aug 24 09:38:01.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 09:38:01.612
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:01.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:01.683
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Aug 24 09:38:01.719: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 24 09:38:06.729: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 09:38:06.729
    STEP: Scaling up "test-rs" replicaset  08/24/22 09:38:06.729
    Aug 24 09:38:06.751: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 08/24/22 09:38:06.751
    W0824 09:38:06.772725      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 24 09:38:06.776: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
    Aug 24 09:38:06.810: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
    Aug 24 09:38:06.875: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
    Aug 24 09:38:06.899: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 1, AvailableReplicas 1
    Aug 24 09:38:08.181: INFO: observed ReplicaSet test-rs in namespace replicaset-7832 with ReadyReplicas 2, AvailableReplicas 2
    Aug 24 09:38:08.667: INFO: observed Replicaset test-rs in namespace replicaset-7832 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 09:38:08.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7832" for this suite. 08/24/22 09:38:08.681
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:08.742
Aug 24 09:38:08.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 09:38:08.749
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:08.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:08.803
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Aug 24 09:38:08.851: INFO: created pod pod-service-account-defaultsa
Aug 24 09:38:08.851: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 24 09:38:08.873: INFO: created pod pod-service-account-mountsa
Aug 24 09:38:08.874: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 24 09:38:08.902: INFO: created pod pod-service-account-nomountsa
Aug 24 09:38:08.903: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 24 09:38:08.919: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 24 09:38:08.919: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 24 09:38:08.936: INFO: created pod pod-service-account-mountsa-mountspec
Aug 24 09:38:08.937: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 24 09:38:08.986: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 24 09:38:08.987: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 24 09:38:09.021: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 24 09:38:09.021: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 24 09:38:09.074: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 24 09:38:09.074: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 24 09:38:09.121: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 24 09:38:09.122: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 09:38:09.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7951" for this suite. 08/24/22 09:38:09.166
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":39,"skipped":748,"failed":0}
------------------------------
• [0.521 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:08.742
    Aug 24 09:38:08.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 09:38:08.749
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:08.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:08.803
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Aug 24 09:38:08.851: INFO: created pod pod-service-account-defaultsa
    Aug 24 09:38:08.851: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Aug 24 09:38:08.873: INFO: created pod pod-service-account-mountsa
    Aug 24 09:38:08.874: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Aug 24 09:38:08.902: INFO: created pod pod-service-account-nomountsa
    Aug 24 09:38:08.903: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Aug 24 09:38:08.919: INFO: created pod pod-service-account-defaultsa-mountspec
    Aug 24 09:38:08.919: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Aug 24 09:38:08.936: INFO: created pod pod-service-account-mountsa-mountspec
    Aug 24 09:38:08.937: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Aug 24 09:38:08.986: INFO: created pod pod-service-account-nomountsa-mountspec
    Aug 24 09:38:08.987: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Aug 24 09:38:09.021: INFO: created pod pod-service-account-defaultsa-nomountspec
    Aug 24 09:38:09.021: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Aug 24 09:38:09.074: INFO: created pod pod-service-account-mountsa-nomountspec
    Aug 24 09:38:09.074: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Aug 24 09:38:09.121: INFO: created pod pod-service-account-nomountsa-nomountspec
    Aug 24 09:38:09.122: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 09:38:09.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7951" for this suite. 08/24/22 09:38:09.166
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:09.266
Aug 24 09:38:09.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 09:38:09.296
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:09.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:09.349
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 08/24/22 09:38:09.359
STEP: waiting for available Endpoint 08/24/22 09:38:09.369
STEP: listing all Endpoints 08/24/22 09:38:09.372
STEP: updating the Endpoint 08/24/22 09:38:09.379
STEP: fetching the Endpoint 08/24/22 09:38:09.412
STEP: patching the Endpoint 08/24/22 09:38:09.435
STEP: fetching the Endpoint 08/24/22 09:38:09.463
STEP: deleting the Endpoint by Collection 08/24/22 09:38:09.468
STEP: waiting for Endpoint deletion 08/24/22 09:38:09.521
STEP: fetching the Endpoint 08/24/22 09:38:09.524
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 09:38:09.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8214" for this suite. 08/24/22 09:38:09.541
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":40,"skipped":760,"failed":0}
------------------------------
• [0.296 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:09.266
    Aug 24 09:38:09.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 09:38:09.296
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:09.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:09.349
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 08/24/22 09:38:09.359
    STEP: waiting for available Endpoint 08/24/22 09:38:09.369
    STEP: listing all Endpoints 08/24/22 09:38:09.372
    STEP: updating the Endpoint 08/24/22 09:38:09.379
    STEP: fetching the Endpoint 08/24/22 09:38:09.412
    STEP: patching the Endpoint 08/24/22 09:38:09.435
    STEP: fetching the Endpoint 08/24/22 09:38:09.463
    STEP: deleting the Endpoint by Collection 08/24/22 09:38:09.468
    STEP: waiting for Endpoint deletion 08/24/22 09:38:09.521
    STEP: fetching the Endpoint 08/24/22 09:38:09.524
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 09:38:09.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8214" for this suite. 08/24/22 09:38:09.541
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:09.565
Aug 24 09:38:09.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 09:38:09.569
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:09.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:09.665
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 09:38:09.707
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:38:10.51
STEP: Deploying the webhook pod 08/24/22 09:38:10.529
STEP: Wait for the deployment to be ready 08/24/22 09:38:10.553
Aug 24 09:38:10.584: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 09:38:12.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:38:14.614: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 09:38:16.623
STEP: Verifying the service has paired with the endpoint 08/24/22 09:38:16.642
Aug 24 09:38:17.643: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 08/24/22 09:38:17.651
Aug 24 09:38:17.691: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook 08/24/22 09:38:17.81
STEP: create a pod that causes the webhook to hang 08/24/22 09:38:17.836
STEP: create a configmap that should be denied by the webhook 08/24/22 09:38:27.859
STEP: create a configmap that should be admitted by the webhook 08/24/22 09:38:27.909
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/24/22 09:38:27.928
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/24/22 09:38:27.942
STEP: create a namespace that bypass the webhook 08/24/22 09:38:27.952
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/24/22 09:38:27.965
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:38:28.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6932" for this suite. 08/24/22 09:38:28.021
STEP: Destroying namespace "webhook-6932-markers" for this suite. 08/24/22 09:38:28.034
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":41,"skipped":773,"failed":0}
------------------------------
• [SLOW TEST] [18.576 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:09.565
    Aug 24 09:38:09.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 09:38:09.569
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:09.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:09.665
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 09:38:09.707
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:38:10.51
    STEP: Deploying the webhook pod 08/24/22 09:38:10.529
    STEP: Wait for the deployment to be ready 08/24/22 09:38:10.553
    Aug 24 09:38:10.584: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 09:38:12.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:38:14.614: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 38, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 09:38:16.623
    STEP: Verifying the service has paired with the endpoint 08/24/22 09:38:16.642
    Aug 24 09:38:17.643: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 08/24/22 09:38:17.651
    Aug 24 09:38:17.691: INFO: Waiting for webhook configuration to be ready...
    STEP: create a pod that should be denied by the webhook 08/24/22 09:38:17.81
    STEP: create a pod that causes the webhook to hang 08/24/22 09:38:17.836
    STEP: create a configmap that should be denied by the webhook 08/24/22 09:38:27.859
    STEP: create a configmap that should be admitted by the webhook 08/24/22 09:38:27.909
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/24/22 09:38:27.928
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/24/22 09:38:27.942
    STEP: create a namespace that bypass the webhook 08/24/22 09:38:27.952
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/24/22 09:38:27.965
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:38:28.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6932" for this suite. 08/24/22 09:38:28.021
    STEP: Destroying namespace "webhook-6932-markers" for this suite. 08/24/22 09:38:28.034
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:28.142
Aug 24 09:38:28.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 09:38:28.151
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:28.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:28.2
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-914949dc-61c3-4319-9f2e-89cdea8abb45 08/24/22 09:38:28.206
STEP: Creating a pod to test consume secrets 08/24/22 09:38:28.216
Aug 24 09:38:28.234: INFO: Waiting up to 5m0s for pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4" in namespace "secrets-7165" to be "Succeeded or Failed"
Aug 24 09:38:28.240: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444522ms
Aug 24 09:38:30.249: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014544545s
Aug 24 09:38:32.248: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01363005s
STEP: Saw pod success 08/24/22 09:38:32.248
Aug 24 09:38:32.249: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4" satisfied condition "Succeeded or Failed"
Aug 24 09:38:32.254: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 09:38:32.28
Aug 24 09:38:32.303: INFO: Waiting for pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 to disappear
Aug 24 09:38:32.310: INFO: Pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 09:38:32.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7165" for this suite. 08/24/22 09:38:32.32
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":42,"skipped":774,"failed":0}
------------------------------
• [4.187 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:28.142
    Aug 24 09:38:28.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 09:38:28.151
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:28.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:28.2
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-914949dc-61c3-4319-9f2e-89cdea8abb45 08/24/22 09:38:28.206
    STEP: Creating a pod to test consume secrets 08/24/22 09:38:28.216
    Aug 24 09:38:28.234: INFO: Waiting up to 5m0s for pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4" in namespace "secrets-7165" to be "Succeeded or Failed"
    Aug 24 09:38:28.240: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444522ms
    Aug 24 09:38:30.249: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014544545s
    Aug 24 09:38:32.248: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01363005s
    STEP: Saw pod success 08/24/22 09:38:32.248
    Aug 24 09:38:32.249: INFO: Pod "pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4" satisfied condition "Succeeded or Failed"
    Aug 24 09:38:32.254: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 09:38:32.28
    Aug 24 09:38:32.303: INFO: Waiting for pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 to disappear
    Aug 24 09:38:32.310: INFO: Pod pod-secrets-fa4a5808-b6d7-4341-9385-9d40a888f5e4 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 09:38:32.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7165" for this suite. 08/24/22 09:38:32.32
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:32.33
Aug 24 09:38:32.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:38:32.332
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:32.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:32.366
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:38:32.381
Aug 24 09:38:32.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421" in namespace "projected-4927" to be "Succeeded or Failed"
Aug 24 09:38:32.422: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 11.971613ms
Aug 24 09:38:34.431: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021263892s
Aug 24 09:38:36.432: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021607497s
Aug 24 09:38:38.429: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01948018s
STEP: Saw pod success 08/24/22 09:38:38.429
Aug 24 09:38:38.430: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421" satisfied condition "Succeeded or Failed"
Aug 24 09:38:38.436: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 container client-container: <nil>
STEP: delete the pod 08/24/22 09:38:38.453
Aug 24 09:38:38.477: INFO: Waiting for pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 to disappear
Aug 24 09:38:38.485: INFO: Pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 09:38:38.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4927" for this suite. 08/24/22 09:38:38.496
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":43,"skipped":775,"failed":0}
------------------------------
• [SLOW TEST] [6.181 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:32.33
    Aug 24 09:38:32.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:38:32.332
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:32.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:32.366
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:38:32.381
    Aug 24 09:38:32.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421" in namespace "projected-4927" to be "Succeeded or Failed"
    Aug 24 09:38:32.422: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 11.971613ms
    Aug 24 09:38:34.431: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021263892s
    Aug 24 09:38:36.432: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021607497s
    Aug 24 09:38:38.429: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01948018s
    STEP: Saw pod success 08/24/22 09:38:38.429
    Aug 24 09:38:38.430: INFO: Pod "downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421" satisfied condition "Succeeded or Failed"
    Aug 24 09:38:38.436: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 container client-container: <nil>
    STEP: delete the pod 08/24/22 09:38:38.453
    Aug 24 09:38:38.477: INFO: Waiting for pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 to disappear
    Aug 24 09:38:38.485: INFO: Pod downwardapi-volume-147ddcc8-2a90-43d7-8c4d-b87927fe3421 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 09:38:38.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4927" for this suite. 08/24/22 09:38:38.496
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:38.52
Aug 24 09:38:38.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:38:38.523
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:38.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:38.567
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-afa483e3-8292-4204-9206-c38e1bb3c8b7 08/24/22 09:38:38.574
STEP: Creating a pod to test consume configMaps 08/24/22 09:38:38.585
Aug 24 09:38:38.606: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc" in namespace "projected-3493" to be "Succeeded or Failed"
Aug 24 09:38:38.617: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.88559ms
Aug 24 09:38:40.625: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018951103s
Aug 24 09:38:42.624: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018032127s
STEP: Saw pod success 08/24/22 09:38:42.624
Aug 24 09:38:42.625: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc" satisfied condition "Succeeded or Failed"
Aug 24 09:38:42.644: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc container agnhost-container: <nil>
STEP: delete the pod 08/24/22 09:38:42.657
Aug 24 09:38:42.687: INFO: Waiting for pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc to disappear
Aug 24 09:38:42.696: INFO: Pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 09:38:42.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3493" for this suite. 08/24/22 09:38:42.703
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":44,"skipped":780,"failed":0}
------------------------------
• [4.195 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:38.52
    Aug 24 09:38:38.521: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:38:38.523
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:38.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:38.567
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-afa483e3-8292-4204-9206-c38e1bb3c8b7 08/24/22 09:38:38.574
    STEP: Creating a pod to test consume configMaps 08/24/22 09:38:38.585
    Aug 24 09:38:38.606: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc" in namespace "projected-3493" to be "Succeeded or Failed"
    Aug 24 09:38:38.617: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.88559ms
    Aug 24 09:38:40.625: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018951103s
    Aug 24 09:38:42.624: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018032127s
    STEP: Saw pod success 08/24/22 09:38:42.624
    Aug 24 09:38:42.625: INFO: Pod "pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc" satisfied condition "Succeeded or Failed"
    Aug 24 09:38:42.644: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 09:38:42.657
    Aug 24 09:38:42.687: INFO: Waiting for pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc to disappear
    Aug 24 09:38:42.696: INFO: Pod pod-projected-configmaps-d3a6c232-558d-466a-bdcb-e078c00505cc no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 09:38:42.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3493" for this suite. 08/24/22 09:38:42.703
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:42.716
Aug 24 09:38:42.717: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 09:38:42.721
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:42.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:42.776
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/24/22 09:38:42.793
Aug 24 09:38:42.815: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4904" to be "running and ready"
Aug 24 09:38:42.824: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.91819ms
Aug 24 09:38:42.824: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:38:44.832: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016289918s
Aug 24 09:38:44.832: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 24 09:38:44.832: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 08/24/22 09:38:44.84
Aug 24 09:38:44.851: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4904" to be "running and ready"
Aug 24 09:38:44.858: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.141915ms
Aug 24 09:38:44.858: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:38:46.867: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015936743s
Aug 24 09:38:46.867: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Aug 24 09:38:46.867: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/24/22 09:38:46.874
STEP: delete the pod with lifecycle hook 08/24/22 09:38:46.909
Aug 24 09:38:46.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 09:38:46.988: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 24 09:38:48.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 09:38:49.000: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 24 09:38:50.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 09:38:50.996: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 24 09:38:50.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4904" for this suite. 08/24/22 09:38:51.004
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":45,"skipped":782,"failed":0}
------------------------------
• [SLOW TEST] [8.300 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:42.716
    Aug 24 09:38:42.717: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 09:38:42.721
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:42.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:42.776
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/24/22 09:38:42.793
    Aug 24 09:38:42.815: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4904" to be "running and ready"
    Aug 24 09:38:42.824: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.91819ms
    Aug 24 09:38:42.824: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:38:44.832: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016289918s
    Aug 24 09:38:44.832: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 24 09:38:44.832: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 08/24/22 09:38:44.84
    Aug 24 09:38:44.851: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4904" to be "running and ready"
    Aug 24 09:38:44.858: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.141915ms
    Aug 24 09:38:44.858: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:38:46.867: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015936743s
    Aug 24 09:38:46.867: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Aug 24 09:38:46.867: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/24/22 09:38:46.874
    STEP: delete the pod with lifecycle hook 08/24/22 09:38:46.909
    Aug 24 09:38:46.982: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 24 09:38:46.988: INFO: Pod pod-with-poststart-exec-hook still exists
    Aug 24 09:38:48.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 24 09:38:49.000: INFO: Pod pod-with-poststart-exec-hook still exists
    Aug 24 09:38:50.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 24 09:38:50.996: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 24 09:38:50.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4904" for this suite. 08/24/22 09:38:51.004
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:51.018
Aug 24 09:38:51.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 09:38:51.027
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:51.067
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:51.07
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/24/22 09:38:51.075
Aug 24 09:38:51.092: INFO: Waiting up to 5m0s for pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc" in namespace "emptydir-7487" to be "Succeeded or Failed"
Aug 24 09:38:51.100: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.952796ms
Aug 24 09:38:53.112: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019503622s
Aug 24 09:38:55.109: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016622054s
STEP: Saw pod success 08/24/22 09:38:55.109
Aug 24 09:38:55.109: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc" satisfied condition "Succeeded or Failed"
Aug 24 09:38:55.114: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc container test-container: <nil>
STEP: delete the pod 08/24/22 09:38:55.13
Aug 24 09:38:55.149: INFO: Waiting for pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc to disappear
Aug 24 09:38:55.153: INFO: Pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 09:38:55.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7487" for this suite. 08/24/22 09:38:55.162
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":46,"skipped":782,"failed":0}
------------------------------
• [4.155 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:51.018
    Aug 24 09:38:51.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 09:38:51.027
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:51.067
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:51.07
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/24/22 09:38:51.075
    Aug 24 09:38:51.092: INFO: Waiting up to 5m0s for pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc" in namespace "emptydir-7487" to be "Succeeded or Failed"
    Aug 24 09:38:51.100: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.952796ms
    Aug 24 09:38:53.112: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019503622s
    Aug 24 09:38:55.109: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016622054s
    STEP: Saw pod success 08/24/22 09:38:55.109
    Aug 24 09:38:55.109: INFO: Pod "pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc" satisfied condition "Succeeded or Failed"
    Aug 24 09:38:55.114: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc container test-container: <nil>
    STEP: delete the pod 08/24/22 09:38:55.13
    Aug 24 09:38:55.149: INFO: Waiting for pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc to disappear
    Aug 24 09:38:55.153: INFO: Pod pod-82a0e425-209f-40f8-9c1e-78a10b4c8bbc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 09:38:55.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7487" for this suite. 08/24/22 09:38:55.162
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:38:55.18
Aug 24 09:38:55.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 09:38:55.184
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:55.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:55.233
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 in namespace container-probe-4002 08/24/22 09:38:55.24
Aug 24 09:38:55.255: INFO: Waiting up to 5m0s for pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536" in namespace "container-probe-4002" to be "not pending"
Aug 24 09:38:55.263: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536": Phase="Pending", Reason="", readiness=false. Elapsed: 7.917244ms
Aug 24 09:38:57.271: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536": Phase="Running", Reason="", readiness=true. Elapsed: 2.016113594s
Aug 24 09:38:57.271: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536" satisfied condition "not pending"
Aug 24 09:38:57.272: INFO: Started pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 in namespace container-probe-4002
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:38:57.272
Aug 24 09:38:57.279: INFO: Initial restart count of pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 is 0
STEP: deleting the pod 08/24/22 09:42:58.282
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 09:42:58.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4002" for this suite. 08/24/22 09:42:58.331
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":47,"skipped":789,"failed":0}
------------------------------
• [SLOW TEST] [243.173 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:38:55.18
    Aug 24 09:38:55.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 09:38:55.184
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:38:55.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:38:55.233
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 in namespace container-probe-4002 08/24/22 09:38:55.24
    Aug 24 09:38:55.255: INFO: Waiting up to 5m0s for pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536" in namespace "container-probe-4002" to be "not pending"
    Aug 24 09:38:55.263: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536": Phase="Pending", Reason="", readiness=false. Elapsed: 7.917244ms
    Aug 24 09:38:57.271: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536": Phase="Running", Reason="", readiness=true. Elapsed: 2.016113594s
    Aug 24 09:38:57.271: INFO: Pod "test-webserver-a5d9117a-5922-4718-9101-1ce814411536" satisfied condition "not pending"
    Aug 24 09:38:57.272: INFO: Started pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 in namespace container-probe-4002
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:38:57.272
    Aug 24 09:38:57.279: INFO: Initial restart count of pod test-webserver-a5d9117a-5922-4718-9101-1ce814411536 is 0
    STEP: deleting the pod 08/24/22 09:42:58.282
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 09:42:58.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4002" for this suite. 08/24/22 09:42:58.331
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:42:58.377
Aug 24 09:42:58.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:42:58.381
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:42:58.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:42:58.431
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-359a2fff-8a71-4cde-9986-f980d7996069 08/24/22 09:42:58.436
STEP: Creating secret with name secret-projected-all-test-volume-d8eecdfa-f6f6-449e-8e28-7b4b6d42b048 08/24/22 09:42:58.449
STEP: Creating a pod to test Check all projections for projected volume plugin 08/24/22 09:42:58.463
Aug 24 09:42:58.485: INFO: Waiting up to 5m0s for pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755" in namespace "projected-9934" to be "Succeeded or Failed"
Aug 24 09:42:58.496: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Pending", Reason="", readiness=false. Elapsed: 10.801358ms
Aug 24 09:43:00.505: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019459014s
Aug 24 09:43:02.514: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028369439s
STEP: Saw pod success 08/24/22 09:43:02.515
Aug 24 09:43:02.516: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755" satisfied condition "Succeeded or Failed"
Aug 24 09:43:02.523: INFO: Trying to get logs from node kah9uighaagh-3 pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 container projected-all-volume-test: <nil>
STEP: delete the pod 08/24/22 09:43:02.553
Aug 24 09:43:02.577: INFO: Waiting for pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 to disappear
Aug 24 09:43:02.586: INFO: Pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Aug 24 09:43:02.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9934" for this suite. 08/24/22 09:43:02.594
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":48,"skipped":851,"failed":0}
------------------------------
• [4.230 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:42:58.377
    Aug 24 09:42:58.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:42:58.381
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:42:58.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:42:58.431
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-359a2fff-8a71-4cde-9986-f980d7996069 08/24/22 09:42:58.436
    STEP: Creating secret with name secret-projected-all-test-volume-d8eecdfa-f6f6-449e-8e28-7b4b6d42b048 08/24/22 09:42:58.449
    STEP: Creating a pod to test Check all projections for projected volume plugin 08/24/22 09:42:58.463
    Aug 24 09:42:58.485: INFO: Waiting up to 5m0s for pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755" in namespace "projected-9934" to be "Succeeded or Failed"
    Aug 24 09:42:58.496: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Pending", Reason="", readiness=false. Elapsed: 10.801358ms
    Aug 24 09:43:00.505: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019459014s
    Aug 24 09:43:02.514: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028369439s
    STEP: Saw pod success 08/24/22 09:43:02.515
    Aug 24 09:43:02.516: INFO: Pod "projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755" satisfied condition "Succeeded or Failed"
    Aug 24 09:43:02.523: INFO: Trying to get logs from node kah9uighaagh-3 pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 container projected-all-volume-test: <nil>
    STEP: delete the pod 08/24/22 09:43:02.553
    Aug 24 09:43:02.577: INFO: Waiting for pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 to disappear
    Aug 24 09:43:02.586: INFO: Pod projected-volume-19156f4e-b7e3-47b2-86ed-42a82e130755 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Aug 24 09:43:02.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9934" for this suite. 08/24/22 09:43:02.594
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:43:02.612
Aug 24 09:43:02.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 09:43:02.62
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:43:02.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:43:02.652
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 in namespace container-probe-5270 08/24/22 09:43:02.656
Aug 24 09:43:02.671: INFO: Waiting up to 5m0s for pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1" in namespace "container-probe-5270" to be "not pending"
Aug 24 09:43:02.677: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.258158ms
Aug 24 09:43:04.686: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014877402s
Aug 24 09:43:04.686: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1" satisfied condition "not pending"
Aug 24 09:43:04.686: INFO: Started pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 in namespace container-probe-5270
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:43:04.686
Aug 24 09:43:04.692: INFO: Initial restart count of pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 is 0
Aug 24 09:43:24.783: INFO: Restart count of pod container-probe-5270/liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 is now 1 (20.0907615s elapsed)
STEP: deleting the pod 08/24/22 09:43:24.783
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 09:43:24.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5270" for this suite. 08/24/22 09:43:24.82
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":49,"skipped":873,"failed":0}
------------------------------
• [SLOW TEST] [22.220 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:43:02.612
    Aug 24 09:43:02.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 09:43:02.62
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:43:02.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:43:02.652
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 in namespace container-probe-5270 08/24/22 09:43:02.656
    Aug 24 09:43:02.671: INFO: Waiting up to 5m0s for pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1" in namespace "container-probe-5270" to be "not pending"
    Aug 24 09:43:02.677: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.258158ms
    Aug 24 09:43:04.686: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1": Phase="Running", Reason="", readiness=true. Elapsed: 2.014877402s
    Aug 24 09:43:04.686: INFO: Pod "liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1" satisfied condition "not pending"
    Aug 24 09:43:04.686: INFO: Started pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 in namespace container-probe-5270
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:43:04.686
    Aug 24 09:43:04.692: INFO: Initial restart count of pod liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 is 0
    Aug 24 09:43:24.783: INFO: Restart count of pod container-probe-5270/liveness-7d6aa8f9-a28d-48a6-879d-0fc129c33ca1 is now 1 (20.0907615s elapsed)
    STEP: deleting the pod 08/24/22 09:43:24.783
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 09:43:24.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5270" for this suite. 08/24/22 09:43:24.82
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:43:24.844
Aug 24 09:43:24.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename taint-multiple-pods 08/24/22 09:43:24.846
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:43:24.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:43:24.881
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Aug 24 09:43:24.885: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 09:44:24.927: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Aug 24 09:44:24.935: INFO: Starting informer...
STEP: Starting pods... 08/24/22 09:44:24.935
Aug 24 09:44:25.176: INFO: Pod1 is running on kah9uighaagh-3. Tainting Node
Aug 24 09:44:25.403: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-2575" to be "running"
Aug 24 09:44:25.409: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.204375ms
Aug 24 09:44:27.415: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142749s
Aug 24 09:44:27.416: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Aug 24 09:44:27.416: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-2575" to be "running"
Aug 24 09:44:27.425: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 9.300345ms
Aug 24 09:44:27.425: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Aug 24 09:44:27.425: INFO: Pod2 is running on kah9uighaagh-3. Tainting Node
STEP: Trying to apply a taint on the Node 08/24/22 09:44:27.425
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 09:44:27.458
STEP: Waiting for Pod1 and Pod2 to be deleted 08/24/22 09:44:27.471
Aug 24 09:44:33.342: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug 24 09:44:54.193: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 09:44:54.227
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:44:54.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-2575" for this suite. 08/24/22 09:44:54.241
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":50,"skipped":908,"failed":0}
------------------------------
• [SLOW TEST] [89.415 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:43:24.844
    Aug 24 09:43:24.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename taint-multiple-pods 08/24/22 09:43:24.846
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:43:24.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:43:24.881
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Aug 24 09:43:24.885: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 09:44:24.927: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Aug 24 09:44:24.935: INFO: Starting informer...
    STEP: Starting pods... 08/24/22 09:44:24.935
    Aug 24 09:44:25.176: INFO: Pod1 is running on kah9uighaagh-3. Tainting Node
    Aug 24 09:44:25.403: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-2575" to be "running"
    Aug 24 09:44:25.409: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.204375ms
    Aug 24 09:44:27.415: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142749s
    Aug 24 09:44:27.416: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Aug 24 09:44:27.416: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-2575" to be "running"
    Aug 24 09:44:27.425: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 9.300345ms
    Aug 24 09:44:27.425: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Aug 24 09:44:27.425: INFO: Pod2 is running on kah9uighaagh-3. Tainting Node
    STEP: Trying to apply a taint on the Node 08/24/22 09:44:27.425
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 09:44:27.458
    STEP: Waiting for Pod1 and Pod2 to be deleted 08/24/22 09:44:27.471
    Aug 24 09:44:33.342: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Aug 24 09:44:54.193: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 09:44:54.227
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:44:54.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-2575" for this suite. 08/24/22 09:44:54.241
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:44:54.302
Aug 24 09:44:54.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 09:44:54.309
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:44:54.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:44:54.363
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 09:44:54.404
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:44:55.014
STEP: Deploying the webhook pod 08/24/22 09:44:55.029
STEP: Wait for the deployment to be ready 08/24/22 09:44:55.056
Aug 24 09:44:55.074: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 09:44:57.096
STEP: Verifying the service has paired with the endpoint 08/24/22 09:44:57.115
Aug 24 09:44:58.115: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 08/24/22 09:44:58.122
STEP: Creating a custom resource definition that should be denied by the webhook 08/24/22 09:44:58.156
Aug 24 09:44:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:44:58.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7695" for this suite. 08/24/22 09:44:58.197
STEP: Destroying namespace "webhook-7695-markers" for this suite. 08/24/22 09:44:58.208
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":51,"skipped":1015,"failed":0}
------------------------------
• [4.011 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:44:54.302
    Aug 24 09:44:54.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 09:44:54.309
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:44:54.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:44:54.363
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 09:44:54.404
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 09:44:55.014
    STEP: Deploying the webhook pod 08/24/22 09:44:55.029
    STEP: Wait for the deployment to be ready 08/24/22 09:44:55.056
    Aug 24 09:44:55.074: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 09:44:57.096
    STEP: Verifying the service has paired with the endpoint 08/24/22 09:44:57.115
    Aug 24 09:44:58.115: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 08/24/22 09:44:58.122
    STEP: Creating a custom resource definition that should be denied by the webhook 08/24/22 09:44:58.156
    Aug 24 09:44:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:44:58.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7695" for this suite. 08/24/22 09:44:58.197
    STEP: Destroying namespace "webhook-7695-markers" for this suite. 08/24/22 09:44:58.208
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:44:58.318
Aug 24 09:44:58.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replication-controller 08/24/22 09:44:58.32
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:44:58.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:44:58.366
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 08/24/22 09:44:58.385
Aug 24 09:44:58.400: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-3428" to be "running and ready"
Aug 24 09:44:58.406: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.553916ms
Aug 24 09:44:58.406: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:45:00.414: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.013698601s
Aug 24 09:45:00.414: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Aug 24 09:45:00.414: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 08/24/22 09:45:00.42
STEP: Then the orphan pod is adopted 08/24/22 09:45:00.428
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 24 09:45:01.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3428" for this suite. 08/24/22 09:45:01.447
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":52,"skipped":1023,"failed":0}
------------------------------
• [3.141 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:44:58.318
    Aug 24 09:44:58.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replication-controller 08/24/22 09:44:58.32
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:44:58.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:44:58.366
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 08/24/22 09:44:58.385
    Aug 24 09:44:58.400: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-3428" to be "running and ready"
    Aug 24 09:44:58.406: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.553916ms
    Aug 24 09:44:58.406: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:45:00.414: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.013698601s
    Aug 24 09:45:00.414: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Aug 24 09:45:00.414: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 08/24/22 09:45:00.42
    STEP: Then the orphan pod is adopted 08/24/22 09:45:00.428
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 24 09:45:01.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3428" for this suite. 08/24/22 09:45:01.447
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:01.464
Aug 24 09:45:01.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 09:45:01.469
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:01.496
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:01.507
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 08/24/22 09:45:01.514
STEP: Counting existing ResourceQuota 08/24/22 09:45:06.524
STEP: Creating a ResourceQuota 08/24/22 09:45:11.532
STEP: Ensuring resource quota status is calculated 08/24/22 09:45:11.544
STEP: Creating a Secret 08/24/22 09:45:13.554
STEP: Ensuring resource quota status captures secret creation 08/24/22 09:45:13.575
STEP: Deleting a secret 08/24/22 09:45:15.636
STEP: Ensuring resource quota status released usage 08/24/22 09:45:15.655
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 09:45:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6493" for this suite. 08/24/22 09:45:17.686
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":53,"skipped":1027,"failed":0}
------------------------------
• [SLOW TEST] [16.238 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:01.464
    Aug 24 09:45:01.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 09:45:01.469
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:01.496
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:01.507
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 08/24/22 09:45:01.514
    STEP: Counting existing ResourceQuota 08/24/22 09:45:06.524
    STEP: Creating a ResourceQuota 08/24/22 09:45:11.532
    STEP: Ensuring resource quota status is calculated 08/24/22 09:45:11.544
    STEP: Creating a Secret 08/24/22 09:45:13.554
    STEP: Ensuring resource quota status captures secret creation 08/24/22 09:45:13.575
    STEP: Deleting a secret 08/24/22 09:45:15.636
    STEP: Ensuring resource quota status released usage 08/24/22 09:45:15.655
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 09:45:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6493" for this suite. 08/24/22 09:45:17.686
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:17.705
Aug 24 09:45:17.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 09:45:17.71
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:17.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:17.755
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Aug 24 09:45:17.809: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 24 09:45:22.818: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 09:45:22.819
Aug 24 09:45:22.819: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 24 09:45:24.828: INFO: Creating deployment "test-rollover-deployment"
Aug 24 09:45:24.846: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 24 09:45:26.860: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 24 09:45:26.872: INFO: Ensure that both replica sets have 1 created replica
Aug 24 09:45:26.886: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 24 09:45:26.919: INFO: Updating deployment test-rollover-deployment
Aug 24 09:45:26.919: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 24 09:45:28.937: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 24 09:45:28.951: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 24 09:45:28.962: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 09:45:28.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:45:30.977: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 09:45:30.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:45:32.982: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 09:45:32.982: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:45:34.981: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 09:45:34.981: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:45:36.976: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 09:45:36.976: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 09:45:38.979: INFO: 
Aug 24 09:45:38.979: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 09:45:39.007: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-6694  9085a733-ed96-4404-ab57-85cb93044809 11086 2 2022-08-24 09:45:24 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-24 09:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc88a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 09:45:24 +0000 UTC,LastTransitionTime:2022-08-24 09:45:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-08-24 09:45:38 +0000 UTC,LastTransitionTime:2022-08-24 09:45:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 09:45:39.014: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-6694  5f11d54e-9bab-4050-91f0-13633e8f419d 11076 2 2022-08-24 09:45:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8e97 0xc002dc8e98}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc8f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:45:39.014: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 24 09:45:39.015: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-6694  f77a2c09-ec34-420e-a438-8ad4d3e3a328 11085 2 2022-08-24 09:45:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8c47 0xc002dc8c48}] [] [{e2e.test Update apps/v1 2022-08-24 09:45:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002dc8d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:45:39.015: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-6694  4d3b72ed-0d18-4db8-945e-1455dd64bef2 11042 2 2022-08-24 09:45:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8d77 0xc002dc8d78}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc8e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:45:39.028: INFO: Pod "test-rollover-deployment-6d45fd857b-mzl5t" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-mzl5t test-rollover-deployment-6d45fd857b- deployment-6694  cf4673e9-1bdc-4100-beac-ba558594831d 11058 0 2022-08-24 09:45:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 5f11d54e-9bab-4050-91f0-13633e8f419d 0xc002dc9497 0xc002dc9498}] [] [{kube-controller-manager Update v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f11d54e-9bab-4050-91f0-13633e8f419d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.124\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gtpvf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gtpvf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.124,StartTime:2022-08-24 09:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:45:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787,ContainerID:cri-o://8f1226ec823a5109b42e04436980c16a503165c9a166377011db8a9580ee88d1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.124,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 09:45:39.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6694" for this suite. 08/24/22 09:45:39.037
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":54,"skipped":1032,"failed":0}
------------------------------
• [SLOW TEST] [21.344 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:17.705
    Aug 24 09:45:17.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 09:45:17.71
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:17.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:17.755
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Aug 24 09:45:17.809: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Aug 24 09:45:22.818: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 09:45:22.819
    Aug 24 09:45:22.819: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Aug 24 09:45:24.828: INFO: Creating deployment "test-rollover-deployment"
    Aug 24 09:45:24.846: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Aug 24 09:45:26.860: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Aug 24 09:45:26.872: INFO: Ensure that both replica sets have 1 created replica
    Aug 24 09:45:26.886: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Aug 24 09:45:26.919: INFO: Updating deployment test-rollover-deployment
    Aug 24 09:45:26.919: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Aug 24 09:45:28.937: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Aug 24 09:45:28.951: INFO: Make sure deployment "test-rollover-deployment" is complete
    Aug 24 09:45:28.962: INFO: all replica sets need to contain the pod-template-hash label
    Aug 24 09:45:28.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:45:30.977: INFO: all replica sets need to contain the pod-template-hash label
    Aug 24 09:45:30.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:45:32.982: INFO: all replica sets need to contain the pod-template-hash label
    Aug 24 09:45:32.982: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:45:34.981: INFO: all replica sets need to contain the pod-template-hash label
    Aug 24 09:45:34.981: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:45:36.976: INFO: all replica sets need to contain the pod-template-hash label
    Aug 24 09:45:36.976: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 45, 28, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 45, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 09:45:38.979: INFO: 
    Aug 24 09:45:38.979: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 09:45:39.007: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-6694  9085a733-ed96-4404-ab57-85cb93044809 11086 2 2022-08-24 09:45:24 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-24 09:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc88a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 09:45:24 +0000 UTC,LastTransitionTime:2022-08-24 09:45:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-08-24 09:45:38 +0000 UTC,LastTransitionTime:2022-08-24 09:45:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 24 09:45:39.014: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-6694  5f11d54e-9bab-4050-91f0-13633e8f419d 11076 2 2022-08-24 09:45:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8e97 0xc002dc8e98}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc8f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:45:39.014: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Aug 24 09:45:39.015: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-6694  f77a2c09-ec34-420e-a438-8ad4d3e3a328 11085 2 2022-08-24 09:45:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8c47 0xc002dc8c48}] [] [{e2e.test Update apps/v1 2022-08-24 09:45:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002dc8d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:45:39.015: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-6694  4d3b72ed-0d18-4db8-945e-1455dd64bef2 11042 2 2022-08-24 09:45:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9085a733-ed96-4404-ab57-85cb93044809 0xc002dc8d77 0xc002dc8d78}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9085a733-ed96-4404-ab57-85cb93044809\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dc8e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:45:39.028: INFO: Pod "test-rollover-deployment-6d45fd857b-mzl5t" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-mzl5t test-rollover-deployment-6d45fd857b- deployment-6694  cf4673e9-1bdc-4100-beac-ba558594831d 11058 0 2022-08-24 09:45:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 5f11d54e-9bab-4050-91f0-13633e8f419d 0xc002dc9497 0xc002dc9498}] [] [{kube-controller-manager Update v1 2022-08-24 09:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f11d54e-9bab-4050-91f0-13633e8f419d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.124\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gtpvf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gtpvf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.124,StartTime:2022-08-24 09:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:45:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787,ContainerID:cri-o://8f1226ec823a5109b42e04436980c16a503165c9a166377011db8a9580ee88d1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.124,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 09:45:39.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6694" for this suite. 08/24/22 09:45:39.037
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:39.052
Aug 24 09:45:39.052: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 09:45:39.057
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:39.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:39.096
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 08/24/22 09:45:39.102
STEP: Verify that the required pods have come up 08/24/22 09:45:39.111
Aug 24 09:45:39.117: INFO: Pod name sample-pod: Found 0 pods out of 3
Aug 24 09:45:44.128: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 08/24/22 09:45:44.128
Aug 24 09:45:44.133: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 08/24/22 09:45:44.133
STEP: DeleteCollection of the ReplicaSets 08/24/22 09:45:44.138
STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/24/22 09:45:44.152
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 09:45:44.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1587" for this suite. 08/24/22 09:45:44.165
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":55,"skipped":1034,"failed":0}
------------------------------
• [SLOW TEST] [5.124 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:39.052
    Aug 24 09:45:39.052: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 09:45:39.057
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:39.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:39.096
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 08/24/22 09:45:39.102
    STEP: Verify that the required pods have come up 08/24/22 09:45:39.111
    Aug 24 09:45:39.117: INFO: Pod name sample-pod: Found 0 pods out of 3
    Aug 24 09:45:44.128: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 08/24/22 09:45:44.128
    Aug 24 09:45:44.133: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 08/24/22 09:45:44.133
    STEP: DeleteCollection of the ReplicaSets 08/24/22 09:45:44.138
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/24/22 09:45:44.152
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 09:45:44.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1587" for this suite. 08/24/22 09:45:44.165
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:44.185
Aug 24 09:45:44.185: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 09:45:44.187
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:44.275
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:44.282
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 08/24/22 09:45:44.287
STEP: submitting the pod to kubernetes 08/24/22 09:45:44.288
Aug 24 09:45:44.304: INFO: Waiting up to 5m0s for pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" in namespace "pods-348" to be "running and ready"
Aug 24 09:45:44.312: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.708881ms
Aug 24 09:45:44.312: INFO: The phase of Pod pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:45:46.319: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.014792279s
Aug 24 09:45:46.319: INFO: The phase of Pod pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7 is Running (Ready = true)
Aug 24 09:45:46.319: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/24/22 09:45:46.324
STEP: updating the pod 08/24/22 09:45:46.328
Aug 24 09:45:46.853: INFO: Successfully updated pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7"
Aug 24 09:45:46.853: INFO: Waiting up to 5m0s for pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" in namespace "pods-348" to be "running"
Aug 24 09:45:46.858: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Running", Reason="", readiness=true. Elapsed: 4.869199ms
Aug 24 09:45:46.858: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 08/24/22 09:45:46.858
Aug 24 09:45:46.864: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 09:45:46.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-348" for this suite. 08/24/22 09:45:46.87
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":56,"skipped":1065,"failed":0}
------------------------------
• [2.697 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:44.185
    Aug 24 09:45:44.185: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 09:45:44.187
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:44.275
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:44.282
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 08/24/22 09:45:44.287
    STEP: submitting the pod to kubernetes 08/24/22 09:45:44.288
    Aug 24 09:45:44.304: INFO: Waiting up to 5m0s for pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" in namespace "pods-348" to be "running and ready"
    Aug 24 09:45:44.312: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.708881ms
    Aug 24 09:45:44.312: INFO: The phase of Pod pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:45:46.319: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.014792279s
    Aug 24 09:45:46.319: INFO: The phase of Pod pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7 is Running (Ready = true)
    Aug 24 09:45:46.319: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/24/22 09:45:46.324
    STEP: updating the pod 08/24/22 09:45:46.328
    Aug 24 09:45:46.853: INFO: Successfully updated pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7"
    Aug 24 09:45:46.853: INFO: Waiting up to 5m0s for pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" in namespace "pods-348" to be "running"
    Aug 24 09:45:46.858: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7": Phase="Running", Reason="", readiness=true. Elapsed: 4.869199ms
    Aug 24 09:45:46.858: INFO: Pod "pod-update-45a116b8-198f-4ea3-a06d-4d4ecb844fb7" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 08/24/22 09:45:46.858
    Aug 24 09:45:46.864: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 09:45:46.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-348" for this suite. 08/24/22 09:45:46.87
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:46.887
Aug 24 09:45:46.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename proxy 08/24/22 09:45:46.89
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:46.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:46.939
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Aug 24 09:45:46.943: INFO: Creating pod...
Aug 24 09:45:46.955: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4641" to be "running"
Aug 24 09:45:46.961: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.415894ms
Aug 24 09:45:48.968: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.013063884s
Aug 24 09:45:48.968: INFO: Pod "agnhost" satisfied condition "running"
Aug 24 09:45:48.968: INFO: Creating service...
Aug 24 09:45:48.986: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/DELETE
Aug 24 09:45:49.013: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 09:45:49.013: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/GET
Aug 24 09:45:49.022: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 24 09:45:49.023: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/HEAD
Aug 24 09:45:49.029: INFO: http.Client request:HEAD | StatusCode:200
Aug 24 09:45:49.030: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/OPTIONS
Aug 24 09:45:49.038: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 09:45:49.039: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/PATCH
Aug 24 09:45:49.045: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 09:45:49.045: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/POST
Aug 24 09:45:49.078: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 09:45:49.078: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/PUT
Aug 24 09:45:49.089: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 24 09:45:49.089: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/DELETE
Aug 24 09:45:49.103: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 09:45:49.103: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/GET
Aug 24 09:45:49.121: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 24 09:45:49.121: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/HEAD
Aug 24 09:45:49.131: INFO: http.Client request:HEAD | StatusCode:200
Aug 24 09:45:49.131: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/OPTIONS
Aug 24 09:45:49.141: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 09:45:49.141: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/PATCH
Aug 24 09:45:49.163: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 09:45:49.163: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/POST
Aug 24 09:45:49.173: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 09:45:49.173: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/PUT
Aug 24 09:45:49.182: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 24 09:45:49.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4641" for this suite. 08/24/22 09:45:49.19
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":57,"skipped":1085,"failed":0}
------------------------------
• [2.316 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:46.887
    Aug 24 09:45:46.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename proxy 08/24/22 09:45:46.89
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:46.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:46.939
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Aug 24 09:45:46.943: INFO: Creating pod...
    Aug 24 09:45:46.955: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4641" to be "running"
    Aug 24 09:45:46.961: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.415894ms
    Aug 24 09:45:48.968: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.013063884s
    Aug 24 09:45:48.968: INFO: Pod "agnhost" satisfied condition "running"
    Aug 24 09:45:48.968: INFO: Creating service...
    Aug 24 09:45:48.986: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/DELETE
    Aug 24 09:45:49.013: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 24 09:45:49.013: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/GET
    Aug 24 09:45:49.022: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 24 09:45:49.023: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/HEAD
    Aug 24 09:45:49.029: INFO: http.Client request:HEAD | StatusCode:200
    Aug 24 09:45:49.030: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/OPTIONS
    Aug 24 09:45:49.038: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 24 09:45:49.039: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/PATCH
    Aug 24 09:45:49.045: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 24 09:45:49.045: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/POST
    Aug 24 09:45:49.078: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 24 09:45:49.078: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/pods/agnhost/proxy/some/path/with/PUT
    Aug 24 09:45:49.089: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 24 09:45:49.089: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/DELETE
    Aug 24 09:45:49.103: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 24 09:45:49.103: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/GET
    Aug 24 09:45:49.121: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 24 09:45:49.121: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/HEAD
    Aug 24 09:45:49.131: INFO: http.Client request:HEAD | StatusCode:200
    Aug 24 09:45:49.131: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/OPTIONS
    Aug 24 09:45:49.141: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 24 09:45:49.141: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/PATCH
    Aug 24 09:45:49.163: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 24 09:45:49.163: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/POST
    Aug 24 09:45:49.173: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 24 09:45:49.173: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4641/services/test-service/proxy/some/path/with/PUT
    Aug 24 09:45:49.182: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 24 09:45:49.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4641" for this suite. 08/24/22 09:45:49.19
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:49.219
Aug 24 09:45:49.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:45:49.221
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:49.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:49.282
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 08/24/22 09:45:49.312
Aug 24 09:45:49.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 24 09:45:49.721: INFO: stderr: ""
Aug 24 09:45:49.721: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 08/24/22 09:45:49.721
Aug 24 09:45:49.722: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 24 09:45:49.722: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3949" to be "running and ready, or succeeded"
Aug 24 09:45:49.727: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.795527ms
Aug 24 09:45:49.728: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'kah9uighaagh-3' to be 'Running' but was 'Pending'
Aug 24 09:45:51.740: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01826849s
Aug 24 09:45:51.740: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 24 09:45:51.740: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 08/24/22 09:45:51.74
Aug 24 09:45:51.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator'
Aug 24 09:45:51.909: INFO: stderr: ""
Aug 24 09:45:51.909: INFO: stdout: "I0824 09:45:50.565049       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/x6lg 356\nI0824 09:45:50.765169       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4km 366\nI0824 09:45:50.965802       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/hnw 287\nI0824 09:45:51.165195       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9cg 521\nI0824 09:45:51.365643       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/5m99 453\nI0824 09:45:51.566229       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/jks 241\nI0824 09:45:51.765709       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/pcr 585\n"
STEP: limiting log lines 08/24/22 09:45:51.909
Aug 24 09:45:51.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --tail=1'
Aug 24 09:45:52.124: INFO: stderr: ""
Aug 24 09:45:52.124: INFO: stdout: "I0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\n"
Aug 24 09:45:52.124: INFO: got output "I0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\n"
STEP: limiting log bytes 08/24/22 09:45:52.124
Aug 24 09:45:52.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --limit-bytes=1'
Aug 24 09:45:52.326: INFO: stderr: ""
Aug 24 09:45:52.326: INFO: stdout: "I"
Aug 24 09:45:52.326: INFO: got output "I"
STEP: exposing timestamps 08/24/22 09:45:52.326
Aug 24 09:45:52.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --tail=1 --timestamps'
Aug 24 09:45:52.535: INFO: stderr: ""
Aug 24 09:45:52.535: INFO: stdout: "2022-08-24T09:45:52.367461711Z I0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\n"
Aug 24 09:45:52.535: INFO: got output "2022-08-24T09:45:52.367461711Z I0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\n"
STEP: restricting to a time range 08/24/22 09:45:52.535
Aug 24 09:45:55.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --since=1s'
Aug 24 09:45:55.291: INFO: stderr: ""
Aug 24 09:45:55.291: INFO: stdout: "I0824 09:45:54.365381       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/vdfx 357\nI0824 09:45:54.565902       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/9t8 520\nI0824 09:45:54.765258       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jq6w 590\nI0824 09:45:54.966324       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/55rp 592\nI0824 09:45:55.166154       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/g2tw 485\n"
Aug 24 09:45:55.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --since=24h'
Aug 24 09:45:55.478: INFO: stderr: ""
Aug 24 09:45:55.478: INFO: stdout: "I0824 09:45:50.565049       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/x6lg 356\nI0824 09:45:50.765169       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4km 366\nI0824 09:45:50.965802       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/hnw 287\nI0824 09:45:51.165195       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9cg 521\nI0824 09:45:51.365643       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/5m99 453\nI0824 09:45:51.566229       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/jks 241\nI0824 09:45:51.765709       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/pcr 585\nI0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\nI0824 09:45:52.168979       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/m47d 210\nI0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\nI0824 09:45:52.565694       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/4nj 503\nI0824 09:45:52.766156       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/2w7h 545\nI0824 09:45:52.965343       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/j49 579\nI0824 09:45:53.165851       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/cb4c 429\nI0824 09:45:53.366144       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/s6v 426\nI0824 09:45:53.565806       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/7wmx 330\nI0824 09:45:53.765250       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/grk8 388\nI0824 09:45:53.965729       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/wm7 449\nI0824 09:45:54.165100       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/9xpg 569\nI0824 09:45:54.365381       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/vdfx 357\nI0824 09:45:54.565902       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/9t8 520\nI0824 09:45:54.765258       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jq6w 590\nI0824 09:45:54.966324       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/55rp 592\nI0824 09:45:55.166154       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/g2tw 485\nI0824 09:45:55.365622       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/ldtx 528\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Aug 24 09:45:55.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 delete pod logs-generator'
Aug 24 09:45:56.717: INFO: stderr: ""
Aug 24 09:45:56.717: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:45:56.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3949" for this suite. 08/24/22 09:45:56.73
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":58,"skipped":1113,"failed":0}
------------------------------
• [SLOW TEST] [7.531 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:49.219
    Aug 24 09:45:49.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:45:49.221
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:49.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:49.282
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 08/24/22 09:45:49.312
    Aug 24 09:45:49.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Aug 24 09:45:49.721: INFO: stderr: ""
    Aug 24 09:45:49.721: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 08/24/22 09:45:49.721
    Aug 24 09:45:49.722: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Aug 24 09:45:49.722: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3949" to be "running and ready, or succeeded"
    Aug 24 09:45:49.727: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.795527ms
    Aug 24 09:45:49.728: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'kah9uighaagh-3' to be 'Running' but was 'Pending'
    Aug 24 09:45:51.740: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01826849s
    Aug 24 09:45:51.740: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Aug 24 09:45:51.740: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 08/24/22 09:45:51.74
    Aug 24 09:45:51.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator'
    Aug 24 09:45:51.909: INFO: stderr: ""
    Aug 24 09:45:51.909: INFO: stdout: "I0824 09:45:50.565049       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/x6lg 356\nI0824 09:45:50.765169       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4km 366\nI0824 09:45:50.965802       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/hnw 287\nI0824 09:45:51.165195       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9cg 521\nI0824 09:45:51.365643       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/5m99 453\nI0824 09:45:51.566229       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/jks 241\nI0824 09:45:51.765709       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/pcr 585\n"
    STEP: limiting log lines 08/24/22 09:45:51.909
    Aug 24 09:45:51.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --tail=1'
    Aug 24 09:45:52.124: INFO: stderr: ""
    Aug 24 09:45:52.124: INFO: stdout: "I0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\n"
    Aug 24 09:45:52.124: INFO: got output "I0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\n"
    STEP: limiting log bytes 08/24/22 09:45:52.124
    Aug 24 09:45:52.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --limit-bytes=1'
    Aug 24 09:45:52.326: INFO: stderr: ""
    Aug 24 09:45:52.326: INFO: stdout: "I"
    Aug 24 09:45:52.326: INFO: got output "I"
    STEP: exposing timestamps 08/24/22 09:45:52.326
    Aug 24 09:45:52.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --tail=1 --timestamps'
    Aug 24 09:45:52.535: INFO: stderr: ""
    Aug 24 09:45:52.535: INFO: stdout: "2022-08-24T09:45:52.367461711Z I0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\n"
    Aug 24 09:45:52.535: INFO: got output "2022-08-24T09:45:52.367461711Z I0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\n"
    STEP: restricting to a time range 08/24/22 09:45:52.535
    Aug 24 09:45:55.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --since=1s'
    Aug 24 09:45:55.291: INFO: stderr: ""
    Aug 24 09:45:55.291: INFO: stdout: "I0824 09:45:54.365381       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/vdfx 357\nI0824 09:45:54.565902       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/9t8 520\nI0824 09:45:54.765258       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jq6w 590\nI0824 09:45:54.966324       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/55rp 592\nI0824 09:45:55.166154       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/g2tw 485\n"
    Aug 24 09:45:55.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 logs logs-generator logs-generator --since=24h'
    Aug 24 09:45:55.478: INFO: stderr: ""
    Aug 24 09:45:55.478: INFO: stdout: "I0824 09:45:50.565049       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/x6lg 356\nI0824 09:45:50.765169       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4km 366\nI0824 09:45:50.965802       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/hnw 287\nI0824 09:45:51.165195       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9cg 521\nI0824 09:45:51.365643       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/5m99 453\nI0824 09:45:51.566229       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/jks 241\nI0824 09:45:51.765709       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/pcr 585\nI0824 09:45:51.969034       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4glt 245\nI0824 09:45:52.168979       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/m47d 210\nI0824 09:45:52.365159       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/vg8 261\nI0824 09:45:52.565694       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/4nj 503\nI0824 09:45:52.766156       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/2w7h 545\nI0824 09:45:52.965343       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/j49 579\nI0824 09:45:53.165851       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/cb4c 429\nI0824 09:45:53.366144       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/s6v 426\nI0824 09:45:53.565806       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/7wmx 330\nI0824 09:45:53.765250       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/grk8 388\nI0824 09:45:53.965729       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/wm7 449\nI0824 09:45:54.165100       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/9xpg 569\nI0824 09:45:54.365381       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/vdfx 357\nI0824 09:45:54.565902       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/9t8 520\nI0824 09:45:54.765258       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jq6w 590\nI0824 09:45:54.966324       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/55rp 592\nI0824 09:45:55.166154       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/g2tw 485\nI0824 09:45:55.365622       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/ldtx 528\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Aug 24 09:45:55.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3949 delete pod logs-generator'
    Aug 24 09:45:56.717: INFO: stderr: ""
    Aug 24 09:45:56.717: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:45:56.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3949" for this suite. 08/24/22 09:45:56.73
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:45:56.754
Aug 24 09:45:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 09:45:56.759
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:56.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:56.793
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 08/24/22 09:45:56.798
Aug 24 09:45:56.810: INFO: Waiting up to 5m0s for pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00" in namespace "emptydir-5611" to be "Succeeded or Failed"
Aug 24 09:45:56.815: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Pending", Reason="", readiness=false. Elapsed: 5.038161ms
Aug 24 09:45:58.824: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Running", Reason="", readiness=false. Elapsed: 2.014285176s
Aug 24 09:46:00.824: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01437842s
STEP: Saw pod success 08/24/22 09:46:00.825
Aug 24 09:46:00.826: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00" satisfied condition "Succeeded or Failed"
Aug 24 09:46:00.833: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 container test-container: <nil>
STEP: delete the pod 08/24/22 09:46:00.866
Aug 24 09:46:00.886: INFO: Waiting for pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 to disappear
Aug 24 09:46:00.927: INFO: Pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 09:46:00.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5611" for this suite. 08/24/22 09:46:00.936
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":1134,"failed":0}
------------------------------
• [4.199 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:45:56.754
    Aug 24 09:45:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 09:45:56.759
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:45:56.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:45:56.793
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/24/22 09:45:56.798
    Aug 24 09:45:56.810: INFO: Waiting up to 5m0s for pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00" in namespace "emptydir-5611" to be "Succeeded or Failed"
    Aug 24 09:45:56.815: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Pending", Reason="", readiness=false. Elapsed: 5.038161ms
    Aug 24 09:45:58.824: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Running", Reason="", readiness=false. Elapsed: 2.014285176s
    Aug 24 09:46:00.824: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01437842s
    STEP: Saw pod success 08/24/22 09:46:00.825
    Aug 24 09:46:00.826: INFO: Pod "pod-164f0bd0-4e04-425d-9a01-a0652edcdc00" satisfied condition "Succeeded or Failed"
    Aug 24 09:46:00.833: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 container test-container: <nil>
    STEP: delete the pod 08/24/22 09:46:00.866
    Aug 24 09:46:00.886: INFO: Waiting for pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 to disappear
    Aug 24 09:46:00.927: INFO: Pod pod-164f0bd0-4e04-425d-9a01-a0652edcdc00 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 09:46:00.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5611" for this suite. 08/24/22 09:46:00.936
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:00.955
Aug 24 09:46:00.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 09:46:00.958
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:00.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:00.993
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 08/24/22 09:46:01.004
Aug 24 09:46:01.004: INFO: Creating simple deployment test-deployment-mwsg7
Aug 24 09:46:01.029: INFO: deployment "test-deployment-mwsg7" doesn't have the required revision set
STEP: Getting /status 08/24/22 09:46:03.055
Aug 24 09:46:03.068: INFO: Deployment test-deployment-mwsg7 has Conditions: [{Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 08/24/22 09:46:03.068
Aug 24 09:46:03.088: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 46, 1, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-mwsg7-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 08/24/22 09:46:03.088
Aug 24 09:46:03.093: INFO: Observed &Deployment event: ADDED
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mwsg7-777898ffcc" is progressing.}
Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
Aug 24 09:46:03.094: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.094: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 09:46:03.094: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
Aug 24 09:46:03.094: INFO: Found Deployment test-deployment-mwsg7 in namespace deployment-9903 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 09:46:03.094: INFO: Deployment test-deployment-mwsg7 has an updated status
STEP: patching the Statefulset Status 08/24/22 09:46:03.094
Aug 24 09:46:03.094: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 09:46:03.107: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 08/24/22 09:46:03.107
Aug 24 09:46:03.110: INFO: Observed &Deployment event: ADDED
Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
Aug 24 09:46:03.110: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 09:46:03.111: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mwsg7-777898ffcc" is progressing.}
Aug 24 09:46:03.111: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
Aug 24 09:46:03.112: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 09:46:03.112: INFO: Observed &Deployment event: MODIFIED
Aug 24 09:46:03.112: INFO: Found deployment test-deployment-mwsg7 in namespace deployment-9903 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Aug 24 09:46:03.112: INFO: Deployment test-deployment-mwsg7 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 09:46:03.121: INFO: Deployment "test-deployment-mwsg7":
&Deployment{ObjectMeta:{test-deployment-mwsg7  deployment-9903  1365298c-6190-4ef3-ab30-418b4f12944a 11350 1 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-24 09:46:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:46:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00351f398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-mwsg7-777898ffcc",LastUpdateTime:2022-08-24 09:46:03 +0000 UTC,LastTransitionTime:2022-08-24 09:46:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 09:46:03.128: INFO: New ReplicaSet "test-deployment-mwsg7-777898ffcc" of Deployment "test-deployment-mwsg7":
&ReplicaSet{ObjectMeta:{test-deployment-mwsg7-777898ffcc  deployment-9903  a23c78aa-52b5-4754-9012-34b0f4a2a60b 11345 1 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-mwsg7 1365298c-6190-4ef3-ab30-418b4f12944a 0xc003575310 0xc003575311}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1365298c-6190-4ef3-ab30-418b4f12944a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035753b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:46:03.135: INFO: Pod "test-deployment-mwsg7-777898ffcc-t7m2c" is available:
&Pod{ObjectMeta:{test-deployment-mwsg7-777898ffcc-t7m2c test-deployment-mwsg7-777898ffcc- deployment-9903  35e8b149-a131-4dba-9baf-e519909b715b 11344 0 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-mwsg7-777898ffcc a23c78aa-52b5-4754-9012-34b0f4a2a60b 0xc003575777 0xc003575778}] [] [{kube-controller-manager Update v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a23c78aa-52b5-4754-9012-34b0f4a2a60b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qsn4r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qsn4r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.130,StartTime:2022-08-24 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:46:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://b859c9da465152ff4fbbd1e6d857a98987ecee074fc8e47a5054c3d74aa3472b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 09:46:03.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9903" for this suite. 08/24/22 09:46:03.142
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":60,"skipped":1144,"failed":0}
------------------------------
• [2.197 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:00.955
    Aug 24 09:46:00.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 09:46:00.958
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:00.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:00.993
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 08/24/22 09:46:01.004
    Aug 24 09:46:01.004: INFO: Creating simple deployment test-deployment-mwsg7
    Aug 24 09:46:01.029: INFO: deployment "test-deployment-mwsg7" doesn't have the required revision set
    STEP: Getting /status 08/24/22 09:46:03.055
    Aug 24 09:46:03.068: INFO: Deployment test-deployment-mwsg7 has Conditions: [{Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 08/24/22 09:46:03.068
    Aug 24 09:46:03.088: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 9, 46, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 9, 46, 1, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-mwsg7-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 08/24/22 09:46:03.088
    Aug 24 09:46:03.093: INFO: Observed &Deployment event: ADDED
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
    Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mwsg7-777898ffcc" is progressing.}
    Aug 24 09:46:03.093: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 24 09:46:03.093: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
    Aug 24 09:46:03.094: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.094: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 24 09:46:03.094: INFO: Observed Deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
    Aug 24 09:46:03.094: INFO: Found Deployment test-deployment-mwsg7 in namespace deployment-9903 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 24 09:46:03.094: INFO: Deployment test-deployment-mwsg7 has an updated status
    STEP: patching the Statefulset Status 08/24/22 09:46:03.094
    Aug 24 09:46:03.094: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 24 09:46:03.107: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 08/24/22 09:46:03.107
    Aug 24 09:46:03.110: INFO: Observed &Deployment event: ADDED
    Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
    Aug 24 09:46:03.110: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mwsg7-777898ffcc"}
    Aug 24 09:46:03.110: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 24 09:46:03.111: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:01 +0000 UTC 2022-08-24 09:46:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mwsg7-777898ffcc" is progressing.}
    Aug 24 09:46:03.111: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 24 09:46:03.111: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
    Aug 24 09:46:03.112: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 09:46:02 +0000 UTC 2022-08-24 09:46:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mwsg7-777898ffcc" has successfully progressed.}
    Aug 24 09:46:03.112: INFO: Observed deployment test-deployment-mwsg7 in namespace deployment-9903 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 24 09:46:03.112: INFO: Observed &Deployment event: MODIFIED
    Aug 24 09:46:03.112: INFO: Found deployment test-deployment-mwsg7 in namespace deployment-9903 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Aug 24 09:46:03.112: INFO: Deployment test-deployment-mwsg7 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 09:46:03.121: INFO: Deployment "test-deployment-mwsg7":
    &Deployment{ObjectMeta:{test-deployment-mwsg7  deployment-9903  1365298c-6190-4ef3-ab30-418b4f12944a 11350 1 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-24 09:46:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:46:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00351f398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-mwsg7-777898ffcc",LastUpdateTime:2022-08-24 09:46:03 +0000 UTC,LastTransitionTime:2022-08-24 09:46:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 24 09:46:03.128: INFO: New ReplicaSet "test-deployment-mwsg7-777898ffcc" of Deployment "test-deployment-mwsg7":
    &ReplicaSet{ObjectMeta:{test-deployment-mwsg7-777898ffcc  deployment-9903  a23c78aa-52b5-4754-9012-34b0f4a2a60b 11345 1 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-mwsg7 1365298c-6190-4ef3-ab30-418b4f12944a 0xc003575310 0xc003575311}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1365298c-6190-4ef3-ab30-418b4f12944a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035753b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:46:03.135: INFO: Pod "test-deployment-mwsg7-777898ffcc-t7m2c" is available:
    &Pod{ObjectMeta:{test-deployment-mwsg7-777898ffcc-t7m2c test-deployment-mwsg7-777898ffcc- deployment-9903  35e8b149-a131-4dba-9baf-e519909b715b 11344 0 2022-08-24 09:46:01 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-mwsg7-777898ffcc a23c78aa-52b5-4754-9012-34b0f4a2a60b 0xc003575777 0xc003575778}] [] [{kube-controller-manager Update v1 2022-08-24 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a23c78aa-52b5-4754-9012-34b0f4a2a60b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qsn4r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qsn4r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.130,StartTime:2022-08-24 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:46:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://b859c9da465152ff4fbbd1e6d857a98987ecee074fc8e47a5054c3d74aa3472b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 09:46:03.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9903" for this suite. 08/24/22 09:46:03.142
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:03.155
Aug 24 09:46:03.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename server-version 08/24/22 09:46:03.158
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:03.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:03.193
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 08/24/22 09:46:03.197
STEP: Confirm major version 08/24/22 09:46:03.199
Aug 24 09:46:03.199: INFO: Major version: 1
STEP: Confirm minor version 08/24/22 09:46:03.199
Aug 24 09:46:03.199: INFO: cleanMinorVersion: 25
Aug 24 09:46:03.199: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Aug 24 09:46:03.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1514" for this suite. 08/24/22 09:46:03.208
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":61,"skipped":1154,"failed":0}
------------------------------
• [0.067 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:03.155
    Aug 24 09:46:03.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename server-version 08/24/22 09:46:03.158
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:03.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:03.193
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 08/24/22 09:46:03.197
    STEP: Confirm major version 08/24/22 09:46:03.199
    Aug 24 09:46:03.199: INFO: Major version: 1
    STEP: Confirm minor version 08/24/22 09:46:03.199
    Aug 24 09:46:03.199: INFO: cleanMinorVersion: 25
    Aug 24 09:46:03.199: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Aug 24 09:46:03.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1514" for this suite. 08/24/22 09:46:03.208
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:03.223
Aug 24 09:46:03.223: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:46:03.226
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:03.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:03.262
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-003aee59-4be4-4f11-9059-5f9a06c48e5e 08/24/22 09:46:03.269
STEP: Creating a pod to test consume configMaps 08/24/22 09:46:03.279
Aug 24 09:46:03.300: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a" in namespace "projected-8130" to be "Succeeded or Failed"
Aug 24 09:46:03.306: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758275ms
Aug 24 09:46:05.317: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017097544s
Aug 24 09:46:07.315: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015113722s
STEP: Saw pod success 08/24/22 09:46:07.315
Aug 24 09:46:07.315: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a" satisfied condition "Succeeded or Failed"
Aug 24 09:46:07.321: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a container projected-configmap-volume-test: <nil>
STEP: delete the pod 08/24/22 09:46:07.332
Aug 24 09:46:07.361: INFO: Waiting for pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a to disappear
Aug 24 09:46:07.366: INFO: Pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 09:46:07.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8130" for this suite. 08/24/22 09:46:07.376
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":62,"skipped":1159,"failed":0}
------------------------------
• [4.182 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:03.223
    Aug 24 09:46:03.223: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:46:03.226
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:03.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:03.262
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-003aee59-4be4-4f11-9059-5f9a06c48e5e 08/24/22 09:46:03.269
    STEP: Creating a pod to test consume configMaps 08/24/22 09:46:03.279
    Aug 24 09:46:03.300: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a" in namespace "projected-8130" to be "Succeeded or Failed"
    Aug 24 09:46:03.306: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758275ms
    Aug 24 09:46:05.317: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017097544s
    Aug 24 09:46:07.315: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015113722s
    STEP: Saw pod success 08/24/22 09:46:07.315
    Aug 24 09:46:07.315: INFO: Pod "pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a" satisfied condition "Succeeded or Failed"
    Aug 24 09:46:07.321: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a container projected-configmap-volume-test: <nil>
    STEP: delete the pod 08/24/22 09:46:07.332
    Aug 24 09:46:07.361: INFO: Waiting for pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a to disappear
    Aug 24 09:46:07.366: INFO: Pod pod-projected-configmaps-5662b63e-341e-4e9b-85e7-c2bf85c2562a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 09:46:07.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8130" for this suite. 08/24/22 09:46:07.376
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:07.407
Aug 24 09:46:07.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename podtemplate 08/24/22 09:46:07.41
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:07.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:07.455
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 08/24/22 09:46:07.459
STEP: Replace a pod template 08/24/22 09:46:07.478
Aug 24 09:46:07.504: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 24 09:46:07.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2175" for this suite. 08/24/22 09:46:07.522
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":63,"skipped":1160,"failed":0}
------------------------------
• [0.127 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:07.407
    Aug 24 09:46:07.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename podtemplate 08/24/22 09:46:07.41
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:07.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:07.455
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 08/24/22 09:46:07.459
    STEP: Replace a pod template 08/24/22 09:46:07.478
    Aug 24 09:46:07.504: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 24 09:46:07.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2175" for this suite. 08/24/22 09:46:07.522
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:07.549
Aug 24 09:46:07.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svc-latency 08/24/22 09:46:07.552
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:07.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:07.584
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Aug 24 09:46:07.588: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: creating replication controller svc-latency-rc in namespace svc-latency-830 08/24/22 09:46:07.589
I0824 09:46:07.606289      14 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-830, replica count: 1
I0824 09:46:08.658381      14 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 09:46:09.658977      14 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 09:46:09.780: INFO: Created: latency-svc-9z4kj
Aug 24 09:46:09.796: INFO: Got endpoints: latency-svc-9z4kj [37.235437ms]
Aug 24 09:46:09.830: INFO: Created: latency-svc-mpqv4
Aug 24 09:46:09.836: INFO: Got endpoints: latency-svc-mpqv4 [39.242508ms]
Aug 24 09:46:09.840: INFO: Created: latency-svc-fps42
Aug 24 09:46:09.852: INFO: Created: latency-svc-w6l92
Aug 24 09:46:09.855: INFO: Got endpoints: latency-svc-fps42 [57.672498ms]
Aug 24 09:46:09.863: INFO: Created: latency-svc-rbm96
Aug 24 09:46:09.868: INFO: Got endpoints: latency-svc-w6l92 [69.949446ms]
Aug 24 09:46:09.873: INFO: Created: latency-svc-wxxk9
Aug 24 09:46:09.879: INFO: Got endpoints: latency-svc-rbm96 [81.194877ms]
Aug 24 09:46:09.892: INFO: Got endpoints: latency-svc-wxxk9 [93.995824ms]
Aug 24 09:46:09.895: INFO: Created: latency-svc-nhm9g
Aug 24 09:46:09.905: INFO: Got endpoints: latency-svc-nhm9g [106.963322ms]
Aug 24 09:46:09.911: INFO: Created: latency-svc-ngw9l
Aug 24 09:46:09.922: INFO: Created: latency-svc-w4kvs
Aug 24 09:46:09.924: INFO: Got endpoints: latency-svc-ngw9l [124.575007ms]
Aug 24 09:46:09.941: INFO: Got endpoints: latency-svc-w4kvs [143.883248ms]
Aug 24 09:46:09.944: INFO: Created: latency-svc-rzgbv
Aug 24 09:46:09.953: INFO: Created: latency-svc-t8nz2
Aug 24 09:46:09.953: INFO: Got endpoints: latency-svc-rzgbv [154.478383ms]
Aug 24 09:46:09.963: INFO: Created: latency-svc-4ks2x
Aug 24 09:46:09.973: INFO: Got endpoints: latency-svc-t8nz2 [174.185555ms]
Aug 24 09:46:09.981: INFO: Got endpoints: latency-svc-4ks2x [182.872492ms]
Aug 24 09:46:09.998: INFO: Created: latency-svc-8x2ql
Aug 24 09:46:10.005: INFO: Got endpoints: latency-svc-8x2ql [205.493357ms]
Aug 24 09:46:10.016: INFO: Created: latency-svc-p2sw6
Aug 24 09:46:10.029: INFO: Got endpoints: latency-svc-p2sw6 [229.110936ms]
Aug 24 09:46:10.036: INFO: Created: latency-svc-95frp
Aug 24 09:46:10.050: INFO: Created: latency-svc-7bbnd
Aug 24 09:46:10.051: INFO: Got endpoints: latency-svc-95frp [251.676842ms]
Aug 24 09:46:10.066: INFO: Got endpoints: latency-svc-7bbnd [266.983777ms]
Aug 24 09:46:10.079: INFO: Created: latency-svc-trxzb
Aug 24 09:46:10.087: INFO: Got endpoints: latency-svc-trxzb [250.874446ms]
Aug 24 09:46:10.087: INFO: Created: latency-svc-sd544
Aug 24 09:46:10.095: INFO: Got endpoints: latency-svc-sd544 [239.811736ms]
Aug 24 09:46:10.208: INFO: Created: latency-svc-d754c
Aug 24 09:46:10.208: INFO: Created: latency-svc-jpd4g
Aug 24 09:46:10.212: INFO: Created: latency-svc-tg76m
Aug 24 09:46:10.212: INFO: Created: latency-svc-4wplp
Aug 24 09:46:10.227: INFO: Created: latency-svc-znpwm
Aug 24 09:46:10.227: INFO: Created: latency-svc-d5jxw
Aug 24 09:46:10.227: INFO: Created: latency-svc-jgs44
Aug 24 09:46:10.228: INFO: Created: latency-svc-6f2g6
Aug 24 09:46:10.230: INFO: Created: latency-svc-r6nfp
Aug 24 09:46:10.230: INFO: Created: latency-svc-mdtqw
Aug 24 09:46:10.231: INFO: Created: latency-svc-czhd2
Aug 24 09:46:10.231: INFO: Created: latency-svc-v92wn
Aug 24 09:46:10.231: INFO: Got endpoints: latency-svc-d754c [143.940445ms]
Aug 24 09:46:10.231: INFO: Created: latency-svc-2bj2q
Aug 24 09:46:10.231: INFO: Created: latency-svc-jvcwx
Aug 24 09:46:10.232: INFO: Got endpoints: latency-svc-jpd4g [165.229185ms]
Aug 24 09:46:10.233: INFO: Created: latency-svc-mtqsc
Aug 24 09:46:10.250: INFO: Got endpoints: latency-svc-tg76m [308.363594ms]
Aug 24 09:46:10.261: INFO: Got endpoints: latency-svc-4wplp [392.963293ms]
Aug 24 09:46:10.271: INFO: Created: latency-svc-n6fr5
Aug 24 09:46:10.273: INFO: Got endpoints: latency-svc-r6nfp [367.19052ms]
Aug 24 09:46:10.277: INFO: Got endpoints: latency-svc-2bj2q [384.261937ms]
Aug 24 09:46:10.278: INFO: Got endpoints: latency-svc-jgs44 [182.843089ms]
Aug 24 09:46:10.286: INFO: Got endpoints: latency-svc-v92wn [304.598515ms]
Aug 24 09:46:10.288: INFO: Got endpoints: latency-svc-6f2g6 [364.262807ms]
Aug 24 09:46:10.298: INFO: Created: latency-svc-vrmsf
Aug 24 09:46:10.310: INFO: Got endpoints: latency-svc-d5jxw [337.275569ms]
Aug 24 09:46:10.311: INFO: Got endpoints: latency-svc-znpwm [431.225961ms]
Aug 24 09:46:10.317: INFO: Created: latency-svc-d52t5
Aug 24 09:46:10.329: INFO: Got endpoints: latency-svc-mdtqw [299.449043ms]
Aug 24 09:46:10.338: INFO: Created: latency-svc-lp4vt
Aug 24 09:46:10.346: INFO: Got endpoints: latency-svc-jvcwx [391.422852ms]
Aug 24 09:46:10.347: INFO: Got endpoints: latency-svc-mtqsc [295.516137ms]
Aug 24 09:46:10.356: INFO: Got endpoints: latency-svc-n6fr5 [124.630808ms]
Aug 24 09:46:10.365: INFO: Got endpoints: latency-svc-czhd2 [359.991362ms]
Aug 24 09:46:10.366: INFO: Got endpoints: latency-svc-vrmsf [134.287013ms]
Aug 24 09:46:10.385: INFO: Got endpoints: latency-svc-d52t5 [134.359775ms]
Aug 24 09:46:10.404: INFO: Got endpoints: latency-svc-lp4vt [142.948254ms]
Aug 24 09:46:10.408: INFO: Created: latency-svc-xs8gg
Aug 24 09:46:10.423: INFO: Created: latency-svc-99pjm
Aug 24 09:46:10.432: INFO: Got endpoints: latency-svc-xs8gg [159.006584ms]
Aug 24 09:46:10.444: INFO: Created: latency-svc-4c25b
Aug 24 09:46:10.452: INFO: Got endpoints: latency-svc-99pjm [174.993915ms]
Aug 24 09:46:10.473: INFO: Created: latency-svc-jxtnj
Aug 24 09:46:10.495: INFO: Created: latency-svc-wgw5s
Aug 24 09:46:10.498: INFO: Got endpoints: latency-svc-4c25b [219.878024ms]
Aug 24 09:46:10.502: INFO: Got endpoints: latency-svc-jxtnj [213.471317ms]
Aug 24 09:46:10.513: INFO: Created: latency-svc-xv87t
Aug 24 09:46:10.515: INFO: Got endpoints: latency-svc-wgw5s [204.387595ms]
Aug 24 09:46:10.527: INFO: Created: latency-svc-hhrwh
Aug 24 09:46:10.544: INFO: Created: latency-svc-25fdr
Aug 24 09:46:10.562: INFO: Created: latency-svc-rxccx
Aug 24 09:46:10.568: INFO: Created: latency-svc-slncp
Aug 24 09:46:10.581: INFO: Created: latency-svc-79bgt
Aug 24 09:46:10.582: INFO: Got endpoints: latency-svc-xv87t [272.051963ms]
Aug 24 09:46:10.583: INFO: Got endpoints: latency-svc-25fdr [236.218808ms]
Aug 24 09:46:10.583: INFO: Got endpoints: latency-svc-hhrwh [254.447718ms]
Aug 24 09:46:10.601: INFO: Created: latency-svc-lpvgb
Aug 24 09:46:10.610: INFO: Created: latency-svc-snfs9
Aug 24 09:46:10.622: INFO: Created: latency-svc-c2lhb
Aug 24 09:46:10.631: INFO: Got endpoints: latency-svc-rxccx [284.437218ms]
Aug 24 09:46:10.637: INFO: Created: latency-svc-229wd
Aug 24 09:46:10.654: INFO: Created: latency-svc-q89kp
Aug 24 09:46:10.666: INFO: Created: latency-svc-mx4dt
Aug 24 09:46:10.709: INFO: Got endpoints: latency-svc-slncp [353.566189ms]
Aug 24 09:46:10.715: INFO: Got endpoints: latency-svc-79bgt [349.158485ms]
Aug 24 09:46:10.717: INFO: Created: latency-svc-pl54g
Aug 24 09:46:10.750: INFO: Created: latency-svc-xhbfc
Aug 24 09:46:10.760: INFO: Created: latency-svc-npv5g
Aug 24 09:46:10.766: INFO: Got endpoints: latency-svc-lpvgb [400.154004ms]
Aug 24 09:46:10.794: INFO: Got endpoints: latency-svc-snfs9 [409.483201ms]
Aug 24 09:46:10.799: INFO: Created: latency-svc-lvgqt
Aug 24 09:46:10.834: INFO: Created: latency-svc-qmfc8
Aug 24 09:46:10.842: INFO: Created: latency-svc-jz4pw
Aug 24 09:46:10.857: INFO: Got endpoints: latency-svc-c2lhb [452.556122ms]
Aug 24 09:46:10.863: INFO: Created: latency-svc-f2lgq
Aug 24 09:46:10.913: INFO: Created: latency-svc-mq4v5
Aug 24 09:46:10.920: INFO: Created: latency-svc-2sgbz
Aug 24 09:46:10.961: INFO: Got endpoints: latency-svc-q89kp [674.528287ms]
Aug 24 09:46:10.962: INFO: Got endpoints: latency-svc-229wd [530.15609ms]
Aug 24 09:46:11.011: INFO: Got endpoints: latency-svc-mx4dt [558.943371ms]
Aug 24 09:46:11.031: INFO: Created: latency-svc-6vj4z
Aug 24 09:46:11.040: INFO: Created: latency-svc-9wlvc
Aug 24 09:46:11.048: INFO: Got endpoints: latency-svc-pl54g [550.452436ms]
Aug 24 09:46:11.056: INFO: Created: latency-svc-2h9cb
Aug 24 09:46:11.099: INFO: Created: latency-svc-zqlp7
Aug 24 09:46:11.104: INFO: Got endpoints: latency-svc-xhbfc [601.781899ms]
Aug 24 09:46:11.113: INFO: Created: latency-svc-r5p92
Aug 24 09:46:11.128: INFO: Created: latency-svc-6vkbg
Aug 24 09:46:11.147: INFO: Got endpoints: latency-svc-npv5g [631.198511ms]
Aug 24 09:46:11.173: INFO: Created: latency-svc-pjwpw
Aug 24 09:46:11.189: INFO: Created: latency-svc-2hgtl
Aug 24 09:46:11.193: INFO: Got endpoints: latency-svc-lvgqt [609.594009ms]
Aug 24 09:46:11.194: INFO: Created: latency-svc-bbdfr
Aug 24 09:46:11.214: INFO: Created: latency-svc-6qh9z
Aug 24 09:46:11.239: INFO: Got endpoints: latency-svc-qmfc8 [656.055306ms]
Aug 24 09:46:11.254: INFO: Created: latency-svc-wjd2j
Aug 24 09:46:11.299: INFO: Got endpoints: latency-svc-jz4pw [715.676079ms]
Aug 24 09:46:11.319: INFO: Created: latency-svc-qczsp
Aug 24 09:46:11.341: INFO: Got endpoints: latency-svc-f2lgq [710.308756ms]
Aug 24 09:46:11.366: INFO: Created: latency-svc-f9tvz
Aug 24 09:46:11.402: INFO: Got endpoints: latency-svc-mq4v5 [692.246281ms]
Aug 24 09:46:11.438: INFO: Created: latency-svc-x2w5v
Aug 24 09:46:11.447: INFO: Got endpoints: latency-svc-2sgbz [732.256833ms]
Aug 24 09:46:11.497: INFO: Got endpoints: latency-svc-9wlvc [730.558761ms]
Aug 24 09:46:11.536: INFO: Created: latency-svc-z9jsk
Aug 24 09:46:11.559: INFO: Created: latency-svc-5tcbs
Aug 24 09:46:11.561: INFO: Got endpoints: latency-svc-6vj4z [766.653833ms]
Aug 24 09:46:11.577: INFO: Created: latency-svc-95dc9
Aug 24 09:46:11.590: INFO: Got endpoints: latency-svc-2h9cb [732.859217ms]
Aug 24 09:46:11.608: INFO: Created: latency-svc-q9gqp
Aug 24 09:46:11.645: INFO: Got endpoints: latency-svc-zqlp7 [684.028603ms]
Aug 24 09:46:11.665: INFO: Created: latency-svc-99vgf
Aug 24 09:46:11.698: INFO: Got endpoints: latency-svc-r5p92 [735.74282ms]
Aug 24 09:46:11.714: INFO: Created: latency-svc-qdq75
Aug 24 09:46:11.740: INFO: Got endpoints: latency-svc-6vkbg [728.711481ms]
Aug 24 09:46:11.757: INFO: Created: latency-svc-dg5lt
Aug 24 09:46:11.789: INFO: Got endpoints: latency-svc-pjwpw [741.213486ms]
Aug 24 09:46:11.808: INFO: Created: latency-svc-qhcr9
Aug 24 09:46:11.845: INFO: Got endpoints: latency-svc-2hgtl [698.58294ms]
Aug 24 09:46:11.862: INFO: Created: latency-svc-7hlpb
Aug 24 09:46:11.894: INFO: Got endpoints: latency-svc-bbdfr [789.96677ms]
Aug 24 09:46:11.913: INFO: Created: latency-svc-7nz6l
Aug 24 09:46:11.940: INFO: Got endpoints: latency-svc-6qh9z [747.735494ms]
Aug 24 09:46:11.962: INFO: Created: latency-svc-dkn2m
Aug 24 09:46:11.992: INFO: Got endpoints: latency-svc-wjd2j [752.953188ms]
Aug 24 09:46:12.011: INFO: Created: latency-svc-5gzbm
Aug 24 09:46:12.042: INFO: Got endpoints: latency-svc-qczsp [742.278181ms]
Aug 24 09:46:12.074: INFO: Created: latency-svc-2kw4m
Aug 24 09:46:12.096: INFO: Got endpoints: latency-svc-f9tvz [754.74076ms]
Aug 24 09:46:12.125: INFO: Created: latency-svc-jtdrg
Aug 24 09:46:12.140: INFO: Got endpoints: latency-svc-x2w5v [737.952868ms]
Aug 24 09:46:12.155: INFO: Created: latency-svc-96lrj
Aug 24 09:46:12.191: INFO: Got endpoints: latency-svc-z9jsk [743.561775ms]
Aug 24 09:46:12.207: INFO: Created: latency-svc-8cl6t
Aug 24 09:46:12.242: INFO: Got endpoints: latency-svc-5tcbs [744.315347ms]
Aug 24 09:46:12.266: INFO: Created: latency-svc-6rqvp
Aug 24 09:46:12.292: INFO: Got endpoints: latency-svc-95dc9 [730.860061ms]
Aug 24 09:46:12.311: INFO: Created: latency-svc-nk6p2
Aug 24 09:46:12.350: INFO: Got endpoints: latency-svc-q9gqp [759.374452ms]
Aug 24 09:46:12.367: INFO: Created: latency-svc-9m7k9
Aug 24 09:46:12.390: INFO: Got endpoints: latency-svc-99vgf [744.882309ms]
Aug 24 09:46:12.415: INFO: Created: latency-svc-8r84w
Aug 24 09:46:12.445: INFO: Got endpoints: latency-svc-qdq75 [746.767182ms]
Aug 24 09:46:12.466: INFO: Created: latency-svc-svtgb
Aug 24 09:46:12.511: INFO: Got endpoints: latency-svc-dg5lt [770.942733ms]
Aug 24 09:46:12.533: INFO: Created: latency-svc-9stvc
Aug 24 09:46:12.544: INFO: Got endpoints: latency-svc-qhcr9 [753.962089ms]
Aug 24 09:46:12.567: INFO: Created: latency-svc-td68b
Aug 24 09:46:12.621: INFO: Got endpoints: latency-svc-7hlpb [775.239676ms]
Aug 24 09:46:12.644: INFO: Created: latency-svc-zxr6d
Aug 24 09:46:12.683: INFO: Got endpoints: latency-svc-7nz6l [788.813763ms]
Aug 24 09:46:12.711: INFO: Got endpoints: latency-svc-dkn2m [769.91762ms]
Aug 24 09:46:12.722: INFO: Created: latency-svc-2sc8t
Aug 24 09:46:12.745: INFO: Got endpoints: latency-svc-5gzbm [752.949155ms]
Aug 24 09:46:12.788: INFO: Created: latency-svc-jlngz
Aug 24 09:46:12.791: INFO: Created: latency-svc-jpjlq
Aug 24 09:46:12.803: INFO: Got endpoints: latency-svc-2kw4m [761.03381ms]
Aug 24 09:46:12.843: INFO: Got endpoints: latency-svc-jtdrg [746.322292ms]
Aug 24 09:46:12.859: INFO: Created: latency-svc-wszzl
Aug 24 09:46:12.881: INFO: Created: latency-svc-856s2
Aug 24 09:46:12.897: INFO: Got endpoints: latency-svc-96lrj [756.629803ms]
Aug 24 09:46:12.950: INFO: Created: latency-svc-2lvh2
Aug 24 09:46:12.970: INFO: Got endpoints: latency-svc-8cl6t [778.499149ms]
Aug 24 09:46:13.013: INFO: Got endpoints: latency-svc-6rqvp [771.491625ms]
Aug 24 09:46:13.015: INFO: Created: latency-svc-nbrlr
Aug 24 09:46:13.065: INFO: Got endpoints: latency-svc-nk6p2 [773.07689ms]
Aug 24 09:46:13.076: INFO: Created: latency-svc-hrnpk
Aug 24 09:46:13.099: INFO: Created: latency-svc-fw7pw
Aug 24 09:46:13.099: INFO: Got endpoints: latency-svc-9m7k9 [749.339523ms]
Aug 24 09:46:13.126: INFO: Created: latency-svc-zqwbg
Aug 24 09:46:13.139: INFO: Got endpoints: latency-svc-8r84w [748.586284ms]
Aug 24 09:46:13.163: INFO: Created: latency-svc-hlwsq
Aug 24 09:46:13.198: INFO: Got endpoints: latency-svc-svtgb [753.094767ms]
Aug 24 09:46:13.224: INFO: Created: latency-svc-9llnv
Aug 24 09:46:13.244: INFO: Got endpoints: latency-svc-9stvc [732.706856ms]
Aug 24 09:46:13.265: INFO: Created: latency-svc-zjfn8
Aug 24 09:46:13.293: INFO: Got endpoints: latency-svc-td68b [748.906696ms]
Aug 24 09:46:13.314: INFO: Created: latency-svc-cgtw8
Aug 24 09:46:13.344: INFO: Got endpoints: latency-svc-zxr6d [721.489048ms]
Aug 24 09:46:13.364: INFO: Created: latency-svc-g7lbk
Aug 24 09:46:13.407: INFO: Got endpoints: latency-svc-2sc8t [724.45499ms]
Aug 24 09:46:13.435: INFO: Created: latency-svc-4sdrm
Aug 24 09:46:13.444: INFO: Got endpoints: latency-svc-jpjlq [733.268682ms]
Aug 24 09:46:13.462: INFO: Created: latency-svc-m4dr9
Aug 24 09:46:13.503: INFO: Got endpoints: latency-svc-jlngz [757.417009ms]
Aug 24 09:46:13.524: INFO: Created: latency-svc-jpd66
Aug 24 09:46:13.539: INFO: Got endpoints: latency-svc-wszzl [736.337316ms]
Aug 24 09:46:13.565: INFO: Created: latency-svc-5ggfl
Aug 24 09:46:13.605: INFO: Got endpoints: latency-svc-856s2 [762.106695ms]
Aug 24 09:46:13.647: INFO: Created: latency-svc-dckrc
Aug 24 09:46:13.651: INFO: Got endpoints: latency-svc-2lvh2 [754.127831ms]
Aug 24 09:46:13.682: INFO: Created: latency-svc-spcqf
Aug 24 09:46:13.702: INFO: Got endpoints: latency-svc-nbrlr [731.583959ms]
Aug 24 09:46:13.726: INFO: Created: latency-svc-wcrxs
Aug 24 09:46:13.751: INFO: Got endpoints: latency-svc-hrnpk [737.053111ms]
Aug 24 09:46:13.773: INFO: Created: latency-svc-lw2f8
Aug 24 09:46:13.796: INFO: Got endpoints: latency-svc-fw7pw [730.127294ms]
Aug 24 09:46:13.829: INFO: Created: latency-svc-h4hwb
Aug 24 09:46:13.843: INFO: Got endpoints: latency-svc-zqwbg [743.546422ms]
Aug 24 09:46:13.862: INFO: Created: latency-svc-4kdqn
Aug 24 09:46:13.900: INFO: Got endpoints: latency-svc-hlwsq [760.949043ms]
Aug 24 09:46:13.919: INFO: Created: latency-svc-25bfb
Aug 24 09:46:13.942: INFO: Got endpoints: latency-svc-9llnv [743.617867ms]
Aug 24 09:46:13.969: INFO: Created: latency-svc-cjr5h
Aug 24 09:46:13.991: INFO: Got endpoints: latency-svc-zjfn8 [746.149322ms]
Aug 24 09:46:14.006: INFO: Created: latency-svc-56wvs
Aug 24 09:46:14.038: INFO: Got endpoints: latency-svc-cgtw8 [745.414647ms]
Aug 24 09:46:14.056: INFO: Created: latency-svc-zrs2w
Aug 24 09:46:14.091: INFO: Got endpoints: latency-svc-g7lbk [746.755757ms]
Aug 24 09:46:14.111: INFO: Created: latency-svc-2mr7w
Aug 24 09:46:14.144: INFO: Got endpoints: latency-svc-4sdrm [735.979032ms]
Aug 24 09:46:14.168: INFO: Created: latency-svc-86x2z
Aug 24 09:46:14.188: INFO: Got endpoints: latency-svc-m4dr9 [743.935547ms]
Aug 24 09:46:14.212: INFO: Created: latency-svc-kfmx7
Aug 24 09:46:14.241: INFO: Got endpoints: latency-svc-jpd66 [737.69839ms]
Aug 24 09:46:14.260: INFO: Created: latency-svc-p2xjk
Aug 24 09:46:14.290: INFO: Got endpoints: latency-svc-5ggfl [750.614339ms]
Aug 24 09:46:14.308: INFO: Created: latency-svc-5lthn
Aug 24 09:46:14.342: INFO: Got endpoints: latency-svc-dckrc [736.602336ms]
Aug 24 09:46:14.363: INFO: Created: latency-svc-ngwv9
Aug 24 09:46:14.392: INFO: Got endpoints: latency-svc-spcqf [740.569941ms]
Aug 24 09:46:14.417: INFO: Created: latency-svc-bhdlw
Aug 24 09:46:14.443: INFO: Got endpoints: latency-svc-wcrxs [741.676549ms]
Aug 24 09:46:14.469: INFO: Created: latency-svc-2xp2n
Aug 24 09:46:14.492: INFO: Got endpoints: latency-svc-lw2f8 [741.353544ms]
Aug 24 09:46:14.514: INFO: Created: latency-svc-rzkpf
Aug 24 09:46:14.543: INFO: Got endpoints: latency-svc-h4hwb [746.662021ms]
Aug 24 09:46:14.561: INFO: Created: latency-svc-lnpct
Aug 24 09:46:14.594: INFO: Got endpoints: latency-svc-4kdqn [751.029048ms]
Aug 24 09:46:14.612: INFO: Created: latency-svc-xcz5p
Aug 24 09:46:14.655: INFO: Got endpoints: latency-svc-25bfb [753.998568ms]
Aug 24 09:46:14.686: INFO: Created: latency-svc-7s42q
Aug 24 09:46:14.693: INFO: Got endpoints: latency-svc-cjr5h [750.872597ms]
Aug 24 09:46:14.726: INFO: Created: latency-svc-v4vhl
Aug 24 09:46:14.746: INFO: Got endpoints: latency-svc-56wvs [754.974965ms]
Aug 24 09:46:14.768: INFO: Created: latency-svc-9g8gd
Aug 24 09:46:14.790: INFO: Got endpoints: latency-svc-zrs2w [750.941828ms]
Aug 24 09:46:14.822: INFO: Created: latency-svc-qzlnt
Aug 24 09:46:14.839: INFO: Got endpoints: latency-svc-2mr7w [748.459672ms]
Aug 24 09:46:14.858: INFO: Created: latency-svc-tjhb9
Aug 24 09:46:14.905: INFO: Got endpoints: latency-svc-86x2z [760.902972ms]
Aug 24 09:46:14.935: INFO: Created: latency-svc-h8pwt
Aug 24 09:46:14.942: INFO: Got endpoints: latency-svc-kfmx7 [753.565294ms]
Aug 24 09:46:15.005: INFO: Got endpoints: latency-svc-p2xjk [763.888635ms]
Aug 24 09:46:15.012: INFO: Created: latency-svc-w6xrv
Aug 24 09:46:15.037: INFO: Created: latency-svc-cq4l6
Aug 24 09:46:15.042: INFO: Got endpoints: latency-svc-5lthn [751.511851ms]
Aug 24 09:46:15.058: INFO: Created: latency-svc-hm92q
Aug 24 09:46:15.089: INFO: Got endpoints: latency-svc-ngwv9 [746.739821ms]
Aug 24 09:46:15.116: INFO: Created: latency-svc-gdc4v
Aug 24 09:46:15.140: INFO: Got endpoints: latency-svc-bhdlw [747.754649ms]
Aug 24 09:46:15.157: INFO: Created: latency-svc-wwhbz
Aug 24 09:46:15.190: INFO: Got endpoints: latency-svc-2xp2n [746.659052ms]
Aug 24 09:46:15.206: INFO: Created: latency-svc-7lg9c
Aug 24 09:46:15.240: INFO: Got endpoints: latency-svc-rzkpf [747.093301ms]
Aug 24 09:46:15.257: INFO: Created: latency-svc-ggmvm
Aug 24 09:46:15.299: INFO: Got endpoints: latency-svc-lnpct [755.896637ms]
Aug 24 09:46:15.318: INFO: Created: latency-svc-m2qvq
Aug 24 09:46:15.342: INFO: Got endpoints: latency-svc-xcz5p [747.435351ms]
Aug 24 09:46:15.371: INFO: Created: latency-svc-qqmvh
Aug 24 09:46:15.398: INFO: Got endpoints: latency-svc-7s42q [743.322782ms]
Aug 24 09:46:15.441: INFO: Created: latency-svc-8lkfk
Aug 24 09:46:15.441: INFO: Got endpoints: latency-svc-v4vhl [747.137357ms]
Aug 24 09:46:15.457: INFO: Created: latency-svc-whkkp
Aug 24 09:46:15.490: INFO: Got endpoints: latency-svc-9g8gd [744.435947ms]
Aug 24 09:46:15.520: INFO: Created: latency-svc-bc7m7
Aug 24 09:46:15.542: INFO: Got endpoints: latency-svc-qzlnt [752.01144ms]
Aug 24 09:46:15.561: INFO: Created: latency-svc-99spb
Aug 24 09:46:15.598: INFO: Got endpoints: latency-svc-tjhb9 [758.610117ms]
Aug 24 09:46:15.625: INFO: Created: latency-svc-x8566
Aug 24 09:46:15.642: INFO: Got endpoints: latency-svc-h8pwt [736.599281ms]
Aug 24 09:46:15.664: INFO: Created: latency-svc-4mj55
Aug 24 09:46:15.690: INFO: Got endpoints: latency-svc-w6xrv [747.990385ms]
Aug 24 09:46:15.713: INFO: Created: latency-svc-ck4m5
Aug 24 09:46:15.743: INFO: Got endpoints: latency-svc-cq4l6 [738.246407ms]
Aug 24 09:46:15.767: INFO: Created: latency-svc-v75zn
Aug 24 09:46:15.790: INFO: Got endpoints: latency-svc-hm92q [748.386304ms]
Aug 24 09:46:15.811: INFO: Created: latency-svc-5lwz6
Aug 24 09:46:15.847: INFO: Got endpoints: latency-svc-gdc4v [757.755257ms]
Aug 24 09:46:15.867: INFO: Created: latency-svc-r5cbl
Aug 24 09:46:15.892: INFO: Got endpoints: latency-svc-wwhbz [751.912551ms]
Aug 24 09:46:15.909: INFO: Created: latency-svc-lsswt
Aug 24 09:46:15.944: INFO: Got endpoints: latency-svc-7lg9c [753.853818ms]
Aug 24 09:46:15.968: INFO: Created: latency-svc-xmjqr
Aug 24 09:46:15.990: INFO: Got endpoints: latency-svc-ggmvm [749.74953ms]
Aug 24 09:46:16.016: INFO: Created: latency-svc-5qzj6
Aug 24 09:46:16.051: INFO: Got endpoints: latency-svc-m2qvq [751.796423ms]
Aug 24 09:46:16.069: INFO: Created: latency-svc-vsnxf
Aug 24 09:46:16.092: INFO: Got endpoints: latency-svc-qqmvh [749.881585ms]
Aug 24 09:46:16.107: INFO: Created: latency-svc-j8qzr
Aug 24 09:46:16.158: INFO: Got endpoints: latency-svc-8lkfk [759.373388ms]
Aug 24 09:46:16.180: INFO: Created: latency-svc-vhpgm
Aug 24 09:46:16.192: INFO: Got endpoints: latency-svc-whkkp [751.076587ms]
Aug 24 09:46:16.210: INFO: Created: latency-svc-8fjc9
Aug 24 09:46:16.241: INFO: Got endpoints: latency-svc-bc7m7 [750.642337ms]
Aug 24 09:46:16.259: INFO: Created: latency-svc-49cvt
Aug 24 09:46:16.291: INFO: Got endpoints: latency-svc-99spb [748.921916ms]
Aug 24 09:46:16.306: INFO: Created: latency-svc-j4qjv
Aug 24 09:46:16.346: INFO: Got endpoints: latency-svc-x8566 [747.444378ms]
Aug 24 09:46:16.368: INFO: Created: latency-svc-hvmw5
Aug 24 09:46:16.394: INFO: Got endpoints: latency-svc-4mj55 [752.515141ms]
Aug 24 09:46:16.412: INFO: Created: latency-svc-ffnrd
Aug 24 09:46:16.442: INFO: Got endpoints: latency-svc-ck4m5 [751.775115ms]
Aug 24 09:46:16.461: INFO: Created: latency-svc-ls82v
Aug 24 09:46:16.490: INFO: Got endpoints: latency-svc-v75zn [746.407481ms]
Aug 24 09:46:16.510: INFO: Created: latency-svc-m9msg
Aug 24 09:46:16.552: INFO: Got endpoints: latency-svc-5lwz6 [761.374392ms]
Aug 24 09:46:16.568: INFO: Created: latency-svc-g92ls
Aug 24 09:46:16.591: INFO: Got endpoints: latency-svc-r5cbl [743.579506ms]
Aug 24 09:46:16.625: INFO: Created: latency-svc-92srw
Aug 24 09:46:16.643: INFO: Got endpoints: latency-svc-lsswt [750.627512ms]
Aug 24 09:46:16.661: INFO: Created: latency-svc-4q8vv
Aug 24 09:46:16.691: INFO: Got endpoints: latency-svc-xmjqr [746.605558ms]
Aug 24 09:46:16.714: INFO: Created: latency-svc-l7ncp
Aug 24 09:46:16.747: INFO: Got endpoints: latency-svc-5qzj6 [756.786552ms]
Aug 24 09:46:16.795: INFO: Created: latency-svc-2jb9m
Aug 24 09:46:16.796: INFO: Got endpoints: latency-svc-vsnxf [745.046814ms]
Aug 24 09:46:16.813: INFO: Created: latency-svc-wzd9h
Aug 24 09:46:16.844: INFO: Got endpoints: latency-svc-j8qzr [752.170492ms]
Aug 24 09:46:16.863: INFO: Created: latency-svc-jj5bd
Aug 24 09:46:16.895: INFO: Got endpoints: latency-svc-vhpgm [736.666276ms]
Aug 24 09:46:16.927: INFO: Created: latency-svc-zmtbn
Aug 24 09:46:16.942: INFO: Got endpoints: latency-svc-8fjc9 [749.577043ms]
Aug 24 09:46:16.961: INFO: Created: latency-svc-7tvhb
Aug 24 09:46:16.999: INFO: Got endpoints: latency-svc-49cvt [757.815503ms]
Aug 24 09:46:17.020: INFO: Created: latency-svc-gf78j
Aug 24 09:46:17.042: INFO: Got endpoints: latency-svc-j4qjv [750.987941ms]
Aug 24 09:46:17.072: INFO: Created: latency-svc-bkqhl
Aug 24 09:46:17.093: INFO: Got endpoints: latency-svc-hvmw5 [746.914078ms]
Aug 24 09:46:17.113: INFO: Created: latency-svc-7z9jg
Aug 24 09:46:17.138: INFO: Got endpoints: latency-svc-ffnrd [743.664394ms]
Aug 24 09:46:17.159: INFO: Created: latency-svc-f2lt7
Aug 24 09:46:17.196: INFO: Got endpoints: latency-svc-ls82v [754.091969ms]
Aug 24 09:46:17.212: INFO: Created: latency-svc-nxmhn
Aug 24 09:46:17.248: INFO: Got endpoints: latency-svc-m9msg [758.600468ms]
Aug 24 09:46:17.265: INFO: Created: latency-svc-xvvmk
Aug 24 09:46:17.290: INFO: Got endpoints: latency-svc-g92ls [738.241279ms]
Aug 24 09:46:17.309: INFO: Created: latency-svc-fkxzs
Aug 24 09:46:17.342: INFO: Got endpoints: latency-svc-92srw [751.395581ms]
Aug 24 09:46:17.363: INFO: Created: latency-svc-7lgk6
Aug 24 09:46:17.397: INFO: Got endpoints: latency-svc-4q8vv [753.461845ms]
Aug 24 09:46:17.434: INFO: Created: latency-svc-s8b2j
Aug 24 09:46:17.443: INFO: Got endpoints: latency-svc-l7ncp [752.486537ms]
Aug 24 09:46:17.466: INFO: Created: latency-svc-rg959
Aug 24 09:46:17.491: INFO: Got endpoints: latency-svc-2jb9m [741.275455ms]
Aug 24 09:46:17.510: INFO: Created: latency-svc-62g94
Aug 24 09:46:17.549: INFO: Got endpoints: latency-svc-wzd9h [753.4512ms]
Aug 24 09:46:17.574: INFO: Created: latency-svc-ggn7d
Aug 24 09:46:17.593: INFO: Got endpoints: latency-svc-jj5bd [748.363947ms]
Aug 24 09:46:17.623: INFO: Created: latency-svc-5n6vj
Aug 24 09:46:17.641: INFO: Got endpoints: latency-svc-zmtbn [746.434936ms]
Aug 24 09:46:17.693: INFO: Got endpoints: latency-svc-7tvhb [751.039779ms]
Aug 24 09:46:17.745: INFO: Got endpoints: latency-svc-gf78j [745.291981ms]
Aug 24 09:46:17.788: INFO: Got endpoints: latency-svc-bkqhl [745.769674ms]
Aug 24 09:46:17.841: INFO: Got endpoints: latency-svc-7z9jg [748.108854ms]
Aug 24 09:46:17.890: INFO: Got endpoints: latency-svc-f2lt7 [751.650646ms]
Aug 24 09:46:17.939: INFO: Got endpoints: latency-svc-nxmhn [742.569609ms]
Aug 24 09:46:17.992: INFO: Got endpoints: latency-svc-xvvmk [742.85397ms]
Aug 24 09:46:18.041: INFO: Got endpoints: latency-svc-fkxzs [750.588988ms]
Aug 24 09:46:18.090: INFO: Got endpoints: latency-svc-7lgk6 [747.916037ms]
Aug 24 09:46:18.138: INFO: Got endpoints: latency-svc-s8b2j [741.476744ms]
Aug 24 09:46:18.190: INFO: Got endpoints: latency-svc-rg959 [745.790239ms]
Aug 24 09:46:18.241: INFO: Got endpoints: latency-svc-62g94 [749.341095ms]
Aug 24 09:46:18.290: INFO: Got endpoints: latency-svc-ggn7d [740.272661ms]
Aug 24 09:46:18.342: INFO: Got endpoints: latency-svc-5n6vj [749.49986ms]
Aug 24 09:46:18.343: INFO: Latencies: [39.242508ms 57.672498ms 69.949446ms 81.194877ms 93.995824ms 106.963322ms 124.575007ms 124.630808ms 134.287013ms 134.359775ms 142.948254ms 143.883248ms 143.940445ms 154.478383ms 159.006584ms 165.229185ms 174.185555ms 174.993915ms 182.843089ms 182.872492ms 204.387595ms 205.493357ms 213.471317ms 219.878024ms 229.110936ms 236.218808ms 239.811736ms 250.874446ms 251.676842ms 254.447718ms 266.983777ms 272.051963ms 284.437218ms 295.516137ms 299.449043ms 304.598515ms 308.363594ms 337.275569ms 349.158485ms 353.566189ms 359.991362ms 364.262807ms 367.19052ms 384.261937ms 391.422852ms 392.963293ms 400.154004ms 409.483201ms 431.225961ms 452.556122ms 530.15609ms 550.452436ms 558.943371ms 601.781899ms 609.594009ms 631.198511ms 656.055306ms 674.528287ms 684.028603ms 692.246281ms 698.58294ms 710.308756ms 715.676079ms 721.489048ms 724.45499ms 728.711481ms 730.127294ms 730.558761ms 730.860061ms 731.583959ms 732.256833ms 732.706856ms 732.859217ms 733.268682ms 735.74282ms 735.979032ms 736.337316ms 736.599281ms 736.602336ms 736.666276ms 737.053111ms 737.69839ms 737.952868ms 738.241279ms 738.246407ms 740.272661ms 740.569941ms 741.213486ms 741.275455ms 741.353544ms 741.476744ms 741.676549ms 742.278181ms 742.569609ms 742.85397ms 743.322782ms 743.546422ms 743.561775ms 743.579506ms 743.617867ms 743.664394ms 743.935547ms 744.315347ms 744.435947ms 744.882309ms 745.046814ms 745.291981ms 745.414647ms 745.769674ms 745.790239ms 746.149322ms 746.322292ms 746.407481ms 746.434936ms 746.605558ms 746.659052ms 746.662021ms 746.739821ms 746.755757ms 746.767182ms 746.914078ms 747.093301ms 747.137357ms 747.435351ms 747.444378ms 747.735494ms 747.754649ms 747.916037ms 747.990385ms 748.108854ms 748.363947ms 748.386304ms 748.459672ms 748.586284ms 748.906696ms 748.921916ms 749.339523ms 749.341095ms 749.49986ms 749.577043ms 749.74953ms 749.881585ms 750.588988ms 750.614339ms 750.627512ms 750.642337ms 750.872597ms 750.941828ms 750.987941ms 751.029048ms 751.039779ms 751.076587ms 751.395581ms 751.511851ms 751.650646ms 751.775115ms 751.796423ms 751.912551ms 752.01144ms 752.170492ms 752.486537ms 752.515141ms 752.949155ms 752.953188ms 753.094767ms 753.4512ms 753.461845ms 753.565294ms 753.853818ms 753.962089ms 753.998568ms 754.091969ms 754.127831ms 754.74076ms 754.974965ms 755.896637ms 756.629803ms 756.786552ms 757.417009ms 757.755257ms 757.815503ms 758.600468ms 758.610117ms 759.373388ms 759.374452ms 760.902972ms 760.949043ms 761.03381ms 761.374392ms 762.106695ms 763.888635ms 766.653833ms 769.91762ms 770.942733ms 771.491625ms 773.07689ms 775.239676ms 778.499149ms 788.813763ms 789.96677ms]
Aug 24 09:46:18.343: INFO: 50 %ile: 743.664394ms
Aug 24 09:46:18.343: INFO: 90 %ile: 757.815503ms
Aug 24 09:46:18.343: INFO: 99 %ile: 788.813763ms
Aug 24 09:46:18.343: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Aug 24 09:46:18.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-830" for this suite. 08/24/22 09:46:18.354
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":64,"skipped":1182,"failed":0}
------------------------------
• [SLOW TEST] [10.820 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:07.549
    Aug 24 09:46:07.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svc-latency 08/24/22 09:46:07.552
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:07.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:07.584
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Aug 24 09:46:07.588: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-830 08/24/22 09:46:07.589
    I0824 09:46:07.606289      14 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-830, replica count: 1
    I0824 09:46:08.658381      14 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 09:46:09.658977      14 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 09:46:09.780: INFO: Created: latency-svc-9z4kj
    Aug 24 09:46:09.796: INFO: Got endpoints: latency-svc-9z4kj [37.235437ms]
    Aug 24 09:46:09.830: INFO: Created: latency-svc-mpqv4
    Aug 24 09:46:09.836: INFO: Got endpoints: latency-svc-mpqv4 [39.242508ms]
    Aug 24 09:46:09.840: INFO: Created: latency-svc-fps42
    Aug 24 09:46:09.852: INFO: Created: latency-svc-w6l92
    Aug 24 09:46:09.855: INFO: Got endpoints: latency-svc-fps42 [57.672498ms]
    Aug 24 09:46:09.863: INFO: Created: latency-svc-rbm96
    Aug 24 09:46:09.868: INFO: Got endpoints: latency-svc-w6l92 [69.949446ms]
    Aug 24 09:46:09.873: INFO: Created: latency-svc-wxxk9
    Aug 24 09:46:09.879: INFO: Got endpoints: latency-svc-rbm96 [81.194877ms]
    Aug 24 09:46:09.892: INFO: Got endpoints: latency-svc-wxxk9 [93.995824ms]
    Aug 24 09:46:09.895: INFO: Created: latency-svc-nhm9g
    Aug 24 09:46:09.905: INFO: Got endpoints: latency-svc-nhm9g [106.963322ms]
    Aug 24 09:46:09.911: INFO: Created: latency-svc-ngw9l
    Aug 24 09:46:09.922: INFO: Created: latency-svc-w4kvs
    Aug 24 09:46:09.924: INFO: Got endpoints: latency-svc-ngw9l [124.575007ms]
    Aug 24 09:46:09.941: INFO: Got endpoints: latency-svc-w4kvs [143.883248ms]
    Aug 24 09:46:09.944: INFO: Created: latency-svc-rzgbv
    Aug 24 09:46:09.953: INFO: Created: latency-svc-t8nz2
    Aug 24 09:46:09.953: INFO: Got endpoints: latency-svc-rzgbv [154.478383ms]
    Aug 24 09:46:09.963: INFO: Created: latency-svc-4ks2x
    Aug 24 09:46:09.973: INFO: Got endpoints: latency-svc-t8nz2 [174.185555ms]
    Aug 24 09:46:09.981: INFO: Got endpoints: latency-svc-4ks2x [182.872492ms]
    Aug 24 09:46:09.998: INFO: Created: latency-svc-8x2ql
    Aug 24 09:46:10.005: INFO: Got endpoints: latency-svc-8x2ql [205.493357ms]
    Aug 24 09:46:10.016: INFO: Created: latency-svc-p2sw6
    Aug 24 09:46:10.029: INFO: Got endpoints: latency-svc-p2sw6 [229.110936ms]
    Aug 24 09:46:10.036: INFO: Created: latency-svc-95frp
    Aug 24 09:46:10.050: INFO: Created: latency-svc-7bbnd
    Aug 24 09:46:10.051: INFO: Got endpoints: latency-svc-95frp [251.676842ms]
    Aug 24 09:46:10.066: INFO: Got endpoints: latency-svc-7bbnd [266.983777ms]
    Aug 24 09:46:10.079: INFO: Created: latency-svc-trxzb
    Aug 24 09:46:10.087: INFO: Got endpoints: latency-svc-trxzb [250.874446ms]
    Aug 24 09:46:10.087: INFO: Created: latency-svc-sd544
    Aug 24 09:46:10.095: INFO: Got endpoints: latency-svc-sd544 [239.811736ms]
    Aug 24 09:46:10.208: INFO: Created: latency-svc-d754c
    Aug 24 09:46:10.208: INFO: Created: latency-svc-jpd4g
    Aug 24 09:46:10.212: INFO: Created: latency-svc-tg76m
    Aug 24 09:46:10.212: INFO: Created: latency-svc-4wplp
    Aug 24 09:46:10.227: INFO: Created: latency-svc-znpwm
    Aug 24 09:46:10.227: INFO: Created: latency-svc-d5jxw
    Aug 24 09:46:10.227: INFO: Created: latency-svc-jgs44
    Aug 24 09:46:10.228: INFO: Created: latency-svc-6f2g6
    Aug 24 09:46:10.230: INFO: Created: latency-svc-r6nfp
    Aug 24 09:46:10.230: INFO: Created: latency-svc-mdtqw
    Aug 24 09:46:10.231: INFO: Created: latency-svc-czhd2
    Aug 24 09:46:10.231: INFO: Created: latency-svc-v92wn
    Aug 24 09:46:10.231: INFO: Got endpoints: latency-svc-d754c [143.940445ms]
    Aug 24 09:46:10.231: INFO: Created: latency-svc-2bj2q
    Aug 24 09:46:10.231: INFO: Created: latency-svc-jvcwx
    Aug 24 09:46:10.232: INFO: Got endpoints: latency-svc-jpd4g [165.229185ms]
    Aug 24 09:46:10.233: INFO: Created: latency-svc-mtqsc
    Aug 24 09:46:10.250: INFO: Got endpoints: latency-svc-tg76m [308.363594ms]
    Aug 24 09:46:10.261: INFO: Got endpoints: latency-svc-4wplp [392.963293ms]
    Aug 24 09:46:10.271: INFO: Created: latency-svc-n6fr5
    Aug 24 09:46:10.273: INFO: Got endpoints: latency-svc-r6nfp [367.19052ms]
    Aug 24 09:46:10.277: INFO: Got endpoints: latency-svc-2bj2q [384.261937ms]
    Aug 24 09:46:10.278: INFO: Got endpoints: latency-svc-jgs44 [182.843089ms]
    Aug 24 09:46:10.286: INFO: Got endpoints: latency-svc-v92wn [304.598515ms]
    Aug 24 09:46:10.288: INFO: Got endpoints: latency-svc-6f2g6 [364.262807ms]
    Aug 24 09:46:10.298: INFO: Created: latency-svc-vrmsf
    Aug 24 09:46:10.310: INFO: Got endpoints: latency-svc-d5jxw [337.275569ms]
    Aug 24 09:46:10.311: INFO: Got endpoints: latency-svc-znpwm [431.225961ms]
    Aug 24 09:46:10.317: INFO: Created: latency-svc-d52t5
    Aug 24 09:46:10.329: INFO: Got endpoints: latency-svc-mdtqw [299.449043ms]
    Aug 24 09:46:10.338: INFO: Created: latency-svc-lp4vt
    Aug 24 09:46:10.346: INFO: Got endpoints: latency-svc-jvcwx [391.422852ms]
    Aug 24 09:46:10.347: INFO: Got endpoints: latency-svc-mtqsc [295.516137ms]
    Aug 24 09:46:10.356: INFO: Got endpoints: latency-svc-n6fr5 [124.630808ms]
    Aug 24 09:46:10.365: INFO: Got endpoints: latency-svc-czhd2 [359.991362ms]
    Aug 24 09:46:10.366: INFO: Got endpoints: latency-svc-vrmsf [134.287013ms]
    Aug 24 09:46:10.385: INFO: Got endpoints: latency-svc-d52t5 [134.359775ms]
    Aug 24 09:46:10.404: INFO: Got endpoints: latency-svc-lp4vt [142.948254ms]
    Aug 24 09:46:10.408: INFO: Created: latency-svc-xs8gg
    Aug 24 09:46:10.423: INFO: Created: latency-svc-99pjm
    Aug 24 09:46:10.432: INFO: Got endpoints: latency-svc-xs8gg [159.006584ms]
    Aug 24 09:46:10.444: INFO: Created: latency-svc-4c25b
    Aug 24 09:46:10.452: INFO: Got endpoints: latency-svc-99pjm [174.993915ms]
    Aug 24 09:46:10.473: INFO: Created: latency-svc-jxtnj
    Aug 24 09:46:10.495: INFO: Created: latency-svc-wgw5s
    Aug 24 09:46:10.498: INFO: Got endpoints: latency-svc-4c25b [219.878024ms]
    Aug 24 09:46:10.502: INFO: Got endpoints: latency-svc-jxtnj [213.471317ms]
    Aug 24 09:46:10.513: INFO: Created: latency-svc-xv87t
    Aug 24 09:46:10.515: INFO: Got endpoints: latency-svc-wgw5s [204.387595ms]
    Aug 24 09:46:10.527: INFO: Created: latency-svc-hhrwh
    Aug 24 09:46:10.544: INFO: Created: latency-svc-25fdr
    Aug 24 09:46:10.562: INFO: Created: latency-svc-rxccx
    Aug 24 09:46:10.568: INFO: Created: latency-svc-slncp
    Aug 24 09:46:10.581: INFO: Created: latency-svc-79bgt
    Aug 24 09:46:10.582: INFO: Got endpoints: latency-svc-xv87t [272.051963ms]
    Aug 24 09:46:10.583: INFO: Got endpoints: latency-svc-25fdr [236.218808ms]
    Aug 24 09:46:10.583: INFO: Got endpoints: latency-svc-hhrwh [254.447718ms]
    Aug 24 09:46:10.601: INFO: Created: latency-svc-lpvgb
    Aug 24 09:46:10.610: INFO: Created: latency-svc-snfs9
    Aug 24 09:46:10.622: INFO: Created: latency-svc-c2lhb
    Aug 24 09:46:10.631: INFO: Got endpoints: latency-svc-rxccx [284.437218ms]
    Aug 24 09:46:10.637: INFO: Created: latency-svc-229wd
    Aug 24 09:46:10.654: INFO: Created: latency-svc-q89kp
    Aug 24 09:46:10.666: INFO: Created: latency-svc-mx4dt
    Aug 24 09:46:10.709: INFO: Got endpoints: latency-svc-slncp [353.566189ms]
    Aug 24 09:46:10.715: INFO: Got endpoints: latency-svc-79bgt [349.158485ms]
    Aug 24 09:46:10.717: INFO: Created: latency-svc-pl54g
    Aug 24 09:46:10.750: INFO: Created: latency-svc-xhbfc
    Aug 24 09:46:10.760: INFO: Created: latency-svc-npv5g
    Aug 24 09:46:10.766: INFO: Got endpoints: latency-svc-lpvgb [400.154004ms]
    Aug 24 09:46:10.794: INFO: Got endpoints: latency-svc-snfs9 [409.483201ms]
    Aug 24 09:46:10.799: INFO: Created: latency-svc-lvgqt
    Aug 24 09:46:10.834: INFO: Created: latency-svc-qmfc8
    Aug 24 09:46:10.842: INFO: Created: latency-svc-jz4pw
    Aug 24 09:46:10.857: INFO: Got endpoints: latency-svc-c2lhb [452.556122ms]
    Aug 24 09:46:10.863: INFO: Created: latency-svc-f2lgq
    Aug 24 09:46:10.913: INFO: Created: latency-svc-mq4v5
    Aug 24 09:46:10.920: INFO: Created: latency-svc-2sgbz
    Aug 24 09:46:10.961: INFO: Got endpoints: latency-svc-q89kp [674.528287ms]
    Aug 24 09:46:10.962: INFO: Got endpoints: latency-svc-229wd [530.15609ms]
    Aug 24 09:46:11.011: INFO: Got endpoints: latency-svc-mx4dt [558.943371ms]
    Aug 24 09:46:11.031: INFO: Created: latency-svc-6vj4z
    Aug 24 09:46:11.040: INFO: Created: latency-svc-9wlvc
    Aug 24 09:46:11.048: INFO: Got endpoints: latency-svc-pl54g [550.452436ms]
    Aug 24 09:46:11.056: INFO: Created: latency-svc-2h9cb
    Aug 24 09:46:11.099: INFO: Created: latency-svc-zqlp7
    Aug 24 09:46:11.104: INFO: Got endpoints: latency-svc-xhbfc [601.781899ms]
    Aug 24 09:46:11.113: INFO: Created: latency-svc-r5p92
    Aug 24 09:46:11.128: INFO: Created: latency-svc-6vkbg
    Aug 24 09:46:11.147: INFO: Got endpoints: latency-svc-npv5g [631.198511ms]
    Aug 24 09:46:11.173: INFO: Created: latency-svc-pjwpw
    Aug 24 09:46:11.189: INFO: Created: latency-svc-2hgtl
    Aug 24 09:46:11.193: INFO: Got endpoints: latency-svc-lvgqt [609.594009ms]
    Aug 24 09:46:11.194: INFO: Created: latency-svc-bbdfr
    Aug 24 09:46:11.214: INFO: Created: latency-svc-6qh9z
    Aug 24 09:46:11.239: INFO: Got endpoints: latency-svc-qmfc8 [656.055306ms]
    Aug 24 09:46:11.254: INFO: Created: latency-svc-wjd2j
    Aug 24 09:46:11.299: INFO: Got endpoints: latency-svc-jz4pw [715.676079ms]
    Aug 24 09:46:11.319: INFO: Created: latency-svc-qczsp
    Aug 24 09:46:11.341: INFO: Got endpoints: latency-svc-f2lgq [710.308756ms]
    Aug 24 09:46:11.366: INFO: Created: latency-svc-f9tvz
    Aug 24 09:46:11.402: INFO: Got endpoints: latency-svc-mq4v5 [692.246281ms]
    Aug 24 09:46:11.438: INFO: Created: latency-svc-x2w5v
    Aug 24 09:46:11.447: INFO: Got endpoints: latency-svc-2sgbz [732.256833ms]
    Aug 24 09:46:11.497: INFO: Got endpoints: latency-svc-9wlvc [730.558761ms]
    Aug 24 09:46:11.536: INFO: Created: latency-svc-z9jsk
    Aug 24 09:46:11.559: INFO: Created: latency-svc-5tcbs
    Aug 24 09:46:11.561: INFO: Got endpoints: latency-svc-6vj4z [766.653833ms]
    Aug 24 09:46:11.577: INFO: Created: latency-svc-95dc9
    Aug 24 09:46:11.590: INFO: Got endpoints: latency-svc-2h9cb [732.859217ms]
    Aug 24 09:46:11.608: INFO: Created: latency-svc-q9gqp
    Aug 24 09:46:11.645: INFO: Got endpoints: latency-svc-zqlp7 [684.028603ms]
    Aug 24 09:46:11.665: INFO: Created: latency-svc-99vgf
    Aug 24 09:46:11.698: INFO: Got endpoints: latency-svc-r5p92 [735.74282ms]
    Aug 24 09:46:11.714: INFO: Created: latency-svc-qdq75
    Aug 24 09:46:11.740: INFO: Got endpoints: latency-svc-6vkbg [728.711481ms]
    Aug 24 09:46:11.757: INFO: Created: latency-svc-dg5lt
    Aug 24 09:46:11.789: INFO: Got endpoints: latency-svc-pjwpw [741.213486ms]
    Aug 24 09:46:11.808: INFO: Created: latency-svc-qhcr9
    Aug 24 09:46:11.845: INFO: Got endpoints: latency-svc-2hgtl [698.58294ms]
    Aug 24 09:46:11.862: INFO: Created: latency-svc-7hlpb
    Aug 24 09:46:11.894: INFO: Got endpoints: latency-svc-bbdfr [789.96677ms]
    Aug 24 09:46:11.913: INFO: Created: latency-svc-7nz6l
    Aug 24 09:46:11.940: INFO: Got endpoints: latency-svc-6qh9z [747.735494ms]
    Aug 24 09:46:11.962: INFO: Created: latency-svc-dkn2m
    Aug 24 09:46:11.992: INFO: Got endpoints: latency-svc-wjd2j [752.953188ms]
    Aug 24 09:46:12.011: INFO: Created: latency-svc-5gzbm
    Aug 24 09:46:12.042: INFO: Got endpoints: latency-svc-qczsp [742.278181ms]
    Aug 24 09:46:12.074: INFO: Created: latency-svc-2kw4m
    Aug 24 09:46:12.096: INFO: Got endpoints: latency-svc-f9tvz [754.74076ms]
    Aug 24 09:46:12.125: INFO: Created: latency-svc-jtdrg
    Aug 24 09:46:12.140: INFO: Got endpoints: latency-svc-x2w5v [737.952868ms]
    Aug 24 09:46:12.155: INFO: Created: latency-svc-96lrj
    Aug 24 09:46:12.191: INFO: Got endpoints: latency-svc-z9jsk [743.561775ms]
    Aug 24 09:46:12.207: INFO: Created: latency-svc-8cl6t
    Aug 24 09:46:12.242: INFO: Got endpoints: latency-svc-5tcbs [744.315347ms]
    Aug 24 09:46:12.266: INFO: Created: latency-svc-6rqvp
    Aug 24 09:46:12.292: INFO: Got endpoints: latency-svc-95dc9 [730.860061ms]
    Aug 24 09:46:12.311: INFO: Created: latency-svc-nk6p2
    Aug 24 09:46:12.350: INFO: Got endpoints: latency-svc-q9gqp [759.374452ms]
    Aug 24 09:46:12.367: INFO: Created: latency-svc-9m7k9
    Aug 24 09:46:12.390: INFO: Got endpoints: latency-svc-99vgf [744.882309ms]
    Aug 24 09:46:12.415: INFO: Created: latency-svc-8r84w
    Aug 24 09:46:12.445: INFO: Got endpoints: latency-svc-qdq75 [746.767182ms]
    Aug 24 09:46:12.466: INFO: Created: latency-svc-svtgb
    Aug 24 09:46:12.511: INFO: Got endpoints: latency-svc-dg5lt [770.942733ms]
    Aug 24 09:46:12.533: INFO: Created: latency-svc-9stvc
    Aug 24 09:46:12.544: INFO: Got endpoints: latency-svc-qhcr9 [753.962089ms]
    Aug 24 09:46:12.567: INFO: Created: latency-svc-td68b
    Aug 24 09:46:12.621: INFO: Got endpoints: latency-svc-7hlpb [775.239676ms]
    Aug 24 09:46:12.644: INFO: Created: latency-svc-zxr6d
    Aug 24 09:46:12.683: INFO: Got endpoints: latency-svc-7nz6l [788.813763ms]
    Aug 24 09:46:12.711: INFO: Got endpoints: latency-svc-dkn2m [769.91762ms]
    Aug 24 09:46:12.722: INFO: Created: latency-svc-2sc8t
    Aug 24 09:46:12.745: INFO: Got endpoints: latency-svc-5gzbm [752.949155ms]
    Aug 24 09:46:12.788: INFO: Created: latency-svc-jlngz
    Aug 24 09:46:12.791: INFO: Created: latency-svc-jpjlq
    Aug 24 09:46:12.803: INFO: Got endpoints: latency-svc-2kw4m [761.03381ms]
    Aug 24 09:46:12.843: INFO: Got endpoints: latency-svc-jtdrg [746.322292ms]
    Aug 24 09:46:12.859: INFO: Created: latency-svc-wszzl
    Aug 24 09:46:12.881: INFO: Created: latency-svc-856s2
    Aug 24 09:46:12.897: INFO: Got endpoints: latency-svc-96lrj [756.629803ms]
    Aug 24 09:46:12.950: INFO: Created: latency-svc-2lvh2
    Aug 24 09:46:12.970: INFO: Got endpoints: latency-svc-8cl6t [778.499149ms]
    Aug 24 09:46:13.013: INFO: Got endpoints: latency-svc-6rqvp [771.491625ms]
    Aug 24 09:46:13.015: INFO: Created: latency-svc-nbrlr
    Aug 24 09:46:13.065: INFO: Got endpoints: latency-svc-nk6p2 [773.07689ms]
    Aug 24 09:46:13.076: INFO: Created: latency-svc-hrnpk
    Aug 24 09:46:13.099: INFO: Created: latency-svc-fw7pw
    Aug 24 09:46:13.099: INFO: Got endpoints: latency-svc-9m7k9 [749.339523ms]
    Aug 24 09:46:13.126: INFO: Created: latency-svc-zqwbg
    Aug 24 09:46:13.139: INFO: Got endpoints: latency-svc-8r84w [748.586284ms]
    Aug 24 09:46:13.163: INFO: Created: latency-svc-hlwsq
    Aug 24 09:46:13.198: INFO: Got endpoints: latency-svc-svtgb [753.094767ms]
    Aug 24 09:46:13.224: INFO: Created: latency-svc-9llnv
    Aug 24 09:46:13.244: INFO: Got endpoints: latency-svc-9stvc [732.706856ms]
    Aug 24 09:46:13.265: INFO: Created: latency-svc-zjfn8
    Aug 24 09:46:13.293: INFO: Got endpoints: latency-svc-td68b [748.906696ms]
    Aug 24 09:46:13.314: INFO: Created: latency-svc-cgtw8
    Aug 24 09:46:13.344: INFO: Got endpoints: latency-svc-zxr6d [721.489048ms]
    Aug 24 09:46:13.364: INFO: Created: latency-svc-g7lbk
    Aug 24 09:46:13.407: INFO: Got endpoints: latency-svc-2sc8t [724.45499ms]
    Aug 24 09:46:13.435: INFO: Created: latency-svc-4sdrm
    Aug 24 09:46:13.444: INFO: Got endpoints: latency-svc-jpjlq [733.268682ms]
    Aug 24 09:46:13.462: INFO: Created: latency-svc-m4dr9
    Aug 24 09:46:13.503: INFO: Got endpoints: latency-svc-jlngz [757.417009ms]
    Aug 24 09:46:13.524: INFO: Created: latency-svc-jpd66
    Aug 24 09:46:13.539: INFO: Got endpoints: latency-svc-wszzl [736.337316ms]
    Aug 24 09:46:13.565: INFO: Created: latency-svc-5ggfl
    Aug 24 09:46:13.605: INFO: Got endpoints: latency-svc-856s2 [762.106695ms]
    Aug 24 09:46:13.647: INFO: Created: latency-svc-dckrc
    Aug 24 09:46:13.651: INFO: Got endpoints: latency-svc-2lvh2 [754.127831ms]
    Aug 24 09:46:13.682: INFO: Created: latency-svc-spcqf
    Aug 24 09:46:13.702: INFO: Got endpoints: latency-svc-nbrlr [731.583959ms]
    Aug 24 09:46:13.726: INFO: Created: latency-svc-wcrxs
    Aug 24 09:46:13.751: INFO: Got endpoints: latency-svc-hrnpk [737.053111ms]
    Aug 24 09:46:13.773: INFO: Created: latency-svc-lw2f8
    Aug 24 09:46:13.796: INFO: Got endpoints: latency-svc-fw7pw [730.127294ms]
    Aug 24 09:46:13.829: INFO: Created: latency-svc-h4hwb
    Aug 24 09:46:13.843: INFO: Got endpoints: latency-svc-zqwbg [743.546422ms]
    Aug 24 09:46:13.862: INFO: Created: latency-svc-4kdqn
    Aug 24 09:46:13.900: INFO: Got endpoints: latency-svc-hlwsq [760.949043ms]
    Aug 24 09:46:13.919: INFO: Created: latency-svc-25bfb
    Aug 24 09:46:13.942: INFO: Got endpoints: latency-svc-9llnv [743.617867ms]
    Aug 24 09:46:13.969: INFO: Created: latency-svc-cjr5h
    Aug 24 09:46:13.991: INFO: Got endpoints: latency-svc-zjfn8 [746.149322ms]
    Aug 24 09:46:14.006: INFO: Created: latency-svc-56wvs
    Aug 24 09:46:14.038: INFO: Got endpoints: latency-svc-cgtw8 [745.414647ms]
    Aug 24 09:46:14.056: INFO: Created: latency-svc-zrs2w
    Aug 24 09:46:14.091: INFO: Got endpoints: latency-svc-g7lbk [746.755757ms]
    Aug 24 09:46:14.111: INFO: Created: latency-svc-2mr7w
    Aug 24 09:46:14.144: INFO: Got endpoints: latency-svc-4sdrm [735.979032ms]
    Aug 24 09:46:14.168: INFO: Created: latency-svc-86x2z
    Aug 24 09:46:14.188: INFO: Got endpoints: latency-svc-m4dr9 [743.935547ms]
    Aug 24 09:46:14.212: INFO: Created: latency-svc-kfmx7
    Aug 24 09:46:14.241: INFO: Got endpoints: latency-svc-jpd66 [737.69839ms]
    Aug 24 09:46:14.260: INFO: Created: latency-svc-p2xjk
    Aug 24 09:46:14.290: INFO: Got endpoints: latency-svc-5ggfl [750.614339ms]
    Aug 24 09:46:14.308: INFO: Created: latency-svc-5lthn
    Aug 24 09:46:14.342: INFO: Got endpoints: latency-svc-dckrc [736.602336ms]
    Aug 24 09:46:14.363: INFO: Created: latency-svc-ngwv9
    Aug 24 09:46:14.392: INFO: Got endpoints: latency-svc-spcqf [740.569941ms]
    Aug 24 09:46:14.417: INFO: Created: latency-svc-bhdlw
    Aug 24 09:46:14.443: INFO: Got endpoints: latency-svc-wcrxs [741.676549ms]
    Aug 24 09:46:14.469: INFO: Created: latency-svc-2xp2n
    Aug 24 09:46:14.492: INFO: Got endpoints: latency-svc-lw2f8 [741.353544ms]
    Aug 24 09:46:14.514: INFO: Created: latency-svc-rzkpf
    Aug 24 09:46:14.543: INFO: Got endpoints: latency-svc-h4hwb [746.662021ms]
    Aug 24 09:46:14.561: INFO: Created: latency-svc-lnpct
    Aug 24 09:46:14.594: INFO: Got endpoints: latency-svc-4kdqn [751.029048ms]
    Aug 24 09:46:14.612: INFO: Created: latency-svc-xcz5p
    Aug 24 09:46:14.655: INFO: Got endpoints: latency-svc-25bfb [753.998568ms]
    Aug 24 09:46:14.686: INFO: Created: latency-svc-7s42q
    Aug 24 09:46:14.693: INFO: Got endpoints: latency-svc-cjr5h [750.872597ms]
    Aug 24 09:46:14.726: INFO: Created: latency-svc-v4vhl
    Aug 24 09:46:14.746: INFO: Got endpoints: latency-svc-56wvs [754.974965ms]
    Aug 24 09:46:14.768: INFO: Created: latency-svc-9g8gd
    Aug 24 09:46:14.790: INFO: Got endpoints: latency-svc-zrs2w [750.941828ms]
    Aug 24 09:46:14.822: INFO: Created: latency-svc-qzlnt
    Aug 24 09:46:14.839: INFO: Got endpoints: latency-svc-2mr7w [748.459672ms]
    Aug 24 09:46:14.858: INFO: Created: latency-svc-tjhb9
    Aug 24 09:46:14.905: INFO: Got endpoints: latency-svc-86x2z [760.902972ms]
    Aug 24 09:46:14.935: INFO: Created: latency-svc-h8pwt
    Aug 24 09:46:14.942: INFO: Got endpoints: latency-svc-kfmx7 [753.565294ms]
    Aug 24 09:46:15.005: INFO: Got endpoints: latency-svc-p2xjk [763.888635ms]
    Aug 24 09:46:15.012: INFO: Created: latency-svc-w6xrv
    Aug 24 09:46:15.037: INFO: Created: latency-svc-cq4l6
    Aug 24 09:46:15.042: INFO: Got endpoints: latency-svc-5lthn [751.511851ms]
    Aug 24 09:46:15.058: INFO: Created: latency-svc-hm92q
    Aug 24 09:46:15.089: INFO: Got endpoints: latency-svc-ngwv9 [746.739821ms]
    Aug 24 09:46:15.116: INFO: Created: latency-svc-gdc4v
    Aug 24 09:46:15.140: INFO: Got endpoints: latency-svc-bhdlw [747.754649ms]
    Aug 24 09:46:15.157: INFO: Created: latency-svc-wwhbz
    Aug 24 09:46:15.190: INFO: Got endpoints: latency-svc-2xp2n [746.659052ms]
    Aug 24 09:46:15.206: INFO: Created: latency-svc-7lg9c
    Aug 24 09:46:15.240: INFO: Got endpoints: latency-svc-rzkpf [747.093301ms]
    Aug 24 09:46:15.257: INFO: Created: latency-svc-ggmvm
    Aug 24 09:46:15.299: INFO: Got endpoints: latency-svc-lnpct [755.896637ms]
    Aug 24 09:46:15.318: INFO: Created: latency-svc-m2qvq
    Aug 24 09:46:15.342: INFO: Got endpoints: latency-svc-xcz5p [747.435351ms]
    Aug 24 09:46:15.371: INFO: Created: latency-svc-qqmvh
    Aug 24 09:46:15.398: INFO: Got endpoints: latency-svc-7s42q [743.322782ms]
    Aug 24 09:46:15.441: INFO: Created: latency-svc-8lkfk
    Aug 24 09:46:15.441: INFO: Got endpoints: latency-svc-v4vhl [747.137357ms]
    Aug 24 09:46:15.457: INFO: Created: latency-svc-whkkp
    Aug 24 09:46:15.490: INFO: Got endpoints: latency-svc-9g8gd [744.435947ms]
    Aug 24 09:46:15.520: INFO: Created: latency-svc-bc7m7
    Aug 24 09:46:15.542: INFO: Got endpoints: latency-svc-qzlnt [752.01144ms]
    Aug 24 09:46:15.561: INFO: Created: latency-svc-99spb
    Aug 24 09:46:15.598: INFO: Got endpoints: latency-svc-tjhb9 [758.610117ms]
    Aug 24 09:46:15.625: INFO: Created: latency-svc-x8566
    Aug 24 09:46:15.642: INFO: Got endpoints: latency-svc-h8pwt [736.599281ms]
    Aug 24 09:46:15.664: INFO: Created: latency-svc-4mj55
    Aug 24 09:46:15.690: INFO: Got endpoints: latency-svc-w6xrv [747.990385ms]
    Aug 24 09:46:15.713: INFO: Created: latency-svc-ck4m5
    Aug 24 09:46:15.743: INFO: Got endpoints: latency-svc-cq4l6 [738.246407ms]
    Aug 24 09:46:15.767: INFO: Created: latency-svc-v75zn
    Aug 24 09:46:15.790: INFO: Got endpoints: latency-svc-hm92q [748.386304ms]
    Aug 24 09:46:15.811: INFO: Created: latency-svc-5lwz6
    Aug 24 09:46:15.847: INFO: Got endpoints: latency-svc-gdc4v [757.755257ms]
    Aug 24 09:46:15.867: INFO: Created: latency-svc-r5cbl
    Aug 24 09:46:15.892: INFO: Got endpoints: latency-svc-wwhbz [751.912551ms]
    Aug 24 09:46:15.909: INFO: Created: latency-svc-lsswt
    Aug 24 09:46:15.944: INFO: Got endpoints: latency-svc-7lg9c [753.853818ms]
    Aug 24 09:46:15.968: INFO: Created: latency-svc-xmjqr
    Aug 24 09:46:15.990: INFO: Got endpoints: latency-svc-ggmvm [749.74953ms]
    Aug 24 09:46:16.016: INFO: Created: latency-svc-5qzj6
    Aug 24 09:46:16.051: INFO: Got endpoints: latency-svc-m2qvq [751.796423ms]
    Aug 24 09:46:16.069: INFO: Created: latency-svc-vsnxf
    Aug 24 09:46:16.092: INFO: Got endpoints: latency-svc-qqmvh [749.881585ms]
    Aug 24 09:46:16.107: INFO: Created: latency-svc-j8qzr
    Aug 24 09:46:16.158: INFO: Got endpoints: latency-svc-8lkfk [759.373388ms]
    Aug 24 09:46:16.180: INFO: Created: latency-svc-vhpgm
    Aug 24 09:46:16.192: INFO: Got endpoints: latency-svc-whkkp [751.076587ms]
    Aug 24 09:46:16.210: INFO: Created: latency-svc-8fjc9
    Aug 24 09:46:16.241: INFO: Got endpoints: latency-svc-bc7m7 [750.642337ms]
    Aug 24 09:46:16.259: INFO: Created: latency-svc-49cvt
    Aug 24 09:46:16.291: INFO: Got endpoints: latency-svc-99spb [748.921916ms]
    Aug 24 09:46:16.306: INFO: Created: latency-svc-j4qjv
    Aug 24 09:46:16.346: INFO: Got endpoints: latency-svc-x8566 [747.444378ms]
    Aug 24 09:46:16.368: INFO: Created: latency-svc-hvmw5
    Aug 24 09:46:16.394: INFO: Got endpoints: latency-svc-4mj55 [752.515141ms]
    Aug 24 09:46:16.412: INFO: Created: latency-svc-ffnrd
    Aug 24 09:46:16.442: INFO: Got endpoints: latency-svc-ck4m5 [751.775115ms]
    Aug 24 09:46:16.461: INFO: Created: latency-svc-ls82v
    Aug 24 09:46:16.490: INFO: Got endpoints: latency-svc-v75zn [746.407481ms]
    Aug 24 09:46:16.510: INFO: Created: latency-svc-m9msg
    Aug 24 09:46:16.552: INFO: Got endpoints: latency-svc-5lwz6 [761.374392ms]
    Aug 24 09:46:16.568: INFO: Created: latency-svc-g92ls
    Aug 24 09:46:16.591: INFO: Got endpoints: latency-svc-r5cbl [743.579506ms]
    Aug 24 09:46:16.625: INFO: Created: latency-svc-92srw
    Aug 24 09:46:16.643: INFO: Got endpoints: latency-svc-lsswt [750.627512ms]
    Aug 24 09:46:16.661: INFO: Created: latency-svc-4q8vv
    Aug 24 09:46:16.691: INFO: Got endpoints: latency-svc-xmjqr [746.605558ms]
    Aug 24 09:46:16.714: INFO: Created: latency-svc-l7ncp
    Aug 24 09:46:16.747: INFO: Got endpoints: latency-svc-5qzj6 [756.786552ms]
    Aug 24 09:46:16.795: INFO: Created: latency-svc-2jb9m
    Aug 24 09:46:16.796: INFO: Got endpoints: latency-svc-vsnxf [745.046814ms]
    Aug 24 09:46:16.813: INFO: Created: latency-svc-wzd9h
    Aug 24 09:46:16.844: INFO: Got endpoints: latency-svc-j8qzr [752.170492ms]
    Aug 24 09:46:16.863: INFO: Created: latency-svc-jj5bd
    Aug 24 09:46:16.895: INFO: Got endpoints: latency-svc-vhpgm [736.666276ms]
    Aug 24 09:46:16.927: INFO: Created: latency-svc-zmtbn
    Aug 24 09:46:16.942: INFO: Got endpoints: latency-svc-8fjc9 [749.577043ms]
    Aug 24 09:46:16.961: INFO: Created: latency-svc-7tvhb
    Aug 24 09:46:16.999: INFO: Got endpoints: latency-svc-49cvt [757.815503ms]
    Aug 24 09:46:17.020: INFO: Created: latency-svc-gf78j
    Aug 24 09:46:17.042: INFO: Got endpoints: latency-svc-j4qjv [750.987941ms]
    Aug 24 09:46:17.072: INFO: Created: latency-svc-bkqhl
    Aug 24 09:46:17.093: INFO: Got endpoints: latency-svc-hvmw5 [746.914078ms]
    Aug 24 09:46:17.113: INFO: Created: latency-svc-7z9jg
    Aug 24 09:46:17.138: INFO: Got endpoints: latency-svc-ffnrd [743.664394ms]
    Aug 24 09:46:17.159: INFO: Created: latency-svc-f2lt7
    Aug 24 09:46:17.196: INFO: Got endpoints: latency-svc-ls82v [754.091969ms]
    Aug 24 09:46:17.212: INFO: Created: latency-svc-nxmhn
    Aug 24 09:46:17.248: INFO: Got endpoints: latency-svc-m9msg [758.600468ms]
    Aug 24 09:46:17.265: INFO: Created: latency-svc-xvvmk
    Aug 24 09:46:17.290: INFO: Got endpoints: latency-svc-g92ls [738.241279ms]
    Aug 24 09:46:17.309: INFO: Created: latency-svc-fkxzs
    Aug 24 09:46:17.342: INFO: Got endpoints: latency-svc-92srw [751.395581ms]
    Aug 24 09:46:17.363: INFO: Created: latency-svc-7lgk6
    Aug 24 09:46:17.397: INFO: Got endpoints: latency-svc-4q8vv [753.461845ms]
    Aug 24 09:46:17.434: INFO: Created: latency-svc-s8b2j
    Aug 24 09:46:17.443: INFO: Got endpoints: latency-svc-l7ncp [752.486537ms]
    Aug 24 09:46:17.466: INFO: Created: latency-svc-rg959
    Aug 24 09:46:17.491: INFO: Got endpoints: latency-svc-2jb9m [741.275455ms]
    Aug 24 09:46:17.510: INFO: Created: latency-svc-62g94
    Aug 24 09:46:17.549: INFO: Got endpoints: latency-svc-wzd9h [753.4512ms]
    Aug 24 09:46:17.574: INFO: Created: latency-svc-ggn7d
    Aug 24 09:46:17.593: INFO: Got endpoints: latency-svc-jj5bd [748.363947ms]
    Aug 24 09:46:17.623: INFO: Created: latency-svc-5n6vj
    Aug 24 09:46:17.641: INFO: Got endpoints: latency-svc-zmtbn [746.434936ms]
    Aug 24 09:46:17.693: INFO: Got endpoints: latency-svc-7tvhb [751.039779ms]
    Aug 24 09:46:17.745: INFO: Got endpoints: latency-svc-gf78j [745.291981ms]
    Aug 24 09:46:17.788: INFO: Got endpoints: latency-svc-bkqhl [745.769674ms]
    Aug 24 09:46:17.841: INFO: Got endpoints: latency-svc-7z9jg [748.108854ms]
    Aug 24 09:46:17.890: INFO: Got endpoints: latency-svc-f2lt7 [751.650646ms]
    Aug 24 09:46:17.939: INFO: Got endpoints: latency-svc-nxmhn [742.569609ms]
    Aug 24 09:46:17.992: INFO: Got endpoints: latency-svc-xvvmk [742.85397ms]
    Aug 24 09:46:18.041: INFO: Got endpoints: latency-svc-fkxzs [750.588988ms]
    Aug 24 09:46:18.090: INFO: Got endpoints: latency-svc-7lgk6 [747.916037ms]
    Aug 24 09:46:18.138: INFO: Got endpoints: latency-svc-s8b2j [741.476744ms]
    Aug 24 09:46:18.190: INFO: Got endpoints: latency-svc-rg959 [745.790239ms]
    Aug 24 09:46:18.241: INFO: Got endpoints: latency-svc-62g94 [749.341095ms]
    Aug 24 09:46:18.290: INFO: Got endpoints: latency-svc-ggn7d [740.272661ms]
    Aug 24 09:46:18.342: INFO: Got endpoints: latency-svc-5n6vj [749.49986ms]
    Aug 24 09:46:18.343: INFO: Latencies: [39.242508ms 57.672498ms 69.949446ms 81.194877ms 93.995824ms 106.963322ms 124.575007ms 124.630808ms 134.287013ms 134.359775ms 142.948254ms 143.883248ms 143.940445ms 154.478383ms 159.006584ms 165.229185ms 174.185555ms 174.993915ms 182.843089ms 182.872492ms 204.387595ms 205.493357ms 213.471317ms 219.878024ms 229.110936ms 236.218808ms 239.811736ms 250.874446ms 251.676842ms 254.447718ms 266.983777ms 272.051963ms 284.437218ms 295.516137ms 299.449043ms 304.598515ms 308.363594ms 337.275569ms 349.158485ms 353.566189ms 359.991362ms 364.262807ms 367.19052ms 384.261937ms 391.422852ms 392.963293ms 400.154004ms 409.483201ms 431.225961ms 452.556122ms 530.15609ms 550.452436ms 558.943371ms 601.781899ms 609.594009ms 631.198511ms 656.055306ms 674.528287ms 684.028603ms 692.246281ms 698.58294ms 710.308756ms 715.676079ms 721.489048ms 724.45499ms 728.711481ms 730.127294ms 730.558761ms 730.860061ms 731.583959ms 732.256833ms 732.706856ms 732.859217ms 733.268682ms 735.74282ms 735.979032ms 736.337316ms 736.599281ms 736.602336ms 736.666276ms 737.053111ms 737.69839ms 737.952868ms 738.241279ms 738.246407ms 740.272661ms 740.569941ms 741.213486ms 741.275455ms 741.353544ms 741.476744ms 741.676549ms 742.278181ms 742.569609ms 742.85397ms 743.322782ms 743.546422ms 743.561775ms 743.579506ms 743.617867ms 743.664394ms 743.935547ms 744.315347ms 744.435947ms 744.882309ms 745.046814ms 745.291981ms 745.414647ms 745.769674ms 745.790239ms 746.149322ms 746.322292ms 746.407481ms 746.434936ms 746.605558ms 746.659052ms 746.662021ms 746.739821ms 746.755757ms 746.767182ms 746.914078ms 747.093301ms 747.137357ms 747.435351ms 747.444378ms 747.735494ms 747.754649ms 747.916037ms 747.990385ms 748.108854ms 748.363947ms 748.386304ms 748.459672ms 748.586284ms 748.906696ms 748.921916ms 749.339523ms 749.341095ms 749.49986ms 749.577043ms 749.74953ms 749.881585ms 750.588988ms 750.614339ms 750.627512ms 750.642337ms 750.872597ms 750.941828ms 750.987941ms 751.029048ms 751.039779ms 751.076587ms 751.395581ms 751.511851ms 751.650646ms 751.775115ms 751.796423ms 751.912551ms 752.01144ms 752.170492ms 752.486537ms 752.515141ms 752.949155ms 752.953188ms 753.094767ms 753.4512ms 753.461845ms 753.565294ms 753.853818ms 753.962089ms 753.998568ms 754.091969ms 754.127831ms 754.74076ms 754.974965ms 755.896637ms 756.629803ms 756.786552ms 757.417009ms 757.755257ms 757.815503ms 758.600468ms 758.610117ms 759.373388ms 759.374452ms 760.902972ms 760.949043ms 761.03381ms 761.374392ms 762.106695ms 763.888635ms 766.653833ms 769.91762ms 770.942733ms 771.491625ms 773.07689ms 775.239676ms 778.499149ms 788.813763ms 789.96677ms]
    Aug 24 09:46:18.343: INFO: 50 %ile: 743.664394ms
    Aug 24 09:46:18.343: INFO: 90 %ile: 757.815503ms
    Aug 24 09:46:18.343: INFO: 99 %ile: 788.813763ms
    Aug 24 09:46:18.343: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Aug 24 09:46:18.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-830" for this suite. 08/24/22 09:46:18.354
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:18.381
Aug 24 09:46:18.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 09:46:18.386
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:18.415
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:18.419
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Aug 24 09:46:18.436: INFO: Waiting up to 2m0s for pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" in namespace "var-expansion-1696" to be "container 0 failed with reason CreateContainerConfigError"
Aug 24 09:46:18.441: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238": Phase="Pending", Reason="", readiness=false. Elapsed: 4.987716ms
Aug 24 09:46:20.448: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012712672s
Aug 24 09:46:20.449: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 24 09:46:20.449: INFO: Deleting pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" in namespace "var-expansion-1696"
Aug 24 09:46:20.464: INFO: Wait up to 5m0s for pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 09:46:22.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1696" for this suite. 08/24/22 09:46:22.484
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":65,"skipped":1200,"failed":0}
------------------------------
• [4.115 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:18.381
    Aug 24 09:46:18.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 09:46:18.386
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:18.415
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:18.419
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Aug 24 09:46:18.436: INFO: Waiting up to 2m0s for pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" in namespace "var-expansion-1696" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 24 09:46:18.441: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238": Phase="Pending", Reason="", readiness=false. Elapsed: 4.987716ms
    Aug 24 09:46:20.448: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012712672s
    Aug 24 09:46:20.449: INFO: Pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 24 09:46:20.449: INFO: Deleting pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" in namespace "var-expansion-1696"
    Aug 24 09:46:20.464: INFO: Wait up to 5m0s for pod "var-expansion-f288bae4-ac9d-480a-b9f6-302172659238" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 09:46:22.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1696" for this suite. 08/24/22 09:46:22.484
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:22.497
Aug 24 09:46:22.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 09:46:22.502
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:22.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:22.54
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 08/24/22 09:46:22.545
Aug 24 09:46:22.560: INFO: Waiting up to 5m0s for pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d" in namespace "emptydir-3512" to be "Succeeded or Failed"
Aug 24 09:46:22.576: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.991124ms
Aug 24 09:46:24.583: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022690641s
Aug 24 09:46:26.586: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025790011s
STEP: Saw pod success 08/24/22 09:46:26.586
Aug 24 09:46:26.587: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d" satisfied condition "Succeeded or Failed"
Aug 24 09:46:26.595: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d container test-container: <nil>
STEP: delete the pod 08/24/22 09:46:26.652
Aug 24 09:46:26.760: INFO: Waiting for pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d to disappear
Aug 24 09:46:26.767: INFO: Pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 09:46:26.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3512" for this suite. 08/24/22 09:46:26.775
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":66,"skipped":1202,"failed":0}
------------------------------
• [4.297 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:22.497
    Aug 24 09:46:22.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 09:46:22.502
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:22.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:22.54
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/24/22 09:46:22.545
    Aug 24 09:46:22.560: INFO: Waiting up to 5m0s for pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d" in namespace "emptydir-3512" to be "Succeeded or Failed"
    Aug 24 09:46:22.576: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.991124ms
    Aug 24 09:46:24.583: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022690641s
    Aug 24 09:46:26.586: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025790011s
    STEP: Saw pod success 08/24/22 09:46:26.586
    Aug 24 09:46:26.587: INFO: Pod "pod-3bce70aa-91de-4a0f-9cc7-e9528959423d" satisfied condition "Succeeded or Failed"
    Aug 24 09:46:26.595: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d container test-container: <nil>
    STEP: delete the pod 08/24/22 09:46:26.652
    Aug 24 09:46:26.760: INFO: Waiting for pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d to disappear
    Aug 24 09:46:26.767: INFO: Pod pod-3bce70aa-91de-4a0f-9cc7-e9528959423d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 09:46:26.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3512" for this suite. 08/24/22 09:46:26.775
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:26.795
Aug 24 09:46:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 09:46:26.798
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:26.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:26.881
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 08/24/22 09:46:26.931
STEP: waiting for Deployment to be created 08/24/22 09:46:26.954
STEP: waiting for all Replicas to be Ready 08/24/22 09:46:26.957
Aug 24 09:46:26.959: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:26.960: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.018: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.019: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.128: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.128: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.205: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:27.206: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 09:46:28.955: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 24 09:46:28.955: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 24 09:46:29.095: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 08/24/22 09:46:29.095
W0824 09:46:29.129763      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 24 09:46:29.135: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 08/24/22 09:46:29.135
Aug 24 09:46:29.140: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.143: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.279: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.279: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:29.329: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:29.329: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:29.356: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:29.356: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:31.192: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:31.192: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:31.282: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
STEP: listing Deployments 08/24/22 09:46:31.282
Aug 24 09:46:31.335: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 08/24/22 09:46:31.336
Aug 24 09:46:31.368: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 08/24/22 09:46:31.368
Aug 24 09:46:31.457: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:31.491: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:31.592: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:31.650: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:33.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:33.204: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:33.324: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:33.354: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 09:46:35.103: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 08/24/22 09:46:35.173
STEP: fetching the DeploymentStatus 08/24/22 09:46:35.208
Aug 24 09:46:35.224: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:35.225: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:35.225: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3
Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3
STEP: deleting the Deployment 08/24/22 09:46:35.227
Aug 24 09:46:35.319: INFO: observed event type MODIFIED
Aug 24 09:46:35.322: INFO: observed event type MODIFIED
Aug 24 09:46:35.323: INFO: observed event type MODIFIED
Aug 24 09:46:35.331: INFO: observed event type MODIFIED
Aug 24 09:46:35.331: INFO: observed event type MODIFIED
Aug 24 09:46:35.331: INFO: observed event type MODIFIED
Aug 24 09:46:35.332: INFO: observed event type MODIFIED
Aug 24 09:46:35.332: INFO: observed event type MODIFIED
Aug 24 09:46:35.332: INFO: observed event type MODIFIED
Aug 24 09:46:35.332: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 09:46:35.342: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 09:46:35.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4482" for this suite. 08/24/22 09:46:35.388
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":67,"skipped":1206,"failed":0}
------------------------------
• [SLOW TEST] [8.712 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:26.795
    Aug 24 09:46:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 09:46:26.798
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:26.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:26.881
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 08/24/22 09:46:26.931
    STEP: waiting for Deployment to be created 08/24/22 09:46:26.954
    STEP: waiting for all Replicas to be Ready 08/24/22 09:46:26.957
    Aug 24 09:46:26.959: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:26.960: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.018: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.019: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.128: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.128: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.205: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:27.206: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 24 09:46:28.955: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 24 09:46:28.955: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 24 09:46:29.095: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 08/24/22 09:46:29.095
    W0824 09:46:29.129763      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 24 09:46:29.135: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 08/24/22 09:46:29.135
    Aug 24 09:46:29.140: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.141: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 0
    Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.143: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.279: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.279: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:29.329: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:29.329: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:29.356: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:29.356: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:31.192: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:31.192: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:31.282: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    STEP: listing Deployments 08/24/22 09:46:31.282
    Aug 24 09:46:31.335: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 08/24/22 09:46:31.336
    Aug 24 09:46:31.368: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 08/24/22 09:46:31.368
    Aug 24 09:46:31.457: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:31.491: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:31.592: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:31.650: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:33.142: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:33.204: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:33.324: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:33.354: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 24 09:46:35.103: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 08/24/22 09:46:35.173
    STEP: fetching the DeploymentStatus 08/24/22 09:46:35.208
    Aug 24 09:46:35.224: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:35.225: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:35.225: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 1
    Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:35.226: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3
    Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 2
    Aug 24 09:46:35.227: INFO: observed Deployment test-deployment in namespace deployment-4482 with ReadyReplicas 3
    STEP: deleting the Deployment 08/24/22 09:46:35.227
    Aug 24 09:46:35.319: INFO: observed event type MODIFIED
    Aug 24 09:46:35.322: INFO: observed event type MODIFIED
    Aug 24 09:46:35.323: INFO: observed event type MODIFIED
    Aug 24 09:46:35.331: INFO: observed event type MODIFIED
    Aug 24 09:46:35.331: INFO: observed event type MODIFIED
    Aug 24 09:46:35.331: INFO: observed event type MODIFIED
    Aug 24 09:46:35.332: INFO: observed event type MODIFIED
    Aug 24 09:46:35.332: INFO: observed event type MODIFIED
    Aug 24 09:46:35.332: INFO: observed event type MODIFIED
    Aug 24 09:46:35.332: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 09:46:35.342: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 09:46:35.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4482" for this suite. 08/24/22 09:46:35.388
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:46:35.54
Aug 24 09:46:35.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 09:46:35.547
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:35.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:35.613
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 08/24/22 09:46:35.617
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local;sleep 1; done
 08/24/22 09:46:35.634
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local;sleep 1; done
 08/24/22 09:46:35.634
STEP: creating a pod to probe DNS 08/24/22 09:46:35.635
STEP: submitting the pod to kubernetes 08/24/22 09:46:35.635
Aug 24 09:46:35.666: INFO: Waiting up to 15m0s for pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb" in namespace "dns-1472" to be "running"
Aug 24 09:46:35.673: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199239ms
Aug 24 09:46:37.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015337756s
Aug 24 09:46:39.687: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021053585s
Aug 24 09:46:41.680: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014235403s
Aug 24 09:46:43.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014668393s
Aug 24 09:46:45.688: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021476494s
Aug 24 09:46:47.686: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020096802s
Aug 24 09:46:49.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.014604442s
Aug 24 09:46:51.684: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018119482s
Aug 24 09:46:53.680: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Running", Reason="", readiness=true. Elapsed: 18.014432742s
Aug 24 09:46:53.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb" satisfied condition "running"
STEP: retrieving the pod 08/24/22 09:46:53.681
STEP: looking for the results for each expected name from probers 08/24/22 09:46:53.687
Aug 24 09:46:53.699: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.706: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.718: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.727: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.737: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.744: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.749: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.754: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:53.754: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

Aug 24 09:46:58.762: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.769: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.776: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.783: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.789: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.794: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.799: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.805: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:46:58.805: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

Aug 24 09:47:03.763: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.769: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.776: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.782: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.788: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.793: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.799: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.805: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:03.805: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

Aug 24 09:47:08.774: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:08.793: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:08.798: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
Aug 24 09:47:08.809: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local]

Aug 24 09:47:13.810: INFO: DNS probes using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb succeeded

STEP: deleting the pod 08/24/22 09:47:13.81
STEP: deleting the test headless service 08/24/22 09:47:13.848
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 09:47:13.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1472" for this suite. 08/24/22 09:47:13.922
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":68,"skipped":1239,"failed":0}
------------------------------
• [SLOW TEST] [38.396 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:46:35.54
    Aug 24 09:46:35.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 09:46:35.547
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:46:35.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:46:35.613
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 08/24/22 09:46:35.617
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local;sleep 1; done
     08/24/22 09:46:35.634
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1472.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local;sleep 1; done
     08/24/22 09:46:35.634
    STEP: creating a pod to probe DNS 08/24/22 09:46:35.635
    STEP: submitting the pod to kubernetes 08/24/22 09:46:35.635
    Aug 24 09:46:35.666: INFO: Waiting up to 15m0s for pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb" in namespace "dns-1472" to be "running"
    Aug 24 09:46:35.673: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199239ms
    Aug 24 09:46:37.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015337756s
    Aug 24 09:46:39.687: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021053585s
    Aug 24 09:46:41.680: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014235403s
    Aug 24 09:46:43.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014668393s
    Aug 24 09:46:45.688: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021476494s
    Aug 24 09:46:47.686: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020096802s
    Aug 24 09:46:49.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.014604442s
    Aug 24 09:46:51.684: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018119482s
    Aug 24 09:46:53.680: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb": Phase="Running", Reason="", readiness=true. Elapsed: 18.014432742s
    Aug 24 09:46:53.681: INFO: Pod "dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 09:46:53.681
    STEP: looking for the results for each expected name from probers 08/24/22 09:46:53.687
    Aug 24 09:46:53.699: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.706: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.718: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.727: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.737: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.744: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.749: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.754: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:53.754: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

    Aug 24 09:46:58.762: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.769: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.776: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.783: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.789: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.794: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.799: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.805: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:46:58.805: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

    Aug 24 09:47:03.763: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.769: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.776: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.782: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.788: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.793: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.799: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.805: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:03.805: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1472.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1472.svc.cluster.local]

    Aug 24 09:47:08.774: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:08.793: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:08.798: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local from pod dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb: the server could not find the requested resource (get pods dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb)
    Aug 24 09:47:08.809: INFO: Lookups using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1472.svc.cluster.local]

    Aug 24 09:47:13.810: INFO: DNS probes using dns-1472/dns-test-7da3c7e9-a124-49db-894a-c7ec15e7facb succeeded

    STEP: deleting the pod 08/24/22 09:47:13.81
    STEP: deleting the test headless service 08/24/22 09:47:13.848
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 09:47:13.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1472" for this suite. 08/24/22 09:47:13.922
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:47:13.94
Aug 24 09:47:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 09:47:13.951
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:13.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:14.005
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Aug 24 09:47:14.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: creating the pod 08/24/22 09:47:14.029
STEP: submitting the pod to kubernetes 08/24/22 09:47:14.029
Aug 24 09:47:14.047: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467" in namespace "pods-2048" to be "running and ready"
Aug 24 09:47:14.055: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467": Phase="Pending", Reason="", readiness=false. Elapsed: 6.947219ms
Aug 24 09:47:14.055: INFO: The phase of Pod pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:47:16.060: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467": Phase="Running", Reason="", readiness=true. Elapsed: 2.012604596s
Aug 24 09:47:16.060: INFO: The phase of Pod pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467 is Running (Ready = true)
Aug 24 09:47:16.061: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 09:47:16.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2048" for this suite. 08/24/22 09:47:16.097
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":69,"skipped":1249,"failed":0}
------------------------------
• [2.169 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:47:13.94
    Aug 24 09:47:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 09:47:13.951
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:13.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:14.005
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Aug 24 09:47:14.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: creating the pod 08/24/22 09:47:14.029
    STEP: submitting the pod to kubernetes 08/24/22 09:47:14.029
    Aug 24 09:47:14.047: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467" in namespace "pods-2048" to be "running and ready"
    Aug 24 09:47:14.055: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467": Phase="Pending", Reason="", readiness=false. Elapsed: 6.947219ms
    Aug 24 09:47:14.055: INFO: The phase of Pod pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:47:16.060: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467": Phase="Running", Reason="", readiness=true. Elapsed: 2.012604596s
    Aug 24 09:47:16.060: INFO: The phase of Pod pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467 is Running (Ready = true)
    Aug 24 09:47:16.061: INFO: Pod "pod-logs-websocket-b91399b3-4b4b-4251-a72d-29520ed15467" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 09:47:16.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2048" for this suite. 08/24/22 09:47:16.097
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:47:16.111
Aug 24 09:47:16.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 09:47:16.114
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:16.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:16.145
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 08/24/22 09:47:16.149
STEP: Wait for the Deployment to create new ReplicaSet 08/24/22 09:47:16.157
STEP: delete the deployment 08/24/22 09:47:16.673
STEP: wait for all rs to be garbage collected 08/24/22 09:47:16.693
STEP: expected 0 rs, got 1 rs 08/24/22 09:47:16.704
STEP: expected 0 pods, got 2 pods 08/24/22 09:47:16.712
STEP: Gathering metrics 08/24/22 09:47:17.232
Aug 24 09:47:17.275: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 09:47:17.286: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.0035ms
Aug 24 09:47:17.286: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 09:47:17.286: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 09:47:17.432: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 09:47:17.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8983" for this suite. 08/24/22 09:47:17.442
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":70,"skipped":1249,"failed":0}
------------------------------
• [1.347 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:47:16.111
    Aug 24 09:47:16.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 09:47:16.114
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:16.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:16.145
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 08/24/22 09:47:16.149
    STEP: Wait for the Deployment to create new ReplicaSet 08/24/22 09:47:16.157
    STEP: delete the deployment 08/24/22 09:47:16.673
    STEP: wait for all rs to be garbage collected 08/24/22 09:47:16.693
    STEP: expected 0 rs, got 1 rs 08/24/22 09:47:16.704
    STEP: expected 0 pods, got 2 pods 08/24/22 09:47:16.712
    STEP: Gathering metrics 08/24/22 09:47:17.232
    Aug 24 09:47:17.275: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 09:47:17.286: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 11.0035ms
    Aug 24 09:47:17.286: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 09:47:17.286: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 09:47:17.432: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 09:47:17.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8983" for this suite. 08/24/22 09:47:17.442
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:47:17.459
Aug 24 09:47:17.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:47:17.462
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:17.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:17.509
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:47:17.513
Aug 24 09:47:17.530: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13" in namespace "projected-4891" to be "Succeeded or Failed"
Aug 24 09:47:17.542: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Pending", Reason="", readiness=false. Elapsed: 11.919969ms
Aug 24 09:47:19.550: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01922567s
Aug 24 09:47:21.553: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023016455s
STEP: Saw pod success 08/24/22 09:47:21.554
Aug 24 09:47:21.554: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13" satisfied condition "Succeeded or Failed"
Aug 24 09:47:21.561: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 container client-container: <nil>
STEP: delete the pod 08/24/22 09:47:21.577
Aug 24 09:47:21.604: INFO: Waiting for pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 to disappear
Aug 24 09:47:21.622: INFO: Pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 09:47:21.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4891" for this suite. 08/24/22 09:47:21.638
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":71,"skipped":1259,"failed":0}
------------------------------
• [4.194 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:47:17.459
    Aug 24 09:47:17.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:47:17.462
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:17.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:17.509
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:47:17.513
    Aug 24 09:47:17.530: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13" in namespace "projected-4891" to be "Succeeded or Failed"
    Aug 24 09:47:17.542: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Pending", Reason="", readiness=false. Elapsed: 11.919969ms
    Aug 24 09:47:19.550: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01922567s
    Aug 24 09:47:21.553: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023016455s
    STEP: Saw pod success 08/24/22 09:47:21.554
    Aug 24 09:47:21.554: INFO: Pod "downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13" satisfied condition "Succeeded or Failed"
    Aug 24 09:47:21.561: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 container client-container: <nil>
    STEP: delete the pod 08/24/22 09:47:21.577
    Aug 24 09:47:21.604: INFO: Waiting for pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 to disappear
    Aug 24 09:47:21.622: INFO: Pod downwardapi-volume-65dac279-0d83-4d52-99a3-105a6fbbea13 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 09:47:21.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4891" for this suite. 08/24/22 09:47:21.638
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:47:21.656
Aug 24 09:47:21.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 09:47:21.66
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:21.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:21.699
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 08/24/22 09:47:21.703
STEP: Creating a ResourceQuota 08/24/22 09:47:26.71
STEP: Ensuring resource quota status is calculated 08/24/22 09:47:26.72
STEP: Creating a Service 08/24/22 09:47:28.729
STEP: Creating a NodePort Service 08/24/22 09:47:28.768
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/24/22 09:47:28.826
STEP: Ensuring resource quota status captures service creation 08/24/22 09:47:28.889
STEP: Deleting Services 08/24/22 09:47:30.926
STEP: Ensuring resource quota status released usage 08/24/22 09:47:31.013
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 09:47:33.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2017" for this suite. 08/24/22 09:47:33.03
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":72,"skipped":1259,"failed":0}
------------------------------
• [SLOW TEST] [11.403 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:47:21.656
    Aug 24 09:47:21.657: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 09:47:21.66
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:21.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:21.699
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 08/24/22 09:47:21.703
    STEP: Creating a ResourceQuota 08/24/22 09:47:26.71
    STEP: Ensuring resource quota status is calculated 08/24/22 09:47:26.72
    STEP: Creating a Service 08/24/22 09:47:28.729
    STEP: Creating a NodePort Service 08/24/22 09:47:28.768
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/24/22 09:47:28.826
    STEP: Ensuring resource quota status captures service creation 08/24/22 09:47:28.889
    STEP: Deleting Services 08/24/22 09:47:30.926
    STEP: Ensuring resource quota status released usage 08/24/22 09:47:31.013
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 09:47:33.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2017" for this suite. 08/24/22 09:47:33.03
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:47:33.065
Aug 24 09:47:33.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 09:47:33.076
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:33.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:33.113
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-1003 08/24/22 09:47:33.12
Aug 24 09:47:33.132: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1003" to be "running and ready"
Aug 24 09:47:33.138: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 5.222569ms
Aug 24 09:47:33.138: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:47:35.149: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.017066939s
Aug 24 09:47:35.150: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 24 09:47:35.150: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Aug 24 09:47:35.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 24 09:47:35.563: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 24 09:47:35.563: INFO: stdout: "iptables"
Aug 24 09:47:35.563: INFO: proxyMode: iptables
Aug 24 09:47:35.601: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 24 09:47:35.615: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-1003 08/24/22 09:47:35.616
STEP: creating replication controller affinity-nodeport-timeout in namespace services-1003 08/24/22 09:47:35.653
I0824 09:47:35.674435      14 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1003, replica count: 3
I0824 09:47:38.726168      14 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 09:47:38.752: INFO: Creating new exec pod
Aug 24 09:47:38.761: INFO: Waiting up to 5m0s for pod "execpod-affinitykcjgk" in namespace "services-1003" to be "running"
Aug 24 09:47:38.781: INFO: Pod "execpod-affinitykcjgk": Phase="Pending", Reason="", readiness=false. Elapsed: 19.754475ms
Aug 24 09:47:40.787: INFO: Pod "execpod-affinitykcjgk": Phase="Running", Reason="", readiness=true. Elapsed: 2.026172038s
Aug 24 09:47:40.787: INFO: Pod "execpod-affinitykcjgk" satisfied condition "running"
Aug 24 09:47:41.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Aug 24 09:47:42.078: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Aug 24 09:47:42.078: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:47:42.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.123 80'
Aug 24 09:47:42.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.123 80\nConnection to 10.233.29.123 80 port [tcp/http] succeeded!\n"
Aug 24 09:47:42.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:47:42.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 31140'
Aug 24 09:47:42.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 31140\nConnection to 192.168.121.54 31140 port [tcp/*] succeeded!\n"
Aug 24 09:47:42.525: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:47:42.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 31140'
Aug 24 09:47:42.782: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.214 31140\nConnection to 192.168.121.214 31140 port [tcp/*] succeeded!\n"
Aug 24 09:47:42.782: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 09:47:42.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:31140/ ; done'
Aug 24 09:47:43.311: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
Aug 24 09:47:43.311: INFO: stdout: "\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs"
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
Aug 24 09:47:43.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.119:31140/'
Aug 24 09:47:43.647: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
Aug 24 09:47:43.647: INFO: stdout: "affinity-nodeport-timeout-vzszs"
Aug 24 09:48:03.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.119:31140/'
Aug 24 09:48:03.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
Aug 24 09:48:03.886: INFO: stdout: "affinity-nodeport-timeout-4swrp"
Aug 24 09:48:03.886: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1003, will wait for the garbage collector to delete the pods 08/24/22 09:48:03.914
Aug 24 09:48:03.984: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 12.288147ms
Aug 24 09:48:04.085: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 101.155377ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 09:48:06.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1003" for this suite. 08/24/22 09:48:06.666
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":73,"skipped":1260,"failed":0}
------------------------------
• [SLOW TEST] [33.617 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:47:33.065
    Aug 24 09:47:33.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 09:47:33.076
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:47:33.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:47:33.113
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-1003 08/24/22 09:47:33.12
    Aug 24 09:47:33.132: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1003" to be "running and ready"
    Aug 24 09:47:33.138: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 5.222569ms
    Aug 24 09:47:33.138: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:47:35.149: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.017066939s
    Aug 24 09:47:35.150: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Aug 24 09:47:35.150: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Aug 24 09:47:35.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Aug 24 09:47:35.563: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Aug 24 09:47:35.563: INFO: stdout: "iptables"
    Aug 24 09:47:35.563: INFO: proxyMode: iptables
    Aug 24 09:47:35.601: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Aug 24 09:47:35.615: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-1003 08/24/22 09:47:35.616
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-1003 08/24/22 09:47:35.653
    I0824 09:47:35.674435      14 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1003, replica count: 3
    I0824 09:47:38.726168      14 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 09:47:38.752: INFO: Creating new exec pod
    Aug 24 09:47:38.761: INFO: Waiting up to 5m0s for pod "execpod-affinitykcjgk" in namespace "services-1003" to be "running"
    Aug 24 09:47:38.781: INFO: Pod "execpod-affinitykcjgk": Phase="Pending", Reason="", readiness=false. Elapsed: 19.754475ms
    Aug 24 09:47:40.787: INFO: Pod "execpod-affinitykcjgk": Phase="Running", Reason="", readiness=true. Elapsed: 2.026172038s
    Aug 24 09:47:40.787: INFO: Pod "execpod-affinitykcjgk" satisfied condition "running"
    Aug 24 09:47:41.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Aug 24 09:47:42.078: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Aug 24 09:47:42.078: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:47:42.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.123 80'
    Aug 24 09:47:42.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.123 80\nConnection to 10.233.29.123 80 port [tcp/http] succeeded!\n"
    Aug 24 09:47:42.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:47:42.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 31140'
    Aug 24 09:47:42.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 31140\nConnection to 192.168.121.54 31140 port [tcp/*] succeeded!\n"
    Aug 24 09:47:42.525: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:47:42.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 31140'
    Aug 24 09:47:42.782: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.214 31140\nConnection to 192.168.121.214 31140 port [tcp/*] succeeded!\n"
    Aug 24 09:47:42.782: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 09:47:42.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:31140/ ; done'
    Aug 24 09:47:43.311: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
    Aug 24 09:47:43.311: INFO: stdout: "\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs\naffinity-nodeport-timeout-vzszs"
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.311: INFO: Received response from host: affinity-nodeport-timeout-vzszs
    Aug 24 09:47:43.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.119:31140/'
    Aug 24 09:47:43.647: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
    Aug 24 09:47:43.647: INFO: stdout: "affinity-nodeport-timeout-vzszs"
    Aug 24 09:48:03.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-1003 exec execpod-affinitykcjgk -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.119:31140/'
    Aug 24 09:48:03.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.119:31140/\n"
    Aug 24 09:48:03.886: INFO: stdout: "affinity-nodeport-timeout-4swrp"
    Aug 24 09:48:03.886: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1003, will wait for the garbage collector to delete the pods 08/24/22 09:48:03.914
    Aug 24 09:48:03.984: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 12.288147ms
    Aug 24 09:48:04.085: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 101.155377ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 09:48:06.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1003" for this suite. 08/24/22 09:48:06.666
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:06.689
Aug 24 09:48:06.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 09:48:06.693
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:06.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:06.762
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Aug 24 09:48:06.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:48:13.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7427" for this suite. 08/24/22 09:48:13.24
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":74,"skipped":1283,"failed":0}
------------------------------
• [SLOW TEST] [6.562 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:06.689
    Aug 24 09:48:06.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 09:48:06.693
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:06.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:06.762
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Aug 24 09:48:06.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:48:13.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7427" for this suite. 08/24/22 09:48:13.24
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:13.254
Aug 24 09:48:13.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 09:48:13.257
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:13.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:13.295
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Aug 24 09:48:13.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/24/22 09:48:16.75
Aug 24 09:48:16.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
Aug 24 09:48:18.394: INFO: stderr: ""
Aug 24 09:48:18.394: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 24 09:48:18.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 delete e2e-test-crd-publish-openapi-938-crds test-foo'
Aug 24 09:48:18.567: INFO: stderr: ""
Aug 24 09:48:18.568: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 24 09:48:18.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
Aug 24 09:48:19.899: INFO: stderr: ""
Aug 24 09:48:19.899: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 24 09:48:19.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 delete e2e-test-crd-publish-openapi-938-crds test-foo'
Aug 24 09:48:20.054: INFO: stderr: ""
Aug 24 09:48:20.054: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/24/22 09:48:20.054
Aug 24 09:48:20.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
Aug 24 09:48:20.487: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/24/22 09:48:20.487
Aug 24 09:48:20.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
Aug 24 09:48:20.976: INFO: rc: 1
Aug 24 09:48:20.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
Aug 24 09:48:21.544: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/24/22 09:48:21.544
Aug 24 09:48:21.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
Aug 24 09:48:21.992: INFO: rc: 1
Aug 24 09:48:21.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
Aug 24 09:48:22.345: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 08/24/22 09:48:22.345
Aug 24 09:48:22.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds'
Aug 24 09:48:22.766: INFO: stderr: ""
Aug 24 09:48:22.766: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 08/24/22 09:48:22.766
Aug 24 09:48:22.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.metadata'
Aug 24 09:48:23.223: INFO: stderr: ""
Aug 24 09:48:23.223: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 24 09:48:23.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec'
Aug 24 09:48:23.764: INFO: stderr: ""
Aug 24 09:48:23.764: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 24 09:48:23.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec.bars'
Aug 24 09:48:24.160: INFO: stderr: ""
Aug 24 09:48:24.160: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/24/22 09:48:24.161
Aug 24 09:48:24.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec.bars2'
Aug 24 09:48:24.532: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 09:48:29.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6719" for this suite. 08/24/22 09:48:29.49
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":75,"skipped":1320,"failed":0}
------------------------------
• [SLOW TEST] [16.248 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:13.254
    Aug 24 09:48:13.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 09:48:13.257
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:13.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:13.295
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Aug 24 09:48:13.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/24/22 09:48:16.75
    Aug 24 09:48:16.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
    Aug 24 09:48:18.394: INFO: stderr: ""
    Aug 24 09:48:18.394: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 24 09:48:18.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 delete e2e-test-crd-publish-openapi-938-crds test-foo'
    Aug 24 09:48:18.567: INFO: stderr: ""
    Aug 24 09:48:18.568: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Aug 24 09:48:18.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
    Aug 24 09:48:19.899: INFO: stderr: ""
    Aug 24 09:48:19.899: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 24 09:48:19.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 delete e2e-test-crd-publish-openapi-938-crds test-foo'
    Aug 24 09:48:20.054: INFO: stderr: ""
    Aug 24 09:48:20.054: INFO: stdout: "e2e-test-crd-publish-openapi-938-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/24/22 09:48:20.054
    Aug 24 09:48:20.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
    Aug 24 09:48:20.487: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/24/22 09:48:20.487
    Aug 24 09:48:20.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
    Aug 24 09:48:20.976: INFO: rc: 1
    Aug 24 09:48:20.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
    Aug 24 09:48:21.544: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/24/22 09:48:21.544
    Aug 24 09:48:21.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 create -f -'
    Aug 24 09:48:21.992: INFO: rc: 1
    Aug 24 09:48:21.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 --namespace=crd-publish-openapi-6719 apply -f -'
    Aug 24 09:48:22.345: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 08/24/22 09:48:22.345
    Aug 24 09:48:22.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds'
    Aug 24 09:48:22.766: INFO: stderr: ""
    Aug 24 09:48:22.766: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 08/24/22 09:48:22.766
    Aug 24 09:48:22.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.metadata'
    Aug 24 09:48:23.223: INFO: stderr: ""
    Aug 24 09:48:23.223: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Aug 24 09:48:23.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec'
    Aug 24 09:48:23.764: INFO: stderr: ""
    Aug 24 09:48:23.764: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Aug 24 09:48:23.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec.bars'
    Aug 24 09:48:24.160: INFO: stderr: ""
    Aug 24 09:48:24.160: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-938-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/24/22 09:48:24.161
    Aug 24 09:48:24.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-6719 explain e2e-test-crd-publish-openapi-938-crds.spec.bars2'
    Aug 24 09:48:24.532: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 09:48:29.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6719" for this suite. 08/24/22 09:48:29.49
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:29.523
Aug 24 09:48:29.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 09:48:29.527
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:29.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:29.571
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 08/24/22 09:48:29.618
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:48:29.635
Aug 24 09:48:29.656: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:48:29.656: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:48:30.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 09:48:30.673: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:48:31.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 09:48:31.673: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 08/24/22 09:48:31.678
Aug 24 09:48:31.687: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 08/24/22 09:48:31.687
Aug 24 09:48:31.704: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 08/24/22 09:48:31.704
Aug 24 09:48:31.710: INFO: Observed &DaemonSet event: ADDED
Aug 24 09:48:31.711: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.711: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.712: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.712: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.712: INFO: Found daemon set daemon-set in namespace daemonsets-7751 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 09:48:31.712: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 08/24/22 09:48:31.712
STEP: watching for the daemon set status to be patched 08/24/22 09:48:31.732
Aug 24 09:48:31.739: INFO: Observed &DaemonSet event: ADDED
Aug 24 09:48:31.740: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.741: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.742: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.742: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.742: INFO: Observed daemon set daemon-set in namespace daemonsets-7751 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 09:48:31.743: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 09:48:31.743: INFO: Found daemon set daemon-set in namespace daemonsets-7751 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Aug 24 09:48:31.743: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:48:31.751
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7751, will wait for the garbage collector to delete the pods 08/24/22 09:48:31.752
Aug 24 09:48:31.823: INFO: Deleting DaemonSet.extensions daemon-set took: 14.032515ms
Aug 24 09:48:31.924: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.941568ms
Aug 24 09:48:34.331: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:48:34.331: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 09:48:34.337: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14005"},"items":null}

Aug 24 09:48:34.342: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14005"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:48:34.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7751" for this suite. 08/24/22 09:48:34.388
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":76,"skipped":1342,"failed":0}
------------------------------
• [4.891 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:29.523
    Aug 24 09:48:29.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 09:48:29.527
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:29.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:29.571
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 08/24/22 09:48:29.618
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:48:29.635
    Aug 24 09:48:29.656: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:48:29.656: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:48:30.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 09:48:30.673: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:48:31.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 09:48:31.673: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 08/24/22 09:48:31.678
    Aug 24 09:48:31.687: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 08/24/22 09:48:31.687
    Aug 24 09:48:31.704: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 08/24/22 09:48:31.704
    Aug 24 09:48:31.710: INFO: Observed &DaemonSet event: ADDED
    Aug 24 09:48:31.711: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.711: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.712: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.712: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.712: INFO: Found daemon set daemon-set in namespace daemonsets-7751 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 24 09:48:31.712: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 08/24/22 09:48:31.712
    STEP: watching for the daemon set status to be patched 08/24/22 09:48:31.732
    Aug 24 09:48:31.739: INFO: Observed &DaemonSet event: ADDED
    Aug 24 09:48:31.740: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.741: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.742: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.742: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.742: INFO: Observed daemon set daemon-set in namespace daemonsets-7751 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 24 09:48:31.743: INFO: Observed &DaemonSet event: MODIFIED
    Aug 24 09:48:31.743: INFO: Found daemon set daemon-set in namespace daemonsets-7751 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Aug 24 09:48:31.743: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:48:31.751
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7751, will wait for the garbage collector to delete the pods 08/24/22 09:48:31.752
    Aug 24 09:48:31.823: INFO: Deleting DaemonSet.extensions daemon-set took: 14.032515ms
    Aug 24 09:48:31.924: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.941568ms
    Aug 24 09:48:34.331: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:48:34.331: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 09:48:34.337: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14005"},"items":null}

    Aug 24 09:48:34.342: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14005"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:48:34.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7751" for this suite. 08/24/22 09:48:34.388
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:34.432
Aug 24 09:48:34.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename runtimeclass 08/24/22 09:48:34.435
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:34.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:34.472
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 24 09:48:34.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2104" for this suite. 08/24/22 09:48:34.503
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":77,"skipped":1366,"failed":0}
------------------------------
• [0.088 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:34.432
    Aug 24 09:48:34.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename runtimeclass 08/24/22 09:48:34.435
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:34.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:34.472
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 24 09:48:34.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2104" for this suite. 08/24/22 09:48:34.503
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:34.532
Aug 24 09:48:34.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:48:34.536
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:34.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:34.577
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 08/24/22 09:48:34.582
Aug 24 09:48:34.606: INFO: Waiting up to 5m0s for pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd" in namespace "projected-5067" to be "running and ready"
Aug 24 09:48:34.612: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.926691ms
Aug 24 09:48:34.613: INFO: The phase of Pod annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:48:36.621: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.013988523s
Aug 24 09:48:36.621: INFO: The phase of Pod annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd is Running (Ready = true)
Aug 24 09:48:36.621: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd" satisfied condition "running and ready"
Aug 24 09:48:37.164: INFO: Successfully updated pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 09:48:41.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5067" for this suite. 08/24/22 09:48:41.218
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":78,"skipped":1407,"failed":0}
------------------------------
• [SLOW TEST] [6.702 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:34.532
    Aug 24 09:48:34.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:48:34.536
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:34.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:34.577
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 08/24/22 09:48:34.582
    Aug 24 09:48:34.606: INFO: Waiting up to 5m0s for pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd" in namespace "projected-5067" to be "running and ready"
    Aug 24 09:48:34.612: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.926691ms
    Aug 24 09:48:34.613: INFO: The phase of Pod annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:48:36.621: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.013988523s
    Aug 24 09:48:36.621: INFO: The phase of Pod annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd is Running (Ready = true)
    Aug 24 09:48:36.621: INFO: Pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd" satisfied condition "running and ready"
    Aug 24 09:48:37.164: INFO: Successfully updated pod "annotationupdate98d6c34b-4b49-4a3f-b858-841012d4dbdd"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 09:48:41.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5067" for this suite. 08/24/22 09:48:41.218
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:41.238
Aug 24 09:48:41.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename csistoragecapacity 08/24/22 09:48:41.241
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:41.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:41.287
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 08/24/22 09:48:41.293
STEP: getting /apis/storage.k8s.io 08/24/22 09:48:41.297
STEP: getting /apis/storage.k8s.io/v1 08/24/22 09:48:41.299
STEP: creating 08/24/22 09:48:41.301
STEP: watching 08/24/22 09:48:41.34
Aug 24 09:48:41.340: INFO: starting watch
STEP: getting 08/24/22 09:48:41.354
STEP: listing in namespace 08/24/22 09:48:41.364
STEP: listing across namespaces 08/24/22 09:48:41.374
STEP: patching 08/24/22 09:48:41.382
STEP: updating 08/24/22 09:48:41.407
Aug 24 09:48:41.433: INFO: waiting for watch events with expected annotations in namespace
Aug 24 09:48:41.433: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 08/24/22 09:48:41.434
STEP: deleting a collection 08/24/22 09:48:41.467
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Aug 24 09:48:41.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-349" for this suite. 08/24/22 09:48:41.519
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":79,"skipped":1414,"failed":0}
------------------------------
• [0.296 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:41.238
    Aug 24 09:48:41.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename csistoragecapacity 08/24/22 09:48:41.241
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:41.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:41.287
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 08/24/22 09:48:41.293
    STEP: getting /apis/storage.k8s.io 08/24/22 09:48:41.297
    STEP: getting /apis/storage.k8s.io/v1 08/24/22 09:48:41.299
    STEP: creating 08/24/22 09:48:41.301
    STEP: watching 08/24/22 09:48:41.34
    Aug 24 09:48:41.340: INFO: starting watch
    STEP: getting 08/24/22 09:48:41.354
    STEP: listing in namespace 08/24/22 09:48:41.364
    STEP: listing across namespaces 08/24/22 09:48:41.374
    STEP: patching 08/24/22 09:48:41.382
    STEP: updating 08/24/22 09:48:41.407
    Aug 24 09:48:41.433: INFO: waiting for watch events with expected annotations in namespace
    Aug 24 09:48:41.433: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 08/24/22 09:48:41.434
    STEP: deleting a collection 08/24/22 09:48:41.467
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Aug 24 09:48:41.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-349" for this suite. 08/24/22 09:48:41.519
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:41.547
Aug 24 09:48:41.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:48:41.55
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:41.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:41.589
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 08/24/22 09:48:41.594
Aug 24 09:48:41.609: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546" in namespace "projected-6269" to be "Succeeded or Failed"
Aug 24 09:48:41.616: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033577ms
Aug 24 09:48:43.625: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015430047s
Aug 24 09:48:45.625: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015711614s
STEP: Saw pod success 08/24/22 09:48:45.625
Aug 24 09:48:45.626: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546" satisfied condition "Succeeded or Failed"
Aug 24 09:48:45.632: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 container client-container: <nil>
STEP: delete the pod 08/24/22 09:48:45.646
Aug 24 09:48:45.669: INFO: Waiting for pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 to disappear
Aug 24 09:48:45.674: INFO: Pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 09:48:45.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6269" for this suite. 08/24/22 09:48:45.683
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":80,"skipped":1460,"failed":0}
------------------------------
• [4.172 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:41.547
    Aug 24 09:48:41.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:48:41.55
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:41.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:41.589
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 08/24/22 09:48:41.594
    Aug 24 09:48:41.609: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546" in namespace "projected-6269" to be "Succeeded or Failed"
    Aug 24 09:48:41.616: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033577ms
    Aug 24 09:48:43.625: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015430047s
    Aug 24 09:48:45.625: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015711614s
    STEP: Saw pod success 08/24/22 09:48:45.625
    Aug 24 09:48:45.626: INFO: Pod "downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546" satisfied condition "Succeeded or Failed"
    Aug 24 09:48:45.632: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 container client-container: <nil>
    STEP: delete the pod 08/24/22 09:48:45.646
    Aug 24 09:48:45.669: INFO: Waiting for pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 to disappear
    Aug 24 09:48:45.674: INFO: Pod downwardapi-volume-25ff5b2a-c06c-4dbf-8ac1-163e28a07546 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 09:48:45.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6269" for this suite. 08/24/22 09:48:45.683
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:45.721
Aug 24 09:48:45.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-runtime 08/24/22 09:48:45.725
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:45.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:45.773
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 08/24/22 09:48:45.777
STEP: wait for the container to reach Succeeded 08/24/22 09:48:45.803
STEP: get the container status 08/24/22 09:48:48.879
STEP: the container should be terminated 08/24/22 09:48:48.887
STEP: the termination message should be set 08/24/22 09:48:48.887
Aug 24 09:48:48.887: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 08/24/22 09:48:48.887
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 24 09:48:48.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3069" for this suite. 08/24/22 09:48:48.934
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":81,"skipped":1466,"failed":0}
------------------------------
• [3.227 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:45.721
    Aug 24 09:48:45.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-runtime 08/24/22 09:48:45.725
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:45.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:45.773
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 08/24/22 09:48:45.777
    STEP: wait for the container to reach Succeeded 08/24/22 09:48:45.803
    STEP: get the container status 08/24/22 09:48:48.879
    STEP: the container should be terminated 08/24/22 09:48:48.887
    STEP: the termination message should be set 08/24/22 09:48:48.887
    Aug 24 09:48:48.887: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 08/24/22 09:48:48.887
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 24 09:48:48.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3069" for this suite. 08/24/22 09:48:48.934
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:48:48.964
Aug 24 09:48:48.965: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 09:48:48.97
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:48.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:49.003
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 in namespace container-probe-6735 08/24/22 09:48:49.006
Aug 24 09:48:49.045: INFO: Waiting up to 5m0s for pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693" in namespace "container-probe-6735" to be "not pending"
Aug 24 09:48:49.052: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693": Phase="Pending", Reason="", readiness=false. Elapsed: 7.173988ms
Aug 24 09:48:51.059: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693": Phase="Running", Reason="", readiness=true. Elapsed: 2.014434722s
Aug 24 09:48:51.060: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693" satisfied condition "not pending"
Aug 24 09:48:51.060: INFO: Started pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 in namespace container-probe-6735
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:48:51.06
Aug 24 09:48:51.067: INFO: Initial restart count of pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is 0
Aug 24 09:49:11.153: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 1 (20.085956403s elapsed)
Aug 24 09:49:31.257: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 2 (40.189786878s elapsed)
Aug 24 09:49:51.339: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 3 (1m0.271752292s elapsed)
Aug 24 09:50:11.457: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 4 (1m20.389839074s elapsed)
Aug 24 09:51:11.780: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 5 (2m20.713285742s elapsed)
STEP: deleting the pod 08/24/22 09:51:11.78
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 09:51:11.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6735" for this suite. 08/24/22 09:51:11.823
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":82,"skipped":1479,"failed":0}
------------------------------
• [SLOW TEST] [142.870 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:48:48.964
    Aug 24 09:48:48.965: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 09:48:48.97
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:48:48.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:48:49.003
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 in namespace container-probe-6735 08/24/22 09:48:49.006
    Aug 24 09:48:49.045: INFO: Waiting up to 5m0s for pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693" in namespace "container-probe-6735" to be "not pending"
    Aug 24 09:48:49.052: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693": Phase="Pending", Reason="", readiness=false. Elapsed: 7.173988ms
    Aug 24 09:48:51.059: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693": Phase="Running", Reason="", readiness=true. Elapsed: 2.014434722s
    Aug 24 09:48:51.060: INFO: Pod "liveness-f82fbbd8-3813-473f-b29e-3925e07eb693" satisfied condition "not pending"
    Aug 24 09:48:51.060: INFO: Started pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 in namespace container-probe-6735
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:48:51.06
    Aug 24 09:48:51.067: INFO: Initial restart count of pod liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is 0
    Aug 24 09:49:11.153: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 1 (20.085956403s elapsed)
    Aug 24 09:49:31.257: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 2 (40.189786878s elapsed)
    Aug 24 09:49:51.339: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 3 (1m0.271752292s elapsed)
    Aug 24 09:50:11.457: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 4 (1m20.389839074s elapsed)
    Aug 24 09:51:11.780: INFO: Restart count of pod container-probe-6735/liveness-f82fbbd8-3813-473f-b29e-3925e07eb693 is now 5 (2m20.713285742s elapsed)
    STEP: deleting the pod 08/24/22 09:51:11.78
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 09:51:11.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6735" for this suite. 08/24/22 09:51:11.823
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:11.838
Aug 24 09:51:11.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename containers 08/24/22 09:51:11.844
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:11.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:11.884
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 08/24/22 09:51:11.888
Aug 24 09:51:11.903: INFO: Waiting up to 5m0s for pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d" in namespace "containers-334" to be "Succeeded or Failed"
Aug 24 09:51:11.909: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.944193ms
Aug 24 09:51:13.919: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015613118s
Aug 24 09:51:15.918: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014191012s
STEP: Saw pod success 08/24/22 09:51:15.918
Aug 24 09:51:15.918: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d" satisfied condition "Succeeded or Failed"
Aug 24 09:51:15.923: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d container agnhost-container: <nil>
STEP: delete the pod 08/24/22 09:51:15.946
Aug 24 09:51:15.963: INFO: Waiting for pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d to disappear
Aug 24 09:51:15.968: INFO: Pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 24 09:51:15.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-334" for this suite. 08/24/22 09:51:15.977
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":83,"skipped":1515,"failed":0}
------------------------------
• [4.152 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:11.838
    Aug 24 09:51:11.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename containers 08/24/22 09:51:11.844
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:11.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:11.884
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 08/24/22 09:51:11.888
    Aug 24 09:51:11.903: INFO: Waiting up to 5m0s for pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d" in namespace "containers-334" to be "Succeeded or Failed"
    Aug 24 09:51:11.909: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.944193ms
    Aug 24 09:51:13.919: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015613118s
    Aug 24 09:51:15.918: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014191012s
    STEP: Saw pod success 08/24/22 09:51:15.918
    Aug 24 09:51:15.918: INFO: Pod "client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d" satisfied condition "Succeeded or Failed"
    Aug 24 09:51:15.923: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 09:51:15.946
    Aug 24 09:51:15.963: INFO: Waiting for pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d to disappear
    Aug 24 09:51:15.968: INFO: Pod client-containers-992935c6-1242-4651-b7a0-c9e6c43f367d no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 24 09:51:15.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-334" for this suite. 08/24/22 09:51:15.977
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:15.991
Aug 24 09:51:15.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename runtimeclass 08/24/22 09:51:15.994
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:16.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:16.033
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Aug 24 09:51:16.059: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3016 to be scheduled
Aug 24 09:51:16.063: INFO: 1 pods are not scheduled: [runtimeclass-3016/test-runtimeclass-runtimeclass-3016-preconfigured-handler-pxjkd(8b4f2932-c758-45db-8469-2eb4f9333ebf)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 24 09:51:18.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3016" for this suite. 08/24/22 09:51:18.101
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":84,"skipped":1525,"failed":0}
------------------------------
• [2.121 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:15.991
    Aug 24 09:51:15.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename runtimeclass 08/24/22 09:51:15.994
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:16.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:16.033
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Aug 24 09:51:16.059: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3016 to be scheduled
    Aug 24 09:51:16.063: INFO: 1 pods are not scheduled: [runtimeclass-3016/test-runtimeclass-runtimeclass-3016-preconfigured-handler-pxjkd(8b4f2932-c758-45db-8469-2eb4f9333ebf)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 24 09:51:18.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3016" for this suite. 08/24/22 09:51:18.101
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:18.113
Aug 24 09:51:18.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename init-container 08/24/22 09:51:18.116
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:18.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:18.146
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 08/24/22 09:51:18.149
Aug 24 09:51:18.150: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 09:51:23.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1897" for this suite. 08/24/22 09:51:23.643
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":85,"skipped":1525,"failed":0}
------------------------------
• [SLOW TEST] [5.544 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:18.113
    Aug 24 09:51:18.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename init-container 08/24/22 09:51:18.116
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:18.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:18.146
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 08/24/22 09:51:18.149
    Aug 24 09:51:18.150: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 09:51:23.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1897" for this suite. 08/24/22 09:51:23.643
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:23.664
Aug 24 09:51:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 09:51:23.666
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:23.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:23.702
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Aug 24 09:51:23.756: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:51:23.774
Aug 24 09:51:23.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:51:23.787: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:51:24.805: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:51:24.805: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 09:51:25.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 09:51:25.803: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 08/24/22 09:51:25.826
STEP: Check that daemon pods images are updated. 08/24/22 09:51:25.851
Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-25tf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:26.872: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:26.872: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:27.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:27.874: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:28.887: INFO: Pod daemon-set-r7twg is not available
Aug 24 09:51:28.888: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:28.889: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:29.874: INFO: Pod daemon-set-r7twg is not available
Aug 24 09:51:29.875: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:29.875: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:30.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:31.874: INFO: Pod daemon-set-c9nz5 is not available
Aug 24 09:51:31.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 09:51:33.875: INFO: Pod daemon-set-fxjww is not available
STEP: Check that daemon pods are still running on every node of the cluster. 08/24/22 09:51:33.885
Aug 24 09:51:33.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 09:51:33.907: INFO: Node kah9uighaagh-3 is running 0 daemon pod, expected 1
Aug 24 09:51:34.935: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 09:51:34.935: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:51:34.993
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9031, will wait for the garbage collector to delete the pods 08/24/22 09:51:34.993
Aug 24 09:51:35.067: INFO: Deleting DaemonSet.extensions daemon-set took: 14.874435ms
Aug 24 09:51:35.268: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.650649ms
Aug 24 09:51:37.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 09:51:37.577: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 09:51:37.585: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14653"},"items":null}

Aug 24 09:51:37.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14653"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 09:51:37.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9031" for this suite. 08/24/22 09:51:37.632
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":86,"skipped":1528,"failed":0}
------------------------------
• [SLOW TEST] [13.987 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:23.664
    Aug 24 09:51:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 09:51:23.666
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:23.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:23.702
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Aug 24 09:51:23.756: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 09:51:23.774
    Aug 24 09:51:23.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:51:23.787: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:51:24.805: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:51:24.805: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 09:51:25.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 09:51:25.803: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 08/24/22 09:51:25.826
    STEP: Check that daemon pods images are updated. 08/24/22 09:51:25.851
    Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-25tf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:25.858: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:26.872: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:26.872: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:27.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:27.874: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:28.887: INFO: Pod daemon-set-r7twg is not available
    Aug 24 09:51:28.888: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:28.889: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:29.874: INFO: Pod daemon-set-r7twg is not available
    Aug 24 09:51:29.875: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:29.875: INFO: Wrong image for pod: daemon-set-wjw8s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:30.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:31.874: INFO: Pod daemon-set-c9nz5 is not available
    Aug 24 09:51:31.874: INFO: Wrong image for pod: daemon-set-w7n6t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 24 09:51:33.875: INFO: Pod daemon-set-fxjww is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 08/24/22 09:51:33.885
    Aug 24 09:51:33.907: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 09:51:33.907: INFO: Node kah9uighaagh-3 is running 0 daemon pod, expected 1
    Aug 24 09:51:34.935: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 09:51:34.935: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 09:51:34.993
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9031, will wait for the garbage collector to delete the pods 08/24/22 09:51:34.993
    Aug 24 09:51:35.067: INFO: Deleting DaemonSet.extensions daemon-set took: 14.874435ms
    Aug 24 09:51:35.268: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.650649ms
    Aug 24 09:51:37.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 09:51:37.577: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 09:51:37.585: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14653"},"items":null}

    Aug 24 09:51:37.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14653"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 09:51:37.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9031" for this suite. 08/24/22 09:51:37.632
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:37.689
Aug 24 09:51:37.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 09:51:37.691
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:37.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:37.733
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Aug 24 09:51:37.738: INFO: Creating deployment "webserver-deployment"
Aug 24 09:51:37.754: INFO: Waiting for observed generation 1
Aug 24 09:51:39.773: INFO: Waiting for all required pods to come up
Aug 24 09:51:39.791: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 08/24/22 09:51:39.791
Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tllm6" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8swsb" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qxp2q" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.793: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f5pmz" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-62ttm" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.793: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kz6lq" in namespace "deployment-3803" to be "running"
Aug 24 09:51:39.814: INFO: Pod "webserver-deployment-845c8977d9-8swsb": Phase="Pending", Reason="", readiness=false. Elapsed: 21.778937ms
Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-qxp2q": Phase="Pending", Reason="", readiness=false. Elapsed: 22.351387ms
Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-tllm6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.141085ms
Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-62ttm": Phase="Pending", Reason="", readiness=false. Elapsed: 22.334774ms
Aug 24 09:51:39.818: INFO: Pod "webserver-deployment-845c8977d9-kz6lq": Phase="Pending", Reason="", readiness=false. Elapsed: 25.141647ms
Aug 24 09:51:39.819: INFO: Pod "webserver-deployment-845c8977d9-f5pmz": Phase="Pending", Reason="", readiness=false. Elapsed: 26.092046ms
Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-62ttm": Phase="Running", Reason="", readiness=true. Elapsed: 2.031896392s
Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-62ttm" satisfied condition "running"
Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-qxp2q": Phase="Running", Reason="", readiness=true. Elapsed: 2.033024135s
Aug 24 09:51:41.826: INFO: Pod "webserver-deployment-845c8977d9-qxp2q" satisfied condition "running"
Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-8swsb": Phase="Running", Reason="", readiness=true. Elapsed: 2.034878904s
Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-8swsb" satisfied condition "running"
Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-kz6lq": Phase="Running", Reason="", readiness=true. Elapsed: 2.034129119s
Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-kz6lq" satisfied condition "running"
Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-tllm6": Phase="Running", Reason="", readiness=true. Elapsed: 2.035936137s
Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-tllm6" satisfied condition "running"
Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-f5pmz": Phase="Running", Reason="", readiness=true. Elapsed: 2.035814096s
Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-f5pmz" satisfied condition "running"
Aug 24 09:51:41.829: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 24 09:51:41.841: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 24 09:51:41.857: INFO: Updating deployment webserver-deployment
Aug 24 09:51:41.857: INFO: Waiting for observed generation 2
Aug 24 09:51:43.871: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 24 09:51:43.878: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 24 09:51:43.883: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 24 09:51:43.905: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 24 09:51:43.905: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 24 09:51:43.911: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 24 09:51:43.924: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 24 09:51:43.924: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 24 09:51:43.948: INFO: Updating deployment webserver-deployment
Aug 24 09:51:43.948: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 24 09:51:43.967: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 24 09:51:43.981: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 09:51:43.993: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3803  ce4a173c-50b2-4141-bb8c-59930f3206db 14886 3 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b11058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 09:51:40 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-08-24 09:51:42 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug 24 09:51:44.001: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-3803  db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 14890 3 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ce4a173c-50b2-4141-bb8c-59930f3206db 0xc001fa7697 0xc001fa7698}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce4a173c-50b2-4141-bb8c-59930f3206db\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001fa7748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:51:44.002: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 24 09:51:44.002: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-3803  9f73979c-5af3-40f9-9311-f44cf910e497 14887 3 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ce4a173c-50b2-4141-bb8c-59930f3206db 0xc001fa77a7 0xc001fa77a8}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce4a173c-50b2-4141-bb8c-59930f3206db\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001fa7838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:51:44.024: INFO: Pod "webserver-deployment-69b7448995-f7p9x" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-f7p9x webserver-deployment-69b7448995- deployment-3803  20c0bc35-2c4c-4673-b459-86c716c803f5 14797 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11467 0xc002b11468}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q29gr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q29gr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.026: INFO: Pod "webserver-deployment-69b7448995-fzznf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fzznf webserver-deployment-69b7448995- deployment-3803  1124c63e-c6a2-46c5-9beb-0b6297ea34ea 14808 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11677 0xc002b11678}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n4kw8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n4kw8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.027: INFO: Pod "webserver-deployment-69b7448995-jdxfb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jdxfb webserver-deployment-69b7448995- deployment-3803  c76379ca-b384-4ec7-b1c4-d08edf98285f 14812 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11887 0xc002b11888}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z6c4j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z6c4j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.028: INFO: Pod "webserver-deployment-69b7448995-nplt5" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-nplt5 webserver-deployment-69b7448995- deployment-3803  4ae298c9-4314-4700-87e0-a120604a36a3 14825 0 2022-08-24 09:51:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11a77 0xc002b11a78}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xd7xq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xd7xq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 09:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.033: INFO: Pod "webserver-deployment-69b7448995-q6l9l" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-q6l9l webserver-deployment-69b7448995- deployment-3803  29819bb5-3fa9-4261-a6ed-5beffb3fe64e 14834 0 2022-08-24 09:51:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11c77 0xc002b11c78}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j929f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j929f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2022-08-24 09:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.033: INFO: Pod "webserver-deployment-845c8977d9-2c525" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2c525 webserver-deployment-845c8977d9- deployment-3803  9ef2daa4-be83-45ca-af6c-5d14b07f03f8 14740 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc002b11e67 0xc002b11e68}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xndwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xndwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.87,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://6e36b60e226eaeba9c115f9ed439010c3bcd475a72eced407515610ef8ea083c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.034: INFO: Pod "webserver-deployment-845c8977d9-2kptq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2kptq webserver-deployment-845c8977d9- deployment-3803  361483d6-2bcc-4eb0-8e77-117a394cb429 14889 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820117 0xc003820118}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxcl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxcl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.034: INFO: Pod "webserver-deployment-845c8977d9-49pkq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-49pkq webserver-deployment-845c8977d9- deployment-3803  9c9210c6-ace4-40dc-b465-15d3f497a03e 14743 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc0038205b7 0xc0038205b8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kcvz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kcvz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.88,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://0208c376ebc4fd143f7b19668b1cb07fa86caa69c427234e27c6d40e9c92f434,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.035: INFO: Pod "webserver-deployment-845c8977d9-9r46f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9r46f webserver-deployment-845c8977d9- deployment-3803  a2afc5f9-a281-43bc-82fd-394ef3f9ea31 14752 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820947 0xc003820948}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4j7cx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4j7cx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.155,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://3324eacaa2aa227948a4bebeeb6e63e931c40e5e8b616220b7e3cc920ad1dc26,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-f5pmz" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-f5pmz webserver-deployment-845c8977d9- deployment-3803  3a99bf13-ab5d-4d0b-868e-caddb0f12510 14768 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820b37 0xc003820b38}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dpmct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dpmct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.83,StartTime:2022-08-24 09:51:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://8dd5e25a4a6da787af3fda4cc7c4947210ae037cf4783b530a7f20b777b4d481,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-fbpx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fbpx9 webserver-deployment-845c8977d9- deployment-3803  65c41a7d-24e5-49b5-a82a-8e04e4676280 14892 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820d27 0xc003820d28}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jfdkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jfdkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-kdx6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kdx6m webserver-deployment-845c8977d9- deployment-3803  9d31c3fc-2b71-433b-a589-9255484f28dc 14893 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820e67 0xc003820e68}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dpqqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dpqqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.037: INFO: Pod "webserver-deployment-845c8977d9-kz6lq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kz6lq webserver-deployment-845c8977d9- deployment-3803  7fa88181-4feb-4981-b7d0-33b76792ee9c 14778 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820fa7 0xc003820fa8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kcm9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kcm9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.153,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://641dc466a2b3541a5d38f969b5444d6f83359ced76f0e227b5045809a0ece212,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.038: INFO: Pod "webserver-deployment-845c8977d9-qxp2q" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qxp2q webserver-deployment-845c8977d9- deployment-3803  e00ab102-ce6a-4f60-a034-6afbb5abb042 14774 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003821197 0xc003821198}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dlbjj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dlbjj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.82,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://de6a3a7c80cb77f72ad7f104d2c4b0784d3648d8f1a8e942b1b6170e6df58802,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.038: INFO: Pod "webserver-deployment-845c8977d9-rmvz6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rmvz6 webserver-deployment-845c8977d9- deployment-3803  338b6bcb-a3e3-477d-ac10-18c593121acf 14744 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003821387 0xc003821388}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.89\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kkbf5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kkbf5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.89,StartTime:2022-08-24 09:51:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://8024d16f4e7ddd2c2bba8a0a903eb649a5a880510d9ba5b01804421ae1dcb488,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:51:44.039: INFO: Pod "webserver-deployment-845c8977d9-tllm6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tllm6 webserver-deployment-845c8977d9- deployment-3803  0053d05e-6184-49f5-8712-b57a1f5ebae7 14771 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc0038215b7 0xc0038215b8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xvhdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xvhdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.81,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://2d31214b1409ccf019d6175658b042c3e5f156305d54b039a0c5f193c54bf0b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 09:51:44.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3803" for this suite. 08/24/22 09:51:44.097
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":87,"skipped":1588,"failed":0}
------------------------------
• [SLOW TEST] [6.433 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:37.689
    Aug 24 09:51:37.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 09:51:37.691
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:37.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:37.733
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Aug 24 09:51:37.738: INFO: Creating deployment "webserver-deployment"
    Aug 24 09:51:37.754: INFO: Waiting for observed generation 1
    Aug 24 09:51:39.773: INFO: Waiting for all required pods to come up
    Aug 24 09:51:39.791: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 08/24/22 09:51:39.791
    Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tllm6" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8swsb" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qxp2q" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.793: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f5pmz" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.792: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-62ttm" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.793: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kz6lq" in namespace "deployment-3803" to be "running"
    Aug 24 09:51:39.814: INFO: Pod "webserver-deployment-845c8977d9-8swsb": Phase="Pending", Reason="", readiness=false. Elapsed: 21.778937ms
    Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-qxp2q": Phase="Pending", Reason="", readiness=false. Elapsed: 22.351387ms
    Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-tllm6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.141085ms
    Aug 24 09:51:39.815: INFO: Pod "webserver-deployment-845c8977d9-62ttm": Phase="Pending", Reason="", readiness=false. Elapsed: 22.334774ms
    Aug 24 09:51:39.818: INFO: Pod "webserver-deployment-845c8977d9-kz6lq": Phase="Pending", Reason="", readiness=false. Elapsed: 25.141647ms
    Aug 24 09:51:39.819: INFO: Pod "webserver-deployment-845c8977d9-f5pmz": Phase="Pending", Reason="", readiness=false. Elapsed: 26.092046ms
    Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-62ttm": Phase="Running", Reason="", readiness=true. Elapsed: 2.031896392s
    Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-62ttm" satisfied condition "running"
    Aug 24 09:51:41.825: INFO: Pod "webserver-deployment-845c8977d9-qxp2q": Phase="Running", Reason="", readiness=true. Elapsed: 2.033024135s
    Aug 24 09:51:41.826: INFO: Pod "webserver-deployment-845c8977d9-qxp2q" satisfied condition "running"
    Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-8swsb": Phase="Running", Reason="", readiness=true. Elapsed: 2.034878904s
    Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-8swsb" satisfied condition "running"
    Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-kz6lq": Phase="Running", Reason="", readiness=true. Elapsed: 2.034129119s
    Aug 24 09:51:41.827: INFO: Pod "webserver-deployment-845c8977d9-kz6lq" satisfied condition "running"
    Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-tllm6": Phase="Running", Reason="", readiness=true. Elapsed: 2.035936137s
    Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-tllm6" satisfied condition "running"
    Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-f5pmz": Phase="Running", Reason="", readiness=true. Elapsed: 2.035814096s
    Aug 24 09:51:41.828: INFO: Pod "webserver-deployment-845c8977d9-f5pmz" satisfied condition "running"
    Aug 24 09:51:41.829: INFO: Waiting for deployment "webserver-deployment" to complete
    Aug 24 09:51:41.841: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Aug 24 09:51:41.857: INFO: Updating deployment webserver-deployment
    Aug 24 09:51:41.857: INFO: Waiting for observed generation 2
    Aug 24 09:51:43.871: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Aug 24 09:51:43.878: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Aug 24 09:51:43.883: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 24 09:51:43.905: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Aug 24 09:51:43.905: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Aug 24 09:51:43.911: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 24 09:51:43.924: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Aug 24 09:51:43.924: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Aug 24 09:51:43.948: INFO: Updating deployment webserver-deployment
    Aug 24 09:51:43.948: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Aug 24 09:51:43.967: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Aug 24 09:51:43.981: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 09:51:43.993: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-3803  ce4a173c-50b2-4141-bb8c-59930f3206db 14886 3 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b11058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 09:51:40 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-08-24 09:51:42 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Aug 24 09:51:44.001: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-3803  db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 14890 3 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ce4a173c-50b2-4141-bb8c-59930f3206db 0xc001fa7697 0xc001fa7698}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce4a173c-50b2-4141-bb8c-59930f3206db\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001fa7748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:51:44.002: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Aug 24 09:51:44.002: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-3803  9f73979c-5af3-40f9-9311-f44cf910e497 14887 3 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ce4a173c-50b2-4141-bb8c-59930f3206db 0xc001fa77a7 0xc001fa77a8}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce4a173c-50b2-4141-bb8c-59930f3206db\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001fa7838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:51:44.024: INFO: Pod "webserver-deployment-69b7448995-f7p9x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-f7p9x webserver-deployment-69b7448995- deployment-3803  20c0bc35-2c4c-4673-b459-86c716c803f5 14797 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11467 0xc002b11468}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q29gr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q29gr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.026: INFO: Pod "webserver-deployment-69b7448995-fzznf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fzznf webserver-deployment-69b7448995- deployment-3803  1124c63e-c6a2-46c5-9beb-0b6297ea34ea 14808 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11677 0xc002b11678}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n4kw8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n4kw8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.027: INFO: Pod "webserver-deployment-69b7448995-jdxfb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jdxfb webserver-deployment-69b7448995- deployment-3803  c76379ca-b384-4ec7-b1c4-d08edf98285f 14812 0 2022-08-24 09:51:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11887 0xc002b11888}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z6c4j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z6c4j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:,StartTime:2022-08-24 09:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.028: INFO: Pod "webserver-deployment-69b7448995-nplt5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-nplt5 webserver-deployment-69b7448995- deployment-3803  4ae298c9-4314-4700-87e0-a120604a36a3 14825 0 2022-08-24 09:51:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11a77 0xc002b11a78}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xd7xq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xd7xq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 09:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.033: INFO: Pod "webserver-deployment-69b7448995-q6l9l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-q6l9l webserver-deployment-69b7448995- deployment-3803  29819bb5-3fa9-4261-a6ed-5beffb3fe64e 14834 0 2022-08-24 09:51:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea 0xc002b11c77 0xc002b11c78}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db0b51b9-29fd-4447-8e9d-0c3f1a08c7ea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j929f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j929f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2022-08-24 09:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.033: INFO: Pod "webserver-deployment-845c8977d9-2c525" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2c525 webserver-deployment-845c8977d9- deployment-3803  9ef2daa4-be83-45ca-af6c-5d14b07f03f8 14740 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc002b11e67 0xc002b11e68}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xndwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xndwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.87,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://6e36b60e226eaeba9c115f9ed439010c3bcd475a72eced407515610ef8ea083c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.034: INFO: Pod "webserver-deployment-845c8977d9-2kptq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2kptq webserver-deployment-845c8977d9- deployment-3803  361483d6-2bcc-4eb0-8e77-117a394cb429 14889 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820117 0xc003820118}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxcl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxcl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.034: INFO: Pod "webserver-deployment-845c8977d9-49pkq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-49pkq webserver-deployment-845c8977d9- deployment-3803  9c9210c6-ace4-40dc-b465-15d3f497a03e 14743 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc0038205b7 0xc0038205b8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kcvz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kcvz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.88,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://0208c376ebc4fd143f7b19668b1cb07fa86caa69c427234e27c6d40e9c92f434,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.035: INFO: Pod "webserver-deployment-845c8977d9-9r46f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9r46f webserver-deployment-845c8977d9- deployment-3803  a2afc5f9-a281-43bc-82fd-394ef3f9ea31 14752 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820947 0xc003820948}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4j7cx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4j7cx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.155,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://3324eacaa2aa227948a4bebeeb6e63e931c40e5e8b616220b7e3cc920ad1dc26,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-f5pmz" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-f5pmz webserver-deployment-845c8977d9- deployment-3803  3a99bf13-ab5d-4d0b-868e-caddb0f12510 14768 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820b37 0xc003820b38}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dpmct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dpmct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.83,StartTime:2022-08-24 09:51:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://8dd5e25a4a6da787af3fda4cc7c4947210ae037cf4783b530a7f20b777b4d481,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-fbpx9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fbpx9 webserver-deployment-845c8977d9- deployment-3803  65c41a7d-24e5-49b5-a82a-8e04e4676280 14892 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820d27 0xc003820d28}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jfdkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jfdkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.036: INFO: Pod "webserver-deployment-845c8977d9-kdx6m" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kdx6m webserver-deployment-845c8977d9- deployment-3803  9d31c3fc-2b71-433b-a589-9255484f28dc 14893 0 2022-08-24 09:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820e67 0xc003820e68}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dpqqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dpqqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.037: INFO: Pod "webserver-deployment-845c8977d9-kz6lq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kz6lq webserver-deployment-845c8977d9- deployment-3803  7fa88181-4feb-4981-b7d0-33b76792ee9c 14778 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003820fa7 0xc003820fa8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kcm9s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kcm9s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.153,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://641dc466a2b3541a5d38f969b5444d6f83359ced76f0e227b5045809a0ece212,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.038: INFO: Pod "webserver-deployment-845c8977d9-qxp2q" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qxp2q webserver-deployment-845c8977d9- deployment-3803  e00ab102-ce6a-4f60-a034-6afbb5abb042 14774 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003821197 0xc003821198}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dlbjj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dlbjj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.82,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://de6a3a7c80cb77f72ad7f104d2c4b0784d3648d8f1a8e942b1b6170e6df58802,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.038: INFO: Pod "webserver-deployment-845c8977d9-rmvz6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rmvz6 webserver-deployment-845c8977d9- deployment-3803  338b6bcb-a3e3-477d-ac10-18c593121acf 14744 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc003821387 0xc003821388}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.89\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kkbf5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kkbf5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.65.89,StartTime:2022-08-24 09:51:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://8024d16f4e7ddd2c2bba8a0a903eb649a5a880510d9ba5b01804421ae1dcb488,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:51:44.039: INFO: Pod "webserver-deployment-845c8977d9-tllm6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tllm6 webserver-deployment-845c8977d9- deployment-3803  0053d05e-6184-49f5-8712-b57a1f5ebae7 14771 0 2022-08-24 09:51:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 9f73979c-5af3-40f9-9311-f44cf910e497 0xc0038215b7 0xc0038215b8}] [] [{kube-controller-manager Update v1 2022-08-24 09:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f73979c-5af3-40f9-9311-f44cf910e497\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xvhdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xvhdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:51:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.119,PodIP:10.233.64.81,StartTime:2022-08-24 09:51:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:51:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://2d31214b1409ccf019d6175658b042c3e5f156305d54b039a0c5f193c54bf0b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 09:51:44.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3803" for this suite. 08/24/22 09:51:44.097
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:44.132
Aug 24 09:51:44.133: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:51:44.142
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:44.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:44.298
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:51:44.302
Aug 24 09:51:44.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3905 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Aug 24 09:51:44.490: INFO: stderr: ""
Aug 24 09:51:44.490: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 08/24/22 09:51:44.49
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Aug 24 09:51:44.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3905 delete pods e2e-test-httpd-pod'
Aug 24 09:51:47.669: INFO: stderr: ""
Aug 24 09:51:47.669: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:51:47.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3905" for this suite. 08/24/22 09:51:47.678
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":88,"skipped":1637,"failed":0}
------------------------------
• [3.559 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:44.132
    Aug 24 09:51:44.133: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:51:44.142
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:44.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:44.298
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:51:44.302
    Aug 24 09:51:44.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3905 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Aug 24 09:51:44.490: INFO: stderr: ""
    Aug 24 09:51:44.490: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 08/24/22 09:51:44.49
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Aug 24 09:51:44.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3905 delete pods e2e-test-httpd-pod'
    Aug 24 09:51:47.669: INFO: stderr: ""
    Aug 24 09:51:47.669: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:51:47.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3905" for this suite. 08/24/22 09:51:47.678
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:47.691
Aug 24 09:51:47.692: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename tables 08/24/22 09:51:47.694
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:47.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:47.739
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Aug 24 09:51:47.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-1228" for this suite. 08/24/22 09:51:47.757
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":89,"skipped":1640,"failed":0}
------------------------------
• [0.080 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:47.691
    Aug 24 09:51:47.692: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename tables 08/24/22 09:51:47.694
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:47.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:47.739
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Aug 24 09:51:47.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-1228" for this suite. 08/24/22 09:51:47.757
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:47.772
Aug 24 09:51:47.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 09:51:47.776
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:47.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:47.812
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  08/24/22 09:51:47.817
Aug 24 09:51:47.829: INFO: Waiting up to 5m0s for pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7" in namespace "svcaccounts-9640" to be "Succeeded or Failed"
Aug 24 09:51:47.834: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.715734ms
Aug 24 09:51:49.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.012951695s
Aug 24 09:51:51.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Running", Reason="", readiness=false. Elapsed: 4.013686773s
Aug 24 09:51:53.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013607683s
STEP: Saw pod success 08/24/22 09:51:53.842
Aug 24 09:51:53.843: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7" satisfied condition "Succeeded or Failed"
Aug 24 09:51:53.847: INFO: Trying to get logs from node kah9uighaagh-3 pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 09:51:53.86
Aug 24 09:51:53.882: INFO: Waiting for pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 to disappear
Aug 24 09:51:53.886: INFO: Pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 09:51:53.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9640" for this suite. 08/24/22 09:51:53.891
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":90,"skipped":1640,"failed":0}
------------------------------
• [SLOW TEST] [6.129 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:47.772
    Aug 24 09:51:47.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 09:51:47.776
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:47.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:47.812
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  08/24/22 09:51:47.817
    Aug 24 09:51:47.829: INFO: Waiting up to 5m0s for pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7" in namespace "svcaccounts-9640" to be "Succeeded or Failed"
    Aug 24 09:51:47.834: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.715734ms
    Aug 24 09:51:49.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.012951695s
    Aug 24 09:51:51.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Running", Reason="", readiness=false. Elapsed: 4.013686773s
    Aug 24 09:51:53.842: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013607683s
    STEP: Saw pod success 08/24/22 09:51:53.842
    Aug 24 09:51:53.843: INFO: Pod "test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7" satisfied condition "Succeeded or Failed"
    Aug 24 09:51:53.847: INFO: Trying to get logs from node kah9uighaagh-3 pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 09:51:53.86
    Aug 24 09:51:53.882: INFO: Waiting for pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 to disappear
    Aug 24 09:51:53.886: INFO: Pod test-pod-b9ba6c67-c47f-446e-bef3-1a805bff20b7 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 09:51:53.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9640" for this suite. 08/24/22 09:51:53.891
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:53.906
Aug 24 09:51:53.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 09:51:53.911
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:53.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:53.944
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 09:51:54.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-17" for this suite. 08/24/22 09:51:54.025
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":91,"skipped":1664,"failed":0}
------------------------------
• [0.132 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:53.906
    Aug 24 09:51:53.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 09:51:53.911
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:53.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:53.944
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 09:51:54.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-17" for this suite. 08/24/22 09:51:54.025
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:54.044
Aug 24 09:51:54.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 09:51:54.047
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:54.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:54.088
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 08/24/22 09:51:54.094
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 08/24/22 09:51:54.105
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 08/24/22 09:51:54.105
STEP: creating a pod to probe DNS 08/24/22 09:51:54.105
STEP: submitting the pod to kubernetes 08/24/22 09:51:54.105
Aug 24 09:51:54.129: INFO: Waiting up to 15m0s for pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4" in namespace "dns-826" to be "running"
Aug 24 09:51:54.133: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.380963ms
Aug 24 09:51:56.141: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.011921177s
Aug 24 09:51:56.141: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4" satisfied condition "running"
STEP: retrieving the pod 08/24/22 09:51:56.141
STEP: looking for the results for each expected name from probers 08/24/22 09:51:56.147
Aug 24 09:51:56.181: INFO: DNS probes using dns-826/dns-test-abf00b90-46d6-456a-8afb-81f6155774c4 succeeded

STEP: deleting the pod 08/24/22 09:51:56.181
STEP: deleting the test headless service 08/24/22 09:51:56.207
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 09:51:56.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-826" for this suite. 08/24/22 09:51:56.244
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":92,"skipped":1670,"failed":0}
------------------------------
• [2.213 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:54.044
    Aug 24 09:51:54.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 09:51:54.047
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:54.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:54.088
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 08/24/22 09:51:54.094
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     08/24/22 09:51:54.105
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-826.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     08/24/22 09:51:54.105
    STEP: creating a pod to probe DNS 08/24/22 09:51:54.105
    STEP: submitting the pod to kubernetes 08/24/22 09:51:54.105
    Aug 24 09:51:54.129: INFO: Waiting up to 15m0s for pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4" in namespace "dns-826" to be "running"
    Aug 24 09:51:54.133: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.380963ms
    Aug 24 09:51:56.141: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.011921177s
    Aug 24 09:51:56.141: INFO: Pod "dns-test-abf00b90-46d6-456a-8afb-81f6155774c4" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 09:51:56.141
    STEP: looking for the results for each expected name from probers 08/24/22 09:51:56.147
    Aug 24 09:51:56.181: INFO: DNS probes using dns-826/dns-test-abf00b90-46d6-456a-8afb-81f6155774c4 succeeded

    STEP: deleting the pod 08/24/22 09:51:56.181
    STEP: deleting the test headless service 08/24/22 09:51:56.207
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 09:51:56.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-826" for this suite. 08/24/22 09:51:56.244
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:51:56.262
Aug 24 09:51:56.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pod-network-test 08/24/22 09:51:56.264
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:56.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:56.302
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-5526 08/24/22 09:51:56.307
STEP: creating a selector 08/24/22 09:51:56.307
STEP: Creating the service pods in kubernetes 08/24/22 09:51:56.307
Aug 24 09:51:56.308: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 09:51:56.373: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5526" to be "running and ready"
Aug 24 09:51:56.380: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.893483ms
Aug 24 09:51:56.380: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:51:58.391: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017846724s
Aug 24 09:51:58.391: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:00.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013994903s
Aug 24 09:52:00.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:02.408: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.034365543s
Aug 24 09:52:02.409: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:04.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013965321s
Aug 24 09:52:04.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:06.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.015877009s
Aug 24 09:52:06.389: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:08.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.014165649s
Aug 24 09:52:08.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:10.388: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014974192s
Aug 24 09:52:10.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:12.391: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.018069835s
Aug 24 09:52:12.391: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:14.388: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014814437s
Aug 24 09:52:14.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:16.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.014341376s
Aug 24 09:52:16.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 09:52:18.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.016314641s
Aug 24 09:52:18.390: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 24 09:52:18.390: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 24 09:52:18.396: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5526" to be "running and ready"
Aug 24 09:52:18.402: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.522404ms
Aug 24 09:52:18.402: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 24 09:52:18.402: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 24 09:52:18.408: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5526" to be "running and ready"
Aug 24 09:52:18.414: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.183771ms
Aug 24 09:52:18.415: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 24 09:52:18.415: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/24/22 09:52:18.421
Aug 24 09:52:18.434: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5526" to be "running"
Aug 24 09:52:18.441: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.354037ms
Aug 24 09:52:20.451: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017176675s
Aug 24 09:52:20.451: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 24 09:52:20.459: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 09:52:20.459: INFO: Breadth first check of 10.233.64.85 on host 192.168.121.119...
Aug 24 09:52:20.466: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.64.85&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 09:52:20.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 09:52:20.468: INFO: ExecWithOptions: Clientset creation
Aug 24 09:52:20.469: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.85%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 09:52:20.623: INFO: Waiting for responses: map[]
Aug 24 09:52:20.623: INFO: reached 10.233.64.85 after 0/1 tries
Aug 24 09:52:20.623: INFO: Breadth first check of 10.233.65.92 on host 192.168.121.214...
Aug 24 09:52:20.633: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.65.92&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 09:52:20.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 09:52:20.636: INFO: ExecWithOptions: Clientset creation
Aug 24 09:52:20.636: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.92%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 09:52:20.758: INFO: Waiting for responses: map[]
Aug 24 09:52:20.758: INFO: reached 10.233.65.92 after 0/1 tries
Aug 24 09:52:20.758: INFO: Breadth first check of 10.233.66.162 on host 192.168.121.54...
Aug 24 09:52:20.765: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.66.162&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 09:52:20.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 09:52:20.767: INFO: ExecWithOptions: Clientset creation
Aug 24 09:52:20.768: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.162%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 09:52:20.871: INFO: Waiting for responses: map[]
Aug 24 09:52:20.871: INFO: reached 10.233.66.162 after 0/1 tries
Aug 24 09:52:20.871: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 24 09:52:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5526" for this suite. 08/24/22 09:52:20.883
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":93,"skipped":1687,"failed":0}
------------------------------
• [SLOW TEST] [24.635 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:51:56.262
    Aug 24 09:51:56.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pod-network-test 08/24/22 09:51:56.264
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:51:56.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:51:56.302
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-5526 08/24/22 09:51:56.307
    STEP: creating a selector 08/24/22 09:51:56.307
    STEP: Creating the service pods in kubernetes 08/24/22 09:51:56.307
    Aug 24 09:51:56.308: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 24 09:51:56.373: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5526" to be "running and ready"
    Aug 24 09:51:56.380: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.893483ms
    Aug 24 09:51:56.380: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:51:58.391: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017846724s
    Aug 24 09:51:58.391: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:00.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013994903s
    Aug 24 09:52:00.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:02.408: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.034365543s
    Aug 24 09:52:02.409: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:04.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013965321s
    Aug 24 09:52:04.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:06.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.015877009s
    Aug 24 09:52:06.389: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:08.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.014165649s
    Aug 24 09:52:08.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:10.388: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014974192s
    Aug 24 09:52:10.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:12.391: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.018069835s
    Aug 24 09:52:12.391: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:14.388: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014814437s
    Aug 24 09:52:14.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:16.387: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.014341376s
    Aug 24 09:52:16.388: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 09:52:18.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.016314641s
    Aug 24 09:52:18.390: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 24 09:52:18.390: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 24 09:52:18.396: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5526" to be "running and ready"
    Aug 24 09:52:18.402: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.522404ms
    Aug 24 09:52:18.402: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 24 09:52:18.402: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 24 09:52:18.408: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5526" to be "running and ready"
    Aug 24 09:52:18.414: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.183771ms
    Aug 24 09:52:18.415: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 24 09:52:18.415: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/24/22 09:52:18.421
    Aug 24 09:52:18.434: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5526" to be "running"
    Aug 24 09:52:18.441: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.354037ms
    Aug 24 09:52:20.451: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017176675s
    Aug 24 09:52:20.451: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 24 09:52:20.459: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 24 09:52:20.459: INFO: Breadth first check of 10.233.64.85 on host 192.168.121.119...
    Aug 24 09:52:20.466: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.64.85&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 09:52:20.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 09:52:20.468: INFO: ExecWithOptions: Clientset creation
    Aug 24 09:52:20.469: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.85%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 09:52:20.623: INFO: Waiting for responses: map[]
    Aug 24 09:52:20.623: INFO: reached 10.233.64.85 after 0/1 tries
    Aug 24 09:52:20.623: INFO: Breadth first check of 10.233.65.92 on host 192.168.121.214...
    Aug 24 09:52:20.633: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.65.92&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 09:52:20.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 09:52:20.636: INFO: ExecWithOptions: Clientset creation
    Aug 24 09:52:20.636: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.92%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 09:52:20.758: INFO: Waiting for responses: map[]
    Aug 24 09:52:20.758: INFO: reached 10.233.65.92 after 0/1 tries
    Aug 24 09:52:20.758: INFO: Breadth first check of 10.233.66.162 on host 192.168.121.54...
    Aug 24 09:52:20.765: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.163:9080/dial?request=hostname&protocol=udp&host=10.233.66.162&port=8081&tries=1'] Namespace:pod-network-test-5526 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 09:52:20.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 09:52:20.767: INFO: ExecWithOptions: Clientset creation
    Aug 24 09:52:20.768: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5526/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.163%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.162%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 09:52:20.871: INFO: Waiting for responses: map[]
    Aug 24 09:52:20.871: INFO: reached 10.233.66.162 after 0/1 tries
    Aug 24 09:52:20.871: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 24 09:52:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5526" for this suite. 08/24/22 09:52:20.883
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:52:20.909
Aug 24 09:52:20.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename conformance-tests 08/24/22 09:52:20.934
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:52:20.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:52:20.988
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 08/24/22 09:52:20.998
Aug 24 09:52:20.998: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Aug 24 09:52:21.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-7418" for this suite. 08/24/22 09:52:21.034
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":94,"skipped":1704,"failed":0}
------------------------------
• [0.138 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:52:20.909
    Aug 24 09:52:20.909: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename conformance-tests 08/24/22 09:52:20.934
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:52:20.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:52:20.988
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 08/24/22 09:52:20.998
    Aug 24 09:52:20.998: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Aug 24 09:52:21.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-7418" for this suite. 08/24/22 09:52:21.034
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:52:21.051
Aug 24 09:52:21.051: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename cronjob 08/24/22 09:52:21.053
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:52:21.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:52:21.092
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 08/24/22 09:52:21.097
STEP: Ensuring no jobs are scheduled 08/24/22 09:52:21.107
STEP: Ensuring no job exists by listing jobs explicitly 08/24/22 09:57:21.119
STEP: Removing cronjob 08/24/22 09:57:21.124
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 24 09:57:21.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5012" for this suite. 08/24/22 09:57:21.143
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":95,"skipped":1715,"failed":0}
------------------------------
• [SLOW TEST] [300.106 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:52:21.051
    Aug 24 09:52:21.051: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename cronjob 08/24/22 09:52:21.053
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:52:21.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:52:21.092
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 08/24/22 09:52:21.097
    STEP: Ensuring no jobs are scheduled 08/24/22 09:52:21.107
    STEP: Ensuring no job exists by listing jobs explicitly 08/24/22 09:57:21.119
    STEP: Removing cronjob 08/24/22 09:57:21.124
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 24 09:57:21.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5012" for this suite. 08/24/22 09:57:21.143
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:21.166
Aug 24 09:57:21.166: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 09:57:21.17
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:21.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:21.21
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 08/24/22 09:57:21.215
Aug 24 09:57:21.230: INFO: Waiting up to 5m0s for pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870" in namespace "downward-api-8530" to be "Succeeded or Failed"
Aug 24 09:57:21.237: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Pending", Reason="", readiness=false. Elapsed: 6.76393ms
Aug 24 09:57:23.245: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01524586s
Aug 24 09:57:25.245: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015227172s
STEP: Saw pod success 08/24/22 09:57:25.245
Aug 24 09:57:25.246: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870" satisfied condition "Succeeded or Failed"
Aug 24 09:57:25.250: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 container dapi-container: <nil>
STEP: delete the pod 08/24/22 09:57:25.278
Aug 24 09:57:25.301: INFO: Waiting for pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 to disappear
Aug 24 09:57:25.307: INFO: Pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 24 09:57:25.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8530" for this suite. 08/24/22 09:57:25.314
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":96,"skipped":1721,"failed":0}
------------------------------
• [4.160 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:21.166
    Aug 24 09:57:21.166: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 09:57:21.17
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:21.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:21.21
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 08/24/22 09:57:21.215
    Aug 24 09:57:21.230: INFO: Waiting up to 5m0s for pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870" in namespace "downward-api-8530" to be "Succeeded or Failed"
    Aug 24 09:57:21.237: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Pending", Reason="", readiness=false. Elapsed: 6.76393ms
    Aug 24 09:57:23.245: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01524586s
    Aug 24 09:57:25.245: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015227172s
    STEP: Saw pod success 08/24/22 09:57:25.245
    Aug 24 09:57:25.246: INFO: Pod "downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870" satisfied condition "Succeeded or Failed"
    Aug 24 09:57:25.250: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 09:57:25.278
    Aug 24 09:57:25.301: INFO: Waiting for pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 to disappear
    Aug 24 09:57:25.307: INFO: Pod downward-api-bc2f3a4c-82a6-4b03-b659-d1d7c4f30870 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 24 09:57:25.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8530" for this suite. 08/24/22 09:57:25.314
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:25.327
Aug 24 09:57:25.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 09:57:25.338
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:25.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:25.375
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-54d9e764-d303-4341-89d4-0f81edd841c2 08/24/22 09:57:25.38
STEP: Creating a pod to test consume secrets 08/24/22 09:57:25.41
Aug 24 09:57:25.437: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845" in namespace "projected-1397" to be "Succeeded or Failed"
Aug 24 09:57:25.445: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008875ms
Aug 24 09:57:27.455: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Running", Reason="", readiness=false. Elapsed: 2.017958935s
Aug 24 09:57:29.454: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017133435s
STEP: Saw pod success 08/24/22 09:57:29.454
Aug 24 09:57:29.454: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845" satisfied condition "Succeeded or Failed"
Aug 24 09:57:29.461: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/24/22 09:57:29.474
Aug 24 09:57:29.500: INFO: Waiting for pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 to disappear
Aug 24 09:57:29.507: INFO: Pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 09:57:29.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1397" for this suite. 08/24/22 09:57:29.52
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":97,"skipped":1737,"failed":0}
------------------------------
• [4.206 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:25.327
    Aug 24 09:57:25.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 09:57:25.338
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:25.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:25.375
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-54d9e764-d303-4341-89d4-0f81edd841c2 08/24/22 09:57:25.38
    STEP: Creating a pod to test consume secrets 08/24/22 09:57:25.41
    Aug 24 09:57:25.437: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845" in namespace "projected-1397" to be "Succeeded or Failed"
    Aug 24 09:57:25.445: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008875ms
    Aug 24 09:57:27.455: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Running", Reason="", readiness=false. Elapsed: 2.017958935s
    Aug 24 09:57:29.454: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017133435s
    STEP: Saw pod success 08/24/22 09:57:29.454
    Aug 24 09:57:29.454: INFO: Pod "pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845" satisfied condition "Succeeded or Failed"
    Aug 24 09:57:29.461: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 09:57:29.474
    Aug 24 09:57:29.500: INFO: Waiting for pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 to disappear
    Aug 24 09:57:29.507: INFO: Pod pod-projected-secrets-ab9ebb23-3eb1-4cd8-a473-de56318d7845 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 09:57:29.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1397" for this suite. 08/24/22 09:57:29.52
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:29.534
Aug 24 09:57:29.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 09:57:29.539
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:29.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:29.577
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 08/24/22 09:57:29.58
STEP: listing secrets in all namespaces to ensure that there are more than zero 08/24/22 09:57:29.589
STEP: patching the secret 08/24/22 09:57:29.596
STEP: deleting the secret using a LabelSelector 08/24/22 09:57:29.616
STEP: listing secrets in all namespaces, searching for label name and value in patch 08/24/22 09:57:29.631
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 24 09:57:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5616" for this suite. 08/24/22 09:57:29.645
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":98,"skipped":1737,"failed":0}
------------------------------
• [0.128 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:29.534
    Aug 24 09:57:29.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 09:57:29.539
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:29.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:29.577
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 08/24/22 09:57:29.58
    STEP: listing secrets in all namespaces to ensure that there are more than zero 08/24/22 09:57:29.589
    STEP: patching the secret 08/24/22 09:57:29.596
    STEP: deleting the secret using a LabelSelector 08/24/22 09:57:29.616
    STEP: listing secrets in all namespaces, searching for label name and value in patch 08/24/22 09:57:29.631
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 09:57:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5616" for this suite. 08/24/22 09:57:29.645
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:29.666
Aug 24 09:57:29.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 09:57:29.668
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:29.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:29.709
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 08/24/22 09:57:29.713
Aug 24 09:57:29.730: INFO: Waiting up to 5m0s for pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d" in namespace "downward-api-6337" to be "running and ready"
Aug 24 09:57:29.740: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.747507ms
Aug 24 09:57:29.740: INFO: The phase of Pod annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d is Pending, waiting for it to be Running (with Ready = true)
Aug 24 09:57:31.749: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018875565s
Aug 24 09:57:31.749: INFO: The phase of Pod annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d is Running (Ready = true)
Aug 24 09:57:31.749: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d" satisfied condition "running and ready"
Aug 24 09:57:32.289: INFO: Successfully updated pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 09:57:36.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6337" for this suite. 08/24/22 09:57:36.339
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":99,"skipped":1741,"failed":0}
------------------------------
• [SLOW TEST] [6.683 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:29.666
    Aug 24 09:57:29.666: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 09:57:29.668
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:29.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:29.709
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 08/24/22 09:57:29.713
    Aug 24 09:57:29.730: INFO: Waiting up to 5m0s for pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d" in namespace "downward-api-6337" to be "running and ready"
    Aug 24 09:57:29.740: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.747507ms
    Aug 24 09:57:29.740: INFO: The phase of Pod annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 09:57:31.749: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018875565s
    Aug 24 09:57:31.749: INFO: The phase of Pod annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d is Running (Ready = true)
    Aug 24 09:57:31.749: INFO: Pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d" satisfied condition "running and ready"
    Aug 24 09:57:32.289: INFO: Successfully updated pod "annotationupdate4891b1fb-c419-47c3-a1a9-87aca615c49d"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 09:57:36.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6337" for this suite. 08/24/22 09:57:36.339
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:36.355
Aug 24 09:57:36.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 09:57:36.357
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:36.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:36.403
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Aug 24 09:57:36.407: INFO: Creating simple deployment test-new-deployment
Aug 24 09:57:36.428: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource 08/24/22 09:57:38.454
STEP: updating a scale subresource 08/24/22 09:57:38.46
STEP: verifying the deployment Spec.Replicas was modified 08/24/22 09:57:38.47
STEP: Patch a scale subresource 08/24/22 09:57:38.491
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 09:57:38.568: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-4176  470ee22c-6a3f-4909-a5af-ff08154de228 15921 3 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-24 09:57:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000951e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-08-24 09:57:38 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 09:57:38 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 09:57:38.589: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4176  4b61736e-8050-4c5e-a335-6871842b73dd 15926 3 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 470ee22c-6a3f-4909-a5af-ff08154de228 0xc000c4a707 0xc000c4a708}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"470ee22c-6a3f-4909-a5af-ff08154de228\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000c4a8d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 09:57:38.602: INFO: Pod "test-new-deployment-845c8977d9-8pk26" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-8pk26 test-new-deployment-845c8977d9- deployment-4176  98343311-0e44-487f-af5d-b9b84f74a78f 15913 0 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 4b61736e-8050-4c5e-a335-6871842b73dd 0xc002f77597 0xc002f77598}] [] [{kube-controller-manager Update v1 2022-08-24 09:57:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4b61736e-8050-4c5e-a335-6871842b73dd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.167\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2k4zb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2k4zb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.167,StartTime:2022-08-24 09:57:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:57:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://6862115c0965ed9d0272992890523438d9b7709a3dc362ef64741bdc2d868735,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 09:57:38.603: INFO: Pod "test-new-deployment-845c8977d9-rpczm" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rpczm test-new-deployment-845c8977d9- deployment-4176  26b5aa33-3875-481a-8230-5148b3cdb84f 15923 0 2022-08-24 09:57:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 4b61736e-8050-4c5e-a335-6871842b73dd 0xc002f77787 0xc002f77788}] [] [{kube-controller-manager Update v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4b61736e-8050-4c5e-a335-6871842b73dd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xm7ft,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xm7ft,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 09:57:38.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4176" for this suite. 08/24/22 09:57:38.625
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":100,"skipped":1750,"failed":0}
------------------------------
• [2.284 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:36.355
    Aug 24 09:57:36.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 09:57:36.357
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:36.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:36.403
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Aug 24 09:57:36.407: INFO: Creating simple deployment test-new-deployment
    Aug 24 09:57:36.428: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
    STEP: getting scale subresource 08/24/22 09:57:38.454
    STEP: updating a scale subresource 08/24/22 09:57:38.46
    STEP: verifying the deployment Spec.Replicas was modified 08/24/22 09:57:38.47
    STEP: Patch a scale subresource 08/24/22 09:57:38.491
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 09:57:38.568: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-4176  470ee22c-6a3f-4909-a5af-ff08154de228 15921 3 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-24 09:57:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000951e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-08-24 09:57:38 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 09:57:38 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 24 09:57:38.589: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4176  4b61736e-8050-4c5e-a335-6871842b73dd 15926 3 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 470ee22c-6a3f-4909-a5af-ff08154de228 0xc000c4a707 0xc000c4a708}] [] [{kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"470ee22c-6a3f-4909-a5af-ff08154de228\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000c4a8d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 09:57:38.602: INFO: Pod "test-new-deployment-845c8977d9-8pk26" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-8pk26 test-new-deployment-845c8977d9- deployment-4176  98343311-0e44-487f-af5d-b9b84f74a78f 15913 0 2022-08-24 09:57:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 4b61736e-8050-4c5e-a335-6871842b73dd 0xc002f77597 0xc002f77598}] [] [{kube-controller-manager Update v1 2022-08-24 09:57:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4b61736e-8050-4c5e-a335-6871842b73dd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.167\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2k4zb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2k4zb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.167,StartTime:2022-08-24 09:57:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 09:57:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://6862115c0965ed9d0272992890523438d9b7709a3dc362ef64741bdc2d868735,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 09:57:38.603: INFO: Pod "test-new-deployment-845c8977d9-rpczm" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rpczm test-new-deployment-845c8977d9- deployment-4176  26b5aa33-3875-481a-8230-5148b3cdb84f 15923 0 2022-08-24 09:57:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 4b61736e-8050-4c5e-a335-6871842b73dd 0xc002f77787 0xc002f77788}] [] [{kube-controller-manager Update v1 2022-08-24 09:57:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4b61736e-8050-4c5e-a335-6871842b73dd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xm7ft,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xm7ft,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 09:57:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 09:57:38.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4176" for this suite. 08/24/22 09:57:38.625
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:38.643
Aug 24 09:57:38.643: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 09:57:38.647
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:38.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:38.76
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 08/24/22 09:57:38.768
Aug 24 09:57:38.789: INFO: Waiting up to 5m0s for pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6" in namespace "var-expansion-2934" to be "Succeeded or Failed"
Aug 24 09:57:38.801: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.435895ms
Aug 24 09:57:40.809: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020077299s
Aug 24 09:57:42.808: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019290328s
STEP: Saw pod success 08/24/22 09:57:42.809
Aug 24 09:57:42.809: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6" satisfied condition "Succeeded or Failed"
Aug 24 09:57:42.815: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 container dapi-container: <nil>
STEP: delete the pod 08/24/22 09:57:42.827
Aug 24 09:57:42.849: INFO: Waiting for pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 to disappear
Aug 24 09:57:42.856: INFO: Pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 09:57:42.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2934" for this suite. 08/24/22 09:57:42.865
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":101,"skipped":1771,"failed":0}
------------------------------
• [4.239 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:38.643
    Aug 24 09:57:38.643: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 09:57:38.647
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:38.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:38.76
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 08/24/22 09:57:38.768
    Aug 24 09:57:38.789: INFO: Waiting up to 5m0s for pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6" in namespace "var-expansion-2934" to be "Succeeded or Failed"
    Aug 24 09:57:38.801: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.435895ms
    Aug 24 09:57:40.809: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020077299s
    Aug 24 09:57:42.808: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019290328s
    STEP: Saw pod success 08/24/22 09:57:42.809
    Aug 24 09:57:42.809: INFO: Pod "var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6" satisfied condition "Succeeded or Failed"
    Aug 24 09:57:42.815: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 09:57:42.827
    Aug 24 09:57:42.849: INFO: Waiting for pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 to disappear
    Aug 24 09:57:42.856: INFO: Pod var-expansion-aedec46d-0846-4e21-b2e0-c3050dd43ef6 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 09:57:42.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2934" for this suite. 08/24/22 09:57:42.865
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:42.891
Aug 24 09:57:42.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:57:42.893
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:42.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:42.94
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:57:42.944
Aug 24 09:57:42.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 24 09:57:43.128: INFO: stderr: ""
Aug 24 09:57:43.128: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 08/24/22 09:57:43.128
Aug 24 09:57:43.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Aug 24 09:57:44.764: INFO: stderr: ""
Aug 24 09:57:44.764: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:57:44.764
Aug 24 09:57:44.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 delete pods e2e-test-httpd-pod'
Aug 24 09:57:47.648: INFO: stderr: ""
Aug 24 09:57:47.648: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:57:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4102" for this suite. 08/24/22 09:57:47.657
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":102,"skipped":1791,"failed":0}
------------------------------
• [4.776 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:42.891
    Aug 24 09:57:42.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:57:42.893
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:42.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:42.94
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:57:42.944
    Aug 24 09:57:42.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 24 09:57:43.128: INFO: stderr: ""
    Aug 24 09:57:43.128: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 08/24/22 09:57:43.128
    Aug 24 09:57:43.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Aug 24 09:57:44.764: INFO: stderr: ""
    Aug 24 09:57:44.764: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 09:57:44.764
    Aug 24 09:57:44.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-4102 delete pods e2e-test-httpd-pod'
    Aug 24 09:57:47.648: INFO: stderr: ""
    Aug 24 09:57:47.648: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:57:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4102" for this suite. 08/24/22 09:57:47.657
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:47.669
Aug 24 09:57:47.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 09:57:47.674
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:47.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:47.71
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Aug 24 09:57:47.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-8257 version'
Aug 24 09:57:47.813: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Aug 24 09:57:47.813: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 09:57:47.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8257" for this suite. 08/24/22 09:57:47.821
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":103,"skipped":1809,"failed":0}
------------------------------
• [0.163 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:47.669
    Aug 24 09:57:47.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 09:57:47.674
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:47.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:47.71
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Aug 24 09:57:47.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-8257 version'
    Aug 24 09:57:47.813: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Aug 24 09:57:47.813: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 09:57:47.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8257" for this suite. 08/24/22 09:57:47.821
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:57:47.834
Aug 24 09:57:47.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename subpath 08/24/22 09:57:47.836
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:47.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:47.882
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/24/22 09:57:47.891
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-ljf2 08/24/22 09:57:47.91
STEP: Creating a pod to test atomic-volume-subpath 08/24/22 09:57:47.91
Aug 24 09:57:47.929: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ljf2" in namespace "subpath-8930" to be "Succeeded or Failed"
Aug 24 09:57:47.934: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.245612ms
Aug 24 09:57:49.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012593074s
Aug 24 09:57:51.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 4.01332752s
Aug 24 09:57:53.947: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 6.018588625s
Aug 24 09:57:55.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 8.013249722s
Aug 24 09:57:57.949: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 10.020659552s
Aug 24 09:57:59.943: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 12.014034575s
Aug 24 09:58:01.944: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 14.015298554s
Aug 24 09:58:03.943: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 16.014247139s
Aug 24 09:58:05.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 18.012058416s
Aug 24 09:58:07.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 20.011804974s
Aug 24 09:58:09.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=false. Elapsed: 22.011926316s
Aug 24 09:58:11.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013154601s
STEP: Saw pod success 08/24/22 09:58:11.942
Aug 24 09:58:11.942: INFO: Pod "pod-subpath-test-configmap-ljf2" satisfied condition "Succeeded or Failed"
Aug 24 09:58:11.947: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-configmap-ljf2 container test-container-subpath-configmap-ljf2: <nil>
STEP: delete the pod 08/24/22 09:58:11.959
Aug 24 09:58:11.978: INFO: Waiting for pod pod-subpath-test-configmap-ljf2 to disappear
Aug 24 09:58:11.989: INFO: Pod pod-subpath-test-configmap-ljf2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ljf2 08/24/22 09:58:11.989
Aug 24 09:58:11.989: INFO: Deleting pod "pod-subpath-test-configmap-ljf2" in namespace "subpath-8930"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 24 09:58:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8930" for this suite. 08/24/22 09:58:12.003
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":104,"skipped":1827,"failed":0}
------------------------------
• [SLOW TEST] [24.181 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:57:47.834
    Aug 24 09:57:47.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename subpath 08/24/22 09:57:47.836
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:57:47.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:57:47.882
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/24/22 09:57:47.891
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-ljf2 08/24/22 09:57:47.91
    STEP: Creating a pod to test atomic-volume-subpath 08/24/22 09:57:47.91
    Aug 24 09:57:47.929: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ljf2" in namespace "subpath-8930" to be "Succeeded or Failed"
    Aug 24 09:57:47.934: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.245612ms
    Aug 24 09:57:49.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012593074s
    Aug 24 09:57:51.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 4.01332752s
    Aug 24 09:57:53.947: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 6.018588625s
    Aug 24 09:57:55.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 8.013249722s
    Aug 24 09:57:57.949: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 10.020659552s
    Aug 24 09:57:59.943: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 12.014034575s
    Aug 24 09:58:01.944: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 14.015298554s
    Aug 24 09:58:03.943: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 16.014247139s
    Aug 24 09:58:05.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 18.012058416s
    Aug 24 09:58:07.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=true. Elapsed: 20.011804974s
    Aug 24 09:58:09.941: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Running", Reason="", readiness=false. Elapsed: 22.011926316s
    Aug 24 09:58:11.942: INFO: Pod "pod-subpath-test-configmap-ljf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013154601s
    STEP: Saw pod success 08/24/22 09:58:11.942
    Aug 24 09:58:11.942: INFO: Pod "pod-subpath-test-configmap-ljf2" satisfied condition "Succeeded or Failed"
    Aug 24 09:58:11.947: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-configmap-ljf2 container test-container-subpath-configmap-ljf2: <nil>
    STEP: delete the pod 08/24/22 09:58:11.959
    Aug 24 09:58:11.978: INFO: Waiting for pod pod-subpath-test-configmap-ljf2 to disappear
    Aug 24 09:58:11.989: INFO: Pod pod-subpath-test-configmap-ljf2 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-ljf2 08/24/22 09:58:11.989
    Aug 24 09:58:11.989: INFO: Deleting pod "pod-subpath-test-configmap-ljf2" in namespace "subpath-8930"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 24 09:58:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8930" for this suite. 08/24/22 09:58:12.003
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 09:58:12.018
Aug 24 09:58:12.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 09:58:12.021
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:58:12.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:58:12.058
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-3761295a-612d-4913-a027-be1bc25ade0b in namespace container-probe-3570 08/24/22 09:58:12.064
Aug 24 09:58:12.086: INFO: Waiting up to 5m0s for pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b" in namespace "container-probe-3570" to be "not pending"
Aug 24 09:58:12.096: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.933375ms
Aug 24 09:58:14.105: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.018415936s
Aug 24 09:58:14.105: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b" satisfied condition "not pending"
Aug 24 09:58:14.105: INFO: Started pod liveness-3761295a-612d-4913-a027-be1bc25ade0b in namespace container-probe-3570
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:58:14.105
Aug 24 09:58:14.112: INFO: Initial restart count of pod liveness-3761295a-612d-4913-a027-be1bc25ade0b is 0
STEP: deleting the pod 08/24/22 10:02:15.13
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 10:02:15.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3570" for this suite. 08/24/22 10:02:15.169
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":105,"skipped":1848,"failed":0}
------------------------------
• [SLOW TEST] [243.161 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 09:58:12.018
    Aug 24 09:58:12.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 09:58:12.021
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 09:58:12.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 09:58:12.058
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-3761295a-612d-4913-a027-be1bc25ade0b in namespace container-probe-3570 08/24/22 09:58:12.064
    Aug 24 09:58:12.086: INFO: Waiting up to 5m0s for pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b" in namespace "container-probe-3570" to be "not pending"
    Aug 24 09:58:12.096: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.933375ms
    Aug 24 09:58:14.105: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.018415936s
    Aug 24 09:58:14.105: INFO: Pod "liveness-3761295a-612d-4913-a027-be1bc25ade0b" satisfied condition "not pending"
    Aug 24 09:58:14.105: INFO: Started pod liveness-3761295a-612d-4913-a027-be1bc25ade0b in namespace container-probe-3570
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 09:58:14.105
    Aug 24 09:58:14.112: INFO: Initial restart count of pod liveness-3761295a-612d-4913-a027-be1bc25ade0b is 0
    STEP: deleting the pod 08/24/22 10:02:15.13
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 10:02:15.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3570" for this suite. 08/24/22 10:02:15.169
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:15.187
Aug 24 10:02:15.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:02:15.197
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:15.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:15.235
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:02:15.262
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:02:16.943
STEP: Deploying the webhook pod 08/24/22 10:02:16.957
STEP: Wait for the deployment to be ready 08/24/22 10:02:16.99
Aug 24 10:02:17.020: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/24/22 10:02:19.039
STEP: Verifying the service has paired with the endpoint 08/24/22 10:02:19.057
Aug 24 10:02:20.057: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 08/24/22 10:02:20.065
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/24/22 10:02:20.068
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/24/22 10:02:20.068
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/24/22 10:02:20.068
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/24/22 10:02:20.07
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/24/22 10:02:20.07
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/24/22 10:02:20.072
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:02:20.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6842" for this suite. 08/24/22 10:02:20.085
STEP: Destroying namespace "webhook-6842-markers" for this suite. 08/24/22 10:02:20.097
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":106,"skipped":1853,"failed":0}
------------------------------
• [SLOW TEST] [5.001 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:15.187
    Aug 24 10:02:15.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:02:15.197
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:15.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:15.235
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:02:15.262
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:02:16.943
    STEP: Deploying the webhook pod 08/24/22 10:02:16.957
    STEP: Wait for the deployment to be ready 08/24/22 10:02:16.99
    Aug 24 10:02:17.020: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/24/22 10:02:19.039
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:02:19.057
    Aug 24 10:02:20.057: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 08/24/22 10:02:20.065
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/24/22 10:02:20.068
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/24/22 10:02:20.068
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/24/22 10:02:20.068
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/24/22 10:02:20.07
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/24/22 10:02:20.07
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/24/22 10:02:20.072
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:02:20.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6842" for this suite. 08/24/22 10:02:20.085
    STEP: Destroying namespace "webhook-6842-markers" for this suite. 08/24/22 10:02:20.097
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:20.189
Aug 24 10:02:20.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 10:02:20.194
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:20.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:20.234
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 08/24/22 10:02:20.282
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:02:20.298
Aug 24 10:02:20.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:02:20.317: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:02:21.334: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:02:21.338: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:02:22.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 10:02:22.335: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 08/24/22 10:02:22.343
STEP: DeleteCollection of the DaemonSets 08/24/22 10:02:22.35
STEP: Verify that ReplicaSets have been deleted 08/24/22 10:02:22.398
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Aug 24 10:02:22.442: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16588"},"items":null}

Aug 24 10:02:22.460: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16589"},"items":[{"metadata":{"name":"daemon-set-2tttw","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"23cb97c5-589f-4141-81ac-d0678f08109e","resourceVersion":"16588","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.173\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-9fx29","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-9fx29","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.54","podIP":"10.233.66.173","podIPs":[{"ip":"10.233.66.173"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://3532fef640e27639d0b09fe0fa591cc5c63d8e45903b943b4ac78f118149aab8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-74v5x","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"bde5d359-efbc-4751-adaf-4c1c620b4d7f","resourceVersion":"16589","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vhztk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vhztk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.119","podIP":"10.233.64.86","podIPs":[{"ip":"10.233.64.86"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://6af88701e601a43ef7c9b241e1130702f05bb2634a6f35be94c603ae629d3143","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wlwww","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"b238ed52-a885-431f-8a58-2ded19f135b6","resourceVersion":"16587","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mwllz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mwllz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.214","podIP":"10.233.65.93","podIPs":[{"ip":"10.233.65.93"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://09e14236927c2e3f6461a76063f91cc129d947983e03973541aca5783b640206","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:02:22.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4037" for this suite. 08/24/22 10:02:22.497
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":107,"skipped":1859,"failed":0}
------------------------------
• [2.321 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:20.189
    Aug 24 10:02:20.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 10:02:20.194
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:20.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:20.234
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 08/24/22 10:02:20.282
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:02:20.298
    Aug 24 10:02:20.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:02:20.317: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:02:21.334: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:02:21.338: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:02:22.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 10:02:22.335: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 08/24/22 10:02:22.343
    STEP: DeleteCollection of the DaemonSets 08/24/22 10:02:22.35
    STEP: Verify that ReplicaSets have been deleted 08/24/22 10:02:22.398
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Aug 24 10:02:22.442: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16588"},"items":null}

    Aug 24 10:02:22.460: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16589"},"items":[{"metadata":{"name":"daemon-set-2tttw","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"23cb97c5-589f-4141-81ac-d0678f08109e","resourceVersion":"16588","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.173\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-9fx29","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-9fx29","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.54","podIP":"10.233.66.173","podIPs":[{"ip":"10.233.66.173"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://3532fef640e27639d0b09fe0fa591cc5c63d8e45903b943b4ac78f118149aab8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-74v5x","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"bde5d359-efbc-4751-adaf-4c1c620b4d7f","resourceVersion":"16589","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vhztk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vhztk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.119","podIP":"10.233.64.86","podIPs":[{"ip":"10.233.64.86"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://6af88701e601a43ef7c9b241e1130702f05bb2634a6f35be94c603ae629d3143","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wlwww","generateName":"daemon-set-","namespace":"daemonsets-4037","uid":"b238ed52-a885-431f-8a58-2ded19f135b6","resourceVersion":"16587","creationTimestamp":"2022-08-24T10:02:20Z","deletionTimestamp":"2022-08-24T10:02:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d1115adb-4edc-4449-956e-308434ffb6e9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1115adb-4edc-4449-956e-308434ffb6e9\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T10:02:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mwllz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mwllz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"kah9uighaagh-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["kah9uighaagh-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T10:02:20Z"}],"hostIP":"192.168.121.214","podIP":"10.233.65.93","podIPs":[{"ip":"10.233.65.93"}],"startTime":"2022-08-24T10:02:20Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T10:02:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://09e14236927c2e3f6461a76063f91cc129d947983e03973541aca5783b640206","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:02:22.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4037" for this suite. 08/24/22 10:02:22.497
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:22.517
Aug 24 10:02:22.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption 08/24/22 10:02:22.519
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:22.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:22.564
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 08/24/22 10:02:22.579
STEP: Updating PodDisruptionBudget status 08/24/22 10:02:24.6
STEP: Waiting for all pods to be running 08/24/22 10:02:24.63
Aug 24 10:02:24.658: INFO: running pods: 0 < 1
STEP: locating a running pod 08/24/22 10:02:26.675
STEP: Waiting for the pdb to be processed 08/24/22 10:02:26.697
STEP: Patching PodDisruptionBudget status 08/24/22 10:02:26.728
STEP: Waiting for the pdb to be processed 08/24/22 10:02:26.766
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 24 10:02:26.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-44" for this suite. 08/24/22 10:02:26.787
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":108,"skipped":1885,"failed":0}
------------------------------
• [4.287 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:22.517
    Aug 24 10:02:22.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption 08/24/22 10:02:22.519
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:22.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:22.564
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 08/24/22 10:02:22.579
    STEP: Updating PodDisruptionBudget status 08/24/22 10:02:24.6
    STEP: Waiting for all pods to be running 08/24/22 10:02:24.63
    Aug 24 10:02:24.658: INFO: running pods: 0 < 1
    STEP: locating a running pod 08/24/22 10:02:26.675
    STEP: Waiting for the pdb to be processed 08/24/22 10:02:26.697
    STEP: Patching PodDisruptionBudget status 08/24/22 10:02:26.728
    STEP: Waiting for the pdb to be processed 08/24/22 10:02:26.766
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 24 10:02:26.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-44" for this suite. 08/24/22 10:02:26.787
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:26.809
Aug 24 10:02:26.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:02:26.813
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:26.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:26.85
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Aug 24 10:02:26.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: creating the pod 08/24/22 10:02:26.856
STEP: submitting the pod to kubernetes 08/24/22 10:02:26.856
Aug 24 10:02:26.869: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1" in namespace "pods-7591" to be "running and ready"
Aug 24 10:02:26.874: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.474248ms
Aug 24 10:02:26.875: INFO: The phase of Pod pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:02:28.882: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01345913s
Aug 24 10:02:28.884: INFO: The phase of Pod pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1 is Running (Ready = true)
Aug 24 10:02:28.884: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:02:29.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7591" for this suite. 08/24/22 10:02:29.154
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":109,"skipped":1892,"failed":0}
------------------------------
• [2.361 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:26.809
    Aug 24 10:02:26.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:02:26.813
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:26.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:26.85
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Aug 24 10:02:26.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: creating the pod 08/24/22 10:02:26.856
    STEP: submitting the pod to kubernetes 08/24/22 10:02:26.856
    Aug 24 10:02:26.869: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1" in namespace "pods-7591" to be "running and ready"
    Aug 24 10:02:26.874: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.474248ms
    Aug 24 10:02:26.875: INFO: The phase of Pod pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:02:28.882: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01345913s
    Aug 24 10:02:28.884: INFO: The phase of Pod pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1 is Running (Ready = true)
    Aug 24 10:02:28.884: INFO: Pod "pod-exec-websocket-b637ad41-411e-4903-bcc4-03c1e96617b1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:02:29.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7591" for this suite. 08/24/22 10:02:29.154
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:29.171
Aug 24 10:02:29.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename events 08/24/22 10:02:29.174
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:29.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:29.206
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 08/24/22 10:02:29.21
STEP: listing events in all namespaces 08/24/22 10:02:29.227
STEP: listing events in test namespace 08/24/22 10:02:29.245
STEP: listing events with field selection filtering on source 08/24/22 10:02:29.25
STEP: listing events with field selection filtering on reportingController 08/24/22 10:02:29.257
STEP: getting the test event 08/24/22 10:02:29.261
STEP: patching the test event 08/24/22 10:02:29.265
STEP: getting the test event 08/24/22 10:02:29.28
STEP: updating the test event 08/24/22 10:02:29.285
STEP: getting the test event 08/24/22 10:02:29.293
STEP: deleting the test event 08/24/22 10:02:29.297
STEP: listing events in all namespaces 08/24/22 10:02:29.306
STEP: listing events in test namespace 08/24/22 10:02:29.322
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 24 10:02:29.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4360" for this suite. 08/24/22 10:02:29.335
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":110,"skipped":1903,"failed":0}
------------------------------
• [0.172 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:29.171
    Aug 24 10:02:29.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename events 08/24/22 10:02:29.174
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:29.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:29.206
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 08/24/22 10:02:29.21
    STEP: listing events in all namespaces 08/24/22 10:02:29.227
    STEP: listing events in test namespace 08/24/22 10:02:29.245
    STEP: listing events with field selection filtering on source 08/24/22 10:02:29.25
    STEP: listing events with field selection filtering on reportingController 08/24/22 10:02:29.257
    STEP: getting the test event 08/24/22 10:02:29.261
    STEP: patching the test event 08/24/22 10:02:29.265
    STEP: getting the test event 08/24/22 10:02:29.28
    STEP: updating the test event 08/24/22 10:02:29.285
    STEP: getting the test event 08/24/22 10:02:29.293
    STEP: deleting the test event 08/24/22 10:02:29.297
    STEP: listing events in all namespaces 08/24/22 10:02:29.306
    STEP: listing events in test namespace 08/24/22 10:02:29.322
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 24 10:02:29.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4360" for this suite. 08/24/22 10:02:29.335
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:29.351
Aug 24 10:02:29.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:02:29.352
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:29.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:29.4
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 08/24/22 10:02:29.413
Aug 24 10:02:29.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 create -f -'
Aug 24 10:02:30.044: INFO: stderr: ""
Aug 24 10:02:30.044: INFO: stdout: "pod/pause created\n"
Aug 24 10:02:30.044: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 24 10:02:30.045: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5503" to be "running and ready"
Aug 24 10:02:30.062: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.383807ms
Aug 24 10:02:30.062: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'kah9uighaagh-3' to be 'Running' but was 'Pending'
Aug 24 10:02:32.069: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.024108829s
Aug 24 10:02:32.069: INFO: Pod "pause" satisfied condition "running and ready"
Aug 24 10:02:32.069: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 08/24/22 10:02:32.069
Aug 24 10:02:32.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 label pods pause testing-label=testing-label-value'
Aug 24 10:02:32.244: INFO: stderr: ""
Aug 24 10:02:32.244: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 08/24/22 10:02:32.244
Aug 24 10:02:32.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pod pause -L testing-label'
Aug 24 10:02:32.427: INFO: stderr: ""
Aug 24 10:02:32.427: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 08/24/22 10:02:32.427
Aug 24 10:02:32.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 label pods pause testing-label-'
Aug 24 10:02:32.587: INFO: stderr: ""
Aug 24 10:02:32.587: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 08/24/22 10:02:32.587
Aug 24 10:02:32.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pod pause -L testing-label'
Aug 24 10:02:32.741: INFO: stderr: ""
Aug 24 10:02:32.741: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 08/24/22 10:02:32.741
Aug 24 10:02:32.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 delete --grace-period=0 --force -f -'
Aug 24 10:02:32.874: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:02:32.874: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 24 10:02:32.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get rc,svc -l name=pause --no-headers'
Aug 24 10:02:33.049: INFO: stderr: "No resources found in kubectl-5503 namespace.\n"
Aug 24 10:02:33.049: INFO: stdout: ""
Aug 24 10:02:33.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 10:02:33.221: INFO: stderr: ""
Aug 24 10:02:33.221: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:02:33.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5503" for this suite. 08/24/22 10:02:33.232
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":111,"skipped":1932,"failed":0}
------------------------------
• [3.894 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:29.351
    Aug 24 10:02:29.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:02:29.352
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:29.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:29.4
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 08/24/22 10:02:29.413
    Aug 24 10:02:29.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 create -f -'
    Aug 24 10:02:30.044: INFO: stderr: ""
    Aug 24 10:02:30.044: INFO: stdout: "pod/pause created\n"
    Aug 24 10:02:30.044: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Aug 24 10:02:30.045: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5503" to be "running and ready"
    Aug 24 10:02:30.062: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.383807ms
    Aug 24 10:02:30.062: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'kah9uighaagh-3' to be 'Running' but was 'Pending'
    Aug 24 10:02:32.069: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.024108829s
    Aug 24 10:02:32.069: INFO: Pod "pause" satisfied condition "running and ready"
    Aug 24 10:02:32.069: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 08/24/22 10:02:32.069
    Aug 24 10:02:32.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 label pods pause testing-label=testing-label-value'
    Aug 24 10:02:32.244: INFO: stderr: ""
    Aug 24 10:02:32.244: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 08/24/22 10:02:32.244
    Aug 24 10:02:32.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pod pause -L testing-label'
    Aug 24 10:02:32.427: INFO: stderr: ""
    Aug 24 10:02:32.427: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 08/24/22 10:02:32.427
    Aug 24 10:02:32.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 label pods pause testing-label-'
    Aug 24 10:02:32.587: INFO: stderr: ""
    Aug 24 10:02:32.587: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 08/24/22 10:02:32.587
    Aug 24 10:02:32.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pod pause -L testing-label'
    Aug 24 10:02:32.741: INFO: stderr: ""
    Aug 24 10:02:32.741: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 08/24/22 10:02:32.741
    Aug 24 10:02:32.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 delete --grace-period=0 --force -f -'
    Aug 24 10:02:32.874: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:02:32.874: INFO: stdout: "pod \"pause\" force deleted\n"
    Aug 24 10:02:32.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get rc,svc -l name=pause --no-headers'
    Aug 24 10:02:33.049: INFO: stderr: "No resources found in kubectl-5503 namespace.\n"
    Aug 24 10:02:33.049: INFO: stdout: ""
    Aug 24 10:02:33.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5503 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 24 10:02:33.221: INFO: stderr: ""
    Aug 24 10:02:33.221: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:02:33.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5503" for this suite. 08/24/22 10:02:33.232
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:33.247
Aug 24 10:02:33.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:02:33.25
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:33.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:33.289
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 08/24/22 10:02:33.294
Aug 24 10:02:33.309: INFO: Waiting up to 5m0s for pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e" in namespace "var-expansion-3575" to be "Succeeded or Failed"
Aug 24 10:02:33.315: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.432932ms
Aug 24 10:02:35.322: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013180679s
Aug 24 10:02:37.322: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013152839s
STEP: Saw pod success 08/24/22 10:02:37.323
Aug 24 10:02:37.323: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e" satisfied condition "Succeeded or Failed"
Aug 24 10:02:37.331: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:02:37.363
Aug 24 10:02:37.418: INFO: Waiting for pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e to disappear
Aug 24 10:02:37.434: INFO: Pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:02:37.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3575" for this suite. 08/24/22 10:02:37.443
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":112,"skipped":1978,"failed":0}
------------------------------
• [4.217 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:33.247
    Aug 24 10:02:33.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:02:33.25
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:33.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:33.289
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 08/24/22 10:02:33.294
    Aug 24 10:02:33.309: INFO: Waiting up to 5m0s for pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e" in namespace "var-expansion-3575" to be "Succeeded or Failed"
    Aug 24 10:02:33.315: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.432932ms
    Aug 24 10:02:35.322: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013180679s
    Aug 24 10:02:37.322: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013152839s
    STEP: Saw pod success 08/24/22 10:02:37.323
    Aug 24 10:02:37.323: INFO: Pod "var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e" satisfied condition "Succeeded or Failed"
    Aug 24 10:02:37.331: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:02:37.363
    Aug 24 10:02:37.418: INFO: Waiting for pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e to disappear
    Aug 24 10:02:37.434: INFO: Pod var-expansion-7d964baa-b0e9-4639-8077-9d8d5152018e no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:02:37.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3575" for this suite. 08/24/22 10:02:37.443
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:37.469
Aug 24 10:02:37.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:02:37.471
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:37.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:37.514
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Aug 24 10:02:37.543: INFO: Waiting up to 5m0s for pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503" in namespace "svcaccounts-8275" to be "running"
Aug 24 10:02:37.548: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394582ms
Aug 24 10:02:39.554: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503": Phase="Running", Reason="", readiness=true. Elapsed: 2.011261301s
Aug 24 10:02:39.554: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503" satisfied condition "running"
STEP: reading a file in the container 08/24/22 10:02:39.554
Aug 24 10:02:39.555: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 08/24/22 10:02:39.795
Aug 24 10:02:39.796: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 08/24/22 10:02:40.034
Aug 24 10:02:40.034: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Aug 24 10:02:40.246: INFO: Got root ca configmap in namespace "svcaccounts-8275"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 10:02:40.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8275" for this suite. 08/24/22 10:02:40.254
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":113,"skipped":1989,"failed":0}
------------------------------
• [2.797 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:37.469
    Aug 24 10:02:37.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:02:37.471
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:37.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:37.514
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Aug 24 10:02:37.543: INFO: Waiting up to 5m0s for pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503" in namespace "svcaccounts-8275" to be "running"
    Aug 24 10:02:37.548: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394582ms
    Aug 24 10:02:39.554: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503": Phase="Running", Reason="", readiness=true. Elapsed: 2.011261301s
    Aug 24 10:02:39.554: INFO: Pod "pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503" satisfied condition "running"
    STEP: reading a file in the container 08/24/22 10:02:39.554
    Aug 24 10:02:39.555: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 08/24/22 10:02:39.795
    Aug 24 10:02:39.796: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 08/24/22 10:02:40.034
    Aug 24 10:02:40.034: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8275 pod-service-account-4c6c68bf-da5d-49fd-9233-803eb7c17503 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Aug 24 10:02:40.246: INFO: Got root ca configmap in namespace "svcaccounts-8275"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 10:02:40.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8275" for this suite. 08/24/22 10:02:40.254
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:02:40.268
Aug 24 10:02:40.268: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:02:40.27
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:40.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:40.301
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/24/22 10:02:40.305
Aug 24 10:02:40.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/24/22 10:02:57.365
Aug 24 10:02:57.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:03:02.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:03:18.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2877" for this suite. 08/24/22 10:03:18.396
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":114,"skipped":1992,"failed":0}
------------------------------
• [SLOW TEST] [38.144 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:02:40.268
    Aug 24 10:02:40.268: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:02:40.27
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:02:40.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:02:40.301
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/24/22 10:02:40.305
    Aug 24 10:02:40.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/24/22 10:02:57.365
    Aug 24 10:02:57.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:03:02.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:03:18.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2877" for this suite. 08/24/22 10:03:18.396
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:03:18.413
Aug 24 10:03:18.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:03:18.415
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:03:18.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:03:18.462
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-f658000d-c2da-48c7-abba-2b99f8a7e52f 08/24/22 10:03:18.477
STEP: Creating secret with name s-test-opt-upd-ac6f08bf-94d1-47b9-8af9-a75b836054c6 08/24/22 10:03:18.489
STEP: Creating the pod 08/24/22 10:03:18.499
Aug 24 10:03:18.522: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae" in namespace "projected-8242" to be "running and ready"
Aug 24 10:03:18.535: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Pending", Reason="", readiness=false. Elapsed: 12.982937ms
Aug 24 10:03:18.536: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:03:20.549: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026638115s
Aug 24 10:03:20.549: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:03:22.555: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Running", Reason="", readiness=true. Elapsed: 4.032907621s
Aug 24 10:03:22.555: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Running (Ready = true)
Aug 24 10:03:22.555: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-f658000d-c2da-48c7-abba-2b99f8a7e52f 08/24/22 10:03:22.624
STEP: Updating secret s-test-opt-upd-ac6f08bf-94d1-47b9-8af9-a75b836054c6 08/24/22 10:03:22.643
STEP: Creating secret with name s-test-opt-create-543ad9da-7c3d-437f-ba3b-85b8be0525b1 08/24/22 10:03:22.658
STEP: waiting to observe update in volume 08/24/22 10:03:22.668
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:04:49.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8242" for this suite. 08/24/22 10:04:49.675
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":115,"skipped":1994,"failed":0}
------------------------------
• [SLOW TEST] [91.274 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:03:18.413
    Aug 24 10:03:18.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:03:18.415
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:03:18.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:03:18.462
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-f658000d-c2da-48c7-abba-2b99f8a7e52f 08/24/22 10:03:18.477
    STEP: Creating secret with name s-test-opt-upd-ac6f08bf-94d1-47b9-8af9-a75b836054c6 08/24/22 10:03:18.489
    STEP: Creating the pod 08/24/22 10:03:18.499
    Aug 24 10:03:18.522: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae" in namespace "projected-8242" to be "running and ready"
    Aug 24 10:03:18.535: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Pending", Reason="", readiness=false. Elapsed: 12.982937ms
    Aug 24 10:03:18.536: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:03:20.549: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026638115s
    Aug 24 10:03:20.549: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:03:22.555: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae": Phase="Running", Reason="", readiness=true. Elapsed: 4.032907621s
    Aug 24 10:03:22.555: INFO: The phase of Pod pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae is Running (Ready = true)
    Aug 24 10:03:22.555: INFO: Pod "pod-projected-secrets-dc626ed7-cec4-4bc0-8530-01a91679cbae" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-f658000d-c2da-48c7-abba-2b99f8a7e52f 08/24/22 10:03:22.624
    STEP: Updating secret s-test-opt-upd-ac6f08bf-94d1-47b9-8af9-a75b836054c6 08/24/22 10:03:22.643
    STEP: Creating secret with name s-test-opt-create-543ad9da-7c3d-437f-ba3b-85b8be0525b1 08/24/22 10:03:22.658
    STEP: waiting to observe update in volume 08/24/22 10:03:22.668
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:04:49.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8242" for this suite. 08/24/22 10:04:49.675
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:04:49.689
Aug 24 10:04:49.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:04:49.692
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:49.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:49.74
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 08/24/22 10:04:49.747
Aug 24 10:04:49.763: INFO: Waiting up to 5m0s for pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300" in namespace "var-expansion-8379" to be "Succeeded or Failed"
Aug 24 10:04:49.769: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063957ms
Aug 24 10:04:51.781: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018094338s
Aug 24 10:04:53.777: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013658954s
STEP: Saw pod success 08/24/22 10:04:53.777
Aug 24 10:04:53.778: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300" satisfied condition "Succeeded or Failed"
Aug 24 10:04:53.785: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:04:53.795
Aug 24 10:04:53.815: INFO: Waiting for pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 to disappear
Aug 24 10:04:53.821: INFO: Pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:04:53.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8379" for this suite. 08/24/22 10:04:53.827
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":116,"skipped":1994,"failed":0}
------------------------------
• [4.148 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:04:49.689
    Aug 24 10:04:49.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:04:49.692
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:49.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:49.74
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 08/24/22 10:04:49.747
    Aug 24 10:04:49.763: INFO: Waiting up to 5m0s for pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300" in namespace "var-expansion-8379" to be "Succeeded or Failed"
    Aug 24 10:04:49.769: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063957ms
    Aug 24 10:04:51.781: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018094338s
    Aug 24 10:04:53.777: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013658954s
    STEP: Saw pod success 08/24/22 10:04:53.777
    Aug 24 10:04:53.778: INFO: Pod "var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300" satisfied condition "Succeeded or Failed"
    Aug 24 10:04:53.785: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:04:53.795
    Aug 24 10:04:53.815: INFO: Waiting for pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 to disappear
    Aug 24 10:04:53.821: INFO: Pod var-expansion-f0c70114-64b9-4c3b-8aca-cc937118c300 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:04:53.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8379" for this suite. 08/24/22 10:04:53.827
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:04:53.841
Aug 24 10:04:53.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:04:53.842
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:53.865
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:53.868
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 08/24/22 10:04:53.872
Aug 24 10:04:53.885: INFO: created test-pod-1
Aug 24 10:04:53.904: INFO: created test-pod-2
Aug 24 10:04:53.927: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 08/24/22 10:04:53.927
Aug 24 10:04:53.927: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7200' to be running and ready
Aug 24 10:04:53.968: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 10:04:53.968: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 10:04:53.968: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 10:04:53.968: INFO: 0 / 3 pods in namespace 'pods-7200' are running and ready (0 seconds elapsed)
Aug 24 10:04:53.968: INFO: expected 0 pod replicas in namespace 'pods-7200', 0 are Running and Ready.
Aug 24 10:04:53.968: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Aug 24 10:04:53.968: INFO: test-pod-1  kah9uighaagh-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
Aug 24 10:04:53.968: INFO: test-pod-2  kah9uighaagh-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
Aug 24 10:04:53.968: INFO: test-pod-3  kah9uighaagh-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
Aug 24 10:04:53.968: INFO: 
Aug 24 10:04:55.985: INFO: 3 / 3 pods in namespace 'pods-7200' are running and ready (2 seconds elapsed)
Aug 24 10:04:55.986: INFO: expected 0 pod replicas in namespace 'pods-7200', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 08/24/22 10:04:56.022
Aug 24 10:04:56.029: INFO: Pod quantity 3 is different from expected quantity 0
Aug 24 10:04:57.036: INFO: Pod quantity 3 is different from expected quantity 0
Aug 24 10:04:58.038: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:04:59.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7200" for this suite. 08/24/22 10:04:59.049
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":117,"skipped":2010,"failed":0}
------------------------------
• [SLOW TEST] [5.222 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:04:53.841
    Aug 24 10:04:53.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:04:53.842
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:53.865
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:53.868
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 08/24/22 10:04:53.872
    Aug 24 10:04:53.885: INFO: created test-pod-1
    Aug 24 10:04:53.904: INFO: created test-pod-2
    Aug 24 10:04:53.927: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 08/24/22 10:04:53.927
    Aug 24 10:04:53.927: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7200' to be running and ready
    Aug 24 10:04:53.968: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 24 10:04:53.968: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 24 10:04:53.968: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 24 10:04:53.968: INFO: 0 / 3 pods in namespace 'pods-7200' are running and ready (0 seconds elapsed)
    Aug 24 10:04:53.968: INFO: expected 0 pod replicas in namespace 'pods-7200', 0 are Running and Ready.
    Aug 24 10:04:53.968: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
    Aug 24 10:04:53.968: INFO: test-pod-1  kah9uighaagh-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
    Aug 24 10:04:53.968: INFO: test-pod-2  kah9uighaagh-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
    Aug 24 10:04:53.968: INFO: test-pod-3  kah9uighaagh-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:04:53 +0000 UTC  }]
    Aug 24 10:04:53.968: INFO: 
    Aug 24 10:04:55.985: INFO: 3 / 3 pods in namespace 'pods-7200' are running and ready (2 seconds elapsed)
    Aug 24 10:04:55.986: INFO: expected 0 pod replicas in namespace 'pods-7200', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 08/24/22 10:04:56.022
    Aug 24 10:04:56.029: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 24 10:04:57.036: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 24 10:04:58.038: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:04:59.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7200" for this suite. 08/24/22 10:04:59.049
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:04:59.078
Aug 24 10:04:59.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:04:59.081
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:59.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:59.123
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 08/24/22 10:04:59.149
Aug 24 10:04:59.149: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad" in namespace "kubelet-test-9630" to be "completed"
Aug 24 10:04:59.162: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Pending", Reason="", readiness=false. Elapsed: 12.968565ms
Aug 24 10:05:01.177: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02749835s
Aug 24 10:05:03.171: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02111243s
Aug 24 10:05:03.171: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 24 10:05:03.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9630" for this suite. 08/24/22 10:05:03.19
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":118,"skipped":2127,"failed":0}
------------------------------
• [4.129 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:04:59.078
    Aug 24 10:04:59.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:04:59.081
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:04:59.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:04:59.123
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 08/24/22 10:04:59.149
    Aug 24 10:04:59.149: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad" in namespace "kubelet-test-9630" to be "completed"
    Aug 24 10:04:59.162: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Pending", Reason="", readiness=false. Elapsed: 12.968565ms
    Aug 24 10:05:01.177: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02749835s
    Aug 24 10:05:03.171: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02111243s
    Aug 24 10:05:03.171: INFO: Pod "agnhost-host-aliases2b794cf0-e008-4f97-a135-b9fd5070c2ad" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 24 10:05:03.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9630" for this suite. 08/24/22 10:05:03.19
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:03.213
Aug 24 10:05:03.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename subpath 08/24/22 10:05:03.216
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:03.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:03.243
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/24/22 10:05:03.248
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-rp9c 08/24/22 10:05:03.264
STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:05:03.264
Aug 24 10:05:03.277: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rp9c" in namespace "subpath-6318" to be "Succeeded or Failed"
Aug 24 10:05:03.283: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.557728ms
Aug 24 10:05:05.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011478824s
Aug 24 10:05:07.294: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 4.016123613s
Aug 24 10:05:09.291: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 6.01326865s
Aug 24 10:05:11.292: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 8.014440936s
Aug 24 10:05:13.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 10.012919906s
Aug 24 10:05:15.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 12.011336375s
Aug 24 10:05:17.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 14.0118515s
Aug 24 10:05:19.291: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 16.013836616s
Aug 24 10:05:21.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 18.012955724s
Aug 24 10:05:23.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 20.0125752s
Aug 24 10:05:25.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=false. Elapsed: 22.011489754s
Aug 24 10:05:27.295: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017623467s
STEP: Saw pod success 08/24/22 10:05:27.295
Aug 24 10:05:27.296: INFO: Pod "pod-subpath-test-secret-rp9c" satisfied condition "Succeeded or Failed"
Aug 24 10:05:27.303: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-secret-rp9c container test-container-subpath-secret-rp9c: <nil>
STEP: delete the pod 08/24/22 10:05:27.323
Aug 24 10:05:27.350: INFO: Waiting for pod pod-subpath-test-secret-rp9c to disappear
Aug 24 10:05:27.356: INFO: Pod pod-subpath-test-secret-rp9c no longer exists
STEP: Deleting pod pod-subpath-test-secret-rp9c 08/24/22 10:05:27.357
Aug 24 10:05:27.357: INFO: Deleting pod "pod-subpath-test-secret-rp9c" in namespace "subpath-6318"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 24 10:05:27.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6318" for this suite. 08/24/22 10:05:27.388
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":119,"skipped":2169,"failed":0}
------------------------------
• [SLOW TEST] [24.196 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:03.213
    Aug 24 10:05:03.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename subpath 08/24/22 10:05:03.216
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:03.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:03.243
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/24/22 10:05:03.248
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-rp9c 08/24/22 10:05:03.264
    STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:05:03.264
    Aug 24 10:05:03.277: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rp9c" in namespace "subpath-6318" to be "Succeeded or Failed"
    Aug 24 10:05:03.283: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.557728ms
    Aug 24 10:05:05.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011478824s
    Aug 24 10:05:07.294: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 4.016123613s
    Aug 24 10:05:09.291: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 6.01326865s
    Aug 24 10:05:11.292: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 8.014440936s
    Aug 24 10:05:13.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 10.012919906s
    Aug 24 10:05:15.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 12.011336375s
    Aug 24 10:05:17.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 14.0118515s
    Aug 24 10:05:19.291: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 16.013836616s
    Aug 24 10:05:21.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 18.012955724s
    Aug 24 10:05:23.290: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=true. Elapsed: 20.0125752s
    Aug 24 10:05:25.289: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Running", Reason="", readiness=false. Elapsed: 22.011489754s
    Aug 24 10:05:27.295: INFO: Pod "pod-subpath-test-secret-rp9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017623467s
    STEP: Saw pod success 08/24/22 10:05:27.295
    Aug 24 10:05:27.296: INFO: Pod "pod-subpath-test-secret-rp9c" satisfied condition "Succeeded or Failed"
    Aug 24 10:05:27.303: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-secret-rp9c container test-container-subpath-secret-rp9c: <nil>
    STEP: delete the pod 08/24/22 10:05:27.323
    Aug 24 10:05:27.350: INFO: Waiting for pod pod-subpath-test-secret-rp9c to disappear
    Aug 24 10:05:27.356: INFO: Pod pod-subpath-test-secret-rp9c no longer exists
    STEP: Deleting pod pod-subpath-test-secret-rp9c 08/24/22 10:05:27.357
    Aug 24 10:05:27.357: INFO: Deleting pod "pod-subpath-test-secret-rp9c" in namespace "subpath-6318"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 24 10:05:27.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6318" for this suite. 08/24/22 10:05:27.388
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:27.416
Aug 24 10:05:27.416: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename cronjob 08/24/22 10:05:27.419
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:27.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:27.483
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 08/24/22 10:05:27.487
STEP: creating 08/24/22 10:05:27.487
STEP: getting 08/24/22 10:05:27.499
STEP: listing 08/24/22 10:05:27.505
STEP: watching 08/24/22 10:05:27.511
Aug 24 10:05:27.512: INFO: starting watch
STEP: cluster-wide listing 08/24/22 10:05:27.513
STEP: cluster-wide watching 08/24/22 10:05:27.53
Aug 24 10:05:27.530: INFO: starting watch
STEP: patching 08/24/22 10:05:27.533
STEP: updating 08/24/22 10:05:27.547
Aug 24 10:05:27.566: INFO: waiting for watch events with expected annotations
Aug 24 10:05:27.566: INFO: saw patched and updated annotations
STEP: patching /status 08/24/22 10:05:27.567
STEP: updating /status 08/24/22 10:05:27.58
STEP: get /status 08/24/22 10:05:27.605
STEP: deleting 08/24/22 10:05:27.615
STEP: deleting a collection 08/24/22 10:05:27.656
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 24 10:05:27.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9496" for this suite. 08/24/22 10:05:27.701
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":120,"skipped":2176,"failed":0}
------------------------------
• [0.302 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:27.416
    Aug 24 10:05:27.416: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename cronjob 08/24/22 10:05:27.419
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:27.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:27.483
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 08/24/22 10:05:27.487
    STEP: creating 08/24/22 10:05:27.487
    STEP: getting 08/24/22 10:05:27.499
    STEP: listing 08/24/22 10:05:27.505
    STEP: watching 08/24/22 10:05:27.511
    Aug 24 10:05:27.512: INFO: starting watch
    STEP: cluster-wide listing 08/24/22 10:05:27.513
    STEP: cluster-wide watching 08/24/22 10:05:27.53
    Aug 24 10:05:27.530: INFO: starting watch
    STEP: patching 08/24/22 10:05:27.533
    STEP: updating 08/24/22 10:05:27.547
    Aug 24 10:05:27.566: INFO: waiting for watch events with expected annotations
    Aug 24 10:05:27.566: INFO: saw patched and updated annotations
    STEP: patching /status 08/24/22 10:05:27.567
    STEP: updating /status 08/24/22 10:05:27.58
    STEP: get /status 08/24/22 10:05:27.605
    STEP: deleting 08/24/22 10:05:27.615
    STEP: deleting a collection 08/24/22 10:05:27.656
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 24 10:05:27.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9496" for this suite. 08/24/22 10:05:27.701
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:27.718
Aug 24 10:05:27.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:05:27.72
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:27.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:27.794
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:05:27.828
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:05:28.996
STEP: Deploying the webhook pod 08/24/22 10:05:29.009
STEP: Wait for the deployment to be ready 08/24/22 10:05:29.031
Aug 24 10:05:29.045: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:05:31.062
STEP: Verifying the service has paired with the endpoint 08/24/22 10:05:31.078
Aug 24 10:05:32.078: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/24/22 10:05:32.089
STEP: create a pod that should be updated by the webhook 08/24/22 10:05:32.12
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:05:32.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7861" for this suite. 08/24/22 10:05:32.169
STEP: Destroying namespace "webhook-7861-markers" for this suite. 08/24/22 10:05:32.188
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":121,"skipped":2176,"failed":0}
------------------------------
• [4.576 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:27.718
    Aug 24 10:05:27.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:05:27.72
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:27.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:27.794
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:05:27.828
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:05:28.996
    STEP: Deploying the webhook pod 08/24/22 10:05:29.009
    STEP: Wait for the deployment to be ready 08/24/22 10:05:29.031
    Aug 24 10:05:29.045: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:05:31.062
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:05:31.078
    Aug 24 10:05:32.078: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/24/22 10:05:32.089
    STEP: create a pod that should be updated by the webhook 08/24/22 10:05:32.12
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:05:32.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7861" for this suite. 08/24/22 10:05:32.169
    STEP: Destroying namespace "webhook-7861-markers" for this suite. 08/24/22 10:05:32.188
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:32.302
Aug 24 10:05:32.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:05:32.305
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:32.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:32.344
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-ac0a6653-d2d0-4b52-a6f1-a247e6dd8542 08/24/22 10:05:32.347
STEP: Creating a pod to test consume secrets 08/24/22 10:05:32.374
Aug 24 10:05:32.391: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b" in namespace "projected-9104" to be "Succeeded or Failed"
Aug 24 10:05:32.400: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.931642ms
Aug 24 10:05:34.406: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015462764s
Aug 24 10:05:36.407: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015811577s
STEP: Saw pod success 08/24/22 10:05:36.407
Aug 24 10:05:36.408: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b" satisfied condition "Succeeded or Failed"
Aug 24 10:05:36.414: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:05:36.428
Aug 24 10:05:36.452: INFO: Waiting for pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b to disappear
Aug 24 10:05:36.457: INFO: Pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:05:36.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9104" for this suite. 08/24/22 10:05:36.465
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":122,"skipped":2197,"failed":0}
------------------------------
• [4.173 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:32.302
    Aug 24 10:05:32.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:05:32.305
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:32.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:32.344
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-ac0a6653-d2d0-4b52-a6f1-a247e6dd8542 08/24/22 10:05:32.347
    STEP: Creating a pod to test consume secrets 08/24/22 10:05:32.374
    Aug 24 10:05:32.391: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b" in namespace "projected-9104" to be "Succeeded or Failed"
    Aug 24 10:05:32.400: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.931642ms
    Aug 24 10:05:34.406: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015462764s
    Aug 24 10:05:36.407: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015811577s
    STEP: Saw pod success 08/24/22 10:05:36.407
    Aug 24 10:05:36.408: INFO: Pod "pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b" satisfied condition "Succeeded or Failed"
    Aug 24 10:05:36.414: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:05:36.428
    Aug 24 10:05:36.452: INFO: Waiting for pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b to disappear
    Aug 24 10:05:36.457: INFO: Pod pod-projected-secrets-615131f5-2c50-4e17-8480-c2fb9b74b31b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:05:36.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9104" for this suite. 08/24/22 10:05:36.465
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:36.482
Aug 24 10:05:36.483: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:05:36.485
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:36.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:36.512
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:05:36.565
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:05:37.791
STEP: Deploying the webhook pod 08/24/22 10:05:37.801
STEP: Wait for the deployment to be ready 08/24/22 10:05:37.822
Aug 24 10:05:37.836: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:05:39.856
STEP: Verifying the service has paired with the endpoint 08/24/22 10:05:39.873
Aug 24 10:05:40.874: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/24/22 10:05:40.88
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/24/22 10:05:40.922
STEP: Creating a dummy validating-webhook-configuration object 08/24/22 10:05:40.95
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/24/22 10:05:40.965
STEP: Creating a dummy mutating-webhook-configuration object 08/24/22 10:05:40.975
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/24/22 10:05:40.986
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:05:41.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8568" for this suite. 08/24/22 10:05:41.021
STEP: Destroying namespace "webhook-8568-markers" for this suite. 08/24/22 10:05:41.034
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":123,"skipped":2207,"failed":0}
------------------------------
• [4.654 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:36.482
    Aug 24 10:05:36.483: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:05:36.485
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:36.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:36.512
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:05:36.565
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:05:37.791
    STEP: Deploying the webhook pod 08/24/22 10:05:37.801
    STEP: Wait for the deployment to be ready 08/24/22 10:05:37.822
    Aug 24 10:05:37.836: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:05:39.856
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:05:39.873
    Aug 24 10:05:40.874: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/24/22 10:05:40.88
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/24/22 10:05:40.922
    STEP: Creating a dummy validating-webhook-configuration object 08/24/22 10:05:40.95
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/24/22 10:05:40.965
    STEP: Creating a dummy mutating-webhook-configuration object 08/24/22 10:05:40.975
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/24/22 10:05:40.986
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:05:41.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8568" for this suite. 08/24/22 10:05:41.021
    STEP: Destroying namespace "webhook-8568-markers" for this suite. 08/24/22 10:05:41.034
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:41.153
Aug 24 10:05:41.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:05:41.159
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:41.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:41.191
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-96101a6b-80e6-4ff0-b7a3-381be854ff47 08/24/22 10:05:41.195
STEP: Creating a pod to test consume secrets 08/24/22 10:05:41.203
Aug 24 10:05:41.216: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539" in namespace "projected-6962" to be "Succeeded or Failed"
Aug 24 10:05:41.228: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Pending", Reason="", readiness=false. Elapsed: 12.200608ms
Aug 24 10:05:43.236: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019324477s
Aug 24 10:05:45.239: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022675039s
STEP: Saw pod success 08/24/22 10:05:45.239
Aug 24 10:05:45.239: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539" satisfied condition "Succeeded or Failed"
Aug 24 10:05:45.245: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:05:45.256
Aug 24 10:05:45.274: INFO: Waiting for pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 to disappear
Aug 24 10:05:45.280: INFO: Pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:05:45.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6962" for this suite. 08/24/22 10:05:45.288
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":124,"skipped":2207,"failed":0}
------------------------------
• [4.144 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:41.153
    Aug 24 10:05:41.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:05:41.159
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:41.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:41.191
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-96101a6b-80e6-4ff0-b7a3-381be854ff47 08/24/22 10:05:41.195
    STEP: Creating a pod to test consume secrets 08/24/22 10:05:41.203
    Aug 24 10:05:41.216: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539" in namespace "projected-6962" to be "Succeeded or Failed"
    Aug 24 10:05:41.228: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Pending", Reason="", readiness=false. Elapsed: 12.200608ms
    Aug 24 10:05:43.236: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019324477s
    Aug 24 10:05:45.239: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022675039s
    STEP: Saw pod success 08/24/22 10:05:45.239
    Aug 24 10:05:45.239: INFO: Pod "pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539" satisfied condition "Succeeded or Failed"
    Aug 24 10:05:45.245: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:05:45.256
    Aug 24 10:05:45.274: INFO: Waiting for pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 to disappear
    Aug 24 10:05:45.280: INFO: Pod pod-projected-secrets-5d8c28a0-6e8f-4531-83be-023e0109a539 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:05:45.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6962" for this suite. 08/24/22 10:05:45.288
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:45.298
Aug 24 10:05:45.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:05:45.302
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:45.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:45.333
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 08/24/22 10:05:45.337
Aug 24 10:05:45.349: INFO: Waiting up to 5m0s for pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b" in namespace "emptydir-73" to be "Succeeded or Failed"
Aug 24 10:05:45.353: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.894996ms
Aug 24 10:05:47.360: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010936158s
Aug 24 10:05:49.358: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008536027s
STEP: Saw pod success 08/24/22 10:05:49.358
Aug 24 10:05:49.358: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b" satisfied condition "Succeeded or Failed"
Aug 24 10:05:49.364: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b container test-container: <nil>
STEP: delete the pod 08/24/22 10:05:49.372
Aug 24 10:05:49.422: INFO: Waiting for pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b to disappear
Aug 24 10:05:49.430: INFO: Pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:05:49.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-73" for this suite. 08/24/22 10:05:49.436
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":125,"skipped":2209,"failed":0}
------------------------------
• [4.153 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:45.298
    Aug 24 10:05:45.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:05:45.302
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:45.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:45.333
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 08/24/22 10:05:45.337
    Aug 24 10:05:45.349: INFO: Waiting up to 5m0s for pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b" in namespace "emptydir-73" to be "Succeeded or Failed"
    Aug 24 10:05:45.353: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.894996ms
    Aug 24 10:05:47.360: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010936158s
    Aug 24 10:05:49.358: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008536027s
    STEP: Saw pod success 08/24/22 10:05:49.358
    Aug 24 10:05:49.358: INFO: Pod "pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b" satisfied condition "Succeeded or Failed"
    Aug 24 10:05:49.364: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b container test-container: <nil>
    STEP: delete the pod 08/24/22 10:05:49.372
    Aug 24 10:05:49.422: INFO: Waiting for pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b to disappear
    Aug 24 10:05:49.430: INFO: Pod pod-5fdbd5f9-69e1-41a2-be4c-fa13617eca0b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:05:49.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-73" for this suite. 08/24/22 10:05:49.436
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:49.452
Aug 24 10:05:49.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:05:49.455
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:49.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:49.487
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 08/24/22 10:05:49.49
Aug 24 10:05:49.512: INFO: Waiting up to 5m0s for pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14" in namespace "downward-api-2216" to be "Succeeded or Failed"
Aug 24 10:05:49.519: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Pending", Reason="", readiness=false. Elapsed: 6.792606ms
Aug 24 10:05:51.525: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013329278s
Aug 24 10:05:53.529: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017261153s
STEP: Saw pod success 08/24/22 10:05:53.53
Aug 24 10:05:53.530: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14" satisfied condition "Succeeded or Failed"
Aug 24 10:05:53.535: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:05:53.55
Aug 24 10:05:53.581: INFO: Waiting for pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 to disappear
Aug 24 10:05:53.600: INFO: Pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 24 10:05:53.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2216" for this suite. 08/24/22 10:05:53.608
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":126,"skipped":2209,"failed":0}
------------------------------
• [4.178 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:49.452
    Aug 24 10:05:49.452: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:05:49.455
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:49.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:49.487
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 08/24/22 10:05:49.49
    Aug 24 10:05:49.512: INFO: Waiting up to 5m0s for pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14" in namespace "downward-api-2216" to be "Succeeded or Failed"
    Aug 24 10:05:49.519: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Pending", Reason="", readiness=false. Elapsed: 6.792606ms
    Aug 24 10:05:51.525: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013329278s
    Aug 24 10:05:53.529: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017261153s
    STEP: Saw pod success 08/24/22 10:05:53.53
    Aug 24 10:05:53.530: INFO: Pod "downward-api-77e565fa-2019-486a-b746-df406f18fd14" satisfied condition "Succeeded or Failed"
    Aug 24 10:05:53.535: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:05:53.55
    Aug 24 10:05:53.581: INFO: Waiting for pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 to disappear
    Aug 24 10:05:53.600: INFO: Pod downward-api-77e565fa-2019-486a-b746-df406f18fd14 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 24 10:05:53.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2216" for this suite. 08/24/22 10:05:53.608
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:53.632
Aug 24 10:05:53.632: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename endpointslice 08/24/22 10:05:53.635
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:53.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:53.683
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 24 10:05:57.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6537" for this suite. 08/24/22 10:05:57.829
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":127,"skipped":2212,"failed":0}
------------------------------
• [4.211 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:53.632
    Aug 24 10:05:53.632: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename endpointslice 08/24/22 10:05:53.635
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:53.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:53.683
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 24 10:05:57.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6537" for this suite. 08/24/22 10:05:57.829
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:05:57.843
Aug 24 10:05:57.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename namespaces 08/24/22 10:05:57.845
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:57.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:57.872
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 08/24/22 10:05:57.875
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:57.895
STEP: Creating a pod in the namespace 08/24/22 10:05:57.9
STEP: Waiting for the pod to have running status 08/24/22 10:05:57.922
Aug 24 10:05:57.922: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7800" to be "running"
Aug 24 10:05:57.930: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.753157ms
Aug 24 10:05:59.936: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013563724s
Aug 24 10:05:59.936: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 08/24/22 10:05:59.936
STEP: Waiting for the namespace to be removed. 08/24/22 10:05:59.946
STEP: Recreating the namespace 08/24/22 10:06:10.956
STEP: Verifying there are no pods in the namespace 08/24/22 10:06:10.983
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:06:10.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3492" for this suite. 08/24/22 10:06:10.994
STEP: Destroying namespace "nsdeletetest-7800" for this suite. 08/24/22 10:06:11.005
Aug 24 10:06:11.010: INFO: Namespace nsdeletetest-7800 was already deleted
STEP: Destroying namespace "nsdeletetest-810" for this suite. 08/24/22 10:06:11.01
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":128,"skipped":2215,"failed":0}
------------------------------
• [SLOW TEST] [13.177 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:05:57.843
    Aug 24 10:05:57.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename namespaces 08/24/22 10:05:57.845
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:57.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:05:57.872
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 08/24/22 10:05:57.875
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:05:57.895
    STEP: Creating a pod in the namespace 08/24/22 10:05:57.9
    STEP: Waiting for the pod to have running status 08/24/22 10:05:57.922
    Aug 24 10:05:57.922: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7800" to be "running"
    Aug 24 10:05:57.930: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.753157ms
    Aug 24 10:05:59.936: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013563724s
    Aug 24 10:05:59.936: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 08/24/22 10:05:59.936
    STEP: Waiting for the namespace to be removed. 08/24/22 10:05:59.946
    STEP: Recreating the namespace 08/24/22 10:06:10.956
    STEP: Verifying there are no pods in the namespace 08/24/22 10:06:10.983
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:06:10.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3492" for this suite. 08/24/22 10:06:10.994
    STEP: Destroying namespace "nsdeletetest-7800" for this suite. 08/24/22 10:06:11.005
    Aug 24 10:06:11.010: INFO: Namespace nsdeletetest-7800 was already deleted
    STEP: Destroying namespace "nsdeletetest-810" for this suite. 08/24/22 10:06:11.01
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:06:11.036
Aug 24 10:06:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-pred 08/24/22 10:06:11.038
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:11.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:11.064
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 24 10:06:11.070: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 10:06:11.084: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 10:06:11.089: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
Aug 24 10:06:11.099: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 10:06:11.099: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container coredns ready: true, restart count 1
Aug 24 10:06:11.099: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container coredns ready: true, restart count 1
Aug 24 10:06:11.099: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 10:06:11.099: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 10:06:11.099: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 10:06:11.099: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:06:11.099: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 10:06:11.099: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:06:11.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:06:11.099: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:06:11.099: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
Aug 24 10:06:11.112: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.112: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 10:06:11.112: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.112: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 10:06:11.112: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.112: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 10:06:11.113: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.113: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 10:06:11.113: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.113: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:06:11.113: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.113: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 10:06:11.113: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:06:11.113: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:06:11.113: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:06:11.113: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
Aug 24 10:06:11.130: INFO: kube-flannel-ds-vnzwn from kube-flannel started at 2022-08-24 09:44:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.130: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 10:06:11.130: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.130: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:06:11.130: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.130: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 10:06:11.130: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:06:11.130: INFO: 	Container e2e ready: true, restart count 0
Aug 24 10:06:11.130: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:06:11.130: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:06:11.132: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:06:11.132: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:06:11.132: INFO: webhook-to-be-mutated from webhook-7861 started at 2022-08-24 10:05:32 +0000 UTC (1 container statuses recorded)
Aug 24 10:06:11.132: INFO: 	Container example ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:06:11.132
Aug 24 10:06:11.147: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8521" to be "running"
Aug 24 10:06:11.166: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.953552ms
Aug 24 10:06:13.176: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.029348668s
Aug 24 10:06:13.176: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:06:13.19
STEP: Trying to apply a random label on the found node. 08/24/22 10:06:13.213
STEP: verifying the node has the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b 42 08/24/22 10:06:13.23
STEP: Trying to relaunch the pod, now with labels. 08/24/22 10:06:13.241
Aug 24 10:06:13.254: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8521" to be "not pending"
Aug 24 10:06:13.266: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010272ms
Aug 24 10:06:15.271: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.017206297s
Aug 24 10:06:15.272: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b off the node kah9uighaagh-3 08/24/22 10:06:15.276
STEP: verifying the node doesn't have the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b 08/24/22 10:06:15.298
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:06:15.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8521" for this suite. 08/24/22 10:06:15.316
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":129,"skipped":2250,"failed":0}
------------------------------
• [4.289 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:06:11.036
    Aug 24 10:06:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-pred 08/24/22 10:06:11.038
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:11.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:11.064
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 24 10:06:11.070: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 24 10:06:11.084: INFO: Waiting for terminating namespaces to be deleted...
    Aug 24 10:06:11.089: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
    Aug 24 10:06:11.099: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 10:06:11.099: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:06:11.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:06:11.099: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:06:11.099: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
    Aug 24 10:06:11.112: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.112: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 10:06:11.112: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.112: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 10:06:11.112: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.112: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 10:06:11.113: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.113: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 10:06:11.113: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.113: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:06:11.113: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.113: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 10:06:11.113: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:06:11.113: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:06:11.113: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:06:11.113: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
    Aug 24 10:06:11.130: INFO: kube-flannel-ds-vnzwn from kube-flannel started at 2022-08-24 09:44:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.130: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 24 10:06:11.130: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.130: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:06:11.130: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.130: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 24 10:06:11.130: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:06:11.130: INFO: 	Container e2e ready: true, restart count 0
    Aug 24 10:06:11.130: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:06:11.130: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:06:11.132: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:06:11.132: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:06:11.132: INFO: webhook-to-be-mutated from webhook-7861 started at 2022-08-24 10:05:32 +0000 UTC (1 container statuses recorded)
    Aug 24 10:06:11.132: INFO: 	Container example ready: false, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:06:11.132
    Aug 24 10:06:11.147: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8521" to be "running"
    Aug 24 10:06:11.166: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.953552ms
    Aug 24 10:06:13.176: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.029348668s
    Aug 24 10:06:13.176: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:06:13.19
    STEP: Trying to apply a random label on the found node. 08/24/22 10:06:13.213
    STEP: verifying the node has the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b 42 08/24/22 10:06:13.23
    STEP: Trying to relaunch the pod, now with labels. 08/24/22 10:06:13.241
    Aug 24 10:06:13.254: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8521" to be "not pending"
    Aug 24 10:06:13.266: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010272ms
    Aug 24 10:06:15.271: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.017206297s
    Aug 24 10:06:15.272: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b off the node kah9uighaagh-3 08/24/22 10:06:15.276
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-04b6106b-0864-466f-9b68-7b3905fb834b 08/24/22 10:06:15.298
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:06:15.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8521" for this suite. 08/24/22 10:06:15.316
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:06:15.325
Aug 24 10:06:15.326: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:06:15.327
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:15.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:15.36
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 08/24/22 10:06:15.366
STEP: getting /apis/node.k8s.io 08/24/22 10:06:15.374
STEP: getting /apis/node.k8s.io/v1 08/24/22 10:06:15.375
STEP: creating 08/24/22 10:06:15.38
STEP: watching 08/24/22 10:06:15.438
Aug 24 10:06:15.438: INFO: starting watch
STEP: getting 08/24/22 10:06:15.476
STEP: listing 08/24/22 10:06:15.517
STEP: patching 08/24/22 10:06:15.529
STEP: updating 08/24/22 10:06:15.544
Aug 24 10:06:15.554: INFO: waiting for watch events with expected annotations
STEP: deleting 08/24/22 10:06:15.554
STEP: deleting a collection 08/24/22 10:06:15.596
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 24 10:06:15.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4171" for this suite. 08/24/22 10:06:15.673
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":130,"skipped":2254,"failed":0}
------------------------------
• [0.365 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:06:15.325
    Aug 24 10:06:15.326: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:06:15.327
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:15.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:15.36
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 08/24/22 10:06:15.366
    STEP: getting /apis/node.k8s.io 08/24/22 10:06:15.374
    STEP: getting /apis/node.k8s.io/v1 08/24/22 10:06:15.375
    STEP: creating 08/24/22 10:06:15.38
    STEP: watching 08/24/22 10:06:15.438
    Aug 24 10:06:15.438: INFO: starting watch
    STEP: getting 08/24/22 10:06:15.476
    STEP: listing 08/24/22 10:06:15.517
    STEP: patching 08/24/22 10:06:15.529
    STEP: updating 08/24/22 10:06:15.544
    Aug 24 10:06:15.554: INFO: waiting for watch events with expected annotations
    STEP: deleting 08/24/22 10:06:15.554
    STEP: deleting a collection 08/24/22 10:06:15.596
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 24 10:06:15.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4171" for this suite. 08/24/22 10:06:15.673
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:06:15.698
Aug 24 10:06:15.698: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:06:15.699
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:15.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:15.739
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-5694 08/24/22 10:06:15.747
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[] 08/24/22 10:06:15.828
Aug 24 10:06:15.842: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5694 08/24/22 10:06:15.842
Aug 24 10:06:15.868: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5694" to be "running and ready"
Aug 24 10:06:15.878: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.002252ms
Aug 24 10:06:15.879: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:06:17.892: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024037583s
Aug 24 10:06:17.893: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 24 10:06:17.893: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod1:[80]] 08/24/22 10:06:17.904
Aug 24 10:06:17.921: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 08/24/22 10:06:17.921
Aug 24 10:06:17.922: INFO: Creating new exec pod
Aug 24 10:06:17.932: INFO: Waiting up to 5m0s for pod "execpodhpfzk" in namespace "services-5694" to be "running"
Aug 24 10:06:17.939: INFO: Pod "execpodhpfzk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.97314ms
Aug 24 10:06:19.947: INFO: Pod "execpodhpfzk": Phase="Running", Reason="", readiness=true. Elapsed: 2.013980758s
Aug 24 10:06:19.947: INFO: Pod "execpodhpfzk" satisfied condition "running"
Aug 24 10:06:20.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 10:06:21.408: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:21.409: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:06:21.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
Aug 24 10:06:21.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:21.757: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-5694 08/24/22 10:06:21.757
Aug 24 10:06:21.781: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5694" to be "running and ready"
Aug 24 10:06:21.801: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.230471ms
Aug 24 10:06:21.801: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:06:23.809: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.027852945s
Aug 24 10:06:23.809: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 24 10:06:23.809: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod1:[80] pod2:[80]] 08/24/22 10:06:23.82
Aug 24 10:06:23.839: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 08/24/22 10:06:23.839
Aug 24 10:06:24.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 10:06:25.282: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:25.283: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:06:25.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
Aug 24 10:06:25.671: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:25.671: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5694 08/24/22 10:06:25.671
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod2:[80]] 08/24/22 10:06:25.729
Aug 24 10:06:26.790: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 08/24/22 10:06:26.79
Aug 24 10:06:27.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 10:06:28.008: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:28.008: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:06:28.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
Aug 24 10:06:28.214: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
Aug 24 10:06:28.214: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-5694 08/24/22 10:06:28.214
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[] 08/24/22 10:06:28.258
Aug 24 10:06:28.276: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:06:28.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5694" for this suite. 08/24/22 10:06:28.342
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":131,"skipped":2289,"failed":0}
------------------------------
• [SLOW TEST] [12.659 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:06:15.698
    Aug 24 10:06:15.698: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:06:15.699
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:15.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:15.739
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-5694 08/24/22 10:06:15.747
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[] 08/24/22 10:06:15.828
    Aug 24 10:06:15.842: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5694 08/24/22 10:06:15.842
    Aug 24 10:06:15.868: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5694" to be "running and ready"
    Aug 24 10:06:15.878: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.002252ms
    Aug 24 10:06:15.879: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:06:17.892: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024037583s
    Aug 24 10:06:17.893: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 24 10:06:17.893: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod1:[80]] 08/24/22 10:06:17.904
    Aug 24 10:06:17.921: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 08/24/22 10:06:17.921
    Aug 24 10:06:17.922: INFO: Creating new exec pod
    Aug 24 10:06:17.932: INFO: Waiting up to 5m0s for pod "execpodhpfzk" in namespace "services-5694" to be "running"
    Aug 24 10:06:17.939: INFO: Pod "execpodhpfzk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.97314ms
    Aug 24 10:06:19.947: INFO: Pod "execpodhpfzk": Phase="Running", Reason="", readiness=true. Elapsed: 2.013980758s
    Aug 24 10:06:19.947: INFO: Pod "execpodhpfzk" satisfied condition "running"
    Aug 24 10:06:20.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 24 10:06:21.408: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:21.409: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:06:21.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
    Aug 24 10:06:21.757: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:21.757: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-5694 08/24/22 10:06:21.757
    Aug 24 10:06:21.781: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5694" to be "running and ready"
    Aug 24 10:06:21.801: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.230471ms
    Aug 24 10:06:21.801: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:06:23.809: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.027852945s
    Aug 24 10:06:23.809: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 24 10:06:23.809: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod1:[80] pod2:[80]] 08/24/22 10:06:23.82
    Aug 24 10:06:23.839: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 08/24/22 10:06:23.839
    Aug 24 10:06:24.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 24 10:06:25.282: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:25.283: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:06:25.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
    Aug 24 10:06:25.671: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:25.671: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5694 08/24/22 10:06:25.671
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[pod2:[80]] 08/24/22 10:06:25.729
    Aug 24 10:06:26.790: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 08/24/22 10:06:26.79
    Aug 24 10:06:27.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 24 10:06:28.008: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:28.008: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:06:28.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5694 exec execpodhpfzk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.250 80'
    Aug 24 10:06:28.214: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.250 80\nConnection to 10.233.42.250 80 port [tcp/http] succeeded!\n"
    Aug 24 10:06:28.214: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-5694 08/24/22 10:06:28.214
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5694 to expose endpoints map[] 08/24/22 10:06:28.258
    Aug 24 10:06:28.276: INFO: successfully validated that service endpoint-test2 in namespace services-5694 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:06:28.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5694" for this suite. 08/24/22 10:06:28.342
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:06:28.373
Aug 24 10:06:28.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:06:28.376
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:28.427
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:28.436
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 08/24/22 10:06:28.443
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_tcp@PTR;sleep 1; done
 08/24/22 10:06:28.476
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_tcp@PTR;sleep 1; done
 08/24/22 10:06:28.476
STEP: creating a pod to probe DNS 08/24/22 10:06:28.477
STEP: submitting the pod to kubernetes 08/24/22 10:06:28.477
Aug 24 10:06:28.509: INFO: Waiting up to 15m0s for pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f" in namespace "dns-9959" to be "running"
Aug 24 10:06:28.525: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.811708ms
Aug 24 10:06:30.534: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024083806s
Aug 24 10:06:32.533: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Running", Reason="", readiness=true. Elapsed: 4.022409974s
Aug 24 10:06:32.533: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:06:32.533
STEP: looking for the results for each expected name from probers 08/24/22 10:06:32.539
Aug 24 10:06:32.555: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.562: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.571: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.591: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.633: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.644: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.652: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.662: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:32.686: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:06:37.698: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.706: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.712: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.719: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.757: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.768: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.774: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:37.801: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:06:42.697: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.703: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.712: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.719: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.766: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.781: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.788: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:42.814: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:06:47.696: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.705: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.720: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.762: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.770: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.785: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:47.822: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:06:52.697: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.709: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.719: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.726: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.793: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.797: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.803: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.821: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:52.864: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:06:57.698: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.717: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.733: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.775: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.781: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.787: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
Aug 24 10:06:57.829: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

Aug 24 10:07:02.843: INFO: DNS probes using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f succeeded

STEP: deleting the pod 08/24/22 10:07:02.843
STEP: deleting the test service 08/24/22 10:07:02.887
STEP: deleting the test headless service 08/24/22 10:07:02.974
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:07:03.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9959" for this suite. 08/24/22 10:07:03.027
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":132,"skipped":2333,"failed":0}
------------------------------
• [SLOW TEST] [34.672 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:06:28.373
    Aug 24 10:06:28.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:06:28.376
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:06:28.427
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:06:28.436
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 08/24/22 10:06:28.443
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_tcp@PTR;sleep 1; done
     08/24/22 10:06:28.476
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.21.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.21.23_tcp@PTR;sleep 1; done
     08/24/22 10:06:28.476
    STEP: creating a pod to probe DNS 08/24/22 10:06:28.477
    STEP: submitting the pod to kubernetes 08/24/22 10:06:28.477
    Aug 24 10:06:28.509: INFO: Waiting up to 15m0s for pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f" in namespace "dns-9959" to be "running"
    Aug 24 10:06:28.525: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.811708ms
    Aug 24 10:06:30.534: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024083806s
    Aug 24 10:06:32.533: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f": Phase="Running", Reason="", readiness=true. Elapsed: 4.022409974s
    Aug 24 10:06:32.533: INFO: Pod "dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:06:32.533
    STEP: looking for the results for each expected name from probers 08/24/22 10:06:32.539
    Aug 24 10:06:32.555: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.562: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.571: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.591: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.633: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.644: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.652: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.662: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:32.686: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:06:37.698: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.706: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.712: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.719: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.757: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.768: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.774: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:37.801: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:06:42.697: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.703: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.712: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.719: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.766: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.781: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.788: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:42.814: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:06:47.696: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.705: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.720: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.762: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.770: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.785: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:47.822: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:06:52.697: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.709: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.719: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.726: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.793: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.797: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.803: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.821: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:52.864: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:06:57.698: INFO: Unable to read wheezy_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.717: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.733: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.775: INFO: Unable to read jessie_udp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.781: INFO: Unable to read jessie_tcp@dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.787: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local from pod dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f: the server could not find the requested resource (get pods dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f)
    Aug 24 10:06:57.829: INFO: Lookups using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f failed for: [wheezy_udp@dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@dns-test-service.dns-9959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_udp@dns-test-service.dns-9959.svc.cluster.local jessie_tcp@dns-test-service.dns-9959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9959.svc.cluster.local]

    Aug 24 10:07:02.843: INFO: DNS probes using dns-9959/dns-test-80e85c10-dc0d-4e56-8fa0-5686483af46f succeeded

    STEP: deleting the pod 08/24/22 10:07:02.843
    STEP: deleting the test service 08/24/22 10:07:02.887
    STEP: deleting the test headless service 08/24/22 10:07:02.974
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:07:03.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9959" for this suite. 08/24/22 10:07:03.027
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:03.063
Aug 24 10:07:03.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:07:03.076
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:03.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:03.126
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:07:03.134
Aug 24 10:07:03.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7" in namespace "projected-9469" to be "Succeeded or Failed"
Aug 24 10:07:03.164: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.152757ms
Aug 24 10:07:05.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019390725s
Aug 24 10:07:07.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018831335s
STEP: Saw pod success 08/24/22 10:07:07.171
Aug 24 10:07:07.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7" satisfied condition "Succeeded or Failed"
Aug 24 10:07:07.176: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 container client-container: <nil>
STEP: delete the pod 08/24/22 10:07:07.189
Aug 24 10:07:07.228: INFO: Waiting for pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 to disappear
Aug 24 10:07:07.233: INFO: Pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 10:07:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9469" for this suite. 08/24/22 10:07:07.244
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":133,"skipped":2364,"failed":0}
------------------------------
• [4.202 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:03.063
    Aug 24 10:07:03.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:07:03.076
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:03.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:03.126
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:07:03.134
    Aug 24 10:07:03.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7" in namespace "projected-9469" to be "Succeeded or Failed"
    Aug 24 10:07:03.164: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.152757ms
    Aug 24 10:07:05.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019390725s
    Aug 24 10:07:07.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018831335s
    STEP: Saw pod success 08/24/22 10:07:07.171
    Aug 24 10:07:07.171: INFO: Pod "downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7" satisfied condition "Succeeded or Failed"
    Aug 24 10:07:07.176: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:07:07.189
    Aug 24 10:07:07.228: INFO: Waiting for pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 to disappear
    Aug 24 10:07:07.233: INFO: Pod downwardapi-volume-3594a1b0-270b-42fc-9793-25aec61e76a7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 10:07:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9469" for this suite. 08/24/22 10:07:07.244
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:07.272
Aug 24 10:07:07.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-pred 08/24/22 10:07:07.274
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:07.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:07.314
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 24 10:07:07.321: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 10:07:07.335: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 10:07:07.340: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
Aug 24 10:07:07.351: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 10:07:07.351: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container coredns ready: true, restart count 1
Aug 24 10:07:07.351: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container coredns ready: true, restart count 1
Aug 24 10:07:07.351: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 10:07:07.351: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 10:07:07.351: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 10:07:07.351: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:07:07.351: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 10:07:07.351: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:07:07.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:07:07.351: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:07:07.351: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
Aug 24 10:07:07.367: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-flannel ready: true, restart count 1
Aug 24 10:07:07.367: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-addon-manager ready: true, restart count 1
Aug 24 10:07:07.367: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-apiserver ready: true, restart count 1
Aug 24 10:07:07.367: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-controller-manager ready: true, restart count 1
Aug 24 10:07:07.367: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:07:07.367: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container kube-scheduler ready: true, restart count 1
Aug 24 10:07:07.367: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:07:07.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:07:07.367: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:07:07.367: INFO: 
Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
Aug 24 10:07:07.379: INFO: kube-flannel-ds-vnzwn from kube-flannel started at 2022-08-24 09:44:54 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 10:07:07.379: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container kube-proxy ready: true, restart count 1
Aug 24 10:07:07.379: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 10:07:07.379: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container e2e ready: true, restart count 0
Aug 24 10:07:07.379: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:07:07.379: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 10:07:07.379: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 10:07:07.379: INFO: webhook-to-be-mutated from webhook-7861 started at 2022-08-24 10:05:32 +0000 UTC (1 container statuses recorded)
Aug 24 10:07:07.379: INFO: 	Container example ready: false, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:07:07.379
Aug 24 10:07:07.431: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2974" to be "running"
Aug 24 10:07:07.441: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.050406ms
Aug 24 10:07:09.449: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01790458s
Aug 24 10:07:09.449: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:07:09.455
STEP: Trying to apply a random label on the found node. 08/24/22 10:07:09.486
STEP: verifying the node has the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c 95 08/24/22 10:07:09.522
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/24/22 10:07:09.534
Aug 24 10:07:09.544: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2974" to be "not pending"
Aug 24 10:07:09.553: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.635984ms
Aug 24 10:07:11.560: INFO: Pod "pod4": Phase="Failed", Reason="NodeAffinity", readiness=false. Elapsed: 2.016142573s
Aug 24 10:07:11.560: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.54 on the node which pod4 resides and expect not scheduled 08/24/22 10:07:11.561
Aug 24 10:07:11.571: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2974" to be "not pending"
Aug 24 10:07:11.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.740882ms
Aug 24 10:07:13.587: INFO: Pod "pod5": Phase="Running", Reason="", readiness=false. Elapsed: 2.016234591s
Aug 24 10:07:13.587: INFO: Pod "pod5" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c off the node kah9uighaagh-3 08/24/22 10:07:13.588
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c 08/24/22 10:07:13.614
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:07:13.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2974" for this suite. 08/24/22 10:07:13.658
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":134,"skipped":2378,"failed":0}
------------------------------
• [SLOW TEST] [6.402 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:07.272
    Aug 24 10:07:07.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-pred 08/24/22 10:07:07.274
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:07.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:07.314
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 24 10:07:07.321: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 24 10:07:07.335: INFO: Waiting for terminating namespaces to be deleted...
    Aug 24 10:07:07.340: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-1 before test
    Aug 24 10:07:07.351: INFO: kube-flannel-ds-v9ltq from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: coredns-565d847f94-l25vk from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: coredns-565d847f94-l5p5g from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container coredns ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: kube-addon-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: kube-apiserver-kah9uighaagh-1 from kube-system started at 2022-08-24 09:11:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: kube-controller-manager-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: kube-proxy-thfcl from kube-system started at 2022-08-24 08:54:37 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: kube-scheduler-kah9uighaagh-1 from kube-system started at 2022-08-24 09:06:29 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 10:07:07.351: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:07:07.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:07:07.351: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:07:07.351: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-2 before test
    Aug 24 10:07:07.367: INFO: kube-flannel-ds-xn6l2 from kube-flannel started at 2022-08-24 09:04:26 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-flannel ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: kube-addon-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-addon-manager ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: kube-apiserver-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-apiserver ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: kube-controller-manager-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: kube-proxy-w2mv4 from kube-system started at 2022-08-24 08:54:51 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: kube-scheduler-kah9uighaagh-2 from kube-system started at 2022-08-24 09:11:57 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container kube-scheduler ready: true, restart count 1
    Aug 24 10:07:07.367: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-qlrl7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:07:07.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:07:07.367: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:07:07.367: INFO: 
    Logging pods the apiserver thinks is on node kah9uighaagh-3 before test
    Aug 24 10:07:07.379: INFO: kube-flannel-ds-vnzwn from kube-flannel started at 2022-08-24 09:44:54 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: kube-proxy-v9kb2 from kube-system started at 2022-08-24 09:07:18 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container kube-proxy ready: true, restart count 1
    Aug 24 10:07:07.379: INFO: sonobuoy from sonobuoy started at 2022-08-24 09:18:47 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: sonobuoy-e2e-job-3c870a7ae8ea444b from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container e2e ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: sonobuoy-systemd-logs-daemon-set-931304e6ede74452-pg7v7 from sonobuoy started at 2022-08-24 09:19:34 +0000 UTC (2 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 24 10:07:07.379: INFO: webhook-to-be-mutated from webhook-7861 started at 2022-08-24 10:05:32 +0000 UTC (1 container statuses recorded)
    Aug 24 10:07:07.379: INFO: 	Container example ready: false, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:07:07.379
    Aug 24 10:07:07.431: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2974" to be "running"
    Aug 24 10:07:07.441: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.050406ms
    Aug 24 10:07:09.449: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01790458s
    Aug 24 10:07:09.449: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:07:09.455
    STEP: Trying to apply a random label on the found node. 08/24/22 10:07:09.486
    STEP: verifying the node has the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c 95 08/24/22 10:07:09.522
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/24/22 10:07:09.534
    Aug 24 10:07:09.544: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2974" to be "not pending"
    Aug 24 10:07:09.553: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.635984ms
    Aug 24 10:07:11.560: INFO: Pod "pod4": Phase="Failed", Reason="NodeAffinity", readiness=false. Elapsed: 2.016142573s
    Aug 24 10:07:11.560: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.54 on the node which pod4 resides and expect not scheduled 08/24/22 10:07:11.561
    Aug 24 10:07:11.571: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2974" to be "not pending"
    Aug 24 10:07:11.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.740882ms
    Aug 24 10:07:13.587: INFO: Pod "pod5": Phase="Running", Reason="", readiness=false. Elapsed: 2.016234591s
    Aug 24 10:07:13.587: INFO: Pod "pod5" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c off the node kah9uighaagh-3 08/24/22 10:07:13.588
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-ba2eee89-142f-43de-b5d3-cc485471fe7c 08/24/22 10:07:13.614
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:07:13.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2974" for this suite. 08/24/22 10:07:13.658
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:13.684
Aug 24 10:07:13.684: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:07:13.687
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:13.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:13.73
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 08/24/22 10:07:13.737
STEP: submitting the pod to kubernetes 08/24/22 10:07:13.741
Aug 24 10:07:13.756: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" in namespace "pods-1908" to be "running and ready"
Aug 24 10:07:13.768: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.715259ms
Aug 24 10:07:13.769: INFO: The phase of Pod pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:07:15.776: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 2.019478989s
Aug 24 10:07:15.777: INFO: The phase of Pod pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe is Running (Ready = true)
Aug 24 10:07:15.777: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/24/22 10:07:15.791
STEP: updating the pod 08/24/22 10:07:15.796
Aug 24 10:07:16.317: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe"
Aug 24 10:07:16.317: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" in namespace "pods-1908" to be "terminated with reason DeadlineExceeded"
Aug 24 10:07:16.323: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 5.563694ms
Aug 24 10:07:18.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 2.012539876s
Aug 24 10:07:20.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=false. Elapsed: 4.01243409s
Aug 24 10:07:22.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.012456118s
Aug 24 10:07:22.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:07:22.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1908" for this suite. 08/24/22 10:07:22.336
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":135,"skipped":2415,"failed":0}
------------------------------
• [SLOW TEST] [8.662 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:13.684
    Aug 24 10:07:13.684: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:07:13.687
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:13.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:13.73
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 08/24/22 10:07:13.737
    STEP: submitting the pod to kubernetes 08/24/22 10:07:13.741
    Aug 24 10:07:13.756: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" in namespace "pods-1908" to be "running and ready"
    Aug 24 10:07:13.768: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.715259ms
    Aug 24 10:07:13.769: INFO: The phase of Pod pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:07:15.776: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 2.019478989s
    Aug 24 10:07:15.777: INFO: The phase of Pod pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe is Running (Ready = true)
    Aug 24 10:07:15.777: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/24/22 10:07:15.791
    STEP: updating the pod 08/24/22 10:07:15.796
    Aug 24 10:07:16.317: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe"
    Aug 24 10:07:16.317: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" in namespace "pods-1908" to be "terminated with reason DeadlineExceeded"
    Aug 24 10:07:16.323: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 5.563694ms
    Aug 24 10:07:18.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=true. Elapsed: 2.012539876s
    Aug 24 10:07:20.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Running", Reason="", readiness=false. Elapsed: 4.01243409s
    Aug 24 10:07:22.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.012456118s
    Aug 24 10:07:22.330: INFO: Pod "pod-update-activedeadlineseconds-a4dc5059-4229-4d35-a630-1417d2474abe" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:07:22.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1908" for this suite. 08/24/22 10:07:22.336
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:22.357
Aug 24 10:07:22.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename containers 08/24/22 10:07:22.359
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:22.39
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:22.395
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Aug 24 10:07:22.412: INFO: Waiting up to 5m0s for pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a" in namespace "containers-596" to be "running"
Aug 24 10:07:22.424: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.907939ms
Aug 24 10:07:24.433: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a": Phase="Running", Reason="", readiness=true. Elapsed: 2.020824476s
Aug 24 10:07:24.433: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 24 10:07:24.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-596" for this suite. 08/24/22 10:07:24.458
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":136,"skipped":2426,"failed":0}
------------------------------
• [2.118 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:22.357
    Aug 24 10:07:22.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename containers 08/24/22 10:07:22.359
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:22.39
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:22.395
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Aug 24 10:07:22.412: INFO: Waiting up to 5m0s for pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a" in namespace "containers-596" to be "running"
    Aug 24 10:07:22.424: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.907939ms
    Aug 24 10:07:24.433: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a": Phase="Running", Reason="", readiness=true. Elapsed: 2.020824476s
    Aug 24 10:07:24.433: INFO: Pod "client-containers-c75ecfef-c294-4205-b6e2-a7c95791291a" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 24 10:07:24.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-596" for this suite. 08/24/22 10:07:24.458
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:24.477
Aug 24 10:07:24.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:07:24.479
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:24.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:24.515
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:07:24.519
Aug 24 10:07:24.542: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93" in namespace "downward-api-9994" to be "Succeeded or Failed"
Aug 24 10:07:24.550: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122523ms
Aug 24 10:07:26.558: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01570279s
Aug 24 10:07:28.559: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017047866s
STEP: Saw pod success 08/24/22 10:07:28.559
Aug 24 10:07:28.560: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93" satisfied condition "Succeeded or Failed"
Aug 24 10:07:28.565: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 container client-container: <nil>
STEP: delete the pod 08/24/22 10:07:28.578
Aug 24 10:07:28.605: INFO: Waiting for pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 to disappear
Aug 24 10:07:28.611: INFO: Pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:07:28.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9994" for this suite. 08/24/22 10:07:28.625
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":137,"skipped":2427,"failed":0}
------------------------------
• [4.161 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:24.477
    Aug 24 10:07:24.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:07:24.479
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:24.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:24.515
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:07:24.519
    Aug 24 10:07:24.542: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93" in namespace "downward-api-9994" to be "Succeeded or Failed"
    Aug 24 10:07:24.550: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122523ms
    Aug 24 10:07:26.558: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01570279s
    Aug 24 10:07:28.559: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017047866s
    STEP: Saw pod success 08/24/22 10:07:28.559
    Aug 24 10:07:28.560: INFO: Pod "downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93" satisfied condition "Succeeded or Failed"
    Aug 24 10:07:28.565: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:07:28.578
    Aug 24 10:07:28.605: INFO: Waiting for pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 to disappear
    Aug 24 10:07:28.611: INFO: Pod downwardapi-volume-d1e5575c-849c-42fd-9602-6d0c00afbd93 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:07:28.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9994" for this suite. 08/24/22 10:07:28.625
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:28.641
Aug 24 10:07:28.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:07:28.648
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:28.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:28.694
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Aug 24 10:07:28.708: INFO: Got root ca configmap in namespace "svcaccounts-6824"
Aug 24 10:07:28.725: INFO: Deleted root ca configmap in namespace "svcaccounts-6824"
STEP: waiting for a new root ca configmap created 08/24/22 10:07:29.226
Aug 24 10:07:29.233: INFO: Recreated root ca configmap in namespace "svcaccounts-6824"
Aug 24 10:07:29.242: INFO: Updated root ca configmap in namespace "svcaccounts-6824"
STEP: waiting for the root ca configmap reconciled 08/24/22 10:07:29.742
Aug 24 10:07:29.755: INFO: Reconciled root ca configmap in namespace "svcaccounts-6824"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 10:07:29.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6824" for this suite. 08/24/22 10:07:29.763
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":138,"skipped":2428,"failed":0}
------------------------------
• [1.142 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:28.641
    Aug 24 10:07:28.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:07:28.648
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:28.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:28.694
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Aug 24 10:07:28.708: INFO: Got root ca configmap in namespace "svcaccounts-6824"
    Aug 24 10:07:28.725: INFO: Deleted root ca configmap in namespace "svcaccounts-6824"
    STEP: waiting for a new root ca configmap created 08/24/22 10:07:29.226
    Aug 24 10:07:29.233: INFO: Recreated root ca configmap in namespace "svcaccounts-6824"
    Aug 24 10:07:29.242: INFO: Updated root ca configmap in namespace "svcaccounts-6824"
    STEP: waiting for the root ca configmap reconciled 08/24/22 10:07:29.742
    Aug 24 10:07:29.755: INFO: Reconciled root ca configmap in namespace "svcaccounts-6824"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 10:07:29.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6824" for this suite. 08/24/22 10:07:29.763
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:29.785
Aug 24 10:07:29.786: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:07:29.79
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:29.812
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:29.819
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-db5d16b4-1071-4417-9578-e93652c5d996 08/24/22 10:07:29.823
STEP: Creating a pod to test consume secrets 08/24/22 10:07:29.831
Aug 24 10:07:29.847: INFO: Waiting up to 5m0s for pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900" in namespace "secrets-4214" to be "Succeeded or Failed"
Aug 24 10:07:29.854: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Pending", Reason="", readiness=false. Elapsed: 6.906595ms
Aug 24 10:07:31.867: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020027271s
Aug 24 10:07:33.864: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016593697s
STEP: Saw pod success 08/24/22 10:07:33.864
Aug 24 10:07:33.865: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900" satisfied condition "Succeeded or Failed"
Aug 24 10:07:33.870: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:07:33.89
Aug 24 10:07:33.912: INFO: Waiting for pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 to disappear
Aug 24 10:07:33.919: INFO: Pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:07:33.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4214" for this suite. 08/24/22 10:07:33.928
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":139,"skipped":2438,"failed":0}
------------------------------
• [4.155 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:29.785
    Aug 24 10:07:29.786: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:07:29.79
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:29.812
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:29.819
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-db5d16b4-1071-4417-9578-e93652c5d996 08/24/22 10:07:29.823
    STEP: Creating a pod to test consume secrets 08/24/22 10:07:29.831
    Aug 24 10:07:29.847: INFO: Waiting up to 5m0s for pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900" in namespace "secrets-4214" to be "Succeeded or Failed"
    Aug 24 10:07:29.854: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Pending", Reason="", readiness=false. Elapsed: 6.906595ms
    Aug 24 10:07:31.867: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020027271s
    Aug 24 10:07:33.864: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016593697s
    STEP: Saw pod success 08/24/22 10:07:33.864
    Aug 24 10:07:33.865: INFO: Pod "pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900" satisfied condition "Succeeded or Failed"
    Aug 24 10:07:33.870: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:07:33.89
    Aug 24 10:07:33.912: INFO: Waiting for pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 to disappear
    Aug 24 10:07:33.919: INFO: Pod pod-secrets-c3996bcd-8ad7-493c-935d-fbc3b9188900 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:07:33.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4214" for this suite. 08/24/22 10:07:33.928
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:33.944
Aug 24 10:07:33.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:07:33.948
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:33.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:33.976
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:07:33.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6846" for this suite. 08/24/22 10:07:33.992
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":140,"skipped":2440,"failed":0}
------------------------------
• [0.057 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:33.944
    Aug 24 10:07:33.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:07:33.948
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:33.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:33.976
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:07:33.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6846" for this suite. 08/24/22 10:07:33.992
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:34.006
Aug 24 10:07:34.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context-test 08/24/22 10:07:34.011
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:34.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:34.046
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Aug 24 10:07:34.066: INFO: Waiting up to 5m0s for pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091" in namespace "security-context-test-5806" to be "Succeeded or Failed"
Aug 24 10:07:34.070: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Pending", Reason="", readiness=false. Elapsed: 4.23667ms
Aug 24 10:07:36.082: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015693587s
Aug 24 10:07:38.080: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014024589s
Aug 24 10:07:38.080: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:07:38.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5806" for this suite. 08/24/22 10:07:38.09
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":141,"skipped":2448,"failed":0}
------------------------------
• [4.095 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:34.006
    Aug 24 10:07:34.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context-test 08/24/22 10:07:34.011
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:34.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:34.046
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Aug 24 10:07:34.066: INFO: Waiting up to 5m0s for pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091" in namespace "security-context-test-5806" to be "Succeeded or Failed"
    Aug 24 10:07:34.070: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Pending", Reason="", readiness=false. Elapsed: 4.23667ms
    Aug 24 10:07:36.082: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015693587s
    Aug 24 10:07:38.080: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014024589s
    Aug 24 10:07:38.080: INFO: Pod "busybox-user-65534-2eb8a482-ca6c-4097-882d-76041efaa091" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:07:38.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-5806" for this suite. 08/24/22 10:07:38.09
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:38.106
Aug 24 10:07:38.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:07:38.108
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:38.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:38.139
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 24 10:07:42.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2941" for this suite. 08/24/22 10:07:42.179
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":142,"skipped":2460,"failed":0}
------------------------------
• [4.081 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:38.106
    Aug 24 10:07:38.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:07:38.108
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:38.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:38.139
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 24 10:07:42.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2941" for this suite. 08/24/22 10:07:42.179
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:07:42.189
Aug 24 10:07:42.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 10:07:42.192
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:42.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:42.22
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 10:08:42.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5231" for this suite. 08/24/22 10:08:42.257
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":143,"skipped":2466,"failed":0}
------------------------------
• [SLOW TEST] [60.080 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:07:42.189
    Aug 24 10:07:42.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 10:07:42.192
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:07:42.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:07:42.22
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 10:08:42.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5231" for this suite. 08/24/22 10:08:42.257
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:08:42.272
Aug 24 10:08:42.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:08:42.275
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:42.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:42.303
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:08:42.389
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:08:42.988
STEP: Deploying the webhook pod 08/24/22 10:08:43
STEP: Wait for the deployment to be ready 08/24/22 10:08:43.017
Aug 24 10:08:43.032: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:08:45.049
STEP: Verifying the service has paired with the endpoint 08/24/22 10:08:45.071
Aug 24 10:08:46.072: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Aug 24 10:08:46.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1636-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:08:46.598
Aug 24 10:08:46.654: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 08/24/22 10:08:46.776
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:08:49.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6393" for this suite. 08/24/22 10:08:49.525
STEP: Destroying namespace "webhook-6393-markers" for this suite. 08/24/22 10:08:49.545
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":144,"skipped":2477,"failed":0}
------------------------------
• [SLOW TEST] [7.435 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:08:42.272
    Aug 24 10:08:42.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:08:42.275
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:42.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:42.303
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:08:42.389
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:08:42.988
    STEP: Deploying the webhook pod 08/24/22 10:08:43
    STEP: Wait for the deployment to be ready 08/24/22 10:08:43.017
    Aug 24 10:08:43.032: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:08:45.049
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:08:45.071
    Aug 24 10:08:46.072: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Aug 24 10:08:46.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1636-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:08:46.598
    Aug 24 10:08:46.654: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 08/24/22 10:08:46.776
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:08:49.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6393" for this suite. 08/24/22 10:08:49.525
    STEP: Destroying namespace "webhook-6393-markers" for this suite. 08/24/22 10:08:49.545
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:08:49.722
Aug 24 10:08:49.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context 08/24/22 10:08:49.728
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:49.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:49.775
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/24/22 10:08:49.78
Aug 24 10:08:49.826: INFO: Waiting up to 5m0s for pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f" in namespace "security-context-2069" to be "Succeeded or Failed"
Aug 24 10:08:49.842: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.850756ms
Aug 24 10:08:51.849: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022701981s
Aug 24 10:08:53.851: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024645807s
STEP: Saw pod success 08/24/22 10:08:53.851
Aug 24 10:08:53.851: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f" satisfied condition "Succeeded or Failed"
Aug 24 10:08:53.856: INFO: Trying to get logs from node kah9uighaagh-3 pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f container test-container: <nil>
STEP: delete the pod 08/24/22 10:08:53.868
Aug 24 10:08:53.890: INFO: Waiting for pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f to disappear
Aug 24 10:08:53.895: INFO: Pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:08:53.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-2069" for this suite. 08/24/22 10:08:53.901
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":145,"skipped":2498,"failed":0}
------------------------------
• [4.190 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:08:49.722
    Aug 24 10:08:49.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context 08/24/22 10:08:49.728
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:49.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:49.775
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/24/22 10:08:49.78
    Aug 24 10:08:49.826: INFO: Waiting up to 5m0s for pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f" in namespace "security-context-2069" to be "Succeeded or Failed"
    Aug 24 10:08:49.842: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.850756ms
    Aug 24 10:08:51.849: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022701981s
    Aug 24 10:08:53.851: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024645807s
    STEP: Saw pod success 08/24/22 10:08:53.851
    Aug 24 10:08:53.851: INFO: Pod "security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f" satisfied condition "Succeeded or Failed"
    Aug 24 10:08:53.856: INFO: Trying to get logs from node kah9uighaagh-3 pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f container test-container: <nil>
    STEP: delete the pod 08/24/22 10:08:53.868
    Aug 24 10:08:53.890: INFO: Waiting for pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f to disappear
    Aug 24 10:08:53.895: INFO: Pod security-context-d2e9b28e-ed4d-47fd-ae65-2a29ca7e4f7f no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:08:53.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-2069" for this suite. 08/24/22 10:08:53.901
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:08:53.924
Aug 24 10:08:53.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:08:53.926
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:53.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:53.954
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 08/24/22 10:08:53.959
STEP: Creating a ResourceQuota 08/24/22 10:08:58.966
STEP: Ensuring resource quota status is calculated 08/24/22 10:08:58.975
STEP: Creating a ReplicationController 08/24/22 10:09:00.982
STEP: Ensuring resource quota status captures replication controller creation 08/24/22 10:09:00.997
STEP: Deleting a ReplicationController 08/24/22 10:09:03.004
STEP: Ensuring resource quota status released usage 08/24/22 10:09:03.014
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:09:05.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2989" for this suite. 08/24/22 10:09:05.032
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":146,"skipped":2518,"failed":0}
------------------------------
• [SLOW TEST] [11.118 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:08:53.924
    Aug 24 10:08:53.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:08:53.926
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:08:53.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:08:53.954
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 08/24/22 10:08:53.959
    STEP: Creating a ResourceQuota 08/24/22 10:08:58.966
    STEP: Ensuring resource quota status is calculated 08/24/22 10:08:58.975
    STEP: Creating a ReplicationController 08/24/22 10:09:00.982
    STEP: Ensuring resource quota status captures replication controller creation 08/24/22 10:09:00.997
    STEP: Deleting a ReplicationController 08/24/22 10:09:03.004
    STEP: Ensuring resource quota status released usage 08/24/22 10:09:03.014
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:09:05.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2989" for this suite. 08/24/22 10:09:05.032
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:05.045
Aug 24 10:09:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename proxy 08/24/22 10:09:05.047
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:05.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:05.077
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 08/24/22 10:09:05.098
STEP: creating replication controller proxy-service-29tgv in namespace proxy-5033 08/24/22 10:09:05.099
I0824 10:09:05.113844      14 runners.go:193] Created replication controller with name: proxy-service-29tgv, namespace: proxy-5033, replica count: 1
I0824 10:09:06.166724      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 10:09:07.167347      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0824 10:09:08.168378      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:09:08.174: INFO: setup took 3.094389814s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/24/22 10:09:08.174
Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 43.345549ms)
Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 41.180449ms)
Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 43.388729ms)
Aug 24 10:09:08.219: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 43.758351ms)
Aug 24 10:09:08.221: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 44.393923ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 54.382735ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 54.000723ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 54.288422ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 55.055706ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 53.160948ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 53.284606ms)
Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 54.86809ms)
Aug 24 10:09:08.231: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 54.658527ms)
Aug 24 10:09:08.231: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 54.476259ms)
Aug 24 10:09:08.232: INFO: (0) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 54.790974ms)
Aug 24 10:09:08.233: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 55.864403ms)
Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 30.199304ms)
Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.973119ms)
Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 29.244293ms)
Aug 24 10:09:08.265: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 31.453691ms)
Aug 24 10:09:08.266: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 32.317282ms)
Aug 24 10:09:08.266: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 31.633856ms)
Aug 24 10:09:08.271: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 37.263711ms)
Aug 24 10:09:08.271: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 36.159137ms)
Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 37.573297ms)
Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 37.623188ms)
Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 38.955213ms)
Aug 24 10:09:08.274: INFO: (1) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 40.769918ms)
Aug 24 10:09:08.274: INFO: (1) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 40.334162ms)
Aug 24 10:09:08.275: INFO: (1) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 41.298802ms)
Aug 24 10:09:08.275: INFO: (1) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 42.011832ms)
Aug 24 10:09:08.276: INFO: (1) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 41.917956ms)
Aug 24 10:09:08.306: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 27.629117ms)
Aug 24 10:09:08.306: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 30.118166ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 29.618499ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.621468ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 30.200453ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.609055ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 29.813439ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.278076ms)
Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 30.481047ms)
Aug 24 10:09:08.309: INFO: (2) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 32.212163ms)
Aug 24 10:09:08.309: INFO: (2) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 32.395926ms)
Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 32.964745ms)
Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 32.706094ms)
Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 32.755892ms)
Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 32.342095ms)
Aug 24 10:09:08.315: INFO: (2) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 37.205933ms)
Aug 24 10:09:08.325: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 10.426178ms)
Aug 24 10:09:08.332: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 16.34003ms)
Aug 24 10:09:08.332: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 16.63755ms)
Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 18.264651ms)
Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 17.554629ms)
Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.645136ms)
Aug 24 10:09:08.335: INFO: (3) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 18.671844ms)
Aug 24 10:09:08.335: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 18.529564ms)
Aug 24 10:09:08.336: INFO: (3) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 20.069721ms)
Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 21.540193ms)
Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.950675ms)
Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.640554ms)
Aug 24 10:09:08.338: INFO: (3) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 21.703793ms)
Aug 24 10:09:08.338: INFO: (3) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 22.510535ms)
Aug 24 10:09:08.342: INFO: (3) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 26.751545ms)
Aug 24 10:09:08.344: INFO: (3) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 27.475287ms)
Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 12.232424ms)
Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 12.566887ms)
Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 12.997196ms)
Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 12.969431ms)
Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.635121ms)
Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 13.230913ms)
Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 13.464126ms)
Aug 24 10:09:08.362: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 16.963783ms)
Aug 24 10:09:08.362: INFO: (4) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 17.278022ms)
Aug 24 10:09:08.366: INFO: (4) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 21.303782ms)
Aug 24 10:09:08.366: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.039126ms)
Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 22.057806ms)
Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 21.96131ms)
Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 23.236481ms)
Aug 24 10:09:08.368: INFO: (4) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 23.757887ms)
Aug 24 10:09:08.394: INFO: (4) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 49.208ms)
Aug 24 10:09:08.404: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 9.211545ms)
Aug 24 10:09:08.404: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 9.548068ms)
Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 21.832597ms)
Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.982284ms)
Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.537483ms)
Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 22.090804ms)
Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.308228ms)
Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 24.097308ms)
Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 24.322936ms)
Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 23.742641ms)
Aug 24 10:09:08.420: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 24.155011ms)
Aug 24 10:09:08.420: INFO: (5) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 25.367843ms)
Aug 24 10:09:08.422: INFO: (5) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 27.160667ms)
Aug 24 10:09:08.424: INFO: (5) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 29.645892ms)
Aug 24 10:09:08.426: INFO: (5) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 30.729649ms)
Aug 24 10:09:08.428: INFO: (5) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 31.941095ms)
Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 17.027864ms)
Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.18063ms)
Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 16.94074ms)
Aug 24 10:09:08.448: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 19.329546ms)
Aug 24 10:09:08.449: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.065154ms)
Aug 24 10:09:08.449: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 19.229486ms)
Aug 24 10:09:08.450: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 20.441827ms)
Aug 24 10:09:08.451: INFO: (6) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 22.124951ms)
Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 23.782318ms)
Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.404955ms)
Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 22.947315ms)
Aug 24 10:09:08.455: INFO: (6) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 26.882215ms)
Aug 24 10:09:08.455: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 26.36033ms)
Aug 24 10:09:08.457: INFO: (6) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 29.484477ms)
Aug 24 10:09:08.457: INFO: (6) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 27.871636ms)
Aug 24 10:09:08.473: INFO: (6) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 43.780063ms)
Aug 24 10:09:08.495: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 21.85605ms)
Aug 24 10:09:08.498: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 22.801628ms)
Aug 24 10:09:08.498: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 23.366749ms)
Aug 24 10:09:08.500: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 24.90197ms)
Aug 24 10:09:08.500: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 25.68488ms)
Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 25.99562ms)
Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 26.578113ms)
Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 27.124463ms)
Aug 24 10:09:08.502: INFO: (7) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 28.525628ms)
Aug 24 10:09:08.503: INFO: (7) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 27.713486ms)
Aug 24 10:09:08.503: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.906924ms)
Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.057934ms)
Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 28.88008ms)
Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 30.317184ms)
Aug 24 10:09:08.505: INFO: (7) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 29.848215ms)
Aug 24 10:09:08.505: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.182473ms)
Aug 24 10:09:08.522: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 16.234334ms)
Aug 24 10:09:08.522: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 16.097429ms)
Aug 24 10:09:08.525: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 17.135236ms)
Aug 24 10:09:08.525: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 19.130692ms)
Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 18.272133ms)
Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 20.765226ms)
Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 18.471016ms)
Aug 24 10:09:08.527: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 19.657981ms)
Aug 24 10:09:08.527: INFO: (8) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 20.390651ms)
Aug 24 10:09:08.528: INFO: (8) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 20.994781ms)
Aug 24 10:09:08.529: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 21.689856ms)
Aug 24 10:09:08.531: INFO: (8) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 24.415449ms)
Aug 24 10:09:08.534: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 25.287837ms)
Aug 24 10:09:08.534: INFO: (8) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 25.903554ms)
Aug 24 10:09:08.546: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 37.384952ms)
Aug 24 10:09:08.559: INFO: (8) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 50.640794ms)
Aug 24 10:09:08.577: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 17.695173ms)
Aug 24 10:09:08.592: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 32.673839ms)
Aug 24 10:09:08.596: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 36.739407ms)
Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 37.162019ms)
Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 37.111553ms)
Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 37.804776ms)
Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 37.32804ms)
Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 39.140158ms)
Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 40.274598ms)
Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 40.046201ms)
Aug 24 10:09:08.602: INFO: (9) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 42.675034ms)
Aug 24 10:09:08.602: INFO: (9) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 42.268015ms)
Aug 24 10:09:08.603: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 42.983257ms)
Aug 24 10:09:08.603: INFO: (9) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 43.48837ms)
Aug 24 10:09:08.607: INFO: (9) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 47.388603ms)
Aug 24 10:09:08.607: INFO: (9) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 47.789646ms)
Aug 24 10:09:08.621: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 12.333168ms)
Aug 24 10:09:08.621: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 12.705999ms)
Aug 24 10:09:08.629: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 20.461604ms)
Aug 24 10:09:08.635: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 25.790997ms)
Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 26.797135ms)
Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 26.934581ms)
Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 28.254199ms)
Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 27.29054ms)
Aug 24 10:09:08.638: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.273414ms)
Aug 24 10:09:08.638: INFO: (10) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 29.862234ms)
Aug 24 10:09:08.639: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.323812ms)
Aug 24 10:09:08.643: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 34.405723ms)
Aug 24 10:09:08.645: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 35.868576ms)
Aug 24 10:09:08.645: INFO: (10) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 35.927465ms)
Aug 24 10:09:08.652: INFO: (10) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 43.051646ms)
Aug 24 10:09:08.652: INFO: (10) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 42.781809ms)
Aug 24 10:09:08.666: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.756896ms)
Aug 24 10:09:08.669: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 16.709159ms)
Aug 24 10:09:08.682: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 28.050473ms)
Aug 24 10:09:08.682: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 29.573463ms)
Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 28.879752ms)
Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.796537ms)
Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.195224ms)
Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 30.158511ms)
Aug 24 10:09:08.684: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.335395ms)
Aug 24 10:09:08.684: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 31.867977ms)
Aug 24 10:09:08.690: INFO: (11) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.97664ms)
Aug 24 10:09:08.691: INFO: (11) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 37.240923ms)
Aug 24 10:09:08.691: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 38.676002ms)
Aug 24 10:09:08.696: INFO: (11) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 42.484249ms)
Aug 24 10:09:08.698: INFO: (11) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 45.680359ms)
Aug 24 10:09:08.699: INFO: (11) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 44.91579ms)
Aug 24 10:09:08.709: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 9.127762ms)
Aug 24 10:09:08.718: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.927221ms)
Aug 24 10:09:08.719: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 19.044467ms)
Aug 24 10:09:08.719: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 19.414988ms)
Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.101412ms)
Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.576657ms)
Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.149998ms)
Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 31.980941ms)
Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 30.743468ms)
Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 30.631851ms)
Aug 24 10:09:08.735: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 33.771838ms)
Aug 24 10:09:08.735: INFO: (12) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 34.756161ms)
Aug 24 10:09:08.738: INFO: (12) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 36.874432ms)
Aug 24 10:09:08.738: INFO: (12) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.448813ms)
Aug 24 10:09:08.755: INFO: (12) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 53.649008ms)
Aug 24 10:09:08.755: INFO: (12) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 54.989056ms)
Aug 24 10:09:08.768: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 12.448422ms)
Aug 24 10:09:08.815: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 57.998877ms)
Aug 24 10:09:08.816: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 59.537216ms)
Aug 24 10:09:08.817: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 60.756742ms)
Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 69.659131ms)
Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 70.360668ms)
Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 71.536581ms)
Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 70.307695ms)
Aug 24 10:09:08.831: INFO: (13) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 75.412185ms)
Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 75.241596ms)
Aug 24 10:09:08.831: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 74.52873ms)
Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 75.119903ms)
Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 75.992476ms)
Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 75.259932ms)
Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 76.388332ms)
Aug 24 10:09:08.833: INFO: (13) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 76.534423ms)
Aug 24 10:09:08.855: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.041442ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.673911ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 21.969802ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 21.926443ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 22.128517ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 22.367541ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 20.759515ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 21.334022ms)
Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.636338ms)
Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.566854ms)
Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.262681ms)
Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 30.930434ms)
Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 30.047061ms)
Aug 24 10:09:08.871: INFO: (14) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 36.007642ms)
Aug 24 10:09:08.873: INFO: (14) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.539895ms)
Aug 24 10:09:08.903: INFO: (14) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 68.320073ms)
Aug 24 10:09:08.919: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 15.476025ms)
Aug 24 10:09:08.925: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 21.369255ms)
Aug 24 10:09:08.927: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.718787ms)
Aug 24 10:09:08.928: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 24.533478ms)
Aug 24 10:09:08.928: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.067866ms)
Aug 24 10:09:08.934: INFO: (15) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 30.255604ms)
Aug 24 10:09:08.934: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 29.749654ms)
Aug 24 10:09:08.935: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.572881ms)
Aug 24 10:09:08.935: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 31.312378ms)
Aug 24 10:09:08.938: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 33.754542ms)
Aug 24 10:09:08.939: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 34.116155ms)
Aug 24 10:09:08.941: INFO: (15) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 35.597571ms)
Aug 24 10:09:08.942: INFO: (15) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 38.831564ms)
Aug 24 10:09:08.944: INFO: (15) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 38.942901ms)
Aug 24 10:09:08.969: INFO: (15) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 64.523766ms)
Aug 24 10:09:08.974: INFO: (15) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 70.503936ms)
Aug 24 10:09:08.987: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 12.46673ms)
Aug 24 10:09:08.988: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.270855ms)
Aug 24 10:09:08.991: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 16.319418ms)
Aug 24 10:09:08.991: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 16.380131ms)
Aug 24 10:09:08.992: INFO: (16) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 17.328043ms)
Aug 24 10:09:08.992: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 17.489879ms)
Aug 24 10:09:08.994: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 19.101939ms)
Aug 24 10:09:08.995: INFO: (16) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 20.474215ms)
Aug 24 10:09:09.009: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 33.798849ms)
Aug 24 10:09:09.009: INFO: (16) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 34.532857ms)
Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 45.448404ms)
Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 44.866843ms)
Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 45.693219ms)
Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 45.523585ms)
Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 45.488445ms)
Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 46.202924ms)
Aug 24 10:09:09.044: INFO: (17) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 22.322627ms)
Aug 24 10:09:09.047: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 24.848219ms)
Aug 24 10:09:09.047: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 24.102566ms)
Aug 24 10:09:09.051: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 28.984396ms)
Aug 24 10:09:09.051: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 27.847157ms)
Aug 24 10:09:09.053: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.767915ms)
Aug 24 10:09:09.055: INFO: (17) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 32.558214ms)
Aug 24 10:09:09.059: INFO: (17) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 35.722124ms)
Aug 24 10:09:09.059: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 36.150274ms)
Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 38.71139ms)
Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 39.701045ms)
Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 39.664651ms)
Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 38.085058ms)
Aug 24 10:09:09.062: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 39.46553ms)
Aug 24 10:09:09.063: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 40.15405ms)
Aug 24 10:09:09.063: INFO: (17) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 39.126492ms)
Aug 24 10:09:09.079: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 15.372071ms)
Aug 24 10:09:09.079: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 15.451777ms)
Aug 24 10:09:09.083: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 19.635305ms)
Aug 24 10:09:09.085: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 21.44351ms)
Aug 24 10:09:09.085: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 22.063508ms)
Aug 24 10:09:09.086: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 22.407967ms)
Aug 24 10:09:09.086: INFO: (18) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 23.033837ms)
Aug 24 10:09:09.088: INFO: (18) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 24.172269ms)
Aug 24 10:09:09.088: INFO: (18) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 25.365396ms)
Aug 24 10:09:09.100: INFO: (18) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 36.522651ms)
Aug 24 10:09:09.101: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 38.702198ms)
Aug 24 10:09:09.102: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 38.621364ms)
Aug 24 10:09:09.102: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 38.157614ms)
Aug 24 10:09:09.108: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 44.472342ms)
Aug 24 10:09:09.109: INFO: (18) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 46.342207ms)
Aug 24 10:09:09.111: INFO: (18) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 46.938865ms)
Aug 24 10:09:09.144: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 32.814046ms)
Aug 24 10:09:09.144: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 32.63289ms)
Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 32.789172ms)
Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 33.291379ms)
Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 33.867064ms)
Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 34.028318ms)
Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 35.831527ms)
Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 35.955457ms)
Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 35.627677ms)
Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 35.377378ms)
Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 40.23935ms)
Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 40.340019ms)
Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 41.358826ms)
Aug 24 10:09:09.153: INFO: (19) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 41.68363ms)
Aug 24 10:09:09.164: INFO: (19) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 52.45568ms)
Aug 24 10:09:09.172: INFO: (19) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 61.003692ms)
STEP: deleting ReplicationController proxy-service-29tgv in namespace proxy-5033, will wait for the garbage collector to delete the pods 08/24/22 10:09:09.172
Aug 24 10:09:09.248: INFO: Deleting ReplicationController proxy-service-29tgv took: 17.194319ms
Aug 24 10:09:09.348: INFO: Terminating ReplicationController proxy-service-29tgv pods took: 100.566539ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 24 10:09:11.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5033" for this suite. 08/24/22 10:09:11.559
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":147,"skipped":2528,"failed":0}
------------------------------
• [SLOW TEST] [6.530 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:05.045
    Aug 24 10:09:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename proxy 08/24/22 10:09:05.047
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:05.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:05.077
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 08/24/22 10:09:05.098
    STEP: creating replication controller proxy-service-29tgv in namespace proxy-5033 08/24/22 10:09:05.099
    I0824 10:09:05.113844      14 runners.go:193] Created replication controller with name: proxy-service-29tgv, namespace: proxy-5033, replica count: 1
    I0824 10:09:06.166724      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0824 10:09:07.167347      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0824 10:09:08.168378      14 runners.go:193] proxy-service-29tgv Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:09:08.174: INFO: setup took 3.094389814s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/24/22 10:09:08.174
    Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 43.345549ms)
    Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 41.180449ms)
    Aug 24 10:09:08.218: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 43.388729ms)
    Aug 24 10:09:08.219: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 43.758351ms)
    Aug 24 10:09:08.221: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 44.393923ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 54.382735ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 54.000723ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 54.288422ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 55.055706ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 53.160948ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 53.284606ms)
    Aug 24 10:09:08.230: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 54.86809ms)
    Aug 24 10:09:08.231: INFO: (0) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 54.658527ms)
    Aug 24 10:09:08.231: INFO: (0) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 54.476259ms)
    Aug 24 10:09:08.232: INFO: (0) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 54.790974ms)
    Aug 24 10:09:08.233: INFO: (0) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 55.864403ms)
    Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 30.199304ms)
    Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.973119ms)
    Aug 24 10:09:08.264: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 29.244293ms)
    Aug 24 10:09:08.265: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 31.453691ms)
    Aug 24 10:09:08.266: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 32.317282ms)
    Aug 24 10:09:08.266: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 31.633856ms)
    Aug 24 10:09:08.271: INFO: (1) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 37.263711ms)
    Aug 24 10:09:08.271: INFO: (1) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 36.159137ms)
    Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 37.573297ms)
    Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 37.623188ms)
    Aug 24 10:09:08.272: INFO: (1) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 38.955213ms)
    Aug 24 10:09:08.274: INFO: (1) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 40.769918ms)
    Aug 24 10:09:08.274: INFO: (1) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 40.334162ms)
    Aug 24 10:09:08.275: INFO: (1) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 41.298802ms)
    Aug 24 10:09:08.275: INFO: (1) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 42.011832ms)
    Aug 24 10:09:08.276: INFO: (1) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 41.917956ms)
    Aug 24 10:09:08.306: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 27.629117ms)
    Aug 24 10:09:08.306: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 30.118166ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 29.618499ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.621468ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 30.200453ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.609055ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 29.813439ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.278076ms)
    Aug 24 10:09:08.307: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 30.481047ms)
    Aug 24 10:09:08.309: INFO: (2) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 32.212163ms)
    Aug 24 10:09:08.309: INFO: (2) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 32.395926ms)
    Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 32.964745ms)
    Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 32.706094ms)
    Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 32.755892ms)
    Aug 24 10:09:08.310: INFO: (2) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 32.342095ms)
    Aug 24 10:09:08.315: INFO: (2) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 37.205933ms)
    Aug 24 10:09:08.325: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 10.426178ms)
    Aug 24 10:09:08.332: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 16.34003ms)
    Aug 24 10:09:08.332: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 16.63755ms)
    Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 18.264651ms)
    Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 17.554629ms)
    Aug 24 10:09:08.334: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.645136ms)
    Aug 24 10:09:08.335: INFO: (3) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 18.671844ms)
    Aug 24 10:09:08.335: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 18.529564ms)
    Aug 24 10:09:08.336: INFO: (3) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 20.069721ms)
    Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 21.540193ms)
    Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.950675ms)
    Aug 24 10:09:08.337: INFO: (3) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.640554ms)
    Aug 24 10:09:08.338: INFO: (3) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 21.703793ms)
    Aug 24 10:09:08.338: INFO: (3) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 22.510535ms)
    Aug 24 10:09:08.342: INFO: (3) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 26.751545ms)
    Aug 24 10:09:08.344: INFO: (3) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 27.475287ms)
    Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 12.232424ms)
    Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 12.566887ms)
    Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 12.997196ms)
    Aug 24 10:09:08.357: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 12.969431ms)
    Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.635121ms)
    Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 13.230913ms)
    Aug 24 10:09:08.358: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 13.464126ms)
    Aug 24 10:09:08.362: INFO: (4) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 16.963783ms)
    Aug 24 10:09:08.362: INFO: (4) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 17.278022ms)
    Aug 24 10:09:08.366: INFO: (4) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 21.303782ms)
    Aug 24 10:09:08.366: INFO: (4) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.039126ms)
    Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 22.057806ms)
    Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 21.96131ms)
    Aug 24 10:09:08.367: INFO: (4) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 23.236481ms)
    Aug 24 10:09:08.368: INFO: (4) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 23.757887ms)
    Aug 24 10:09:08.394: INFO: (4) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 49.208ms)
    Aug 24 10:09:08.404: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 9.211545ms)
    Aug 24 10:09:08.404: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 9.548068ms)
    Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 21.832597ms)
    Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.982284ms)
    Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.537483ms)
    Aug 24 10:09:08.417: INFO: (5) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 22.090804ms)
    Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.308228ms)
    Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 24.097308ms)
    Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 24.322936ms)
    Aug 24 10:09:08.419: INFO: (5) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 23.742641ms)
    Aug 24 10:09:08.420: INFO: (5) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 24.155011ms)
    Aug 24 10:09:08.420: INFO: (5) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 25.367843ms)
    Aug 24 10:09:08.422: INFO: (5) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 27.160667ms)
    Aug 24 10:09:08.424: INFO: (5) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 29.645892ms)
    Aug 24 10:09:08.426: INFO: (5) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 30.729649ms)
    Aug 24 10:09:08.428: INFO: (5) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 31.941095ms)
    Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 17.027864ms)
    Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.18063ms)
    Aug 24 10:09:08.446: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 16.94074ms)
    Aug 24 10:09:08.448: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 19.329546ms)
    Aug 24 10:09:08.449: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.065154ms)
    Aug 24 10:09:08.449: INFO: (6) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 19.229486ms)
    Aug 24 10:09:08.450: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 20.441827ms)
    Aug 24 10:09:08.451: INFO: (6) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 22.124951ms)
    Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 23.782318ms)
    Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.404955ms)
    Aug 24 10:09:08.452: INFO: (6) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 22.947315ms)
    Aug 24 10:09:08.455: INFO: (6) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 26.882215ms)
    Aug 24 10:09:08.455: INFO: (6) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 26.36033ms)
    Aug 24 10:09:08.457: INFO: (6) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 29.484477ms)
    Aug 24 10:09:08.457: INFO: (6) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 27.871636ms)
    Aug 24 10:09:08.473: INFO: (6) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 43.780063ms)
    Aug 24 10:09:08.495: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 21.85605ms)
    Aug 24 10:09:08.498: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 22.801628ms)
    Aug 24 10:09:08.498: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 23.366749ms)
    Aug 24 10:09:08.500: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 24.90197ms)
    Aug 24 10:09:08.500: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 25.68488ms)
    Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 25.99562ms)
    Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 26.578113ms)
    Aug 24 10:09:08.501: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 27.124463ms)
    Aug 24 10:09:08.502: INFO: (7) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 28.525628ms)
    Aug 24 10:09:08.503: INFO: (7) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 27.713486ms)
    Aug 24 10:09:08.503: INFO: (7) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.906924ms)
    Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.057934ms)
    Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 28.88008ms)
    Aug 24 10:09:08.504: INFO: (7) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 30.317184ms)
    Aug 24 10:09:08.505: INFO: (7) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 29.848215ms)
    Aug 24 10:09:08.505: INFO: (7) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.182473ms)
    Aug 24 10:09:08.522: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 16.234334ms)
    Aug 24 10:09:08.522: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 16.097429ms)
    Aug 24 10:09:08.525: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 17.135236ms)
    Aug 24 10:09:08.525: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 19.130692ms)
    Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 18.272133ms)
    Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 20.765226ms)
    Aug 24 10:09:08.526: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 18.471016ms)
    Aug 24 10:09:08.527: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 19.657981ms)
    Aug 24 10:09:08.527: INFO: (8) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 20.390651ms)
    Aug 24 10:09:08.528: INFO: (8) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 20.994781ms)
    Aug 24 10:09:08.529: INFO: (8) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 21.689856ms)
    Aug 24 10:09:08.531: INFO: (8) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 24.415449ms)
    Aug 24 10:09:08.534: INFO: (8) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 25.287837ms)
    Aug 24 10:09:08.534: INFO: (8) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 25.903554ms)
    Aug 24 10:09:08.546: INFO: (8) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 37.384952ms)
    Aug 24 10:09:08.559: INFO: (8) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 50.640794ms)
    Aug 24 10:09:08.577: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 17.695173ms)
    Aug 24 10:09:08.592: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 32.673839ms)
    Aug 24 10:09:08.596: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 36.739407ms)
    Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 37.162019ms)
    Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 37.111553ms)
    Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 37.804776ms)
    Aug 24 10:09:08.597: INFO: (9) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 37.32804ms)
    Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 39.140158ms)
    Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 40.274598ms)
    Aug 24 10:09:08.599: INFO: (9) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 40.046201ms)
    Aug 24 10:09:08.602: INFO: (9) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 42.675034ms)
    Aug 24 10:09:08.602: INFO: (9) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 42.268015ms)
    Aug 24 10:09:08.603: INFO: (9) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 42.983257ms)
    Aug 24 10:09:08.603: INFO: (9) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 43.48837ms)
    Aug 24 10:09:08.607: INFO: (9) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 47.388603ms)
    Aug 24 10:09:08.607: INFO: (9) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 47.789646ms)
    Aug 24 10:09:08.621: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 12.333168ms)
    Aug 24 10:09:08.621: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 12.705999ms)
    Aug 24 10:09:08.629: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 20.461604ms)
    Aug 24 10:09:08.635: INFO: (10) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 25.790997ms)
    Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 26.797135ms)
    Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 26.934581ms)
    Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 28.254199ms)
    Aug 24 10:09:08.636: INFO: (10) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 27.29054ms)
    Aug 24 10:09:08.638: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.273414ms)
    Aug 24 10:09:08.638: INFO: (10) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 29.862234ms)
    Aug 24 10:09:08.639: INFO: (10) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.323812ms)
    Aug 24 10:09:08.643: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 34.405723ms)
    Aug 24 10:09:08.645: INFO: (10) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 35.868576ms)
    Aug 24 10:09:08.645: INFO: (10) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 35.927465ms)
    Aug 24 10:09:08.652: INFO: (10) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 43.051646ms)
    Aug 24 10:09:08.652: INFO: (10) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 42.781809ms)
    Aug 24 10:09:08.666: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.756896ms)
    Aug 24 10:09:08.669: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 16.709159ms)
    Aug 24 10:09:08.682: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 28.050473ms)
    Aug 24 10:09:08.682: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 29.573463ms)
    Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 28.879752ms)
    Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.796537ms)
    Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.195224ms)
    Aug 24 10:09:08.683: INFO: (11) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 30.158511ms)
    Aug 24 10:09:08.684: INFO: (11) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.335395ms)
    Aug 24 10:09:08.684: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 31.867977ms)
    Aug 24 10:09:08.690: INFO: (11) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.97664ms)
    Aug 24 10:09:08.691: INFO: (11) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 37.240923ms)
    Aug 24 10:09:08.691: INFO: (11) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 38.676002ms)
    Aug 24 10:09:08.696: INFO: (11) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 42.484249ms)
    Aug 24 10:09:08.698: INFO: (11) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 45.680359ms)
    Aug 24 10:09:08.699: INFO: (11) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 44.91579ms)
    Aug 24 10:09:08.709: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 9.127762ms)
    Aug 24 10:09:08.718: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 18.927221ms)
    Aug 24 10:09:08.719: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 19.044467ms)
    Aug 24 10:09:08.719: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 19.414988ms)
    Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 30.101412ms)
    Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.576657ms)
    Aug 24 10:09:08.731: INFO: (12) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 30.149998ms)
    Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 31.980941ms)
    Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 30.743468ms)
    Aug 24 10:09:08.732: INFO: (12) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 30.631851ms)
    Aug 24 10:09:08.735: INFO: (12) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 33.771838ms)
    Aug 24 10:09:08.735: INFO: (12) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 34.756161ms)
    Aug 24 10:09:08.738: INFO: (12) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 36.874432ms)
    Aug 24 10:09:08.738: INFO: (12) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.448813ms)
    Aug 24 10:09:08.755: INFO: (12) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 53.649008ms)
    Aug 24 10:09:08.755: INFO: (12) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 54.989056ms)
    Aug 24 10:09:08.768: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 12.448422ms)
    Aug 24 10:09:08.815: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 57.998877ms)
    Aug 24 10:09:08.816: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 59.537216ms)
    Aug 24 10:09:08.817: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 60.756742ms)
    Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 69.659131ms)
    Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 70.360668ms)
    Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 71.536581ms)
    Aug 24 10:09:08.827: INFO: (13) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 70.307695ms)
    Aug 24 10:09:08.831: INFO: (13) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 75.412185ms)
    Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 75.241596ms)
    Aug 24 10:09:08.831: INFO: (13) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 74.52873ms)
    Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 75.119903ms)
    Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 75.992476ms)
    Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 75.259932ms)
    Aug 24 10:09:08.832: INFO: (13) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 76.388332ms)
    Aug 24 10:09:08.833: INFO: (13) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 76.534423ms)
    Aug 24 10:09:08.855: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.041442ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 21.673911ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 21.969802ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 21.926443ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 22.128517ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 22.367541ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 20.759515ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 21.334022ms)
    Aug 24 10:09:08.856: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 20.636338ms)
    Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.566854ms)
    Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 29.262681ms)
    Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 30.930434ms)
    Aug 24 10:09:08.865: INFO: (14) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 30.047061ms)
    Aug 24 10:09:08.871: INFO: (14) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 36.007642ms)
    Aug 24 10:09:08.873: INFO: (14) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 36.539895ms)
    Aug 24 10:09:08.903: INFO: (14) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 68.320073ms)
    Aug 24 10:09:08.919: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 15.476025ms)
    Aug 24 10:09:08.925: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 21.369255ms)
    Aug 24 10:09:08.927: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 21.718787ms)
    Aug 24 10:09:08.928: INFO: (15) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 24.533478ms)
    Aug 24 10:09:08.928: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 23.067866ms)
    Aug 24 10:09:08.934: INFO: (15) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 30.255604ms)
    Aug 24 10:09:08.934: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 29.749654ms)
    Aug 24 10:09:08.935: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 29.572881ms)
    Aug 24 10:09:08.935: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 31.312378ms)
    Aug 24 10:09:08.938: INFO: (15) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 33.754542ms)
    Aug 24 10:09:08.939: INFO: (15) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 34.116155ms)
    Aug 24 10:09:08.941: INFO: (15) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 35.597571ms)
    Aug 24 10:09:08.942: INFO: (15) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 38.831564ms)
    Aug 24 10:09:08.944: INFO: (15) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 38.942901ms)
    Aug 24 10:09:08.969: INFO: (15) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 64.523766ms)
    Aug 24 10:09:08.974: INFO: (15) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 70.503936ms)
    Aug 24 10:09:08.987: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 12.46673ms)
    Aug 24 10:09:08.988: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 13.270855ms)
    Aug 24 10:09:08.991: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 16.319418ms)
    Aug 24 10:09:08.991: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 16.380131ms)
    Aug 24 10:09:08.992: INFO: (16) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 17.328043ms)
    Aug 24 10:09:08.992: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 17.489879ms)
    Aug 24 10:09:08.994: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 19.101939ms)
    Aug 24 10:09:08.995: INFO: (16) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 20.474215ms)
    Aug 24 10:09:09.009: INFO: (16) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 33.798849ms)
    Aug 24 10:09:09.009: INFO: (16) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 34.532857ms)
    Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 45.448404ms)
    Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 44.866843ms)
    Aug 24 10:09:09.020: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 45.693219ms)
    Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 45.523585ms)
    Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 45.488445ms)
    Aug 24 10:09:09.021: INFO: (16) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 46.202924ms)
    Aug 24 10:09:09.044: INFO: (17) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 22.322627ms)
    Aug 24 10:09:09.047: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 24.848219ms)
    Aug 24 10:09:09.047: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 24.102566ms)
    Aug 24 10:09:09.051: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 28.984396ms)
    Aug 24 10:09:09.051: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 27.847157ms)
    Aug 24 10:09:09.053: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 30.767915ms)
    Aug 24 10:09:09.055: INFO: (17) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 32.558214ms)
    Aug 24 10:09:09.059: INFO: (17) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 35.722124ms)
    Aug 24 10:09:09.059: INFO: (17) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 36.150274ms)
    Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 38.71139ms)
    Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 39.701045ms)
    Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 39.664651ms)
    Aug 24 10:09:09.061: INFO: (17) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 38.085058ms)
    Aug 24 10:09:09.062: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 39.46553ms)
    Aug 24 10:09:09.063: INFO: (17) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 40.15405ms)
    Aug 24 10:09:09.063: INFO: (17) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 39.126492ms)
    Aug 24 10:09:09.079: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 15.372071ms)
    Aug 24 10:09:09.079: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 15.451777ms)
    Aug 24 10:09:09.083: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 19.635305ms)
    Aug 24 10:09:09.085: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 21.44351ms)
    Aug 24 10:09:09.085: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 22.063508ms)
    Aug 24 10:09:09.086: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 22.407967ms)
    Aug 24 10:09:09.086: INFO: (18) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 23.033837ms)
    Aug 24 10:09:09.088: INFO: (18) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 24.172269ms)
    Aug 24 10:09:09.088: INFO: (18) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 25.365396ms)
    Aug 24 10:09:09.100: INFO: (18) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 36.522651ms)
    Aug 24 10:09:09.101: INFO: (18) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 38.702198ms)
    Aug 24 10:09:09.102: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 38.621364ms)
    Aug 24 10:09:09.102: INFO: (18) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 38.157614ms)
    Aug 24 10:09:09.108: INFO: (18) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 44.472342ms)
    Aug 24 10:09:09.109: INFO: (18) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 46.342207ms)
    Aug 24 10:09:09.111: INFO: (18) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 46.938865ms)
    Aug 24 10:09:09.144: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:160/proxy/: foo (200; 32.814046ms)
    Aug 24 10:09:09.144: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:162/proxy/: bar (200; 32.63289ms)
    Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:1080/proxy/rewriteme">test<... (200; 32.789172ms)
    Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td:162/proxy/: bar (200; 33.291379ms)
    Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:462/proxy/: tls qux (200; 33.867064ms)
    Aug 24 10:09:09.145: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:443/proxy/tlsrewritem... (200; 34.028318ms)
    Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname2/proxy/: bar (200; 35.831527ms)
    Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:160/proxy/: foo (200; 35.955457ms)
    Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/proxy-service-29tgv-ps2td/proxy/rewriteme">test</a> (200; 35.627677ms)
    Aug 24 10:09:09.147: INFO: (19) /api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/: <a href="/api/v1/namespaces/proxy-5033/pods/http:proxy-service-29tgv-ps2td:1080/proxy/rewriteme">... (200; 35.377378ms)
    Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname2/proxy/: bar (200; 40.23935ms)
    Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/pods/https:proxy-service-29tgv-ps2td:460/proxy/: tls baz (200; 40.340019ms)
    Aug 24 10:09:09.152: INFO: (19) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname2/proxy/: tls qux (200; 41.358826ms)
    Aug 24 10:09:09.153: INFO: (19) /api/v1/namespaces/proxy-5033/services/proxy-service-29tgv:portname1/proxy/: foo (200; 41.68363ms)
    Aug 24 10:09:09.164: INFO: (19) /api/v1/namespaces/proxy-5033/services/https:proxy-service-29tgv:tlsportname1/proxy/: tls baz (200; 52.45568ms)
    Aug 24 10:09:09.172: INFO: (19) /api/v1/namespaces/proxy-5033/services/http:proxy-service-29tgv:portname1/proxy/: foo (200; 61.003692ms)
    STEP: deleting ReplicationController proxy-service-29tgv in namespace proxy-5033, will wait for the garbage collector to delete the pods 08/24/22 10:09:09.172
    Aug 24 10:09:09.248: INFO: Deleting ReplicationController proxy-service-29tgv took: 17.194319ms
    Aug 24 10:09:09.348: INFO: Terminating ReplicationController proxy-service-29tgv pods took: 100.566539ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 24 10:09:11.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-5033" for this suite. 08/24/22 10:09:11.559
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:11.578
Aug 24 10:09:11.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:09:11.582
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:11.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:11.651
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-6003 08/24/22 10:09:11.654
STEP: creating replication controller nodeport-test in namespace services-6003 08/24/22 10:09:11.689
I0824 10:09:11.704363      14 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-6003, replica count: 2
I0824 10:09:14.756585      14 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:09:14.756: INFO: Creating new exec pod
Aug 24 10:09:14.764: INFO: Waiting up to 5m0s for pod "execpod2xgpv" in namespace "services-6003" to be "running"
Aug 24 10:09:14.771: INFO: Pod "execpod2xgpv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.83821ms
Aug 24 10:09:16.782: INFO: Pod "execpod2xgpv": Phase="Running", Reason="", readiness=true. Elapsed: 2.017993496s
Aug 24 10:09:16.782: INFO: Pod "execpod2xgpv" satisfied condition "running"
Aug 24 10:09:17.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 24 10:09:18.091: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 24 10:09:18.091: INFO: stdout: "nodeport-test-ghfbz"
Aug 24 10:09:18.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.43.161 80'
Aug 24 10:09:18.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.43.161 80\nConnection to 10.233.43.161 80 port [tcp/http] succeeded!\n"
Aug 24 10:09:18.317: INFO: stdout: "nodeport-test-8cbb5"
Aug 24 10:09:18.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32105'
Aug 24 10:09:18.544: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32105\nConnection to 192.168.121.54 32105 port [tcp/*] succeeded!\n"
Aug 24 10:09:18.544: INFO: stdout: "nodeport-test-ghfbz"
Aug 24 10:09:18.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 32105'
Aug 24 10:09:18.807: INFO: stderr: "+ nc -v -t -w 2 192.168.121.214 32105\n+ echo hostName\nConnection to 192.168.121.214 32105 port [tcp/*] succeeded!\n"
Aug 24 10:09:18.807: INFO: stdout: ""
Aug 24 10:09:19.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 32105'
Aug 24 10:09:20.052: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.214 32105\nConnection to 192.168.121.214 32105 port [tcp/*] succeeded!\n"
Aug 24 10:09:20.052: INFO: stdout: "nodeport-test-8cbb5"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:09:20.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6003" for this suite. 08/24/22 10:09:20.06
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":148,"skipped":2531,"failed":0}
------------------------------
• [SLOW TEST] [8.492 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:11.578
    Aug 24 10:09:11.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:09:11.582
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:11.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:11.651
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-6003 08/24/22 10:09:11.654
    STEP: creating replication controller nodeport-test in namespace services-6003 08/24/22 10:09:11.689
    I0824 10:09:11.704363      14 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-6003, replica count: 2
    I0824 10:09:14.756585      14 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:09:14.756: INFO: Creating new exec pod
    Aug 24 10:09:14.764: INFO: Waiting up to 5m0s for pod "execpod2xgpv" in namespace "services-6003" to be "running"
    Aug 24 10:09:14.771: INFO: Pod "execpod2xgpv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.83821ms
    Aug 24 10:09:16.782: INFO: Pod "execpod2xgpv": Phase="Running", Reason="", readiness=true. Elapsed: 2.017993496s
    Aug 24 10:09:16.782: INFO: Pod "execpod2xgpv" satisfied condition "running"
    Aug 24 10:09:17.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 24 10:09:18.091: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 24 10:09:18.091: INFO: stdout: "nodeport-test-ghfbz"
    Aug 24 10:09:18.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.43.161 80'
    Aug 24 10:09:18.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.43.161 80\nConnection to 10.233.43.161 80 port [tcp/http] succeeded!\n"
    Aug 24 10:09:18.317: INFO: stdout: "nodeport-test-8cbb5"
    Aug 24 10:09:18.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32105'
    Aug 24 10:09:18.544: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32105\nConnection to 192.168.121.54 32105 port [tcp/*] succeeded!\n"
    Aug 24 10:09:18.544: INFO: stdout: "nodeport-test-ghfbz"
    Aug 24 10:09:18.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 32105'
    Aug 24 10:09:18.807: INFO: stderr: "+ nc -v -t -w 2 192.168.121.214 32105\n+ echo hostName\nConnection to 192.168.121.214 32105 port [tcp/*] succeeded!\n"
    Aug 24 10:09:18.807: INFO: stdout: ""
    Aug 24 10:09:19.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-6003 exec execpod2xgpv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.214 32105'
    Aug 24 10:09:20.052: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.214 32105\nConnection to 192.168.121.214 32105 port [tcp/*] succeeded!\n"
    Aug 24 10:09:20.052: INFO: stdout: "nodeport-test-8cbb5"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:09:20.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6003" for this suite. 08/24/22 10:09:20.06
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:20.071
Aug 24 10:09:20.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename watch 08/24/22 10:09:20.072
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:20.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:20.112
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 08/24/22 10:09:20.118
STEP: creating a new configmap 08/24/22 10:09:20.12
STEP: modifying the configmap once 08/24/22 10:09:20.127
STEP: closing the watch once it receives two notifications 08/24/22 10:09:20.14
Aug 24 10:09:20.141: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18642 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:09:20.142: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18643 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 08/24/22 10:09:20.142
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/24/22 10:09:20.159
STEP: deleting the configmap 08/24/22 10:09:20.161
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/24/22 10:09:20.171
Aug 24 10:09:20.171: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18644 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:09:20.172: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18645 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 24 10:09:20.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8237" for this suite. 08/24/22 10:09:20.179
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":149,"skipped":2533,"failed":0}
------------------------------
• [0.121 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:20.071
    Aug 24 10:09:20.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename watch 08/24/22 10:09:20.072
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:20.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:20.112
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 08/24/22 10:09:20.118
    STEP: creating a new configmap 08/24/22 10:09:20.12
    STEP: modifying the configmap once 08/24/22 10:09:20.127
    STEP: closing the watch once it receives two notifications 08/24/22 10:09:20.14
    Aug 24 10:09:20.141: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18642 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:09:20.142: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18643 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 08/24/22 10:09:20.142
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/24/22 10:09:20.159
    STEP: deleting the configmap 08/24/22 10:09:20.161
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/24/22 10:09:20.171
    Aug 24 10:09:20.171: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18644 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:09:20.172: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8237  d55ab71d-8e18-408c-84be-7777eb1d3f10 18645 0 2022-08-24 10:09:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-24 10:09:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 24 10:09:20.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8237" for this suite. 08/24/22 10:09:20.179
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:20.197
Aug 24 10:09:20.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:09:20.199
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:20.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:20.222
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Aug 24 10:09:20.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:09:23.33
Aug 24 10:09:23.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 create -f -'
Aug 24 10:09:25.157: INFO: stderr: ""
Aug 24 10:09:25.157: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 24 10:09:25.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 delete e2e-test-crd-publish-openapi-4361-crds test-cr'
Aug 24 10:09:25.440: INFO: stderr: ""
Aug 24 10:09:25.440: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 24 10:09:25.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 apply -f -'
Aug 24 10:09:26.927: INFO: stderr: ""
Aug 24 10:09:26.927: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 24 10:09:26.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 delete e2e-test-crd-publish-openapi-4361-crds test-cr'
Aug 24 10:09:27.096: INFO: stderr: ""
Aug 24 10:09:27.096: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 08/24/22 10:09:27.096
Aug 24 10:09:27.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 explain e2e-test-crd-publish-openapi-4361-crds'
Aug 24 10:09:27.715: INFO: stderr: ""
Aug 24 10:09:27.715: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4361-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:09:33.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-722" for this suite. 08/24/22 10:09:33.182
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":150,"skipped":2561,"failed":0}
------------------------------
• [SLOW TEST] [12.995 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:20.197
    Aug 24 10:09:20.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:09:20.199
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:20.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:20.222
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Aug 24 10:09:20.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:09:23.33
    Aug 24 10:09:23.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 create -f -'
    Aug 24 10:09:25.157: INFO: stderr: ""
    Aug 24 10:09:25.157: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 24 10:09:25.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 delete e2e-test-crd-publish-openapi-4361-crds test-cr'
    Aug 24 10:09:25.440: INFO: stderr: ""
    Aug 24 10:09:25.440: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Aug 24 10:09:25.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 apply -f -'
    Aug 24 10:09:26.927: INFO: stderr: ""
    Aug 24 10:09:26.927: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 24 10:09:26.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 --namespace=crd-publish-openapi-722 delete e2e-test-crd-publish-openapi-4361-crds test-cr'
    Aug 24 10:09:27.096: INFO: stderr: ""
    Aug 24 10:09:27.096: INFO: stdout: "e2e-test-crd-publish-openapi-4361-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 08/24/22 10:09:27.096
    Aug 24 10:09:27.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-722 explain e2e-test-crd-publish-openapi-4361-crds'
    Aug 24 10:09:27.715: INFO: stderr: ""
    Aug 24 10:09:27.715: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4361-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:09:33.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-722" for this suite. 08/24/22 10:09:33.182
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:33.197
Aug 24 10:09:33.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sysctl 08/24/22 10:09:33.201
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:33.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:33.227
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/24/22 10:09:33.231
STEP: Watching for error events or started pod 08/24/22 10:09:33.248
STEP: Waiting for pod completion 08/24/22 10:09:35.257
Aug 24 10:09:35.258: INFO: Waiting up to 3m0s for pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb" in namespace "sysctl-3637" to be "completed"
Aug 24 10:09:35.262: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.722833ms
Aug 24 10:09:37.268: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010551062s
Aug 24 10:09:37.269: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb" satisfied condition "completed"
STEP: Checking that the pod succeeded 08/24/22 10:09:37.274
STEP: Getting logs from the pod 08/24/22 10:09:37.274
STEP: Checking that the sysctl is actually updated 08/24/22 10:09:37.284
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 10:09:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3637" for this suite. 08/24/22 10:09:37.29
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":151,"skipped":2580,"failed":0}
------------------------------
• [4.103 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:33.197
    Aug 24 10:09:33.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sysctl 08/24/22 10:09:33.201
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:33.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:33.227
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/24/22 10:09:33.231
    STEP: Watching for error events or started pod 08/24/22 10:09:33.248
    STEP: Waiting for pod completion 08/24/22 10:09:35.257
    Aug 24 10:09:35.258: INFO: Waiting up to 3m0s for pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb" in namespace "sysctl-3637" to be "completed"
    Aug 24 10:09:35.262: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.722833ms
    Aug 24 10:09:37.268: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010551062s
    Aug 24 10:09:37.269: INFO: Pod "sysctl-1bb04405-0c81-4b81-8886-42e0e40a48fb" satisfied condition "completed"
    STEP: Checking that the pod succeeded 08/24/22 10:09:37.274
    STEP: Getting logs from the pod 08/24/22 10:09:37.274
    STEP: Checking that the sysctl is actually updated 08/24/22 10:09:37.284
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 10:09:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3637" for this suite. 08/24/22 10:09:37.29
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:37.302
Aug 24 10:09:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:09:37.314
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:37.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:37.35
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-7375 08/24/22 10:09:37.356
STEP: creating service affinity-clusterip in namespace services-7375 08/24/22 10:09:37.356
STEP: creating replication controller affinity-clusterip in namespace services-7375 08/24/22 10:09:37.373
I0824 10:09:37.389153      14 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-7375, replica count: 3
I0824 10:09:40.442460      14 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:09:40.454: INFO: Creating new exec pod
Aug 24 10:09:40.465: INFO: Waiting up to 5m0s for pod "execpod-affinitywkmv9" in namespace "services-7375" to be "running"
Aug 24 10:09:40.472: INFO: Pod "execpod-affinitywkmv9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.282266ms
Aug 24 10:09:42.479: INFO: Pod "execpod-affinitywkmv9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013462988s
Aug 24 10:09:42.479: INFO: Pod "execpod-affinitywkmv9" satisfied condition "running"
Aug 24 10:09:43.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Aug 24 10:09:43.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug 24 10:09:43.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:09:43.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.53.210 80'
Aug 24 10:09:44.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.53.210 80\nConnection to 10.233.53.210 80 port [tcp/http] succeeded!\n"
Aug 24 10:09:44.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:09:44.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.53.210:80/ ; done'
Aug 24 10:09:44.457: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n"
Aug 24 10:09:44.457: INFO: stdout: "\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh"
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
Aug 24 10:09:44.458: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-7375, will wait for the garbage collector to delete the pods 08/24/22 10:09:44.49
Aug 24 10:09:44.564: INFO: Deleting ReplicationController affinity-clusterip took: 14.198248ms
Aug 24 10:09:44.665: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.665652ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:09:46.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7375" for this suite. 08/24/22 10:09:46.923
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":152,"skipped":2593,"failed":0}
------------------------------
• [SLOW TEST] [9.646 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:37.302
    Aug 24 10:09:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:09:37.314
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:37.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:37.35
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-7375 08/24/22 10:09:37.356
    STEP: creating service affinity-clusterip in namespace services-7375 08/24/22 10:09:37.356
    STEP: creating replication controller affinity-clusterip in namespace services-7375 08/24/22 10:09:37.373
    I0824 10:09:37.389153      14 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-7375, replica count: 3
    I0824 10:09:40.442460      14 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:09:40.454: INFO: Creating new exec pod
    Aug 24 10:09:40.465: INFO: Waiting up to 5m0s for pod "execpod-affinitywkmv9" in namespace "services-7375" to be "running"
    Aug 24 10:09:40.472: INFO: Pod "execpod-affinitywkmv9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.282266ms
    Aug 24 10:09:42.479: INFO: Pod "execpod-affinitywkmv9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013462988s
    Aug 24 10:09:42.479: INFO: Pod "execpod-affinitywkmv9" satisfied condition "running"
    Aug 24 10:09:43.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Aug 24 10:09:43.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Aug 24 10:09:43.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:09:43.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.53.210 80'
    Aug 24 10:09:44.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.53.210 80\nConnection to 10.233.53.210 80 port [tcp/http] succeeded!\n"
    Aug 24 10:09:44.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:09:44.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-7375 exec execpod-affinitywkmv9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.53.210:80/ ; done'
    Aug 24 10:09:44.457: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.53.210:80/\n"
    Aug 24 10:09:44.457: INFO: stdout: "\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh\naffinity-clusterip-9bjwh"
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Received response from host: affinity-clusterip-9bjwh
    Aug 24 10:09:44.458: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-7375, will wait for the garbage collector to delete the pods 08/24/22 10:09:44.49
    Aug 24 10:09:44.564: INFO: Deleting ReplicationController affinity-clusterip took: 14.198248ms
    Aug 24 10:09:44.665: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.665652ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:09:46.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7375" for this suite. 08/24/22 10:09:46.923
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:46.953
Aug 24 10:09:46.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename containers 08/24/22 10:09:46.955
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:47.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:47.05
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 08/24/22 10:09:47.056
Aug 24 10:09:47.076: INFO: Waiting up to 5m0s for pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2" in namespace "containers-1716" to be "Succeeded or Failed"
Aug 24 10:09:47.082: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.381149ms
Aug 24 10:09:49.091: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014640156s
Aug 24 10:09:51.090: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014501554s
STEP: Saw pod success 08/24/22 10:09:51.091
Aug 24 10:09:51.091: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2" satisfied condition "Succeeded or Failed"
Aug 24 10:09:51.096: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:09:51.129
Aug 24 10:09:51.149: INFO: Waiting for pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 to disappear
Aug 24 10:09:51.154: INFO: Pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 24 10:09:51.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1716" for this suite. 08/24/22 10:09:51.162
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":153,"skipped":2597,"failed":0}
------------------------------
• [4.218 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:46.953
    Aug 24 10:09:46.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename containers 08/24/22 10:09:46.955
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:47.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:47.05
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 08/24/22 10:09:47.056
    Aug 24 10:09:47.076: INFO: Waiting up to 5m0s for pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2" in namespace "containers-1716" to be "Succeeded or Failed"
    Aug 24 10:09:47.082: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.381149ms
    Aug 24 10:09:49.091: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014640156s
    Aug 24 10:09:51.090: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014501554s
    STEP: Saw pod success 08/24/22 10:09:51.091
    Aug 24 10:09:51.091: INFO: Pod "client-containers-85e72214-ba9f-4e43-838d-3757e42672c2" satisfied condition "Succeeded or Failed"
    Aug 24 10:09:51.096: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:09:51.129
    Aug 24 10:09:51.149: INFO: Waiting for pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 to disappear
    Aug 24 10:09:51.154: INFO: Pod client-containers-85e72214-ba9f-4e43-838d-3757e42672c2 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 24 10:09:51.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1716" for this suite. 08/24/22 10:09:51.162
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:51.172
Aug 24 10:09:51.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:09:51.174
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:51.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:51.206
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 08/24/22 10:09:51.212
Aug 24 10:09:51.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 create -f -'
Aug 24 10:09:52.559: INFO: stderr: ""
Aug 24 10:09:52.559: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 08/24/22 10:09:52.559
Aug 24 10:09:52.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 diff -f -'
Aug 24 10:09:54.191: INFO: rc: 1
Aug 24 10:09:54.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 delete -f -'
Aug 24 10:09:54.335: INFO: stderr: ""
Aug 24 10:09:54.336: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:09:54.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7820" for this suite. 08/24/22 10:09:54.347
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":154,"skipped":2608,"failed":0}
------------------------------
• [3.201 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:51.172
    Aug 24 10:09:51.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:09:51.174
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:51.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:51.206
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 08/24/22 10:09:51.212
    Aug 24 10:09:51.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 create -f -'
    Aug 24 10:09:52.559: INFO: stderr: ""
    Aug 24 10:09:52.559: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 08/24/22 10:09:52.559
    Aug 24 10:09:52.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 diff -f -'
    Aug 24 10:09:54.191: INFO: rc: 1
    Aug 24 10:09:54.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-7820 delete -f -'
    Aug 24 10:09:54.335: INFO: stderr: ""
    Aug 24 10:09:54.336: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:09:54.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7820" for this suite. 08/24/22 10:09:54.347
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:54.385
Aug 24 10:09:54.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:09:54.387
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:54.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:54.417
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/24/22 10:09:54.423
Aug 24 10:09:54.441: INFO: Waiting up to 5m0s for pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65" in namespace "emptydir-3198" to be "Succeeded or Failed"
Aug 24 10:09:54.446: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Pending", Reason="", readiness=false. Elapsed: 5.414886ms
Aug 24 10:09:56.452: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01117083s
Aug 24 10:09:58.453: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01272147s
STEP: Saw pod success 08/24/22 10:09:58.454
Aug 24 10:09:58.454: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65" satisfied condition "Succeeded or Failed"
Aug 24 10:09:58.460: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 container test-container: <nil>
STEP: delete the pod 08/24/22 10:09:58.476
Aug 24 10:09:58.501: INFO: Waiting for pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 to disappear
Aug 24 10:09:58.512: INFO: Pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:09:58.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3198" for this suite. 08/24/22 10:09:58.52
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":155,"skipped":2639,"failed":0}
------------------------------
• [4.147 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:54.385
    Aug 24 10:09:54.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:09:54.387
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:54.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:54.417
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/24/22 10:09:54.423
    Aug 24 10:09:54.441: INFO: Waiting up to 5m0s for pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65" in namespace "emptydir-3198" to be "Succeeded or Failed"
    Aug 24 10:09:54.446: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Pending", Reason="", readiness=false. Elapsed: 5.414886ms
    Aug 24 10:09:56.452: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01117083s
    Aug 24 10:09:58.453: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01272147s
    STEP: Saw pod success 08/24/22 10:09:58.454
    Aug 24 10:09:58.454: INFO: Pod "pod-5164eb77-49af-4004-95d0-87bae8cf9a65" satisfied condition "Succeeded or Failed"
    Aug 24 10:09:58.460: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:09:58.476
    Aug 24 10:09:58.501: INFO: Waiting for pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 to disappear
    Aug 24 10:09:58.512: INFO: Pod pod-5164eb77-49af-4004-95d0-87bae8cf9a65 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:09:58.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3198" for this suite. 08/24/22 10:09:58.52
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:09:58.534
Aug 24 10:09:58.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:09:58.538
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:58.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:58.58
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 08/24/22 10:09:58.585
Aug 24 10:09:58.611: INFO: Waiting up to 5m0s for pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a" in namespace "emptydir-7343" to be "Succeeded or Failed"
Aug 24 10:09:58.620: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.178635ms
Aug 24 10:10:00.628: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017217729s
Aug 24 10:10:02.632: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021455438s
Aug 24 10:10:04.627: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0156829s
STEP: Saw pod success 08/24/22 10:10:04.627
Aug 24 10:10:04.627: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a" satisfied condition "Succeeded or Failed"
Aug 24 10:10:04.633: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-c1057393-8181-483d-b3ff-625f2c2b593a container test-container: <nil>
STEP: delete the pod 08/24/22 10:10:04.649
Aug 24 10:10:04.678: INFO: Waiting for pod pod-c1057393-8181-483d-b3ff-625f2c2b593a to disappear
Aug 24 10:10:04.689: INFO: Pod pod-c1057393-8181-483d-b3ff-625f2c2b593a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:10:04.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7343" for this suite. 08/24/22 10:10:04.696
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":156,"skipped":2641,"failed":0}
------------------------------
• [SLOW TEST] [6.171 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:09:58.534
    Aug 24 10:09:58.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:09:58.538
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:09:58.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:09:58.58
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/24/22 10:09:58.585
    Aug 24 10:09:58.611: INFO: Waiting up to 5m0s for pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a" in namespace "emptydir-7343" to be "Succeeded or Failed"
    Aug 24 10:09:58.620: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.178635ms
    Aug 24 10:10:00.628: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017217729s
    Aug 24 10:10:02.632: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021455438s
    Aug 24 10:10:04.627: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0156829s
    STEP: Saw pod success 08/24/22 10:10:04.627
    Aug 24 10:10:04.627: INFO: Pod "pod-c1057393-8181-483d-b3ff-625f2c2b593a" satisfied condition "Succeeded or Failed"
    Aug 24 10:10:04.633: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-c1057393-8181-483d-b3ff-625f2c2b593a container test-container: <nil>
    STEP: delete the pod 08/24/22 10:10:04.649
    Aug 24 10:10:04.678: INFO: Waiting for pod pod-c1057393-8181-483d-b3ff-625f2c2b593a to disappear
    Aug 24 10:10:04.689: INFO: Pod pod-c1057393-8181-483d-b3ff-625f2c2b593a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:10:04.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7343" for this suite. 08/24/22 10:10:04.696
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:04.708
Aug 24 10:10:04.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:10:04.724
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:04.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:04.823
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 08/24/22 10:10:04.826
STEP: fetching the ConfigMap 08/24/22 10:10:04.833
STEP: patching the ConfigMap 08/24/22 10:10:04.837
STEP: listing all ConfigMaps in all namespaces with a label selector 08/24/22 10:10:04.845
STEP: deleting the ConfigMap by collection with a label selector 08/24/22 10:10:04.85
STEP: listing all ConfigMaps in test namespace 08/24/22 10:10:04.865
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:10:04.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9577" for this suite. 08/24/22 10:10:04.876
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":157,"skipped":2656,"failed":0}
------------------------------
• [0.184 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:04.708
    Aug 24 10:10:04.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:10:04.724
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:04.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:04.823
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 08/24/22 10:10:04.826
    STEP: fetching the ConfigMap 08/24/22 10:10:04.833
    STEP: patching the ConfigMap 08/24/22 10:10:04.837
    STEP: listing all ConfigMaps in all namespaces with a label selector 08/24/22 10:10:04.845
    STEP: deleting the ConfigMap by collection with a label selector 08/24/22 10:10:04.85
    STEP: listing all ConfigMaps in test namespace 08/24/22 10:10:04.865
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:10:04.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9577" for this suite. 08/24/22 10:10:04.876
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:04.893
Aug 24 10:10:04.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/24/22 10:10:04.9
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:04.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:04.977
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 08/24/22 10:10:04.989
STEP: Creating hostNetwork=false pod 08/24/22 10:10:04.99
Aug 24 10:10:05.024: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9838" to be "running and ready"
Aug 24 10:10:05.037: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.442249ms
Aug 24 10:10:05.037: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:10:07.048: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019444426s
Aug 24 10:10:07.048: INFO: The phase of Pod test-pod is Running (Ready = true)
Aug 24 10:10:07.048: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 08/24/22 10:10:07.058
Aug 24 10:10:07.071: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9838" to be "running and ready"
Aug 24 10:10:07.080: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.532814ms
Aug 24 10:10:07.080: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:10:09.087: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01571543s
Aug 24 10:10:09.087: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Aug 24 10:10:09.087: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 08/24/22 10:10:09.093
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/24/22 10:10:09.093
Aug 24 10:10:09.093: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.095: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.095: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 24 10:10:09.237: INFO: Exec stderr: ""
Aug 24 10:10:09.237: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.239: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.239: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 24 10:10:09.368: INFO: Exec stderr: ""
Aug 24 10:10:09.368: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.369: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.369: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 24 10:10:09.522: INFO: Exec stderr: ""
Aug 24 10:10:09.523: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.526: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.526: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 24 10:10:09.651: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/24/22 10:10:09.651
Aug 24 10:10:09.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.653: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.653: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 24 10:10:09.782: INFO: Exec stderr: ""
Aug 24 10:10:09.782: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.783: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.783: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 24 10:10:09.885: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/24/22 10:10:09.885
Aug 24 10:10:09.885: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:09.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:09.886: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:09.887: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 24 10:10:10.007: INFO: Exec stderr: ""
Aug 24 10:10:10.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:10.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:10.009: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:10.009: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 24 10:10:10.075: INFO: Exec stderr: ""
Aug 24 10:10:10.075: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:10.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:10.077: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:10.077: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 24 10:10:10.184: INFO: Exec stderr: ""
Aug 24 10:10:10.184: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:10:10.184: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:10:10.186: INFO: ExecWithOptions: Clientset creation
Aug 24 10:10:10.186: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 24 10:10:10.320: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Aug 24 10:10:10.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9838" for this suite. 08/24/22 10:10:10.33
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":158,"skipped":2656,"failed":0}
------------------------------
• [SLOW TEST] [5.459 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:04.893
    Aug 24 10:10:04.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/24/22 10:10:04.9
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:04.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:04.977
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 08/24/22 10:10:04.989
    STEP: Creating hostNetwork=false pod 08/24/22 10:10:04.99
    Aug 24 10:10:05.024: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9838" to be "running and ready"
    Aug 24 10:10:05.037: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.442249ms
    Aug 24 10:10:05.037: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:10:07.048: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019444426s
    Aug 24 10:10:07.048: INFO: The phase of Pod test-pod is Running (Ready = true)
    Aug 24 10:10:07.048: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 08/24/22 10:10:07.058
    Aug 24 10:10:07.071: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9838" to be "running and ready"
    Aug 24 10:10:07.080: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.532814ms
    Aug 24 10:10:07.080: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:10:09.087: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01571543s
    Aug 24 10:10:09.087: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Aug 24 10:10:09.087: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 08/24/22 10:10:09.093
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/24/22 10:10:09.093
    Aug 24 10:10:09.093: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.095: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.095: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 24 10:10:09.237: INFO: Exec stderr: ""
    Aug 24 10:10:09.237: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.239: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.239: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 24 10:10:09.368: INFO: Exec stderr: ""
    Aug 24 10:10:09.368: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.369: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.369: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 24 10:10:09.522: INFO: Exec stderr: ""
    Aug 24 10:10:09.523: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.526: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.526: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 24 10:10:09.651: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/24/22 10:10:09.651
    Aug 24 10:10:09.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.653: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.653: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 24 10:10:09.782: INFO: Exec stderr: ""
    Aug 24 10:10:09.782: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.783: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.783: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 24 10:10:09.885: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/24/22 10:10:09.885
    Aug 24 10:10:09.885: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:09.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:09.886: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:09.887: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 24 10:10:10.007: INFO: Exec stderr: ""
    Aug 24 10:10:10.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:10.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:10.009: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:10.009: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 24 10:10:10.075: INFO: Exec stderr: ""
    Aug 24 10:10:10.075: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:10.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:10.077: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:10.077: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 24 10:10:10.184: INFO: Exec stderr: ""
    Aug 24 10:10:10.184: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9838 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:10:10.184: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:10:10.186: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:10:10.186: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9838/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 24 10:10:10.320: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Aug 24 10:10:10.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-9838" for this suite. 08/24/22 10:10:10.33
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:10.359
Aug 24 10:10:10.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:10:10.364
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:10.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:10.444
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-553/secret-test-f9b03d67-41af-4865-8b8d-d791ccf331da 08/24/22 10:10:10.455
STEP: Creating a pod to test consume secrets 08/24/22 10:10:10.464
Aug 24 10:10:10.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948" in namespace "secrets-553" to be "Succeeded or Failed"
Aug 24 10:10:10.499: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 7.360573ms
Aug 24 10:10:12.509: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017319934s
Aug 24 10:10:14.506: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014836606s
Aug 24 10:10:16.509: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017318717s
STEP: Saw pod success 08/24/22 10:10:16.509
Aug 24 10:10:16.510: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948" satisfied condition "Succeeded or Failed"
Aug 24 10:10:16.515: INFO: Trying to get logs from node kah9uighaagh-2 pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 container env-test: <nil>
STEP: delete the pod 08/24/22 10:10:16.552
Aug 24 10:10:16.585: INFO: Waiting for pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 to disappear
Aug 24 10:10:16.591: INFO: Pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:10:16.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-553" for this suite. 08/24/22 10:10:16.602
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":159,"skipped":2663,"failed":0}
------------------------------
• [SLOW TEST] [6.257 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:10.359
    Aug 24 10:10:10.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:10:10.364
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:10.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:10.444
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-553/secret-test-f9b03d67-41af-4865-8b8d-d791ccf331da 08/24/22 10:10:10.455
    STEP: Creating a pod to test consume secrets 08/24/22 10:10:10.464
    Aug 24 10:10:10.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948" in namespace "secrets-553" to be "Succeeded or Failed"
    Aug 24 10:10:10.499: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 7.360573ms
    Aug 24 10:10:12.509: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017319934s
    Aug 24 10:10:14.506: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014836606s
    Aug 24 10:10:16.509: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017318717s
    STEP: Saw pod success 08/24/22 10:10:16.509
    Aug 24 10:10:16.510: INFO: Pod "pod-configmaps-54442581-3923-4879-8552-90228ce15948" satisfied condition "Succeeded or Failed"
    Aug 24 10:10:16.515: INFO: Trying to get logs from node kah9uighaagh-2 pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 container env-test: <nil>
    STEP: delete the pod 08/24/22 10:10:16.552
    Aug 24 10:10:16.585: INFO: Waiting for pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 to disappear
    Aug 24 10:10:16.591: INFO: Pod pod-configmaps-54442581-3923-4879-8552-90228ce15948 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:10:16.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-553" for this suite. 08/24/22 10:10:16.602
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:16.622
Aug 24 10:10:16.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:10:16.624
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:16.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:16.656
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 10:10:16.662
Aug 24 10:10:16.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 24 10:10:16.822: INFO: stderr: ""
Aug 24 10:10:16.822: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 08/24/22 10:10:16.823
STEP: verifying the pod e2e-test-httpd-pod was created 08/24/22 10:10:21.875
Aug 24 10:10:21.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 get pod e2e-test-httpd-pod -o json'
Aug 24 10:10:22.049: INFO: stderr: ""
Aug 24 10:10:22.049: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-08-24T10:10:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2308\",\n        \"resourceVersion\": \"19148\",\n        \"uid\": \"8a2bf984-7070-4fee-942a-ea5dfb901ca3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-vkm97\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kah9uighaagh-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-vkm97\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://cf1c60060b26d1afe7940f828b77d54382f303cca9dd741083558b63bafd8249\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-24T10:10:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.214\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.65.99\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.65.99\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-24T10:10:16Z\"\n    }\n}\n"
STEP: replace the image in the pod 08/24/22 10:10:22.049
Aug 24 10:10:22.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 replace -f -'
Aug 24 10:10:22.429: INFO: stderr: ""
Aug 24 10:10:22.429: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/24/22 10:10:22.429
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Aug 24 10:10:22.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 delete pods e2e-test-httpd-pod'
Aug 24 10:10:24.693: INFO: stderr: ""
Aug 24 10:10:24.693: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:10:24.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2308" for this suite. 08/24/22 10:10:24.7
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":160,"skipped":2699,"failed":0}
------------------------------
• [SLOW TEST] [8.090 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:16.622
    Aug 24 10:10:16.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:10:16.624
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:16.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:16.656
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/24/22 10:10:16.662
    Aug 24 10:10:16.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 24 10:10:16.822: INFO: stderr: ""
    Aug 24 10:10:16.822: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 08/24/22 10:10:16.823
    STEP: verifying the pod e2e-test-httpd-pod was created 08/24/22 10:10:21.875
    Aug 24 10:10:21.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 get pod e2e-test-httpd-pod -o json'
    Aug 24 10:10:22.049: INFO: stderr: ""
    Aug 24 10:10:22.049: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-08-24T10:10:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2308\",\n        \"resourceVersion\": \"19148\",\n        \"uid\": \"8a2bf984-7070-4fee-942a-ea5dfb901ca3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-vkm97\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kah9uighaagh-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-vkm97\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T10:10:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://cf1c60060b26d1afe7940f828b77d54382f303cca9dd741083558b63bafd8249\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-24T10:10:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.214\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.65.99\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.65.99\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-24T10:10:16Z\"\n    }\n}\n"
    STEP: replace the image in the pod 08/24/22 10:10:22.049
    Aug 24 10:10:22.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 replace -f -'
    Aug 24 10:10:22.429: INFO: stderr: ""
    Aug 24 10:10:22.429: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/24/22 10:10:22.429
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Aug 24 10:10:22.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2308 delete pods e2e-test-httpd-pod'
    Aug 24 10:10:24.693: INFO: stderr: ""
    Aug 24 10:10:24.693: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:10:24.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2308" for this suite. 08/24/22 10:10:24.7
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:24.719
Aug 24 10:10:24.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:10:24.721
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:24.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:24.764
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-1328-delete-me 08/24/22 10:10:24.775
STEP: Waiting for the RuntimeClass to disappear 08/24/22 10:10:24.785
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 24 10:10:24.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1328" for this suite. 08/24/22 10:10:24.806
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":161,"skipped":2741,"failed":0}
------------------------------
• [0.098 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:24.719
    Aug 24 10:10:24.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:10:24.721
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:24.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:24.764
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-1328-delete-me 08/24/22 10:10:24.775
    STEP: Waiting for the RuntimeClass to disappear 08/24/22 10:10:24.785
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 24 10:10:24.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1328" for this suite. 08/24/22 10:10:24.806
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:24.819
Aug 24 10:10:24.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:10:24.821
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:24.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:24.843
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 08/24/22 10:10:24.848
Aug 24 10:10:24.849: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: rename a version 08/24/22 10:10:34.774
STEP: check the new version name is served 08/24/22 10:10:34.804
STEP: check the old version name is removed 08/24/22 10:10:37.751
STEP: check the other version is not changed 08/24/22 10:10:40.007
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:10:47.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7170" for this suite. 08/24/22 10:10:47.496
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":162,"skipped":2750,"failed":0}
------------------------------
• [SLOW TEST] [22.691 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:24.819
    Aug 24 10:10:24.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:10:24.821
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:24.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:24.843
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 08/24/22 10:10:24.848
    Aug 24 10:10:24.849: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: rename a version 08/24/22 10:10:34.774
    STEP: check the new version name is served 08/24/22 10:10:34.804
    STEP: check the old version name is removed 08/24/22 10:10:37.751
    STEP: check the other version is not changed 08/24/22 10:10:40.007
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:10:47.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7170" for this suite. 08/24/22 10:10:47.496
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:10:47.523
Aug 24 10:10:47.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:10:47.529
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:47.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:47.563
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1838 08/24/22 10:10:47.569
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Aug 24 10:10:47.608: INFO: Found 0 stateful pods, waiting for 1
Aug 24 10:10:57.619: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 08/24/22 10:10:57.629
W0824 10:10:57.644474      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 24 10:10:57.657: INFO: Found 1 stateful pods, waiting for 2
Aug 24 10:11:07.668: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:11:07.669: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 08/24/22 10:11:07.683
STEP: Delete all of the StatefulSets 08/24/22 10:11:07.688
STEP: Verify that StatefulSets have been deleted 08/24/22 10:11:07.7
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:11:07.708: INFO: Deleting all statefulset in ns statefulset-1838
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:11:07.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1838" for this suite. 08/24/22 10:11:07.811
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":163,"skipped":2783,"failed":0}
------------------------------
• [SLOW TEST] [20.309 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:10:47.523
    Aug 24 10:10:47.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:10:47.529
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:10:47.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:10:47.563
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1838 08/24/22 10:10:47.569
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Aug 24 10:10:47.608: INFO: Found 0 stateful pods, waiting for 1
    Aug 24 10:10:57.619: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 08/24/22 10:10:57.629
    W0824 10:10:57.644474      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 24 10:10:57.657: INFO: Found 1 stateful pods, waiting for 2
    Aug 24 10:11:07.668: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:11:07.669: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 08/24/22 10:11:07.683
    STEP: Delete all of the StatefulSets 08/24/22 10:11:07.688
    STEP: Verify that StatefulSets have been deleted 08/24/22 10:11:07.7
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:11:07.708: INFO: Deleting all statefulset in ns statefulset-1838
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:11:07.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1838" for this suite. 08/24/22 10:11:07.811
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:07.841
Aug 24 10:11:07.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename ingressclass 08/24/22 10:11:07.847
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:07.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:07.889
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 08/24/22 10:11:07.897
STEP: getting /apis/networking.k8s.io 08/24/22 10:11:07.905
STEP: getting /apis/networking.k8s.iov1 08/24/22 10:11:07.909
STEP: creating 08/24/22 10:11:07.913
STEP: getting 08/24/22 10:11:07.937
STEP: listing 08/24/22 10:11:07.942
STEP: watching 08/24/22 10:11:07.947
Aug 24 10:11:07.947: INFO: starting watch
STEP: patching 08/24/22 10:11:07.948
STEP: updating 08/24/22 10:11:07.959
Aug 24 10:11:07.967: INFO: waiting for watch events with expected annotations
Aug 24 10:11:07.968: INFO: saw patched and updated annotations
STEP: deleting 08/24/22 10:11:07.968
STEP: deleting a collection 08/24/22 10:11:08.018
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Aug 24 10:11:08.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5782" for this suite. 08/24/22 10:11:08.086
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":164,"skipped":2802,"failed":0}
------------------------------
• [0.256 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:07.841
    Aug 24 10:11:07.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename ingressclass 08/24/22 10:11:07.847
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:07.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:07.889
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 08/24/22 10:11:07.897
    STEP: getting /apis/networking.k8s.io 08/24/22 10:11:07.905
    STEP: getting /apis/networking.k8s.iov1 08/24/22 10:11:07.909
    STEP: creating 08/24/22 10:11:07.913
    STEP: getting 08/24/22 10:11:07.937
    STEP: listing 08/24/22 10:11:07.942
    STEP: watching 08/24/22 10:11:07.947
    Aug 24 10:11:07.947: INFO: starting watch
    STEP: patching 08/24/22 10:11:07.948
    STEP: updating 08/24/22 10:11:07.959
    Aug 24 10:11:07.967: INFO: waiting for watch events with expected annotations
    Aug 24 10:11:07.968: INFO: saw patched and updated annotations
    STEP: deleting 08/24/22 10:11:07.968
    STEP: deleting a collection 08/24/22 10:11:08.018
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Aug 24 10:11:08.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-5782" for this suite. 08/24/22 10:11:08.086
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:08.103
Aug 24 10:11:08.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:11:08.108
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:08.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:08.148
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-26fc787e-b606-47f0-9a63-2ad46646efd6 08/24/22 10:11:08.187
STEP: Creating a pod to test consume secrets 08/24/22 10:11:08.196
Aug 24 10:11:08.213: INFO: Waiting up to 5m0s for pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c" in namespace "secrets-3600" to be "Succeeded or Failed"
Aug 24 10:11:08.221: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.444725ms
Aug 24 10:11:10.231: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017716093s
Aug 24 10:11:12.229: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015771455s
STEP: Saw pod success 08/24/22 10:11:12.229
Aug 24 10:11:12.229: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c" satisfied condition "Succeeded or Failed"
Aug 24 10:11:12.234: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:11:12.245
Aug 24 10:11:12.262: INFO: Waiting for pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c to disappear
Aug 24 10:11:12.266: INFO: Pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:11:12.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3600" for this suite. 08/24/22 10:11:12.271
STEP: Destroying namespace "secret-namespace-3516" for this suite. 08/24/22 10:11:12.282
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":165,"skipped":2853,"failed":0}
------------------------------
• [4.191 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:08.103
    Aug 24 10:11:08.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:11:08.108
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:08.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:08.148
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-26fc787e-b606-47f0-9a63-2ad46646efd6 08/24/22 10:11:08.187
    STEP: Creating a pod to test consume secrets 08/24/22 10:11:08.196
    Aug 24 10:11:08.213: INFO: Waiting up to 5m0s for pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c" in namespace "secrets-3600" to be "Succeeded or Failed"
    Aug 24 10:11:08.221: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.444725ms
    Aug 24 10:11:10.231: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017716093s
    Aug 24 10:11:12.229: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015771455s
    STEP: Saw pod success 08/24/22 10:11:12.229
    Aug 24 10:11:12.229: INFO: Pod "pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c" satisfied condition "Succeeded or Failed"
    Aug 24 10:11:12.234: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:11:12.245
    Aug 24 10:11:12.262: INFO: Waiting for pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c to disappear
    Aug 24 10:11:12.266: INFO: Pod pod-secrets-8c599987-2a32-4f2b-9855-ca987f71372c no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:11:12.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3600" for this suite. 08/24/22 10:11:12.271
    STEP: Destroying namespace "secret-namespace-3516" for this suite. 08/24/22 10:11:12.282
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:12.297
Aug 24 10:11:12.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:11:12.3
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:12.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:12.332
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2069.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2069.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 08/24/22 10:11:12.337
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2069.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2069.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 08/24/22 10:11:12.337
STEP: creating a pod to probe /etc/hosts 08/24/22 10:11:12.337
STEP: submitting the pod to kubernetes 08/24/22 10:11:12.337
Aug 24 10:11:12.354: INFO: Waiting up to 15m0s for pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56" in namespace "dns-2069" to be "running"
Aug 24 10:11:12.382: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Pending", Reason="", readiness=false. Elapsed: 27.921703ms
Aug 24 10:11:14.390: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035910352s
Aug 24 10:11:16.388: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Running", Reason="", readiness=true. Elapsed: 4.034322214s
Aug 24 10:11:16.388: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:11:16.388
STEP: looking for the results for each expected name from probers 08/24/22 10:11:16.394
Aug 24 10:11:16.431: INFO: DNS probes using dns-2069/dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56 succeeded

STEP: deleting the pod 08/24/22 10:11:16.431
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:11:16.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2069" for this suite. 08/24/22 10:11:16.473
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":166,"skipped":2858,"failed":0}
------------------------------
• [4.187 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:12.297
    Aug 24 10:11:12.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:11:12.3
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:12.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:12.332
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2069.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2069.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     08/24/22 10:11:12.337
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2069.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2069.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     08/24/22 10:11:12.337
    STEP: creating a pod to probe /etc/hosts 08/24/22 10:11:12.337
    STEP: submitting the pod to kubernetes 08/24/22 10:11:12.337
    Aug 24 10:11:12.354: INFO: Waiting up to 15m0s for pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56" in namespace "dns-2069" to be "running"
    Aug 24 10:11:12.382: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Pending", Reason="", readiness=false. Elapsed: 27.921703ms
    Aug 24 10:11:14.390: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035910352s
    Aug 24 10:11:16.388: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56": Phase="Running", Reason="", readiness=true. Elapsed: 4.034322214s
    Aug 24 10:11:16.388: INFO: Pod "dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:11:16.388
    STEP: looking for the results for each expected name from probers 08/24/22 10:11:16.394
    Aug 24 10:11:16.431: INFO: DNS probes using dns-2069/dns-test-5f45a946-6aa7-4afd-ba1d-5cbe44e24c56 succeeded

    STEP: deleting the pod 08/24/22 10:11:16.431
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:11:16.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2069" for this suite. 08/24/22 10:11:16.473
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:16.487
Aug 24 10:11:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:11:16.49
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:16.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:16.522
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-25e855f8-b8f3-4f0f-bd09-fd1ce176e14a 08/24/22 10:11:16.526
STEP: Creating a pod to test consume configMaps 08/24/22 10:11:16.544
Aug 24 10:11:16.588: INFO: Waiting up to 5m0s for pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4" in namespace "configmap-8255" to be "Succeeded or Failed"
Aug 24 10:11:16.605: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.405535ms
Aug 24 10:11:18.613: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024220522s
Aug 24 10:11:20.612: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023568756s
STEP: Saw pod success 08/24/22 10:11:20.612
Aug 24 10:11:20.613: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4" satisfied condition "Succeeded or Failed"
Aug 24 10:11:20.618: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:11:20.628
Aug 24 10:11:20.653: INFO: Waiting for pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 to disappear
Aug 24 10:11:20.659: INFO: Pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:11:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8255" for this suite. 08/24/22 10:11:20.668
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":167,"skipped":2889,"failed":0}
------------------------------
• [4.193 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:16.487
    Aug 24 10:11:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:11:16.49
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:16.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:16.522
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-25e855f8-b8f3-4f0f-bd09-fd1ce176e14a 08/24/22 10:11:16.526
    STEP: Creating a pod to test consume configMaps 08/24/22 10:11:16.544
    Aug 24 10:11:16.588: INFO: Waiting up to 5m0s for pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4" in namespace "configmap-8255" to be "Succeeded or Failed"
    Aug 24 10:11:16.605: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.405535ms
    Aug 24 10:11:18.613: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024220522s
    Aug 24 10:11:20.612: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023568756s
    STEP: Saw pod success 08/24/22 10:11:20.612
    Aug 24 10:11:20.613: INFO: Pod "pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4" satisfied condition "Succeeded or Failed"
    Aug 24 10:11:20.618: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:11:20.628
    Aug 24 10:11:20.653: INFO: Waiting for pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 to disappear
    Aug 24 10:11:20.659: INFO: Pod pod-configmaps-54ebdd2a-af4e-42d9-8738-3749ed12f1c4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:11:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8255" for this suite. 08/24/22 10:11:20.668
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:20.687
Aug 24 10:11:20.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:11:20.689
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:20.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:20.72
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:11:20.724
Aug 24 10:11:20.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b" in namespace "downward-api-8872" to be "Succeeded or Failed"
Aug 24 10:11:20.756: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.09406ms
Aug 24 10:11:22.769: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021949846s
Aug 24 10:11:24.762: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014614272s
STEP: Saw pod success 08/24/22 10:11:24.762
Aug 24 10:11:24.762: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b" satisfied condition "Succeeded or Failed"
Aug 24 10:11:24.767: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b container client-container: <nil>
STEP: delete the pod 08/24/22 10:11:24.779
Aug 24 10:11:24.802: INFO: Waiting for pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b to disappear
Aug 24 10:11:24.808: INFO: Pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:11:24.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8872" for this suite. 08/24/22 10:11:24.816
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":168,"skipped":2900,"failed":0}
------------------------------
• [4.140 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:20.687
    Aug 24 10:11:20.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:11:20.689
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:20.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:20.72
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:11:20.724
    Aug 24 10:11:20.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b" in namespace "downward-api-8872" to be "Succeeded or Failed"
    Aug 24 10:11:20.756: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.09406ms
    Aug 24 10:11:22.769: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021949846s
    Aug 24 10:11:24.762: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014614272s
    STEP: Saw pod success 08/24/22 10:11:24.762
    Aug 24 10:11:24.762: INFO: Pod "downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b" satisfied condition "Succeeded or Failed"
    Aug 24 10:11:24.767: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b container client-container: <nil>
    STEP: delete the pod 08/24/22 10:11:24.779
    Aug 24 10:11:24.802: INFO: Waiting for pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b to disappear
    Aug 24 10:11:24.808: INFO: Pod downwardapi-volume-37499bae-ca84-448c-b0b2-56108692a97b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:11:24.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8872" for this suite. 08/24/22 10:11:24.816
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:24.835
Aug 24 10:11:24.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replication-controller 08/24/22 10:11:24.859
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:24.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:24.914
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1 08/24/22 10:11:24.917
Aug 24 10:11:24.942: INFO: Pod name my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Found 0 pods out of 1
Aug 24 10:11:29.960: INFO: Pod name my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Found 1 pods out of 1
Aug 24 10:11:29.960: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1" are running
Aug 24 10:11:29.960: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" in namespace "replication-controller-4658" to be "running"
Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz": Phase="Running", Reason="", readiness=true. Elapsed: 5.651349ms
Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" satisfied condition "running"
Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:24 +0000 UTC Reason: Message:}])
Aug 24 10:11:29.966: INFO: Trying to dial the pod
Aug 24 10:11:34.988: INFO: Controller my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Got expected result from replica 1 [my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz]: "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 24 10:11:34.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4658" for this suite. 08/24/22 10:11:34.997
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":169,"skipped":2915,"failed":0}
------------------------------
• [SLOW TEST] [10.174 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:24.835
    Aug 24 10:11:24.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replication-controller 08/24/22 10:11:24.859
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:24.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:24.914
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1 08/24/22 10:11:24.917
    Aug 24 10:11:24.942: INFO: Pod name my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Found 0 pods out of 1
    Aug 24 10:11:29.960: INFO: Pod name my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Found 1 pods out of 1
    Aug 24 10:11:29.960: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1" are running
    Aug 24 10:11:29.960: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" in namespace "replication-controller-4658" to be "running"
    Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz": Phase="Running", Reason="", readiness=true. Elapsed: 5.651349ms
    Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" satisfied condition "running"
    Aug 24 10:11:29.966: INFO: Pod "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:11:24 +0000 UTC Reason: Message:}])
    Aug 24 10:11:29.966: INFO: Trying to dial the pod
    Aug 24 10:11:34.988: INFO: Controller my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1: Got expected result from replica 1 [my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz]: "my-hostname-basic-6424c65e-94e5-4ecb-a661-c400fa96fba1-m6sgz", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 24 10:11:34.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4658" for this suite. 08/24/22 10:11:34.997
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:35.018
Aug 24 10:11:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename controllerrevisions 08/24/22 10:11:35.027
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:35.067
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:35.071
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-wjf6l-daemon-set" 08/24/22 10:11:35.104
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:11:35.114
Aug 24 10:11:35.127: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 0
Aug 24 10:11:35.127: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:11:36.142: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 1
Aug 24 10:11:36.142: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:11:37.140: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 3
Aug 24 10:11:37.140: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-wjf6l-daemon-set
STEP: Confirm DaemonSet "e2e-wjf6l-daemon-set" successfully created with "daemonset-name=e2e-wjf6l-daemon-set" label 08/24/22 10:11:37.15
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-wjf6l-daemon-set" 08/24/22 10:11:37.16
Aug 24 10:11:37.166: INFO: Located ControllerRevision: "e2e-wjf6l-daemon-set-76bc4c8cc6"
STEP: Patching ControllerRevision "e2e-wjf6l-daemon-set-76bc4c8cc6" 08/24/22 10:11:37.181
Aug 24 10:11:37.195: INFO: e2e-wjf6l-daemon-set-76bc4c8cc6 has been patched
STEP: Create a new ControllerRevision 08/24/22 10:11:37.195
Aug 24 10:11:37.203: INFO: Created ControllerRevision: e2e-wjf6l-daemon-set-6475ddb454
STEP: Confirm that there are two ControllerRevisions 08/24/22 10:11:37.203
Aug 24 10:11:37.203: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 24 10:11:37.209: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-wjf6l-daemon-set-76bc4c8cc6" 08/24/22 10:11:37.209
STEP: Confirm that there is only one ControllerRevision 08/24/22 10:11:37.221
Aug 24 10:11:37.221: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 24 10:11:37.227: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-wjf6l-daemon-set-6475ddb454" 08/24/22 10:11:37.232
Aug 24 10:11:37.251: INFO: e2e-wjf6l-daemon-set-6475ddb454 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 08/24/22 10:11:37.251
W0824 10:11:37.276011      14 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 08/24/22 10:11:37.276
Aug 24 10:11:37.276: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 24 10:11:38.285: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 24 10:11:38.293: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-wjf6l-daemon-set-6475ddb454=updated" 08/24/22 10:11:38.293
STEP: Confirm that there is only one ControllerRevision 08/24/22 10:11:38.306
Aug 24 10:11:38.306: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 24 10:11:38.312: INFO: Found 1 ControllerRevisions
Aug 24 10:11:38.318: INFO: ControllerRevision "e2e-wjf6l-daemon-set-6bd6855d47" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-wjf6l-daemon-set" 08/24/22 10:11:38.324
STEP: deleting DaemonSet.extensions e2e-wjf6l-daemon-set in namespace controllerrevisions-7435, will wait for the garbage collector to delete the pods 08/24/22 10:11:38.324
Aug 24 10:11:38.394: INFO: Deleting DaemonSet.extensions e2e-wjf6l-daemon-set took: 12.916ms
Aug 24 10:11:38.495: INFO: Terminating DaemonSet.extensions e2e-wjf6l-daemon-set pods took: 100.633438ms
Aug 24 10:11:40.107: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 0
Aug 24 10:11:40.107: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-wjf6l-daemon-set
Aug 24 10:11:40.111: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19659"},"items":null}

Aug 24 10:11:40.142: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19659"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:11:40.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-7435" for this suite. 08/24/22 10:11:40.21
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":170,"skipped":2918,"failed":0}
------------------------------
• [SLOW TEST] [5.210 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:35.018
    Aug 24 10:11:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename controllerrevisions 08/24/22 10:11:35.027
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:35.067
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:35.071
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-wjf6l-daemon-set" 08/24/22 10:11:35.104
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:11:35.114
    Aug 24 10:11:35.127: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 0
    Aug 24 10:11:35.127: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:11:36.142: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 1
    Aug 24 10:11:36.142: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:11:37.140: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 3
    Aug 24 10:11:37.140: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-wjf6l-daemon-set
    STEP: Confirm DaemonSet "e2e-wjf6l-daemon-set" successfully created with "daemonset-name=e2e-wjf6l-daemon-set" label 08/24/22 10:11:37.15
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-wjf6l-daemon-set" 08/24/22 10:11:37.16
    Aug 24 10:11:37.166: INFO: Located ControllerRevision: "e2e-wjf6l-daemon-set-76bc4c8cc6"
    STEP: Patching ControllerRevision "e2e-wjf6l-daemon-set-76bc4c8cc6" 08/24/22 10:11:37.181
    Aug 24 10:11:37.195: INFO: e2e-wjf6l-daemon-set-76bc4c8cc6 has been patched
    STEP: Create a new ControllerRevision 08/24/22 10:11:37.195
    Aug 24 10:11:37.203: INFO: Created ControllerRevision: e2e-wjf6l-daemon-set-6475ddb454
    STEP: Confirm that there are two ControllerRevisions 08/24/22 10:11:37.203
    Aug 24 10:11:37.203: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 24 10:11:37.209: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-wjf6l-daemon-set-76bc4c8cc6" 08/24/22 10:11:37.209
    STEP: Confirm that there is only one ControllerRevision 08/24/22 10:11:37.221
    Aug 24 10:11:37.221: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 24 10:11:37.227: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-wjf6l-daemon-set-6475ddb454" 08/24/22 10:11:37.232
    Aug 24 10:11:37.251: INFO: e2e-wjf6l-daemon-set-6475ddb454 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 08/24/22 10:11:37.251
    W0824 10:11:37.276011      14 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 08/24/22 10:11:37.276
    Aug 24 10:11:37.276: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 24 10:11:38.285: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 24 10:11:38.293: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-wjf6l-daemon-set-6475ddb454=updated" 08/24/22 10:11:38.293
    STEP: Confirm that there is only one ControllerRevision 08/24/22 10:11:38.306
    Aug 24 10:11:38.306: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 24 10:11:38.312: INFO: Found 1 ControllerRevisions
    Aug 24 10:11:38.318: INFO: ControllerRevision "e2e-wjf6l-daemon-set-6bd6855d47" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-wjf6l-daemon-set" 08/24/22 10:11:38.324
    STEP: deleting DaemonSet.extensions e2e-wjf6l-daemon-set in namespace controllerrevisions-7435, will wait for the garbage collector to delete the pods 08/24/22 10:11:38.324
    Aug 24 10:11:38.394: INFO: Deleting DaemonSet.extensions e2e-wjf6l-daemon-set took: 12.916ms
    Aug 24 10:11:38.495: INFO: Terminating DaemonSet.extensions e2e-wjf6l-daemon-set pods took: 100.633438ms
    Aug 24 10:11:40.107: INFO: Number of nodes with available pods controlled by daemonset e2e-wjf6l-daemon-set: 0
    Aug 24 10:11:40.107: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-wjf6l-daemon-set
    Aug 24 10:11:40.111: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19659"},"items":null}

    Aug 24 10:11:40.142: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19659"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:11:40.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-7435" for this suite. 08/24/22 10:11:40.21
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:40.231
Aug 24 10:11:40.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:11:40.234
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:40.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:40.265
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-bc295f75-4981-4317-8b46-b02978381554 08/24/22 10:11:40.27
STEP: Creating a pod to test consume secrets 08/24/22 10:11:40.278
Aug 24 10:11:40.289: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370" in namespace "projected-4396" to be "Succeeded or Failed"
Aug 24 10:11:40.295: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Pending", Reason="", readiness=false. Elapsed: 5.750923ms
Aug 24 10:11:42.304: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014552321s
Aug 24 10:11:44.302: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012820639s
STEP: Saw pod success 08/24/22 10:11:44.302
Aug 24 10:11:44.302: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370" satisfied condition "Succeeded or Failed"
Aug 24 10:11:44.307: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:11:44.317
Aug 24 10:11:44.337: INFO: Waiting for pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 to disappear
Aug 24 10:11:44.342: INFO: Pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:11:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4396" for this suite. 08/24/22 10:11:44.349
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":171,"skipped":2922,"failed":0}
------------------------------
• [4.165 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:40.231
    Aug 24 10:11:40.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:11:40.234
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:40.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:40.265
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-bc295f75-4981-4317-8b46-b02978381554 08/24/22 10:11:40.27
    STEP: Creating a pod to test consume secrets 08/24/22 10:11:40.278
    Aug 24 10:11:40.289: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370" in namespace "projected-4396" to be "Succeeded or Failed"
    Aug 24 10:11:40.295: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Pending", Reason="", readiness=false. Elapsed: 5.750923ms
    Aug 24 10:11:42.304: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014552321s
    Aug 24 10:11:44.302: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012820639s
    STEP: Saw pod success 08/24/22 10:11:44.302
    Aug 24 10:11:44.302: INFO: Pod "pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370" satisfied condition "Succeeded or Failed"
    Aug 24 10:11:44.307: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:11:44.317
    Aug 24 10:11:44.337: INFO: Waiting for pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 to disappear
    Aug 24 10:11:44.342: INFO: Pod pod-projected-secrets-6d11646c-343f-48c5-9fc9-04bc08c73370 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:11:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4396" for this suite. 08/24/22 10:11:44.349
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:44.403
Aug 24 10:11:44.403: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:11:44.405
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:44.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:44.443
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 08/24/22 10:11:44.45
Aug 24 10:11:44.451: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug 24 10:11:44.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:44.929: INFO: stderr: ""
Aug 24 10:11:44.929: INFO: stdout: "service/agnhost-replica created\n"
Aug 24 10:11:44.930: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug 24 10:11:44.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:46.422: INFO: stderr: ""
Aug 24 10:11:46.422: INFO: stdout: "service/agnhost-primary created\n"
Aug 24 10:11:46.422: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 24 10:11:46.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:46.861: INFO: stderr: ""
Aug 24 10:11:46.861: INFO: stdout: "service/frontend created\n"
Aug 24 10:11:46.861: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug 24 10:11:46.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:47.352: INFO: stderr: ""
Aug 24 10:11:47.352: INFO: stdout: "deployment.apps/frontend created\n"
Aug 24 10:11:47.352: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 24 10:11:47.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:48.055: INFO: stderr: ""
Aug 24 10:11:48.055: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug 24 10:11:48.055: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 24 10:11:48.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
Aug 24 10:11:48.642: INFO: stderr: ""
Aug 24 10:11:48.642: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 08/24/22 10:11:48.642
Aug 24 10:11:48.642: INFO: Waiting for all frontend pods to be Running.
Aug 24 10:11:53.695: INFO: Waiting for frontend to serve content.
Aug 24 10:11:53.718: INFO: Trying to add a new entry to the guestbook.
Aug 24 10:11:53.745: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 08/24/22 10:11:53.767
Aug 24 10:11:53.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:53.937: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:53.937: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 08/24/22 10:11:53.937
Aug 24 10:11:53.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:54.110: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:54.110: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/24/22 10:11:54.11
Aug 24 10:11:54.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:54.300: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:54.301: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/24/22 10:11:54.301
Aug 24 10:11:54.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:54.420: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:54.420: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/24/22 10:11:54.42
Aug 24 10:11:54.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:54.604: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:54.604: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/24/22 10:11:54.604
Aug 24 10:11:54.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
Aug 24 10:11:54.902: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:11:54.902: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:11:54.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3232" for this suite. 08/24/22 10:11:54.93
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":172,"skipped":2932,"failed":0}
------------------------------
• [SLOW TEST] [10.615 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:44.403
    Aug 24 10:11:44.403: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:11:44.405
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:44.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:44.443
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 08/24/22 10:11:44.45
    Aug 24 10:11:44.451: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Aug 24 10:11:44.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:44.929: INFO: stderr: ""
    Aug 24 10:11:44.929: INFO: stdout: "service/agnhost-replica created\n"
    Aug 24 10:11:44.930: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Aug 24 10:11:44.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:46.422: INFO: stderr: ""
    Aug 24 10:11:46.422: INFO: stdout: "service/agnhost-primary created\n"
    Aug 24 10:11:46.422: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Aug 24 10:11:46.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:46.861: INFO: stderr: ""
    Aug 24 10:11:46.861: INFO: stdout: "service/frontend created\n"
    Aug 24 10:11:46.861: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Aug 24 10:11:46.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:47.352: INFO: stderr: ""
    Aug 24 10:11:47.352: INFO: stdout: "deployment.apps/frontend created\n"
    Aug 24 10:11:47.352: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 24 10:11:47.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:48.055: INFO: stderr: ""
    Aug 24 10:11:48.055: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Aug 24 10:11:48.055: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 24 10:11:48.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 create -f -'
    Aug 24 10:11:48.642: INFO: stderr: ""
    Aug 24 10:11:48.642: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 08/24/22 10:11:48.642
    Aug 24 10:11:48.642: INFO: Waiting for all frontend pods to be Running.
    Aug 24 10:11:53.695: INFO: Waiting for frontend to serve content.
    Aug 24 10:11:53.718: INFO: Trying to add a new entry to the guestbook.
    Aug 24 10:11:53.745: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 08/24/22 10:11:53.767
    Aug 24 10:11:53.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:53.937: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:53.937: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 08/24/22 10:11:53.937
    Aug 24 10:11:53.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:54.110: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:54.110: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/24/22 10:11:54.11
    Aug 24 10:11:54.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:54.300: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:54.301: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/24/22 10:11:54.301
    Aug 24 10:11:54.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:54.420: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:54.420: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/24/22 10:11:54.42
    Aug 24 10:11:54.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:54.604: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:54.604: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/24/22 10:11:54.604
    Aug 24 10:11:54.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-3232 delete --grace-period=0 --force -f -'
    Aug 24 10:11:54.902: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:11:54.902: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:11:54.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3232" for this suite. 08/24/22 10:11:54.93
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:11:55.023
Aug 24 10:11:55.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:11:55.027
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:55.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:55.08
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 08/24/22 10:11:55.084
STEP: waiting for pod running 08/24/22 10:11:55.123
Aug 24 10:11:55.123: INFO: Waiting up to 2m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163" to be "running"
Aug 24 10:11:55.133: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013916ms
Aug 24 10:11:57.143: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.020203057s
Aug 24 10:11:57.143: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" satisfied condition "running"
STEP: creating a file in subpath 08/24/22 10:11:57.144
Aug 24 10:11:57.157: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3163 PodName:var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:11:57.157: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:11:57.159: INFO: ExecWithOptions: Clientset creation
Aug 24 10:11:57.159: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3163/pods/var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 08/24/22 10:11:57.356
Aug 24 10:11:57.361: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3163 PodName:var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:11:57.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:11:57.363: INFO: ExecWithOptions: Clientset creation
Aug 24 10:11:57.363: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3163/pods/var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 08/24/22 10:11:57.492
Aug 24 10:11:58.018: INFO: Successfully updated pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d"
STEP: waiting for annotated pod running 08/24/22 10:11:58.018
Aug 24 10:11:58.018: INFO: Waiting up to 2m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163" to be "running"
Aug 24 10:11:58.024: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Running", Reason="", readiness=true. Elapsed: 5.958267ms
Aug 24 10:11:58.025: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" satisfied condition "running"
STEP: deleting the pod gracefully 08/24/22 10:11:58.025
Aug 24 10:11:58.025: INFO: Deleting pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163"
Aug 24 10:11:58.035: INFO: Wait up to 5m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:12:32.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3163" for this suite. 08/24/22 10:12:32.067
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":173,"skipped":2941,"failed":0}
------------------------------
• [SLOW TEST] [37.059 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:11:55.023
    Aug 24 10:11:55.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:11:55.027
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:11:55.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:11:55.08
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 08/24/22 10:11:55.084
    STEP: waiting for pod running 08/24/22 10:11:55.123
    Aug 24 10:11:55.123: INFO: Waiting up to 2m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163" to be "running"
    Aug 24 10:11:55.133: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013916ms
    Aug 24 10:11:57.143: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.020203057s
    Aug 24 10:11:57.143: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" satisfied condition "running"
    STEP: creating a file in subpath 08/24/22 10:11:57.144
    Aug 24 10:11:57.157: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3163 PodName:var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:11:57.157: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:11:57.159: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:11:57.159: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3163/pods/var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 08/24/22 10:11:57.356
    Aug 24 10:11:57.361: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3163 PodName:var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:11:57.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:11:57.363: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:11:57.363: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3163/pods/var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 08/24/22 10:11:57.492
    Aug 24 10:11:58.018: INFO: Successfully updated pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d"
    STEP: waiting for annotated pod running 08/24/22 10:11:58.018
    Aug 24 10:11:58.018: INFO: Waiting up to 2m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163" to be "running"
    Aug 24 10:11:58.024: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d": Phase="Running", Reason="", readiness=true. Elapsed: 5.958267ms
    Aug 24 10:11:58.025: INFO: Pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" satisfied condition "running"
    STEP: deleting the pod gracefully 08/24/22 10:11:58.025
    Aug 24 10:11:58.025: INFO: Deleting pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" in namespace "var-expansion-3163"
    Aug 24 10:11:58.035: INFO: Wait up to 5m0s for pod "var-expansion-5c2db098-705f-44b1-938a-5d1018664b2d" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:12:32.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3163" for this suite. 08/24/22 10:12:32.067
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:32.091
Aug 24 10:12:32.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 10:12:32.095
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:32.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:32.14
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Aug 24 10:12:32.144: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 24 10:12:32.162: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 10:12:37.169: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 10:12:37.169
Aug 24 10:12:37.170: INFO: Creating deployment "test-rolling-update-deployment"
Aug 24 10:12:37.183: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 24 10:12:37.193: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 24 10:12:39.211: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 24 10:12:39.219: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 10:12:39.241: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7135  b3fbee68-9516-43b8-9897-3a39241eaf1b 20091 1 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004241c18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 10:12:37 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-08-24 10:12:38 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 10:12:39.249: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7135  b19d3761-d8ee-4012-ba23-68d622a5f596 20081 1 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b3fbee68-9516-43b8-9897-3a39241eaf1b 0xc004272207 0xc004272208}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3fbee68-9516-43b8-9897-3a39241eaf1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042722d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 10:12:39.249: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 24 10:12:39.249: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7135  f7b4d80c-ae96-4073-a999-724651158000 20090 2 2022-08-24 10:12:32 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b3fbee68-9516-43b8-9897-3a39241eaf1b 0xc0042720a7 0xc0042720a8}] [] [{e2e.test Update apps/v1 2022-08-24 10:12:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3fbee68-9516-43b8-9897-3a39241eaf1b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004272198 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 10:12:39.257: INFO: Pod "test-rolling-update-deployment-78f575d8ff-z9cpw" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-z9cpw test-rolling-update-deployment-78f575d8ff- deployment-7135  da7bfb45-ea33-42ce-9a0d-fa81ffa3d437 20080 0 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff b19d3761-d8ee-4012-ba23-68d622a5f596 0xc004272847 0xc004272848}] [] [{kube-controller-manager Update v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b19d3761-d8ee-4012-ba23-68d622a5f596\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v846d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v846d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.234,StartTime:2022-08-24 10:12:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 10:12:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787,ContainerID:cri-o://3a5d98b9bee9057d82f6df960026221214ad65d1285ea16e54ebc38f75579922,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 10:12:39.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7135" for this suite. 08/24/22 10:12:39.274
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":174,"skipped":2947,"failed":0}
------------------------------
• [SLOW TEST] [7.203 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:32.091
    Aug 24 10:12:32.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 10:12:32.095
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:32.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:32.14
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Aug 24 10:12:32.144: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Aug 24 10:12:32.162: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 24 10:12:37.169: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 10:12:37.169
    Aug 24 10:12:37.170: INFO: Creating deployment "test-rolling-update-deployment"
    Aug 24 10:12:37.183: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Aug 24 10:12:37.193: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Aug 24 10:12:39.211: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Aug 24 10:12:39.219: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 10:12:39.241: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7135  b3fbee68-9516-43b8-9897-3a39241eaf1b 20091 1 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004241c18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 10:12:37 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-08-24 10:12:38 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 24 10:12:39.249: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7135  b19d3761-d8ee-4012-ba23-68d622a5f596 20081 1 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b3fbee68-9516-43b8-9897-3a39241eaf1b 0xc004272207 0xc004272208}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3fbee68-9516-43b8-9897-3a39241eaf1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042722d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 10:12:39.249: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Aug 24 10:12:39.249: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7135  f7b4d80c-ae96-4073-a999-724651158000 20090 2 2022-08-24 10:12:32 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b3fbee68-9516-43b8-9897-3a39241eaf1b 0xc0042720a7 0xc0042720a8}] [] [{e2e.test Update apps/v1 2022-08-24 10:12:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3fbee68-9516-43b8-9897-3a39241eaf1b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004272198 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 10:12:39.257: INFO: Pod "test-rolling-update-deployment-78f575d8ff-z9cpw" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-z9cpw test-rolling-update-deployment-78f575d8ff- deployment-7135  da7bfb45-ea33-42ce-9a0d-fa81ffa3d437 20080 0 2022-08-24 10:12:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff b19d3761-d8ee-4012-ba23-68d622a5f596 0xc004272847 0xc004272848}] [] [{kube-controller-manager Update v1 2022-08-24 10:12:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b19d3761-d8ee-4012-ba23-68d622a5f596\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:12:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v846d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v846d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:12:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.234,StartTime:2022-08-24 10:12:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 10:12:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787,ContainerID:cri-o://3a5d98b9bee9057d82f6df960026221214ad65d1285ea16e54ebc38f75579922,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 10:12:39.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7135" for this suite. 08/24/22 10:12:39.274
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:39.299
Aug 24 10:12:39.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:12:39.303
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:39.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:39.413
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-aa3f4207-f093-421a-abbb-2996e6318fc6 08/24/22 10:12:39.417
STEP: Creating a pod to test consume configMaps 08/24/22 10:12:39.487
Aug 24 10:12:39.511: INFO: Waiting up to 5m0s for pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695" in namespace "configmap-3268" to be "Succeeded or Failed"
Aug 24 10:12:39.518: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Pending", Reason="", readiness=false. Elapsed: 6.776539ms
Aug 24 10:12:41.540: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029079621s
Aug 24 10:12:43.526: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014680313s
STEP: Saw pod success 08/24/22 10:12:43.526
Aug 24 10:12:43.526: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695" satisfied condition "Succeeded or Failed"
Aug 24 10:12:43.533: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:12:43.549
Aug 24 10:12:43.566: INFO: Waiting for pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 to disappear
Aug 24 10:12:43.574: INFO: Pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:12:43.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3268" for this suite. 08/24/22 10:12:43.582
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":175,"skipped":2954,"failed":0}
------------------------------
• [4.293 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:39.299
    Aug 24 10:12:39.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:12:39.303
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:39.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:39.413
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-aa3f4207-f093-421a-abbb-2996e6318fc6 08/24/22 10:12:39.417
    STEP: Creating a pod to test consume configMaps 08/24/22 10:12:39.487
    Aug 24 10:12:39.511: INFO: Waiting up to 5m0s for pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695" in namespace "configmap-3268" to be "Succeeded or Failed"
    Aug 24 10:12:39.518: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Pending", Reason="", readiness=false. Elapsed: 6.776539ms
    Aug 24 10:12:41.540: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029079621s
    Aug 24 10:12:43.526: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014680313s
    STEP: Saw pod success 08/24/22 10:12:43.526
    Aug 24 10:12:43.526: INFO: Pod "pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695" satisfied condition "Succeeded or Failed"
    Aug 24 10:12:43.533: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:12:43.549
    Aug 24 10:12:43.566: INFO: Waiting for pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 to disappear
    Aug 24 10:12:43.574: INFO: Pod pod-configmaps-e330cb94-ebb4-44f8-bc7f-a1ef6ba9c695 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:12:43.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3268" for this suite. 08/24/22 10:12:43.582
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:43.595
Aug 24 10:12:43.595: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption 08/24/22 10:12:43.609
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:43.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:43.638
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 08/24/22 10:12:43.652
STEP: Waiting for all pods to be running 08/24/22 10:12:45.739
Aug 24 10:12:45.758: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 24 10:12:47.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1278" for this suite. 08/24/22 10:12:47.792
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":176,"skipped":2962,"failed":0}
------------------------------
• [4.215 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:43.595
    Aug 24 10:12:43.595: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption 08/24/22 10:12:43.609
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:43.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:43.638
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 08/24/22 10:12:43.652
    STEP: Waiting for all pods to be running 08/24/22 10:12:45.739
    Aug 24 10:12:45.758: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 24 10:12:47.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1278" for this suite. 08/24/22 10:12:47.792
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:47.813
Aug 24 10:12:47.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename events 08/24/22 10:12:47.816
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:47.842
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:47.846
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 08/24/22 10:12:47.85
Aug 24 10:12:47.861: INFO: created test-event-1
Aug 24 10:12:47.869: INFO: created test-event-2
Aug 24 10:12:47.877: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 08/24/22 10:12:47.877
STEP: delete collection of events 08/24/22 10:12:47.882
Aug 24 10:12:47.883: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/24/22 10:12:47.923
Aug 24 10:12:47.924: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 24 10:12:47.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8752" for this suite. 08/24/22 10:12:47.939
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":177,"skipped":2963,"failed":0}
------------------------------
• [0.134 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:47.813
    Aug 24 10:12:47.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename events 08/24/22 10:12:47.816
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:47.842
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:47.846
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 08/24/22 10:12:47.85
    Aug 24 10:12:47.861: INFO: created test-event-1
    Aug 24 10:12:47.869: INFO: created test-event-2
    Aug 24 10:12:47.877: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 08/24/22 10:12:47.877
    STEP: delete collection of events 08/24/22 10:12:47.882
    Aug 24 10:12:47.883: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/24/22 10:12:47.923
    Aug 24 10:12:47.924: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 24 10:12:47.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8752" for this suite. 08/24/22 10:12:47.939
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:47.955
Aug 24 10:12:47.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption 08/24/22 10:12:47.957
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:47.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:47.988
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 08/24/22 10:12:47.992
STEP: Waiting for the pdb to be processed 08/24/22 10:12:48.005
STEP: First trying to evict a pod which shouldn't be evictable 08/24/22 10:12:50.025
STEP: Waiting for all pods to be running 08/24/22 10:12:50.025
Aug 24 10:12:50.030: INFO: pods: 0 < 3
STEP: locating a running pod 08/24/22 10:12:52.037
STEP: Updating the pdb to allow a pod to be evicted 08/24/22 10:12:52.053
STEP: Waiting for the pdb to be processed 08/24/22 10:12:52.065
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/24/22 10:12:52.073
STEP: Waiting for all pods to be running 08/24/22 10:12:52.074
STEP: Waiting for the pdb to observed all healthy pods 08/24/22 10:12:52.081
STEP: Patching the pdb to disallow a pod to be evicted 08/24/22 10:12:52.113
STEP: Waiting for the pdb to be processed 08/24/22 10:12:52.142
STEP: Waiting for all pods to be running 08/24/22 10:12:54.161
STEP: locating a running pod 08/24/22 10:12:54.17
STEP: Deleting the pdb to allow a pod to be evicted 08/24/22 10:12:54.189
STEP: Waiting for the pdb to be deleted 08/24/22 10:12:54.198
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/24/22 10:12:54.206
STEP: Waiting for all pods to be running 08/24/22 10:12:54.206
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 24 10:12:54.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1705" for this suite. 08/24/22 10:12:54.239
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":178,"skipped":2970,"failed":0}
------------------------------
• [SLOW TEST] [6.299 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:47.955
    Aug 24 10:12:47.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption 08/24/22 10:12:47.957
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:47.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:47.988
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 08/24/22 10:12:47.992
    STEP: Waiting for the pdb to be processed 08/24/22 10:12:48.005
    STEP: First trying to evict a pod which shouldn't be evictable 08/24/22 10:12:50.025
    STEP: Waiting for all pods to be running 08/24/22 10:12:50.025
    Aug 24 10:12:50.030: INFO: pods: 0 < 3
    STEP: locating a running pod 08/24/22 10:12:52.037
    STEP: Updating the pdb to allow a pod to be evicted 08/24/22 10:12:52.053
    STEP: Waiting for the pdb to be processed 08/24/22 10:12:52.065
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/24/22 10:12:52.073
    STEP: Waiting for all pods to be running 08/24/22 10:12:52.074
    STEP: Waiting for the pdb to observed all healthy pods 08/24/22 10:12:52.081
    STEP: Patching the pdb to disallow a pod to be evicted 08/24/22 10:12:52.113
    STEP: Waiting for the pdb to be processed 08/24/22 10:12:52.142
    STEP: Waiting for all pods to be running 08/24/22 10:12:54.161
    STEP: locating a running pod 08/24/22 10:12:54.17
    STEP: Deleting the pdb to allow a pod to be evicted 08/24/22 10:12:54.189
    STEP: Waiting for the pdb to be deleted 08/24/22 10:12:54.198
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/24/22 10:12:54.206
    STEP: Waiting for all pods to be running 08/24/22 10:12:54.206
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 24 10:12:54.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1705" for this suite. 08/24/22 10:12:54.239
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:54.255
Aug 24 10:12:54.255: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 10:12:54.259
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:54.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:54.298
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Aug 24 10:12:54.373: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"aa2029e6-12af-47e5-b44e-318cbdca4506", Controller:(*bool)(0xc003b51b0e), BlockOwnerDeletion:(*bool)(0xc003b51b0f)}}
Aug 24 10:12:54.403: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"80fde7a2-4e13-4f83-8ecb-d438bf1f4aed", Controller:(*bool)(0xc003b51d7a), BlockOwnerDeletion:(*bool)(0xc003b51d7b)}}
Aug 24 10:12:54.415: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"00225200-fe26-4243-b2db-285430cc8452", Controller:(*bool)(0xc004d64096), BlockOwnerDeletion:(*bool)(0xc004d64097)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 10:12:59.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3113" for this suite. 08/24/22 10:12:59.449
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":179,"skipped":2976,"failed":0}
------------------------------
• [SLOW TEST] [5.209 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:54.255
    Aug 24 10:12:54.255: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 10:12:54.259
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:54.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:54.298
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Aug 24 10:12:54.373: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"aa2029e6-12af-47e5-b44e-318cbdca4506", Controller:(*bool)(0xc003b51b0e), BlockOwnerDeletion:(*bool)(0xc003b51b0f)}}
    Aug 24 10:12:54.403: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"80fde7a2-4e13-4f83-8ecb-d438bf1f4aed", Controller:(*bool)(0xc003b51d7a), BlockOwnerDeletion:(*bool)(0xc003b51d7b)}}
    Aug 24 10:12:54.415: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"00225200-fe26-4243-b2db-285430cc8452", Controller:(*bool)(0xc004d64096), BlockOwnerDeletion:(*bool)(0xc004d64097)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 10:12:59.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3113" for this suite. 08/24/22 10:12:59.449
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:12:59.471
Aug 24 10:12:59.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:12:59.473
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:59.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:59.514
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4228 08/24/22 10:12:59.517
STEP: changing the ExternalName service to type=NodePort 08/24/22 10:12:59.528
STEP: creating replication controller externalname-service in namespace services-4228 08/24/22 10:12:59.581
I0824 10:12:59.621486      14 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4228, replica count: 2
I0824 10:13:02.672915      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:13:02.673: INFO: Creating new exec pod
Aug 24 10:13:02.684: INFO: Waiting up to 5m0s for pod "execpodv9rwg" in namespace "services-4228" to be "running"
Aug 24 10:13:02.691: INFO: Pod "execpodv9rwg": Phase="Pending", Reason="", readiness=false. Elapsed: 7.650733ms
Aug 24 10:13:04.700: INFO: Pod "execpodv9rwg": Phase="Running", Reason="", readiness=true. Elapsed: 2.015951511s
Aug 24 10:13:04.700: INFO: Pod "execpodv9rwg" satisfied condition "running"
Aug 24 10:13:05.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 10:13:06.046: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 10:13:06.046: INFO: stdout: "externalname-service-dj5px"
Aug 24 10:13:06.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.30.185 80'
Aug 24 10:13:06.285: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.30.185 80\nConnection to 10.233.30.185 80 port [tcp/http] succeeded!\n"
Aug 24 10:13:06.285: INFO: stdout: ""
Aug 24 10:13:07.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.30.185 80'
Aug 24 10:13:07.693: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.30.185 80\nConnection to 10.233.30.185 80 port [tcp/http] succeeded!\n"
Aug 24 10:13:07.693: INFO: stdout: "externalname-service-6d42m"
Aug 24 10:13:07.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32696'
Aug 24 10:13:07.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32696\nConnection to 192.168.121.54 32696 port [tcp/*] succeeded!\n"
Aug 24 10:13:07.972: INFO: stdout: "externalname-service-dj5px"
Aug 24 10:13:07.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 32696'
Aug 24 10:13:08.229: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 32696\nConnection to 192.168.121.119 32696 port [tcp/*] succeeded!\n"
Aug 24 10:13:08.229: INFO: stdout: "externalname-service-dj5px"
Aug 24 10:13:08.229: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:13:08.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4228" for this suite. 08/24/22 10:13:08.316
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":180,"skipped":3013,"failed":0}
------------------------------
• [SLOW TEST] [8.856 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:12:59.471
    Aug 24 10:12:59.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:12:59.473
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:12:59.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:12:59.514
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4228 08/24/22 10:12:59.517
    STEP: changing the ExternalName service to type=NodePort 08/24/22 10:12:59.528
    STEP: creating replication controller externalname-service in namespace services-4228 08/24/22 10:12:59.581
    I0824 10:12:59.621486      14 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4228, replica count: 2
    I0824 10:13:02.672915      14 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:13:02.673: INFO: Creating new exec pod
    Aug 24 10:13:02.684: INFO: Waiting up to 5m0s for pod "execpodv9rwg" in namespace "services-4228" to be "running"
    Aug 24 10:13:02.691: INFO: Pod "execpodv9rwg": Phase="Pending", Reason="", readiness=false. Elapsed: 7.650733ms
    Aug 24 10:13:04.700: INFO: Pod "execpodv9rwg": Phase="Running", Reason="", readiness=true. Elapsed: 2.015951511s
    Aug 24 10:13:04.700: INFO: Pod "execpodv9rwg" satisfied condition "running"
    Aug 24 10:13:05.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 24 10:13:06.046: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 24 10:13:06.046: INFO: stdout: "externalname-service-dj5px"
    Aug 24 10:13:06.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.30.185 80'
    Aug 24 10:13:06.285: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.30.185 80\nConnection to 10.233.30.185 80 port [tcp/http] succeeded!\n"
    Aug 24 10:13:06.285: INFO: stdout: ""
    Aug 24 10:13:07.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.30.185 80'
    Aug 24 10:13:07.693: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.30.185 80\nConnection to 10.233.30.185 80 port [tcp/http] succeeded!\n"
    Aug 24 10:13:07.693: INFO: stdout: "externalname-service-6d42m"
    Aug 24 10:13:07.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32696'
    Aug 24 10:13:07.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32696\nConnection to 192.168.121.54 32696 port [tcp/*] succeeded!\n"
    Aug 24 10:13:07.972: INFO: stdout: "externalname-service-dj5px"
    Aug 24 10:13:07.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4228 exec execpodv9rwg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 32696'
    Aug 24 10:13:08.229: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 32696\nConnection to 192.168.121.119 32696 port [tcp/*] succeeded!\n"
    Aug 24 10:13:08.229: INFO: stdout: "externalname-service-dj5px"
    Aug 24 10:13:08.229: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:13:08.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4228" for this suite. 08/24/22 10:13:08.316
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:13:08.329
Aug 24 10:13:08.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 10:13:08.335
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:08.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:08.392
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 08/24/22 10:13:08.395
STEP: Wait for the Deployment to create new ReplicaSet 08/24/22 10:13:08.406
STEP: delete the deployment 08/24/22 10:13:08.934
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/24/22 10:13:08.949
STEP: Gathering metrics 08/24/22 10:13:09.509
Aug 24 10:13:09.562: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 10:13:09.573: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.169381ms
Aug 24 10:13:09.573: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 10:13:09.573: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 10:13:09.716: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 10:13:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5022" for this suite. 08/24/22 10:13:09.726
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":181,"skipped":3029,"failed":0}
------------------------------
• [1.420 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:13:08.329
    Aug 24 10:13:08.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 10:13:08.335
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:08.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:08.392
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 08/24/22 10:13:08.395
    STEP: Wait for the Deployment to create new ReplicaSet 08/24/22 10:13:08.406
    STEP: delete the deployment 08/24/22 10:13:08.934
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/24/22 10:13:08.949
    STEP: Gathering metrics 08/24/22 10:13:09.509
    Aug 24 10:13:09.562: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 10:13:09.573: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.169381ms
    Aug 24 10:13:09.573: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 10:13:09.573: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 10:13:09.716: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 10:13:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5022" for this suite. 08/24/22 10:13:09.726
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:13:09.751
Aug 24 10:13:09.751: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:13:09.753
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:09.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:09.787
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:13:09.798
Aug 24 10:13:09.819: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1966" to be "running and ready"
Aug 24 10:13:09.827: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.531244ms
Aug 24 10:13:09.827: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:13:11.836: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.017299767s
Aug 24 10:13:11.836: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 24 10:13:11.836: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 08/24/22 10:13:11.841
Aug 24 10:13:11.852: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1966" to be "running and ready"
Aug 24 10:13:11.861: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.448849ms
Aug 24 10:13:11.861: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:13:13.873: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020379864s
Aug 24 10:13:13.873: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Aug 24 10:13:13.873: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/24/22 10:13:13.883
STEP: delete the pod with lifecycle hook 08/24/22 10:13:13.897
Aug 24 10:13:13.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 10:13:13.928: INFO: Pod pod-with-poststart-http-hook still exists
Aug 24 10:13:15.929: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 10:13:15.934: INFO: Pod pod-with-poststart-http-hook still exists
Aug 24 10:13:17.929: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 10:13:17.936: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 24 10:13:17.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1966" for this suite. 08/24/22 10:13:17.945
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":182,"skipped":3038,"failed":0}
------------------------------
• [SLOW TEST] [8.207 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:13:09.751
    Aug 24 10:13:09.751: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:13:09.753
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:09.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:09.787
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:13:09.798
    Aug 24 10:13:09.819: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1966" to be "running and ready"
    Aug 24 10:13:09.827: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.531244ms
    Aug 24 10:13:09.827: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:13:11.836: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.017299767s
    Aug 24 10:13:11.836: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 24 10:13:11.836: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 08/24/22 10:13:11.841
    Aug 24 10:13:11.852: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1966" to be "running and ready"
    Aug 24 10:13:11.861: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.448849ms
    Aug 24 10:13:11.861: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:13:13.873: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020379864s
    Aug 24 10:13:13.873: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Aug 24 10:13:13.873: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/24/22 10:13:13.883
    STEP: delete the pod with lifecycle hook 08/24/22 10:13:13.897
    Aug 24 10:13:13.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 24 10:13:13.928: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 24 10:13:15.929: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 24 10:13:15.934: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 24 10:13:17.929: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 24 10:13:17.936: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 24 10:13:17.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1966" for this suite. 08/24/22 10:13:17.945
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:13:17.971
Aug 24 10:13:17.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:13:17.973
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:17.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:18.004
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 08/24/22 10:13:18.012
STEP: submitting the pod to kubernetes 08/24/22 10:13:18.012
STEP: verifying QOS class is set on the pod 08/24/22 10:13:18.029
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Aug 24 10:13:18.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6292" for this suite. 08/24/22 10:13:18.051
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":183,"skipped":3088,"failed":0}
------------------------------
• [0.099 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:13:17.971
    Aug 24 10:13:17.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:13:17.973
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:17.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:18.004
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 08/24/22 10:13:18.012
    STEP: submitting the pod to kubernetes 08/24/22 10:13:18.012
    STEP: verifying QOS class is set on the pod 08/24/22 10:13:18.029
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Aug 24 10:13:18.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6292" for this suite. 08/24/22 10:13:18.051
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:13:18.08
Aug 24 10:13:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:13:18.082
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:18.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:18.115
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-4819 08/24/22 10:13:18.119
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[] 08/24/22 10:13:18.141
Aug 24 10:13:18.160: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4819 08/24/22 10:13:18.16
Aug 24 10:13:18.183: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4819" to be "running and ready"
Aug 24 10:13:18.192: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.882025ms
Aug 24 10:13:18.192: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:13:20.201: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.018366712s
Aug 24 10:13:20.201: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 24 10:13:20.201: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod1:[100]] 08/24/22 10:13:20.213
Aug 24 10:13:20.240: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4819 08/24/22 10:13:20.241
Aug 24 10:13:20.254: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4819" to be "running and ready"
Aug 24 10:13:20.260: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055276ms
Aug 24 10:13:20.261: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:13:22.272: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017818279s
Aug 24 10:13:22.273: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 24 10:13:22.273: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod1:[100] pod2:[101]] 08/24/22 10:13:22.281
Aug 24 10:13:22.307: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 08/24/22 10:13:22.307
Aug 24 10:13:22.308: INFO: Creating new exec pod
Aug 24 10:13:22.319: INFO: Waiting up to 5m0s for pod "execpodqq78w" in namespace "services-4819" to be "running"
Aug 24 10:13:22.327: INFO: Pod "execpodqq78w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.750998ms
Aug 24 10:13:24.339: INFO: Pod "execpodqq78w": Phase="Running", Reason="", readiness=true. Elapsed: 2.020311917s
Aug 24 10:13:24.339: INFO: Pod "execpodqq78w" satisfied condition "running"
Aug 24 10:13:25.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Aug 24 10:13:25.705: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Aug 24 10:13:25.705: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:13:25.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.37.131 80'
Aug 24 10:13:25.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.37.131 80\nConnection to 10.233.37.131 80 port [tcp/http] succeeded!\n"
Aug 24 10:13:25.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:13:26.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Aug 24 10:13:26.217: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Aug 24 10:13:26.217: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:13:26.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.37.131 81'
Aug 24 10:13:26.450: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.37.131 81\nConnection to 10.233.37.131 81 port [tcp/*] succeeded!\n"
Aug 24 10:13:26.450: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4819 08/24/22 10:13:26.45
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod2:[101]] 08/24/22 10:13:26.485
Aug 24 10:13:26.565: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4819 08/24/22 10:13:26.566
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[] 08/24/22 10:13:26.662
Aug 24 10:13:27.698: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:13:27.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4819" for this suite. 08/24/22 10:13:27.794
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":184,"skipped":3101,"failed":0}
------------------------------
• [SLOW TEST] [9.738 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:13:18.08
    Aug 24 10:13:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:13:18.082
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:18.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:18.115
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-4819 08/24/22 10:13:18.119
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[] 08/24/22 10:13:18.141
    Aug 24 10:13:18.160: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4819 08/24/22 10:13:18.16
    Aug 24 10:13:18.183: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4819" to be "running and ready"
    Aug 24 10:13:18.192: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.882025ms
    Aug 24 10:13:18.192: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:13:20.201: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.018366712s
    Aug 24 10:13:20.201: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 24 10:13:20.201: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod1:[100]] 08/24/22 10:13:20.213
    Aug 24 10:13:20.240: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-4819 08/24/22 10:13:20.241
    Aug 24 10:13:20.254: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4819" to be "running and ready"
    Aug 24 10:13:20.260: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055276ms
    Aug 24 10:13:20.261: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:13:22.272: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017818279s
    Aug 24 10:13:22.273: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 24 10:13:22.273: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod1:[100] pod2:[101]] 08/24/22 10:13:22.281
    Aug 24 10:13:22.307: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 08/24/22 10:13:22.307
    Aug 24 10:13:22.308: INFO: Creating new exec pod
    Aug 24 10:13:22.319: INFO: Waiting up to 5m0s for pod "execpodqq78w" in namespace "services-4819" to be "running"
    Aug 24 10:13:22.327: INFO: Pod "execpodqq78w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.750998ms
    Aug 24 10:13:24.339: INFO: Pod "execpodqq78w": Phase="Running", Reason="", readiness=true. Elapsed: 2.020311917s
    Aug 24 10:13:24.339: INFO: Pod "execpodqq78w" satisfied condition "running"
    Aug 24 10:13:25.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Aug 24 10:13:25.705: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Aug 24 10:13:25.705: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:13:25.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.37.131 80'
    Aug 24 10:13:25.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.37.131 80\nConnection to 10.233.37.131 80 port [tcp/http] succeeded!\n"
    Aug 24 10:13:25.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:13:26.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Aug 24 10:13:26.217: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Aug 24 10:13:26.217: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:13:26.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4819 exec execpodqq78w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.37.131 81'
    Aug 24 10:13:26.450: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.37.131 81\nConnection to 10.233.37.131 81 port [tcp/*] succeeded!\n"
    Aug 24 10:13:26.450: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4819 08/24/22 10:13:26.45
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[pod2:[101]] 08/24/22 10:13:26.485
    Aug 24 10:13:26.565: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-4819 08/24/22 10:13:26.566
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4819 to expose endpoints map[] 08/24/22 10:13:26.662
    Aug 24 10:13:27.698: INFO: successfully validated that service multi-endpoint-test in namespace services-4819 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:13:27.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4819" for this suite. 08/24/22 10:13:27.794
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:13:27.824
Aug 24 10:13:27.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-watch 08/24/22 10:13:27.832
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:27.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:27.87
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Aug 24 10:13:27.874: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Creating first CR  08/24/22 10:13:30.642
Aug 24 10:13:30.662: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:30Z]] name:name1 resourceVersion:20757 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 08/24/22 10:13:40.662
Aug 24 10:13:40.674: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:40Z]] name:name2 resourceVersion:20794 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 08/24/22 10:13:50.674
Aug 24 10:13:50.686: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:50Z]] name:name1 resourceVersion:20810 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 08/24/22 10:14:00.687
Aug 24 10:14:00.701: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:14:00Z]] name:name2 resourceVersion:20826 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 08/24/22 10:14:10.701
Aug 24 10:14:10.729: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:50Z]] name:name1 resourceVersion:20843 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 08/24/22 10:14:20.73
Aug 24 10:14:20.753: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:14:00Z]] name:name2 resourceVersion:20858 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:14:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7530" for this suite. 08/24/22 10:14:31.309
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":185,"skipped":3108,"failed":0}
------------------------------
• [SLOW TEST] [63.511 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:13:27.824
    Aug 24 10:13:27.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-watch 08/24/22 10:13:27.832
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:13:27.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:13:27.87
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Aug 24 10:13:27.874: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Creating first CR  08/24/22 10:13:30.642
    Aug 24 10:13:30.662: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:30Z]] name:name1 resourceVersion:20757 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 08/24/22 10:13:40.662
    Aug 24 10:13:40.674: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:40Z]] name:name2 resourceVersion:20794 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 08/24/22 10:13:50.674
    Aug 24 10:13:50.686: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:50Z]] name:name1 resourceVersion:20810 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 08/24/22 10:14:00.687
    Aug 24 10:14:00.701: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:14:00Z]] name:name2 resourceVersion:20826 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 08/24/22 10:14:10.701
    Aug 24 10:14:10.729: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:13:50Z]] name:name1 resourceVersion:20843 uid:c7e23cf1-daa6-42d1-b0ed-7e7eed433c4a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 08/24/22 10:14:20.73
    Aug 24 10:14:20.753: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T10:13:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T10:14:00Z]] name:name2 resourceVersion:20858 uid:542d48d4-ea04-4290-9bb5-fedf182f6425] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:14:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-7530" for this suite. 08/24/22 10:14:31.309
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:14:31.343
Aug 24 10:14:31.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:14:31.347
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:14:31.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:14:31.382
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/24/22 10:14:31.385
Aug 24 10:14:31.408: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3682  ada4f09a-c98f-41e4-8241-a90bfae0333c 20884 0 2022-08-24 10:14:31 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-08-24 10:14:31 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rxgp2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rxgp2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 10:14:31.409: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3682" to be "running and ready"
Aug 24 10:14:31.420: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667172ms
Aug 24 10:14:31.420: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:14:33.427: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.017595832s
Aug 24 10:14:33.427: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Aug 24 10:14:33.427: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 08/24/22 10:14:33.427
Aug 24 10:14:33.427: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3682 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:14:33.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:14:33.429: INFO: ExecWithOptions: Clientset creation
Aug 24 10:14:33.429: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3682/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 08/24/22 10:14:33.607
Aug 24 10:14:33.607: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3682 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:14:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:14:33.609: INFO: ExecWithOptions: Clientset creation
Aug 24 10:14:33.609: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3682/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:14:33.865: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:14:33.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3682" for this suite. 08/24/22 10:14:33.895
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":186,"skipped":3117,"failed":0}
------------------------------
• [2.576 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:14:31.343
    Aug 24 10:14:31.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:14:31.347
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:14:31.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:14:31.382
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/24/22 10:14:31.385
    Aug 24 10:14:31.408: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3682  ada4f09a-c98f-41e4-8241-a90bfae0333c 20884 0 2022-08-24 10:14:31 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-08-24 10:14:31 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rxgp2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rxgp2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 24 10:14:31.409: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3682" to be "running and ready"
    Aug 24 10:14:31.420: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667172ms
    Aug 24 10:14:31.420: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:14:33.427: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.017595832s
    Aug 24 10:14:33.427: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Aug 24 10:14:33.427: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 08/24/22 10:14:33.427
    Aug 24 10:14:33.427: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3682 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:14:33.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:14:33.429: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:14:33.429: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3682/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 08/24/22 10:14:33.607
    Aug 24 10:14:33.607: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3682 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:14:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:14:33.609: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:14:33.609: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3682/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:14:33.865: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:14:33.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3682" for this suite. 08/24/22 10:14:33.895
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:14:33.933
Aug 24 10:14:33.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename init-container 08/24/22 10:14:33.935
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:14:34.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:14:34.014
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 08/24/22 10:14:34.019
Aug 24 10:14:34.019: INFO: PodSpec: initContainers in spec.initContainers
Aug 24 10:15:18.299: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f5878497-c13b-4bfe-9f8f-783aa14215d7", GenerateName:"", Namespace:"init-container-4966", SelfLink:"", UID:"c22db336-fa36-4315-81ac-7108fb456800", ResourceVersion:"21004", Generation:0, CreationTimestamp:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"19911166"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003bf2078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 10, 15, 18, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003bf20a8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-khht6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006cd4040), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0037442f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kah9uighaagh-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002ba0000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0037443c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0037443e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0037443e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0037443ec), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000c1c070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.54", PodIP:"10.233.66.250", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.250"}}, StartTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ba00e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ba0230)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"cri-o://c3f119cb6a76579cbbd9cd429c648acfd24af99391a297259e7593c7d8d0ad6a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006cd40e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006cd40c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003744584)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 10:15:18.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4966" for this suite. 08/24/22 10:15:18.321
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":187,"skipped":3141,"failed":0}
------------------------------
• [SLOW TEST] [44.409 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:14:33.933
    Aug 24 10:14:33.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename init-container 08/24/22 10:14:33.935
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:14:34.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:14:34.014
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 08/24/22 10:14:34.019
    Aug 24 10:14:34.019: INFO: PodSpec: initContainers in spec.initContainers
    Aug 24 10:15:18.299: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f5878497-c13b-4bfe-9f8f-783aa14215d7", GenerateName:"", Namespace:"init-container-4966", SelfLink:"", UID:"c22db336-fa36-4315-81ac-7108fb456800", ResourceVersion:"21004", Generation:0, CreationTimestamp:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"19911166"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003bf2078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 10, 15, 18, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003bf20a8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-khht6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc006cd4040), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-khht6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0037442f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kah9uighaagh-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002ba0000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0037443c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0037443e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0037443e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0037443ec), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000c1c070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.54", PodIP:"10.233.66.250", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.250"}}, StartTime:time.Date(2022, time.August, 24, 10, 14, 34, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ba00e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ba0230)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"cri-o://c3f119cb6a76579cbbd9cd429c648acfd24af99391a297259e7593c7d8d0ad6a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006cd40e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc006cd40c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003744584)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 10:15:18.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-4966" for this suite. 08/24/22 10:15:18.321
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:15:18.346
Aug 24 10:15:18.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename limitrange 08/24/22 10:15:18.349
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:18.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:18.41
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 08/24/22 10:15:18.414
STEP: Setting up watch 08/24/22 10:15:18.415
STEP: Submitting a LimitRange 08/24/22 10:15:18.522
STEP: Verifying LimitRange creation was observed 08/24/22 10:15:18.532
STEP: Fetching the LimitRange to ensure it has proper values 08/24/22 10:15:18.534
Aug 24 10:15:18.541: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 24 10:15:18.541: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 08/24/22 10:15:18.541
STEP: Ensuring Pod has resource requirements applied from LimitRange 08/24/22 10:15:18.557
Aug 24 10:15:18.567: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 24 10:15:18.567: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 08/24/22 10:15:18.567
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/24/22 10:15:18.587
Aug 24 10:15:18.636: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug 24 10:15:18.636: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 08/24/22 10:15:18.636
STEP: Failing to create a Pod with more than max resources 08/24/22 10:15:18.641
STEP: Updating a LimitRange 08/24/22 10:15:18.648
STEP: Verifying LimitRange updating is effective 08/24/22 10:15:18.659
STEP: Creating a Pod with less than former min resources 08/24/22 10:15:20.669
STEP: Failing to create a Pod with more than max resources 08/24/22 10:15:20.681
STEP: Deleting a LimitRange 08/24/22 10:15:20.686
STEP: Verifying the LimitRange was deleted 08/24/22 10:15:20.698
Aug 24 10:15:25.709: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 08/24/22 10:15:25.71
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Aug 24 10:15:25.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-7165" for this suite. 08/24/22 10:15:25.745
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":188,"skipped":3145,"failed":0}
------------------------------
• [SLOW TEST] [7.419 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:15:18.346
    Aug 24 10:15:18.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename limitrange 08/24/22 10:15:18.349
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:18.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:18.41
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 08/24/22 10:15:18.414
    STEP: Setting up watch 08/24/22 10:15:18.415
    STEP: Submitting a LimitRange 08/24/22 10:15:18.522
    STEP: Verifying LimitRange creation was observed 08/24/22 10:15:18.532
    STEP: Fetching the LimitRange to ensure it has proper values 08/24/22 10:15:18.534
    Aug 24 10:15:18.541: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 24 10:15:18.541: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 08/24/22 10:15:18.541
    STEP: Ensuring Pod has resource requirements applied from LimitRange 08/24/22 10:15:18.557
    Aug 24 10:15:18.567: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 24 10:15:18.567: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 08/24/22 10:15:18.567
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/24/22 10:15:18.587
    Aug 24 10:15:18.636: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Aug 24 10:15:18.636: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 08/24/22 10:15:18.636
    STEP: Failing to create a Pod with more than max resources 08/24/22 10:15:18.641
    STEP: Updating a LimitRange 08/24/22 10:15:18.648
    STEP: Verifying LimitRange updating is effective 08/24/22 10:15:18.659
    STEP: Creating a Pod with less than former min resources 08/24/22 10:15:20.669
    STEP: Failing to create a Pod with more than max resources 08/24/22 10:15:20.681
    STEP: Deleting a LimitRange 08/24/22 10:15:20.686
    STEP: Verifying the LimitRange was deleted 08/24/22 10:15:20.698
    Aug 24 10:15:25.709: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 08/24/22 10:15:25.71
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Aug 24 10:15:25.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-7165" for this suite. 08/24/22 10:15:25.745
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:15:25.768
Aug 24 10:15:25.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 10:15:25.784
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:25.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:25.817
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 08/24/22 10:15:25.824
STEP: Ensuring active pods == parallelism 08/24/22 10:15:25.843
STEP: Orphaning one of the Job's Pods 08/24/22 10:15:27.875
Aug 24 10:15:28.406: INFO: Successfully updated pod "adopt-release-6hw7b"
STEP: Checking that the Job readopts the Pod 08/24/22 10:15:28.406
Aug 24 10:15:28.407: INFO: Waiting up to 15m0s for pod "adopt-release-6hw7b" in namespace "job-3964" to be "adopted"
Aug 24 10:15:28.416: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 9.622321ms
Aug 24 10:15:30.423: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.016099943s
Aug 24 10:15:30.423: INFO: Pod "adopt-release-6hw7b" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 08/24/22 10:15:30.423
Aug 24 10:15:30.942: INFO: Successfully updated pod "adopt-release-6hw7b"
STEP: Checking that the Job releases the Pod 08/24/22 10:15:30.943
Aug 24 10:15:30.943: INFO: Waiting up to 15m0s for pod "adopt-release-6hw7b" in namespace "job-3964" to be "released"
Aug 24 10:15:30.948: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 5.740286ms
Aug 24 10:15:32.956: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013606888s
Aug 24 10:15:32.956: INFO: Pod "adopt-release-6hw7b" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 10:15:32.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3964" for this suite. 08/24/22 10:15:32.964
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":189,"skipped":3152,"failed":0}
------------------------------
• [SLOW TEST] [7.206 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:15:25.768
    Aug 24 10:15:25.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 10:15:25.784
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:25.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:25.817
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 08/24/22 10:15:25.824
    STEP: Ensuring active pods == parallelism 08/24/22 10:15:25.843
    STEP: Orphaning one of the Job's Pods 08/24/22 10:15:27.875
    Aug 24 10:15:28.406: INFO: Successfully updated pod "adopt-release-6hw7b"
    STEP: Checking that the Job readopts the Pod 08/24/22 10:15:28.406
    Aug 24 10:15:28.407: INFO: Waiting up to 15m0s for pod "adopt-release-6hw7b" in namespace "job-3964" to be "adopted"
    Aug 24 10:15:28.416: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 9.622321ms
    Aug 24 10:15:30.423: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.016099943s
    Aug 24 10:15:30.423: INFO: Pod "adopt-release-6hw7b" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 08/24/22 10:15:30.423
    Aug 24 10:15:30.942: INFO: Successfully updated pod "adopt-release-6hw7b"
    STEP: Checking that the Job releases the Pod 08/24/22 10:15:30.943
    Aug 24 10:15:30.943: INFO: Waiting up to 15m0s for pod "adopt-release-6hw7b" in namespace "job-3964" to be "released"
    Aug 24 10:15:30.948: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 5.740286ms
    Aug 24 10:15:32.956: INFO: Pod "adopt-release-6hw7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013606888s
    Aug 24 10:15:32.956: INFO: Pod "adopt-release-6hw7b" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 10:15:32.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3964" for this suite. 08/24/22 10:15:32.964
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:15:32.982
Aug 24 10:15:32.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 10:15:32.984
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:33.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:33.01
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 08/24/22 10:15:33.013
STEP: Ensure pods equal to paralellism count is attached to the job 08/24/22 10:15:33.022
STEP: patching /status 08/24/22 10:15:35.029
STEP: updating /status 08/24/22 10:15:35.04
STEP: get /status 08/24/22 10:15:35.092
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 10:15:35.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6485" for this suite. 08/24/22 10:15:35.104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":190,"skipped":3198,"failed":0}
------------------------------
• [2.135 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:15:32.982
    Aug 24 10:15:32.982: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 10:15:32.984
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:33.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:33.01
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 08/24/22 10:15:33.013
    STEP: Ensure pods equal to paralellism count is attached to the job 08/24/22 10:15:33.022
    STEP: patching /status 08/24/22 10:15:35.029
    STEP: updating /status 08/24/22 10:15:35.04
    STEP: get /status 08/24/22 10:15:35.092
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 10:15:35.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6485" for this suite. 08/24/22 10:15:35.104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:15:35.122
Aug 24 10:15:35.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:15:35.124
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:35.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:35.158
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:15:35.184
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:15:36.022
STEP: Deploying the webhook pod 08/24/22 10:15:36.047
STEP: Wait for the deployment to be ready 08/24/22 10:15:36.072
Aug 24 10:15:36.090: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 10:15:38.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:15:40.132: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:15:42.131: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:15:44.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:15:46.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:15:48.132
STEP: Verifying the service has paired with the endpoint 08/24/22 10:15:48.167
Aug 24 10:15:49.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 08/24/22 10:15:49.176
STEP: create a pod 08/24/22 10:15:49.207
Aug 24 10:15:49.218: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-7940" to be "running"
Aug 24 10:15:49.246: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 27.854282ms
Aug 24 10:15:51.256: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.037305316s
Aug 24 10:15:51.256: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 08/24/22 10:15:51.257
Aug 24 10:15:51.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=webhook-7940 attach --namespace=webhook-7940 to-be-attached-pod -i -c=container1'
Aug 24 10:15:51.511: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:15:51.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7940" for this suite. 08/24/22 10:15:51.536
STEP: Destroying namespace "webhook-7940-markers" for this suite. 08/24/22 10:15:51.552
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":191,"skipped":3206,"failed":0}
------------------------------
• [SLOW TEST] [16.559 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:15:35.122
    Aug 24 10:15:35.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:15:35.124
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:35.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:35.158
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:15:35.184
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:15:36.022
    STEP: Deploying the webhook pod 08/24/22 10:15:36.047
    STEP: Wait for the deployment to be ready 08/24/22 10:15:36.072
    Aug 24 10:15:36.090: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 10:15:38.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:15:40.132: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:15:42.131: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:15:44.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:15:46.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 15, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:15:48.132
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:15:48.167
    Aug 24 10:15:49.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 08/24/22 10:15:49.176
    STEP: create a pod 08/24/22 10:15:49.207
    Aug 24 10:15:49.218: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-7940" to be "running"
    Aug 24 10:15:49.246: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 27.854282ms
    Aug 24 10:15:51.256: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.037305316s
    Aug 24 10:15:51.256: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 08/24/22 10:15:51.257
    Aug 24 10:15:51.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=webhook-7940 attach --namespace=webhook-7940 to-be-attached-pod -i -c=container1'
    Aug 24 10:15:51.511: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:15:51.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7940" for this suite. 08/24/22 10:15:51.536
    STEP: Destroying namespace "webhook-7940-markers" for this suite. 08/24/22 10:15:51.552
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:15:51.682
Aug 24 10:15:51.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename hostport 08/24/22 10:15:51.694
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:51.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:51.736
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/24/22 10:15:51.769
Aug 24 10:15:51.792: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8632" to be "running and ready"
Aug 24 10:15:51.802: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.548448ms
Aug 24 10:15:51.802: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:15:53.812: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019820544s
Aug 24 10:15:53.812: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 24 10:15:53.812: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.214 on the node which pod1 resides and expect scheduled 08/24/22 10:15:53.812
Aug 24 10:15:53.822: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8632" to be "running and ready"
Aug 24 10:15:53.827: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.556555ms
Aug 24 10:15:53.827: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:15:55.834: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.01221209s
Aug 24 10:15:55.834: INFO: The phase of Pod pod2 is Running (Ready = false)
Aug 24 10:15:57.837: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.015503092s
Aug 24 10:15:57.837: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 24 10:15:57.838: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.214 but use UDP protocol on the node which pod2 resides 08/24/22 10:15:57.838
Aug 24 10:15:57.848: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8632" to be "running and ready"
Aug 24 10:15:57.858: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696021ms
Aug 24 10:15:57.858: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:15:59.865: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.016870159s
Aug 24 10:15:59.866: INFO: The phase of Pod pod3 is Running (Ready = true)
Aug 24 10:15:59.866: INFO: Pod "pod3" satisfied condition "running and ready"
Aug 24 10:15:59.880: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8632" to be "running and ready"
Aug 24 10:15:59.886: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12222ms
Aug 24 10:15:59.887: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:16:01.894: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.014061651s
Aug 24 10:16:01.895: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Aug 24 10:16:01.895: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/24/22 10:16:01.901
Aug 24 10:16:01.901: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.214 http://127.0.0.1:54323/hostname] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:16:01.901: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:16:01.903: INFO: ExecWithOptions: Clientset creation
Aug 24 10:16:01.903: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.214+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 08/24/22 10:16:02.046
Aug 24 10:16:02.047: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.214:54323/hostname] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:16:02.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:16:02.048: INFO: ExecWithOptions: Clientset creation
Aug 24 10:16:02.048: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.214%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 UDP 08/24/22 10:16:02.134
Aug 24 10:16:02.134: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.214 54323] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:16:02.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:16:02.136: INFO: ExecWithOptions: Clientset creation
Aug 24 10:16:02.136: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.214+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Aug 24 10:16:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8632" for this suite. 08/24/22 10:16:07.247
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":192,"skipped":3211,"failed":0}
------------------------------
• [SLOW TEST] [15.576 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:15:51.682
    Aug 24 10:15:51.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename hostport 08/24/22 10:15:51.694
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:15:51.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:15:51.736
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/24/22 10:15:51.769
    Aug 24 10:15:51.792: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8632" to be "running and ready"
    Aug 24 10:15:51.802: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.548448ms
    Aug 24 10:15:51.802: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:15:53.812: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019820544s
    Aug 24 10:15:53.812: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 24 10:15:53.812: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.214 on the node which pod1 resides and expect scheduled 08/24/22 10:15:53.812
    Aug 24 10:15:53.822: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8632" to be "running and ready"
    Aug 24 10:15:53.827: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.556555ms
    Aug 24 10:15:53.827: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:15:55.834: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.01221209s
    Aug 24 10:15:55.834: INFO: The phase of Pod pod2 is Running (Ready = false)
    Aug 24 10:15:57.837: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.015503092s
    Aug 24 10:15:57.837: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 24 10:15:57.838: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.214 but use UDP protocol on the node which pod2 resides 08/24/22 10:15:57.838
    Aug 24 10:15:57.848: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8632" to be "running and ready"
    Aug 24 10:15:57.858: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696021ms
    Aug 24 10:15:57.858: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:15:59.865: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.016870159s
    Aug 24 10:15:59.866: INFO: The phase of Pod pod3 is Running (Ready = true)
    Aug 24 10:15:59.866: INFO: Pod "pod3" satisfied condition "running and ready"
    Aug 24 10:15:59.880: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8632" to be "running and ready"
    Aug 24 10:15:59.886: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12222ms
    Aug 24 10:15:59.887: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:16:01.894: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.014061651s
    Aug 24 10:16:01.895: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Aug 24 10:16:01.895: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/24/22 10:16:01.901
    Aug 24 10:16:01.901: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.214 http://127.0.0.1:54323/hostname] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:16:01.901: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:16:01.903: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:16:01.903: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.214+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 08/24/22 10:16:02.046
    Aug 24 10:16:02.047: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.214:54323/hostname] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:16:02.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:16:02.048: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:16:02.048: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.214%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 UDP 08/24/22 10:16:02.134
    Aug 24 10:16:02.134: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.214 54323] Namespace:hostport-8632 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:16:02.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:16:02.136: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:16:02.136: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-8632/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.214+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Aug 24 10:16:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-8632" for this suite. 08/24/22 10:16:07.247
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:07.262
Aug 24 10:16:07.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir-wrapper 08/24/22 10:16:07.264
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:07.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:07.311
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Aug 24 10:16:07.369: INFO: Waiting up to 5m0s for pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d" in namespace "emptydir-wrapper-5398" to be "running and ready"
Aug 24 10:16:07.374: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.942325ms
Aug 24 10:16:07.374: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:16:09.389: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019433122s
Aug 24 10:16:09.389: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:16:11.392: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Running", Reason="", readiness=true. Elapsed: 4.02298972s
Aug 24 10:16:11.392: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Running (Ready = true)
Aug 24 10:16:11.392: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d" satisfied condition "running and ready"
STEP: Cleaning up the secret 08/24/22 10:16:11.398
STEP: Cleaning up the configmap 08/24/22 10:16:11.45
STEP: Cleaning up the pod 08/24/22 10:16:11.482
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 24 10:16:11.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5398" for this suite. 08/24/22 10:16:11.523
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":193,"skipped":3223,"failed":0}
------------------------------
• [4.278 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:07.262
    Aug 24 10:16:07.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir-wrapper 08/24/22 10:16:07.264
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:07.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:07.311
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Aug 24 10:16:07.369: INFO: Waiting up to 5m0s for pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d" in namespace "emptydir-wrapper-5398" to be "running and ready"
    Aug 24 10:16:07.374: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.942325ms
    Aug 24 10:16:07.374: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:16:09.389: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019433122s
    Aug 24 10:16:09.389: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:16:11.392: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d": Phase="Running", Reason="", readiness=true. Elapsed: 4.02298972s
    Aug 24 10:16:11.392: INFO: The phase of Pod pod-secrets-91466184-d573-4870-a38b-1304c92e547d is Running (Ready = true)
    Aug 24 10:16:11.392: INFO: Pod "pod-secrets-91466184-d573-4870-a38b-1304c92e547d" satisfied condition "running and ready"
    STEP: Cleaning up the secret 08/24/22 10:16:11.398
    STEP: Cleaning up the configmap 08/24/22 10:16:11.45
    STEP: Cleaning up the pod 08/24/22 10:16:11.482
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:16:11.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5398" for this suite. 08/24/22 10:16:11.523
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:11.561
Aug 24 10:16:11.562: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:16:11.566
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:11.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:11.596
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:16:11.602
Aug 24 10:16:11.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844" in namespace "downward-api-1691" to be "Succeeded or Failed"
Aug 24 10:16:11.641: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 14.556749ms
Aug 24 10:16:13.658: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03134907s
Aug 24 10:16:15.651: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024300402s
Aug 24 10:16:17.649: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022757328s
STEP: Saw pod success 08/24/22 10:16:17.65
Aug 24 10:16:17.651: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844" satisfied condition "Succeeded or Failed"
Aug 24 10:16:17.658: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 container client-container: <nil>
STEP: delete the pod 08/24/22 10:16:17.695
Aug 24 10:16:17.722: INFO: Waiting for pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 to disappear
Aug 24 10:16:17.726: INFO: Pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:16:17.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1691" for this suite. 08/24/22 10:16:17.735
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":194,"skipped":3252,"failed":0}
------------------------------
• [SLOW TEST] [6.188 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:11.561
    Aug 24 10:16:11.562: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:16:11.566
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:11.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:11.596
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:16:11.602
    Aug 24 10:16:11.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844" in namespace "downward-api-1691" to be "Succeeded or Failed"
    Aug 24 10:16:11.641: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 14.556749ms
    Aug 24 10:16:13.658: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03134907s
    Aug 24 10:16:15.651: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024300402s
    Aug 24 10:16:17.649: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022757328s
    STEP: Saw pod success 08/24/22 10:16:17.65
    Aug 24 10:16:17.651: INFO: Pod "downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844" satisfied condition "Succeeded or Failed"
    Aug 24 10:16:17.658: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:16:17.695
    Aug 24 10:16:17.722: INFO: Waiting for pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 to disappear
    Aug 24 10:16:17.726: INFO: Pod downwardapi-volume-4c85775c-95e2-42bc-b274-417fbffb8844 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:16:17.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1691" for this suite. 08/24/22 10:16:17.735
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:17.751
Aug 24 10:16:17.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:16:17.769
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:17.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:17.806
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-494 08/24/22 10:16:17.809
STEP: creating service affinity-nodeport-transition in namespace services-494 08/24/22 10:16:17.809
STEP: creating replication controller affinity-nodeport-transition in namespace services-494 08/24/22 10:16:17.84
I0824 10:16:17.856570      14 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-494, replica count: 3
I0824 10:16:20.912657      14 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:16:20.955: INFO: Creating new exec pod
Aug 24 10:16:20.969: INFO: Waiting up to 5m0s for pod "execpod-affinityv786z" in namespace "services-494" to be "running"
Aug 24 10:16:20.975: INFO: Pod "execpod-affinityv786z": Phase="Pending", Reason="", readiness=false. Elapsed: 5.841208ms
Aug 24 10:16:22.986: INFO: Pod "execpod-affinityv786z": Phase="Running", Reason="", readiness=true. Elapsed: 2.016706778s
Aug 24 10:16:22.986: INFO: Pod "execpod-affinityv786z" satisfied condition "running"
Aug 24 10:16:24.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Aug 24 10:16:24.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug 24 10:16:24.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:16:24.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.138 80'
Aug 24 10:16:24.503: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.138 80\nConnection to 10.233.29.138 80 port [tcp/http] succeeded!\n"
Aug 24 10:16:24.503: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:16:24.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 32656'
Aug 24 10:16:24.808: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 32656\nConnection to 192.168.121.119 32656 port [tcp/*] succeeded!\n"
Aug 24 10:16:24.808: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:16:24.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32656'
Aug 24 10:16:25.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32656\nConnection to 192.168.121.54 32656 port [tcp/*] succeeded!\n"
Aug 24 10:16:25.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:16:25.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:32656/ ; done'
Aug 24 10:16:25.912: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n"
Aug 24 10:16:25.912: INFO: stdout: "\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-br6bv\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-br6bv\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-vxnbt"
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-br6bv
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-br6bv
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
Aug 24 10:16:25.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:32656/ ; done'
Aug 24 10:16:26.581: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n"
Aug 24 10:16:26.581: INFO: stdout: "\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q"
Aug 24 10:16:26.581: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
Aug 24 10:16:26.582: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-494, will wait for the garbage collector to delete the pods 08/24/22 10:16:26.606
Aug 24 10:16:26.703: INFO: Deleting ReplicationController affinity-nodeport-transition took: 38.311886ms
Aug 24 10:16:26.904: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 200.87271ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:16:29.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-494" for this suite. 08/24/22 10:16:29.39
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":195,"skipped":3255,"failed":0}
------------------------------
• [SLOW TEST] [11.665 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:17.751
    Aug 24 10:16:17.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:16:17.769
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:17.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:17.806
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-494 08/24/22 10:16:17.809
    STEP: creating service affinity-nodeport-transition in namespace services-494 08/24/22 10:16:17.809
    STEP: creating replication controller affinity-nodeport-transition in namespace services-494 08/24/22 10:16:17.84
    I0824 10:16:17.856570      14 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-494, replica count: 3
    I0824 10:16:20.912657      14 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:16:20.955: INFO: Creating new exec pod
    Aug 24 10:16:20.969: INFO: Waiting up to 5m0s for pod "execpod-affinityv786z" in namespace "services-494" to be "running"
    Aug 24 10:16:20.975: INFO: Pod "execpod-affinityv786z": Phase="Pending", Reason="", readiness=false. Elapsed: 5.841208ms
    Aug 24 10:16:22.986: INFO: Pod "execpod-affinityv786z": Phase="Running", Reason="", readiness=true. Elapsed: 2.016706778s
    Aug 24 10:16:22.986: INFO: Pod "execpod-affinityv786z" satisfied condition "running"
    Aug 24 10:16:24.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Aug 24 10:16:24.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Aug 24 10:16:24.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:16:24.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.138 80'
    Aug 24 10:16:24.503: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.138 80\nConnection to 10.233.29.138 80 port [tcp/http] succeeded!\n"
    Aug 24 10:16:24.503: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:16:24.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 32656'
    Aug 24 10:16:24.808: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 32656\nConnection to 192.168.121.119 32656 port [tcp/*] succeeded!\n"
    Aug 24 10:16:24.808: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:16:24.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 32656'
    Aug 24 10:16:25.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 32656\nConnection to 192.168.121.54 32656 port [tcp/*] succeeded!\n"
    Aug 24 10:16:25.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:16:25.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:32656/ ; done'
    Aug 24 10:16:25.912: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n"
    Aug 24 10:16:25.912: INFO: stdout: "\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-br6bv\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-br6bv\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-vxnbt\naffinity-nodeport-transition-vxnbt"
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-br6bv
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-br6bv
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.912: INFO: Received response from host: affinity-nodeport-transition-vxnbt
    Aug 24 10:16:25.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-494 exec execpod-affinityv786z -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:32656/ ; done'
    Aug 24 10:16:26.581: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:32656/\n"
    Aug 24 10:16:26.581: INFO: stdout: "\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q\naffinity-nodeport-transition-5xl4q"
    Aug 24 10:16:26.581: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Received response from host: affinity-nodeport-transition-5xl4q
    Aug 24 10:16:26.582: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-494, will wait for the garbage collector to delete the pods 08/24/22 10:16:26.606
    Aug 24 10:16:26.703: INFO: Deleting ReplicationController affinity-nodeport-transition took: 38.311886ms
    Aug 24 10:16:26.904: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 200.87271ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:16:29.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-494" for this suite. 08/24/22 10:16:29.39
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:29.419
Aug 24 10:16:29.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:16:29.423
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:29.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:29.471
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:16:29.477
Aug 24 10:16:29.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0" in namespace "projected-8231" to be "Succeeded or Failed"
Aug 24 10:16:29.510: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747058ms
Aug 24 10:16:31.519: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015496626s
Aug 24 10:16:33.518: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015207331s
STEP: Saw pod success 08/24/22 10:16:33.518
Aug 24 10:16:33.519: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0" satisfied condition "Succeeded or Failed"
Aug 24 10:16:33.525: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 container client-container: <nil>
STEP: delete the pod 08/24/22 10:16:33.541
Aug 24 10:16:33.566: INFO: Waiting for pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 to disappear
Aug 24 10:16:33.575: INFO: Pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 10:16:33.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8231" for this suite. 08/24/22 10:16:33.586
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":196,"skipped":3268,"failed":0}
------------------------------
• [4.184 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:29.419
    Aug 24 10:16:29.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:16:29.423
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:29.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:29.471
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:16:29.477
    Aug 24 10:16:29.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0" in namespace "projected-8231" to be "Succeeded or Failed"
    Aug 24 10:16:29.510: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747058ms
    Aug 24 10:16:31.519: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015496626s
    Aug 24 10:16:33.518: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015207331s
    STEP: Saw pod success 08/24/22 10:16:33.518
    Aug 24 10:16:33.519: INFO: Pod "downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0" satisfied condition "Succeeded or Failed"
    Aug 24 10:16:33.525: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:16:33.541
    Aug 24 10:16:33.566: INFO: Waiting for pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 to disappear
    Aug 24 10:16:33.575: INFO: Pod downwardapi-volume-cf175172-4716-4f23-893a-bbd9d06a9eb0 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 10:16:33.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8231" for this suite. 08/24/22 10:16:33.586
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:33.605
Aug 24 10:16:33.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:16:33.608
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:33.65
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:33.657
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-d396dad9-e289-4b5e-ab0f-2d14264479c6 08/24/22 10:16:33.675
STEP: Creating configMap with name cm-test-opt-upd-6c95e687-ef3a-400c-8747-cd6dd6a01a86 08/24/22 10:16:33.683
STEP: Creating the pod 08/24/22 10:16:33.693
Aug 24 10:16:33.714: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788" in namespace "projected-2152" to be "running and ready"
Aug 24 10:16:33.721: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788": Phase="Pending", Reason="", readiness=false. Elapsed: 7.721468ms
Aug 24 10:16:33.721: INFO: The phase of Pod pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:16:35.728: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788": Phase="Running", Reason="", readiness=true. Elapsed: 2.01482252s
Aug 24 10:16:35.729: INFO: The phase of Pod pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788 is Running (Ready = true)
Aug 24 10:16:35.729: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-d396dad9-e289-4b5e-ab0f-2d14264479c6 08/24/22 10:16:35.778
STEP: Updating configmap cm-test-opt-upd-6c95e687-ef3a-400c-8747-cd6dd6a01a86 08/24/22 10:16:35.795
STEP: Creating configMap with name cm-test-opt-create-03cf8b00-4010-465d-8d19-114a5b89e363 08/24/22 10:16:35.81
STEP: waiting to observe update in volume 08/24/22 10:16:35.819
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:16:37.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2152" for this suite. 08/24/22 10:16:37.89
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":197,"skipped":3273,"failed":0}
------------------------------
• [4.297 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:33.605
    Aug 24 10:16:33.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:16:33.608
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:33.65
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:33.657
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-d396dad9-e289-4b5e-ab0f-2d14264479c6 08/24/22 10:16:33.675
    STEP: Creating configMap with name cm-test-opt-upd-6c95e687-ef3a-400c-8747-cd6dd6a01a86 08/24/22 10:16:33.683
    STEP: Creating the pod 08/24/22 10:16:33.693
    Aug 24 10:16:33.714: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788" in namespace "projected-2152" to be "running and ready"
    Aug 24 10:16:33.721: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788": Phase="Pending", Reason="", readiness=false. Elapsed: 7.721468ms
    Aug 24 10:16:33.721: INFO: The phase of Pod pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:16:35.728: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788": Phase="Running", Reason="", readiness=true. Elapsed: 2.01482252s
    Aug 24 10:16:35.729: INFO: The phase of Pod pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788 is Running (Ready = true)
    Aug 24 10:16:35.729: INFO: Pod "pod-projected-configmaps-0124ce86-bfcf-4fcc-a566-dc3596e48788" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-d396dad9-e289-4b5e-ab0f-2d14264479c6 08/24/22 10:16:35.778
    STEP: Updating configmap cm-test-opt-upd-6c95e687-ef3a-400c-8747-cd6dd6a01a86 08/24/22 10:16:35.795
    STEP: Creating configMap with name cm-test-opt-create-03cf8b00-4010-465d-8d19-114a5b89e363 08/24/22 10:16:35.81
    STEP: waiting to observe update in volume 08/24/22 10:16:35.819
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:16:37.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2152" for this suite. 08/24/22 10:16:37.89
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:37.908
Aug 24 10:16:37.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:16:37.91
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:37.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:37.945
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/24/22 10:16:37.951
Aug 24 10:16:37.966: INFO: Waiting up to 5m0s for pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12" in namespace "emptydir-4719" to be "Succeeded or Failed"
Aug 24 10:16:37.971: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.046736ms
Aug 24 10:16:39.983: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016326667s
Aug 24 10:16:41.983: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017201344s
STEP: Saw pod success 08/24/22 10:16:41.984
Aug 24 10:16:41.984: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12" satisfied condition "Succeeded or Failed"
Aug 24 10:16:41.991: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 container test-container: <nil>
STEP: delete the pod 08/24/22 10:16:42.001
Aug 24 10:16:42.016: INFO: Waiting for pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 to disappear
Aug 24 10:16:42.024: INFO: Pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:16:42.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4719" for this suite. 08/24/22 10:16:42.033
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":198,"skipped":3275,"failed":0}
------------------------------
• [4.134 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:37.908
    Aug 24 10:16:37.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:16:37.91
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:37.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:37.945
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/24/22 10:16:37.951
    Aug 24 10:16:37.966: INFO: Waiting up to 5m0s for pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12" in namespace "emptydir-4719" to be "Succeeded or Failed"
    Aug 24 10:16:37.971: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.046736ms
    Aug 24 10:16:39.983: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016326667s
    Aug 24 10:16:41.983: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017201344s
    STEP: Saw pod success 08/24/22 10:16:41.984
    Aug 24 10:16:41.984: INFO: Pod "pod-9cdbee79-5c02-4784-b21a-5671b3545e12" satisfied condition "Succeeded or Failed"
    Aug 24 10:16:41.991: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:16:42.001
    Aug 24 10:16:42.016: INFO: Waiting for pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 to disappear
    Aug 24 10:16:42.024: INFO: Pod pod-9cdbee79-5c02-4784-b21a-5671b3545e12 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:16:42.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4719" for this suite. 08/24/22 10:16:42.033
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:42.054
Aug 24 10:16:42.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:16:42.057
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:42.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:42.084
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 08/24/22 10:16:42.088
Aug 24 10:16:42.099: INFO: Waiting up to 5m0s for pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164" in namespace "emptydir-4190" to be "Succeeded or Failed"
Aug 24 10:16:42.113: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Pending", Reason="", readiness=false. Elapsed: 13.636992ms
Aug 24 10:16:44.119: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019718914s
Aug 24 10:16:46.121: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021988332s
STEP: Saw pod success 08/24/22 10:16:46.121
Aug 24 10:16:46.122: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164" satisfied condition "Succeeded or Failed"
Aug 24 10:16:46.126: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 container test-container: <nil>
STEP: delete the pod 08/24/22 10:16:46.136
Aug 24 10:16:46.154: INFO: Waiting for pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 to disappear
Aug 24 10:16:46.159: INFO: Pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:16:46.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4190" for this suite. 08/24/22 10:16:46.165
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":199,"skipped":3310,"failed":0}
------------------------------
• [4.120 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:42.054
    Aug 24 10:16:42.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:16:42.057
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:42.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:42.084
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/24/22 10:16:42.088
    Aug 24 10:16:42.099: INFO: Waiting up to 5m0s for pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164" in namespace "emptydir-4190" to be "Succeeded or Failed"
    Aug 24 10:16:42.113: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Pending", Reason="", readiness=false. Elapsed: 13.636992ms
    Aug 24 10:16:44.119: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019718914s
    Aug 24 10:16:46.121: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021988332s
    STEP: Saw pod success 08/24/22 10:16:46.121
    Aug 24 10:16:46.122: INFO: Pod "pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164" satisfied condition "Succeeded or Failed"
    Aug 24 10:16:46.126: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:16:46.136
    Aug 24 10:16:46.154: INFO: Waiting for pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 to disappear
    Aug 24 10:16:46.159: INFO: Pod pod-70cce24e-9d8b-4d62-8d31-3a053c7f3164 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:16:46.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4190" for this suite. 08/24/22 10:16:46.165
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:46.195
Aug 24 10:16:46.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 10:16:46.197
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:46.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:46.231
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 08/24/22 10:16:46.24
STEP: Ensuring job reaches completions 08/24/22 10:16:46.257
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 10:16:58.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-855" for this suite. 08/24/22 10:16:58.271
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":200,"skipped":3383,"failed":0}
------------------------------
• [SLOW TEST] [12.089 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:46.195
    Aug 24 10:16:46.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 10:16:46.197
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:46.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:46.231
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 08/24/22 10:16:46.24
    STEP: Ensuring job reaches completions 08/24/22 10:16:46.257
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 10:16:58.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-855" for this suite. 08/24/22 10:16:58.271
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:16:58.284
Aug 24 10:16:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename endpointslice 08/24/22 10:16:58.287
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:58.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:58.314
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 08/24/22 10:17:03.492
STEP: referencing matching pods with named port 08/24/22 10:17:08.522
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/24/22 10:17:13.536
STEP: recreating EndpointSlices after they've been deleted 08/24/22 10:17:18.55
Aug 24 10:17:18.608: INFO: EndpointSlice for Service endpointslice-6667/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 24 10:17:28.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6667" for this suite. 08/24/22 10:17:28.65
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":201,"skipped":3383,"failed":0}
------------------------------
• [SLOW TEST] [30.384 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:16:58.284
    Aug 24 10:16:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename endpointslice 08/24/22 10:16:58.287
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:16:58.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:16:58.314
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 08/24/22 10:17:03.492
    STEP: referencing matching pods with named port 08/24/22 10:17:08.522
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/24/22 10:17:13.536
    STEP: recreating EndpointSlices after they've been deleted 08/24/22 10:17:18.55
    Aug 24 10:17:18.608: INFO: EndpointSlice for Service endpointslice-6667/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 24 10:17:28.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6667" for this suite. 08/24/22 10:17:28.65
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:17:28.671
Aug 24 10:17:28.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:17:28.674
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:17:28.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:17:28.715
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-fb79dee2-2778-46bd-a3af-c51398621e0a 08/24/22 10:17:28.73
STEP: Creating secret with name s-test-opt-upd-b1f801d4-165c-4a83-bc80-136d13f46c86 08/24/22 10:17:28.744
STEP: Creating the pod 08/24/22 10:17:28.754
Aug 24 10:17:28.774: INFO: Waiting up to 5m0s for pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb" in namespace "secrets-5161" to be "running and ready"
Aug 24 10:17:28.782: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.920967ms
Aug 24 10:17:28.782: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:17:30.793: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019353111s
Aug 24 10:17:30.793: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:17:32.789: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Running", Reason="", readiness=true. Elapsed: 4.014950909s
Aug 24 10:17:32.789: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Running (Ready = true)
Aug 24 10:17:32.789: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-fb79dee2-2778-46bd-a3af-c51398621e0a 08/24/22 10:17:32.827
STEP: Updating secret s-test-opt-upd-b1f801d4-165c-4a83-bc80-136d13f46c86 08/24/22 10:17:32.842
STEP: Creating secret with name s-test-opt-create-03266eb9-faf8-4afb-b0f0-a0fd9abd6007 08/24/22 10:17:32.852
STEP: waiting to observe update in volume 08/24/22 10:17:32.861
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:19:00.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5161" for this suite. 08/24/22 10:19:00.021
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":202,"skipped":3399,"failed":0}
------------------------------
• [SLOW TEST] [91.366 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:17:28.671
    Aug 24 10:17:28.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:17:28.674
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:17:28.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:17:28.715
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-fb79dee2-2778-46bd-a3af-c51398621e0a 08/24/22 10:17:28.73
    STEP: Creating secret with name s-test-opt-upd-b1f801d4-165c-4a83-bc80-136d13f46c86 08/24/22 10:17:28.744
    STEP: Creating the pod 08/24/22 10:17:28.754
    Aug 24 10:17:28.774: INFO: Waiting up to 5m0s for pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb" in namespace "secrets-5161" to be "running and ready"
    Aug 24 10:17:28.782: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.920967ms
    Aug 24 10:17:28.782: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:17:30.793: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019353111s
    Aug 24 10:17:30.793: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:17:32.789: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb": Phase="Running", Reason="", readiness=true. Elapsed: 4.014950909s
    Aug 24 10:17:32.789: INFO: The phase of Pod pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb is Running (Ready = true)
    Aug 24 10:17:32.789: INFO: Pod "pod-secrets-fc4d5724-9fc6-42d7-89ce-b518e3d9a5cb" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-fb79dee2-2778-46bd-a3af-c51398621e0a 08/24/22 10:17:32.827
    STEP: Updating secret s-test-opt-upd-b1f801d4-165c-4a83-bc80-136d13f46c86 08/24/22 10:17:32.842
    STEP: Creating secret with name s-test-opt-create-03266eb9-faf8-4afb-b0f0-a0fd9abd6007 08/24/22 10:17:32.852
    STEP: waiting to observe update in volume 08/24/22 10:17:32.861
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:19:00.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5161" for this suite. 08/24/22 10:19:00.021
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:00.04
Aug 24 10:19:00.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:19:00.044
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:00.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:00.077
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 08/24/22 10:19:00.081
Aug 24 10:19:00.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 create -f -'
Aug 24 10:19:00.653: INFO: stderr: ""
Aug 24 10:19:00.653: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:19:00.653
Aug 24 10:19:00.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:19:00.894: INFO: stderr: ""
Aug 24 10:19:00.894: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
Aug 24 10:19:00.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:19:01.094: INFO: stderr: ""
Aug 24 10:19:01.094: INFO: stdout: ""
Aug 24 10:19:01.094: INFO: update-demo-nautilus-j52ff is created but not running
Aug 24 10:19:06.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:19:06.322: INFO: stderr: ""
Aug 24 10:19:06.322: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
Aug 24 10:19:06.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:19:06.541: INFO: stderr: ""
Aug 24 10:19:06.542: INFO: stdout: ""
Aug 24 10:19:06.542: INFO: update-demo-nautilus-j52ff is created but not running
Aug 24 10:19:11.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:19:11.800: INFO: stderr: ""
Aug 24 10:19:11.801: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
Aug 24 10:19:11.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:19:12.053: INFO: stderr: ""
Aug 24 10:19:12.053: INFO: stdout: ""
Aug 24 10:19:12.053: INFO: update-demo-nautilus-j52ff is created but not running
Aug 24 10:19:17.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:19:17.237: INFO: stderr: ""
Aug 24 10:19:17.238: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
Aug 24 10:19:17.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:19:17.375: INFO: stderr: ""
Aug 24 10:19:17.375: INFO: stdout: "true"
Aug 24 10:19:17.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:19:17.539: INFO: stderr: ""
Aug 24 10:19:17.539: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:19:17.539: INFO: validating pod update-demo-nautilus-j52ff
Aug 24 10:19:17.558: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:19:17.558: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:19:17.558: INFO: update-demo-nautilus-j52ff is verified up and running
Aug 24 10:19:17.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-s9x8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:19:17.791: INFO: stderr: ""
Aug 24 10:19:17.791: INFO: stdout: "true"
Aug 24 10:19:17.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-s9x8x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:19:17.965: INFO: stderr: ""
Aug 24 10:19:17.965: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:19:17.965: INFO: validating pod update-demo-nautilus-s9x8x
Aug 24 10:19:17.980: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:19:17.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:19:17.980: INFO: update-demo-nautilus-s9x8x is verified up and running
STEP: using delete to clean up resources 08/24/22 10:19:17.98
Aug 24 10:19:17.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 delete --grace-period=0 --force -f -'
Aug 24 10:19:18.150: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:19:18.150: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 24 10:19:18.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get rc,svc -l name=update-demo --no-headers'
Aug 24 10:19:18.409: INFO: stderr: "No resources found in kubectl-6231 namespace.\n"
Aug 24 10:19:18.409: INFO: stdout: ""
Aug 24 10:19:18.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 10:19:18.570: INFO: stderr: ""
Aug 24 10:19:18.570: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:19:18.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6231" for this suite. 08/24/22 10:19:18.58
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":203,"skipped":3402,"failed":0}
------------------------------
• [SLOW TEST] [18.558 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:00.04
    Aug 24 10:19:00.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:19:00.044
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:00.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:00.077
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 08/24/22 10:19:00.081
    Aug 24 10:19:00.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 create -f -'
    Aug 24 10:19:00.653: INFO: stderr: ""
    Aug 24 10:19:00.653: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:19:00.653
    Aug 24 10:19:00.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:19:00.894: INFO: stderr: ""
    Aug 24 10:19:00.894: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
    Aug 24 10:19:00.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:19:01.094: INFO: stderr: ""
    Aug 24 10:19:01.094: INFO: stdout: ""
    Aug 24 10:19:01.094: INFO: update-demo-nautilus-j52ff is created but not running
    Aug 24 10:19:06.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:19:06.322: INFO: stderr: ""
    Aug 24 10:19:06.322: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
    Aug 24 10:19:06.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:19:06.541: INFO: stderr: ""
    Aug 24 10:19:06.542: INFO: stdout: ""
    Aug 24 10:19:06.542: INFO: update-demo-nautilus-j52ff is created but not running
    Aug 24 10:19:11.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:19:11.800: INFO: stderr: ""
    Aug 24 10:19:11.801: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
    Aug 24 10:19:11.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:19:12.053: INFO: stderr: ""
    Aug 24 10:19:12.053: INFO: stdout: ""
    Aug 24 10:19:12.053: INFO: update-demo-nautilus-j52ff is created but not running
    Aug 24 10:19:17.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:19:17.237: INFO: stderr: ""
    Aug 24 10:19:17.238: INFO: stdout: "update-demo-nautilus-j52ff update-demo-nautilus-s9x8x "
    Aug 24 10:19:17.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:19:17.375: INFO: stderr: ""
    Aug 24 10:19:17.375: INFO: stdout: "true"
    Aug 24 10:19:17.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-j52ff -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:19:17.539: INFO: stderr: ""
    Aug 24 10:19:17.539: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:19:17.539: INFO: validating pod update-demo-nautilus-j52ff
    Aug 24 10:19:17.558: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:19:17.558: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:19:17.558: INFO: update-demo-nautilus-j52ff is verified up and running
    Aug 24 10:19:17.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-s9x8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:19:17.791: INFO: stderr: ""
    Aug 24 10:19:17.791: INFO: stdout: "true"
    Aug 24 10:19:17.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods update-demo-nautilus-s9x8x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:19:17.965: INFO: stderr: ""
    Aug 24 10:19:17.965: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:19:17.965: INFO: validating pod update-demo-nautilus-s9x8x
    Aug 24 10:19:17.980: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:19:17.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:19:17.980: INFO: update-demo-nautilus-s9x8x is verified up and running
    STEP: using delete to clean up resources 08/24/22 10:19:17.98
    Aug 24 10:19:17.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 delete --grace-period=0 --force -f -'
    Aug 24 10:19:18.150: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:19:18.150: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 24 10:19:18.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get rc,svc -l name=update-demo --no-headers'
    Aug 24 10:19:18.409: INFO: stderr: "No resources found in kubectl-6231 namespace.\n"
    Aug 24 10:19:18.409: INFO: stdout: ""
    Aug 24 10:19:18.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6231 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 24 10:19:18.570: INFO: stderr: ""
    Aug 24 10:19:18.570: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:19:18.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6231" for this suite. 08/24/22 10:19:18.58
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:18.61
Aug 24 10:19:18.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:19:18.613
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:18.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:18.665
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Aug 24 10:19:18.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:19:22.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3604" for this suite. 08/24/22 10:19:22.21
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":204,"skipped":3481,"failed":0}
------------------------------
• [3.613 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:18.61
    Aug 24 10:19:18.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:19:18.613
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:18.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:18.665
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Aug 24 10:19:18.669: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:19:22.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3604" for this suite. 08/24/22 10:19:22.21
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:22.235
Aug 24 10:19:22.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption 08/24/22 10:19:22.237
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:22.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:22.271
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:22.275
Aug 24 10:19:22.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption-2 08/24/22 10:19:22.277
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:22.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:22.305
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 08/24/22 10:19:22.319
STEP: Waiting for the pdb to be processed 08/24/22 10:19:24.351
STEP: Waiting for the pdb to be processed 08/24/22 10:19:26.385
STEP: listing a collection of PDBs across all namespaces 08/24/22 10:19:28.409
STEP: listing a collection of PDBs in namespace disruption-245 08/24/22 10:19:28.416
STEP: deleting a collection of PDBs 08/24/22 10:19:28.422
STEP: Waiting for the PDB collection to be deleted 08/24/22 10:19:28.445
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Aug 24 10:19:28.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-5408" for this suite. 08/24/22 10:19:28.459
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 24 10:19:28.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-245" for this suite. 08/24/22 10:19:28.476
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":205,"skipped":3602,"failed":0}
------------------------------
• [SLOW TEST] [6.252 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:22.235
    Aug 24 10:19:22.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption 08/24/22 10:19:22.237
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:22.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:22.271
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:22.275
    Aug 24 10:19:22.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption-2 08/24/22 10:19:22.277
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:22.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:22.305
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 08/24/22 10:19:22.319
    STEP: Waiting for the pdb to be processed 08/24/22 10:19:24.351
    STEP: Waiting for the pdb to be processed 08/24/22 10:19:26.385
    STEP: listing a collection of PDBs across all namespaces 08/24/22 10:19:28.409
    STEP: listing a collection of PDBs in namespace disruption-245 08/24/22 10:19:28.416
    STEP: deleting a collection of PDBs 08/24/22 10:19:28.422
    STEP: Waiting for the PDB collection to be deleted 08/24/22 10:19:28.445
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Aug 24 10:19:28.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-5408" for this suite. 08/24/22 10:19:28.459
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 24 10:19:28.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-245" for this suite. 08/24/22 10:19:28.476
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:28.49
Aug 24 10:19:28.490: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:19:28.492
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:28.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:28.517
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-a264bc6a-01a8-4941-88a7-f344b627f521 08/24/22 10:19:28.526
STEP: Creating a pod to test consume configMaps 08/24/22 10:19:28.54
Aug 24 10:19:28.558: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff" in namespace "configmap-9414" to be "Succeeded or Failed"
Aug 24 10:19:28.583: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Pending", Reason="", readiness=false. Elapsed: 24.819674ms
Aug 24 10:19:30.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0343858s
Aug 24 10:19:32.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033897137s
STEP: Saw pod success 08/24/22 10:19:32.592
Aug 24 10:19:32.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff" satisfied condition "Succeeded or Failed"
Aug 24 10:19:32.599: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:19:32.614
Aug 24 10:19:32.648: INFO: Waiting for pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff to disappear
Aug 24 10:19:32.657: INFO: Pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:19:32.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9414" for this suite. 08/24/22 10:19:32.69
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":206,"skipped":3604,"failed":0}
------------------------------
• [4.237 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:28.49
    Aug 24 10:19:28.490: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:19:28.492
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:28.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:28.517
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-a264bc6a-01a8-4941-88a7-f344b627f521 08/24/22 10:19:28.526
    STEP: Creating a pod to test consume configMaps 08/24/22 10:19:28.54
    Aug 24 10:19:28.558: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff" in namespace "configmap-9414" to be "Succeeded or Failed"
    Aug 24 10:19:28.583: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Pending", Reason="", readiness=false. Elapsed: 24.819674ms
    Aug 24 10:19:30.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0343858s
    Aug 24 10:19:32.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033897137s
    STEP: Saw pod success 08/24/22 10:19:32.592
    Aug 24 10:19:32.592: INFO: Pod "pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff" satisfied condition "Succeeded or Failed"
    Aug 24 10:19:32.599: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:19:32.614
    Aug 24 10:19:32.648: INFO: Waiting for pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff to disappear
    Aug 24 10:19:32.657: INFO: Pod pod-configmaps-aa45c6d1-6e61-4bc0-99c0-c0b8c47e9dff no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:19:32.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9414" for this suite. 08/24/22 10:19:32.69
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:32.731
Aug 24 10:19:32.732: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:19:32.734
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:32.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:32.847
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 08/24/22 10:19:32.851
STEP: Creating a ResourceQuota 08/24/22 10:19:37.858
STEP: Ensuring resource quota status is calculated 08/24/22 10:19:37.889
STEP: Creating a ReplicaSet 08/24/22 10:19:39.896
STEP: Ensuring resource quota status captures replicaset creation 08/24/22 10:19:39.917
STEP: Deleting a ReplicaSet 08/24/22 10:19:41.924
STEP: Ensuring resource quota status released usage 08/24/22 10:19:41.938
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:19:43.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2720" for this suite. 08/24/22 10:19:43.956
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":207,"skipped":3610,"failed":0}
------------------------------
• [SLOW TEST] [11.236 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:32.731
    Aug 24 10:19:32.732: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:19:32.734
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:32.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:32.847
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 08/24/22 10:19:32.851
    STEP: Creating a ResourceQuota 08/24/22 10:19:37.858
    STEP: Ensuring resource quota status is calculated 08/24/22 10:19:37.889
    STEP: Creating a ReplicaSet 08/24/22 10:19:39.896
    STEP: Ensuring resource quota status captures replicaset creation 08/24/22 10:19:39.917
    STEP: Deleting a ReplicaSet 08/24/22 10:19:41.924
    STEP: Ensuring resource quota status released usage 08/24/22 10:19:41.938
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:19:43.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2720" for this suite. 08/24/22 10:19:43.956
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:19:43.977
Aug 24 10:19:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename watch 08/24/22 10:19:43.981
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:44.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:44.007
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 08/24/22 10:19:44.011
STEP: creating a watch on configmaps with label B 08/24/22 10:19:44.013
STEP: creating a watch on configmaps with label A or B 08/24/22 10:19:44.014
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.016
Aug 24 10:19:44.023: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22442 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:44.025: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22442 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.025
Aug 24 10:19:44.049: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22443 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:44.050: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22443 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/24/22 10:19:44.05
Aug 24 10:19:44.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22444 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:44.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22444 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.079
Aug 24 10:19:44.089: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22445 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:44.089: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22445 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/24/22 10:19:44.089
Aug 24 10:19:44.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22446 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:44.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22446 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/24/22 10:19:54.107
Aug 24 10:19:54.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22470 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:19:54.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22470 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 24 10:20:04.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9228" for this suite. 08/24/22 10:20:04.142
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":208,"skipped":3635,"failed":0}
------------------------------
• [SLOW TEST] [20.180 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:19:43.977
    Aug 24 10:19:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename watch 08/24/22 10:19:43.981
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:19:44.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:19:44.007
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 08/24/22 10:19:44.011
    STEP: creating a watch on configmaps with label B 08/24/22 10:19:44.013
    STEP: creating a watch on configmaps with label A or B 08/24/22 10:19:44.014
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.016
    Aug 24 10:19:44.023: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22442 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:44.025: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22442 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.025
    Aug 24 10:19:44.049: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22443 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:44.050: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22443 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/24/22 10:19:44.05
    Aug 24 10:19:44.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22444 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:44.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22444 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/24/22 10:19:44.079
    Aug 24 10:19:44.089: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22445 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:44.089: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9228  a183e96e-4d53-4ac3-84a5-8a7c6a2d9644 22445 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/24/22 10:19:44.089
    Aug 24 10:19:44.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22446 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:44.106: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22446 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/24/22 10:19:54.107
    Aug 24 10:19:54.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22470 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:19:54.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9228  163cb027-06d3-4d71-b00e-52c02f0155cc 22470 0 2022-08-24 10:19:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-24 10:19:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 24 10:20:04.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9228" for this suite. 08/24/22 10:20:04.142
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:20:04.175
Aug 24 10:20:04.176: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:20:04.178
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:20:04.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:20:04.213
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9551 08/24/22 10:20:04.219
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-9551 08/24/22 10:20:04.236
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9551 08/24/22 10:20:04.249
Aug 24 10:20:04.256: INFO: Found 0 stateful pods, waiting for 1
Aug 24 10:20:14.263: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/24/22 10:20:14.263
Aug 24 10:20:14.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:20:14.532: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:20:14.532: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:20:14.532: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:20:14.539: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 24 10:20:24.548: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:20:24.549: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:20:24.592: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 24 10:20:24.592: INFO: ss-0  kah9uighaagh-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
Aug 24 10:20:24.592: INFO: ss-1                  Pending         []
Aug 24 10:20:24.592: INFO: 
Aug 24 10:20:24.592: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 24 10:20:25.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985904662s
Aug 24 10:20:26.617: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969991247s
Aug 24 10:20:27.630: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960924758s
Aug 24 10:20:28.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.927228144s
Aug 24 10:20:29.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.911332889s
Aug 24 10:20:30.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.903852327s
Aug 24 10:20:31.693: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.895706219s
Aug 24 10:20:32.704: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.886606275s
Aug 24 10:20:33.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 874.924666ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9551 08/24/22 10:20:34.715
Aug 24 10:20:34.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:20:35.308: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:20:35.308: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:20:35.308: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:20:35.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:20:35.631: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 24 10:20:35.631: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:20:35.631: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:20:35.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:20:35.983: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 24 10:20:35.983: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:20:35.983: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:20:35.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:20:35.991: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:20:35.991: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 08/24/22 10:20:35.991
Aug 24 10:20:36.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:20:36.263: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:20:36.263: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:20:36.263: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:20:36.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:20:36.473: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:20:36.474: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:20:36.474: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:20:36.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:20:36.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:20:36.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:20:36.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:20:36.825: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:20:36.835: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 24 10:20:46.852: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:20:46.852: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:20:46.852: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:20:46.876: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 24 10:20:46.876: INFO: ss-0  kah9uighaagh-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
Aug 24 10:20:46.876: INFO: ss-1  kah9uighaagh-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
Aug 24 10:20:46.877: INFO: ss-2  kah9uighaagh-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
Aug 24 10:20:46.877: INFO: 
Aug 24 10:20:46.877: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 24 10:20:47.885: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 24 10:20:47.885: INFO: ss-0  kah9uighaagh-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
Aug 24 10:20:47.885: INFO: ss-1  kah9uighaagh-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
Aug 24 10:20:47.885: INFO: ss-2  kah9uighaagh-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
Aug 24 10:20:47.885: INFO: 
Aug 24 10:20:47.885: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 24 10:20:48.894: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.983235108s
Aug 24 10:20:49.899: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.97459173s
Aug 24 10:20:50.917: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.969168989s
Aug 24 10:20:51.925: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.951092057s
Aug 24 10:20:52.930: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.943295421s
Aug 24 10:20:53.937: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.938638381s
Aug 24 10:20:54.944: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.931609211s
Aug 24 10:20:55.951: INFO: Verifying statefulset ss doesn't scale past 0 for another 924.555839ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9551 08/24/22 10:20:56.952
Aug 24 10:20:56.958: INFO: Scaling statefulset ss to 0
Aug 24 10:20:56.979: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:20:56.984: INFO: Deleting all statefulset in ns statefulset-9551
Aug 24 10:20:56.990: INFO: Scaling statefulset ss to 0
Aug 24 10:20:57.008: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:20:57.013: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:20:57.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9551" for this suite. 08/24/22 10:20:57.054
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":209,"skipped":3713,"failed":0}
------------------------------
• [SLOW TEST] [52.895 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:20:04.175
    Aug 24 10:20:04.176: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:20:04.178
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:20:04.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:20:04.213
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9551 08/24/22 10:20:04.219
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-9551 08/24/22 10:20:04.236
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9551 08/24/22 10:20:04.249
    Aug 24 10:20:04.256: INFO: Found 0 stateful pods, waiting for 1
    Aug 24 10:20:14.263: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/24/22 10:20:14.263
    Aug 24 10:20:14.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:20:14.532: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:20:14.532: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:20:14.532: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:20:14.539: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 24 10:20:24.548: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:20:24.549: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:20:24.592: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 24 10:20:24.592: INFO: ss-0  kah9uighaagh-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
    Aug 24 10:20:24.592: INFO: ss-1                  Pending         []
    Aug 24 10:20:24.592: INFO: 
    Aug 24 10:20:24.592: INFO: StatefulSet ss has not reached scale 3, at 2
    Aug 24 10:20:25.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985904662s
    Aug 24 10:20:26.617: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.969991247s
    Aug 24 10:20:27.630: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960924758s
    Aug 24 10:20:28.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.927228144s
    Aug 24 10:20:29.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.911332889s
    Aug 24 10:20:30.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.903852327s
    Aug 24 10:20:31.693: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.895706219s
    Aug 24 10:20:32.704: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.886606275s
    Aug 24 10:20:33.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 874.924666ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9551 08/24/22 10:20:34.715
    Aug 24 10:20:34.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:20:35.308: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:20:35.308: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:20:35.308: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:20:35.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:20:35.631: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 24 10:20:35.631: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:20:35.631: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:20:35.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:20:35.983: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 24 10:20:35.983: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:20:35.983: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:20:35.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:20:35.991: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:20:35.991: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 08/24/22 10:20:35.991
    Aug 24 10:20:36.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:20:36.263: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:20:36.263: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:20:36.263: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:20:36.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:20:36.473: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:20:36.474: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:20:36.474: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:20:36.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9551 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:20:36.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:20:36.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:20:36.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:20:36.825: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:20:36.835: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Aug 24 10:20:46.852: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:20:46.852: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:20:46.852: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:20:46.876: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 24 10:20:46.876: INFO: ss-0  kah9uighaagh-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
    Aug 24 10:20:46.876: INFO: ss-1  kah9uighaagh-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
    Aug 24 10:20:46.877: INFO: ss-2  kah9uighaagh-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
    Aug 24 10:20:46.877: INFO: 
    Aug 24 10:20:46.877: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 24 10:20:47.885: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 24 10:20:47.885: INFO: ss-0  kah9uighaagh-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:04 +0000 UTC  }]
    Aug 24 10:20:47.885: INFO: ss-1  kah9uighaagh-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
    Aug 24 10:20:47.885: INFO: ss-2  kah9uighaagh-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:20:24 +0000 UTC  }]
    Aug 24 10:20:47.885: INFO: 
    Aug 24 10:20:47.885: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 24 10:20:48.894: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.983235108s
    Aug 24 10:20:49.899: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.97459173s
    Aug 24 10:20:50.917: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.969168989s
    Aug 24 10:20:51.925: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.951092057s
    Aug 24 10:20:52.930: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.943295421s
    Aug 24 10:20:53.937: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.938638381s
    Aug 24 10:20:54.944: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.931609211s
    Aug 24 10:20:55.951: INFO: Verifying statefulset ss doesn't scale past 0 for another 924.555839ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9551 08/24/22 10:20:56.952
    Aug 24 10:20:56.958: INFO: Scaling statefulset ss to 0
    Aug 24 10:20:56.979: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:20:56.984: INFO: Deleting all statefulset in ns statefulset-9551
    Aug 24 10:20:56.990: INFO: Scaling statefulset ss to 0
    Aug 24 10:20:57.008: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:20:57.013: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:20:57.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9551" for this suite. 08/24/22 10:20:57.054
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:20:57.075
Aug 24 10:20:57.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 10:20:57.077
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:20:57.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:20:57.115
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 08/24/22 10:20:57.12
STEP: delete the rc 08/24/22 10:21:02.138
STEP: wait for all pods to be garbage collected 08/24/22 10:21:02.147
STEP: Gathering metrics 08/24/22 10:21:07.163
Aug 24 10:21:07.210: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 10:21:07.218: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.022185ms
Aug 24 10:21:07.218: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 10:21:07.218: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 10:21:07.366: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 10:21:07.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1756" for this suite. 08/24/22 10:21:07.387
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":210,"skipped":3753,"failed":0}
------------------------------
• [SLOW TEST] [10.344 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:20:57.075
    Aug 24 10:20:57.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 10:20:57.077
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:20:57.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:20:57.115
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 08/24/22 10:20:57.12
    STEP: delete the rc 08/24/22 10:21:02.138
    STEP: wait for all pods to be garbage collected 08/24/22 10:21:02.147
    STEP: Gathering metrics 08/24/22 10:21:07.163
    Aug 24 10:21:07.210: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 10:21:07.218: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.022185ms
    Aug 24 10:21:07.218: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 10:21:07.218: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 10:21:07.366: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 10:21:07.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1756" for this suite. 08/24/22 10:21:07.387
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:21:07.423
Aug 24 10:21:07.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:21:07.427
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:21:07.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:21:07.494
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 24 10:21:07.532: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 10:22:07.570: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 08/24/22 10:22:07.577
Aug 24 10:22:07.626: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 24 10:22:07.638: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 24 10:22:07.685: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 24 10:22:07.703: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 24 10:22:07.766: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 24 10:22:07.780: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/24/22 10:22:07.78
Aug 24 10:22:07.780: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:07.795: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 15.11919ms
Aug 24 10:22:09.804: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024288305s
Aug 24 10:22:11.816: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036376823s
Aug 24 10:22:13.803: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.023178522s
Aug 24 10:22:13.804: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 24 10:22:13.804: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:13.813: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.47835ms
Aug 24 10:22:13.813: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:22:13.814: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:13.819: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.754901ms
Aug 24 10:22:15.826: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011926758s
Aug 24 10:22:17.826: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012696353s
Aug 24 10:22:19.828: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.014229363s
Aug 24 10:22:19.828: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:22:19.829: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:19.834: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.552744ms
Aug 24 10:22:19.834: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:22:19.834: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:19.840: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.604204ms
Aug 24 10:22:19.840: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:22:19.840: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
Aug 24 10:22:19.845: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.337012ms
Aug 24 10:22:19.845: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 08/24/22 10:22:19.845
Aug 24 10:22:19.862: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Aug 24 10:22:19.866: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.931953ms
Aug 24 10:22:21.877: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014890337s
Aug 24 10:22:23.874: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.012003501s
Aug 24 10:22:23.874: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:22:23.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-324" for this suite. 08/24/22 10:22:23.939
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":211,"skipped":3765,"failed":0}
------------------------------
• [SLOW TEST] [76.592 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:21:07.423
    Aug 24 10:21:07.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:21:07.427
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:21:07.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:21:07.494
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 24 10:21:07.532: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 10:22:07.570: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 08/24/22 10:22:07.577
    Aug 24 10:22:07.626: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 24 10:22:07.638: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 24 10:22:07.685: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 24 10:22:07.703: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Aug 24 10:22:07.766: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Aug 24 10:22:07.780: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/24/22 10:22:07.78
    Aug 24 10:22:07.780: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:07.795: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 15.11919ms
    Aug 24 10:22:09.804: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024288305s
    Aug 24 10:22:11.816: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036376823s
    Aug 24 10:22:13.803: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.023178522s
    Aug 24 10:22:13.804: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 24 10:22:13.804: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:13.813: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.47835ms
    Aug 24 10:22:13.813: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:22:13.814: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:13.819: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.754901ms
    Aug 24 10:22:15.826: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011926758s
    Aug 24 10:22:17.826: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012696353s
    Aug 24 10:22:19.828: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.014229363s
    Aug 24 10:22:19.828: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:22:19.829: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:19.834: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.552744ms
    Aug 24 10:22:19.834: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:22:19.834: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:19.840: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.604204ms
    Aug 24 10:22:19.840: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:22:19.840: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-324" to be "running"
    Aug 24 10:22:19.845: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.337012ms
    Aug 24 10:22:19.845: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 08/24/22 10:22:19.845
    Aug 24 10:22:19.862: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Aug 24 10:22:19.866: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.931953ms
    Aug 24 10:22:21.877: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014890337s
    Aug 24 10:22:23.874: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.012003501s
    Aug 24 10:22:23.874: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:22:23.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-324" for this suite. 08/24/22 10:22:23.939
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:22:24.017
Aug 24 10:22:24.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 10:22:24.021
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:24.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:24.061
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Aug 24 10:22:24.068: INFO: Creating ReplicaSet my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e
Aug 24 10:22:24.080: INFO: Pod name my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Found 0 pods out of 1
Aug 24 10:22:29.087: INFO: Pod name my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Found 1 pods out of 1
Aug 24 10:22:29.087: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e" is running
Aug 24 10:22:29.087: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" in namespace "replicaset-2956" to be "running"
Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx": Phase="Running", Reason="", readiness=true. Elapsed: 6.827276ms
Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" satisfied condition "running"
Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:}])
Aug 24 10:22:29.094: INFO: Trying to dial the pod
Aug 24 10:22:34.117: INFO: Controller my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Got expected result from replica 1 [my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx]: "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 10:22:34.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2956" for this suite. 08/24/22 10:22:34.126
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":212,"skipped":3778,"failed":0}
------------------------------
• [SLOW TEST] [10.120 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:22:24.017
    Aug 24 10:22:24.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 10:22:24.021
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:24.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:24.061
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Aug 24 10:22:24.068: INFO: Creating ReplicaSet my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e
    Aug 24 10:22:24.080: INFO: Pod name my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Found 0 pods out of 1
    Aug 24 10:22:29.087: INFO: Pod name my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Found 1 pods out of 1
    Aug 24 10:22:29.087: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e" is running
    Aug 24 10:22:29.087: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" in namespace "replicaset-2956" to be "running"
    Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx": Phase="Running", Reason="", readiness=true. Elapsed: 6.827276ms
    Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" satisfied condition "running"
    Aug 24 10:22:29.094: INFO: Pod "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 10:22:24 +0000 UTC Reason: Message:}])
    Aug 24 10:22:29.094: INFO: Trying to dial the pod
    Aug 24 10:22:34.117: INFO: Controller my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e: Got expected result from replica 1 [my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx]: "my-hostname-basic-d4a24bac-e09e-4eaa-bff9-0014c60c7f7e-5cbbx", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 10:22:34.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2956" for this suite. 08/24/22 10:22:34.126
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:22:34.151
Aug 24 10:22:34.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:22:34.153
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:34.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:34.182
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Aug 24 10:22:34.206: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5302 to be scheduled
Aug 24 10:22:34.212: INFO: 1 pods are not scheduled: [runtimeclass-5302/test-runtimeclass-runtimeclass-5302-preconfigured-handler-mvdr2(378962b4-e485-4d9c-96c1-33ff79bd191b)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 24 10:22:36.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5302" for this suite. 08/24/22 10:22:36.236
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":213,"skipped":3814,"failed":0}
------------------------------
• [2.095 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:22:34.151
    Aug 24 10:22:34.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename runtimeclass 08/24/22 10:22:34.153
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:34.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:34.182
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Aug 24 10:22:34.206: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5302 to be scheduled
    Aug 24 10:22:34.212: INFO: 1 pods are not scheduled: [runtimeclass-5302/test-runtimeclass-runtimeclass-5302-preconfigured-handler-mvdr2(378962b4-e485-4d9c-96c1-33ff79bd191b)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 24 10:22:36.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5302" for this suite. 08/24/22 10:22:36.236
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:22:36.252
Aug 24 10:22:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename watch 08/24/22 10:22:36.254
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:36.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:36.283
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 08/24/22 10:22:36.287
STEP: starting a background goroutine to produce watch events 08/24/22 10:22:36.293
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/24/22 10:22:36.293
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 24 10:22:39.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4894" for this suite. 08/24/22 10:22:39.113
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":214,"skipped":3838,"failed":0}
------------------------------
• [2.918 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:22:36.252
    Aug 24 10:22:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename watch 08/24/22 10:22:36.254
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:36.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:36.283
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 08/24/22 10:22:36.287
    STEP: starting a background goroutine to produce watch events 08/24/22 10:22:36.293
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/24/22 10:22:36.293
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 24 10:22:39.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4894" for this suite. 08/24/22 10:22:39.113
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:22:39.172
Aug 24 10:22:39.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 10:22:39.176
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:39.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:39.213
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 08/24/22 10:22:39.27
STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:22:39.297
Aug 24 10:22:39.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:22:39.311: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:22:40.328: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:22:40.328: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:22:41.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 10:22:41.326: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 08/24/22 10:22:41.333
Aug 24 10:22:41.369: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 10:22:41.369: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:22:42.391: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 10:22:42.391: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:22:43.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 10:22:43.383: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:22:44.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 10:22:44.421: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:22:45.387: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 10:22:45.388: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:22:45.399
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2477, will wait for the garbage collector to delete the pods 08/24/22 10:22:45.4
Aug 24 10:22:45.466: INFO: Deleting DaemonSet.extensions daemon-set took: 10.515741ms
Aug 24 10:22:45.568: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.384995ms
Aug 24 10:22:47.875: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:22:47.875: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 10:22:47.879: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23371"},"items":null}

Aug 24 10:22:47.883: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23371"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:22:47.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2477" for this suite. 08/24/22 10:22:47.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":215,"skipped":3853,"failed":0}
------------------------------
• [SLOW TEST] [8.752 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:22:39.172
    Aug 24 10:22:39.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 10:22:39.176
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:39.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:39.213
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 08/24/22 10:22:39.27
    STEP: Check that daemon pods launch on every node of the cluster. 08/24/22 10:22:39.297
    Aug 24 10:22:39.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:22:39.311: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:22:40.328: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:22:40.328: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:22:41.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 10:22:41.326: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 08/24/22 10:22:41.333
    Aug 24 10:22:41.369: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 10:22:41.369: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:22:42.391: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 10:22:42.391: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:22:43.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 10:22:43.383: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:22:44.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 24 10:22:44.421: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:22:45.387: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 10:22:45.388: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:22:45.399
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2477, will wait for the garbage collector to delete the pods 08/24/22 10:22:45.4
    Aug 24 10:22:45.466: INFO: Deleting DaemonSet.extensions daemon-set took: 10.515741ms
    Aug 24 10:22:45.568: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.384995ms
    Aug 24 10:22:47.875: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:22:47.875: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 10:22:47.879: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23371"},"items":null}

    Aug 24 10:22:47.883: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23371"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:22:47.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2477" for this suite. 08/24/22 10:22:47.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:22:47.926
Aug 24 10:22:47.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:22:47.93
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:47.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:47.96
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-4426 08/24/22 10:22:47.964
STEP: creating service affinity-nodeport in namespace services-4426 08/24/22 10:22:47.964
STEP: creating replication controller affinity-nodeport in namespace services-4426 08/24/22 10:22:47.999
I0824 10:22:48.016740      14 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4426, replica count: 3
I0824 10:22:51.068311      14 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:22:51.086: INFO: Creating new exec pod
Aug 24 10:22:51.096: INFO: Waiting up to 5m0s for pod "execpod-affinitypp6fq" in namespace "services-4426" to be "running"
Aug 24 10:22:51.100: INFO: Pod "execpod-affinitypp6fq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.738348ms
Aug 24 10:22:53.112: INFO: Pod "execpod-affinitypp6fq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016457808s
Aug 24 10:22:55.107: INFO: Pod "execpod-affinitypp6fq": Phase="Running", Reason="", readiness=true. Elapsed: 4.011409755s
Aug 24 10:22:55.108: INFO: Pod "execpod-affinitypp6fq" satisfied condition "running"
Aug 24 10:22:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Aug 24 10:22:56.360: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug 24 10:22:56.360: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:22:56.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.15.136 80'
Aug 24 10:22:56.616: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.15.136 80\nConnection to 10.233.15.136 80 port [tcp/http] succeeded!\n"
Aug 24 10:22:56.616: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:22:56.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 31755'
Aug 24 10:22:56.845: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 31755\nConnection to 192.168.121.54 31755 port [tcp/*] succeeded!\n"
Aug 24 10:22:56.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:22:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 31755'
Aug 24 10:22:57.349: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 31755\nConnection to 192.168.121.119 31755 port [tcp/*] succeeded!\n"
Aug 24 10:22:57.349: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:22:57.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:31755/ ; done'
Aug 24 10:22:57.923: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n"
Aug 24 10:22:57.923: INFO: stdout: "\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx"
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
Aug 24 10:22:57.923: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4426, will wait for the garbage collector to delete the pods 08/24/22 10:22:57.953
Aug 24 10:22:58.024: INFO: Deleting ReplicationController affinity-nodeport took: 10.307673ms
Aug 24 10:22:58.124: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.311286ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:23:00.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4426" for this suite. 08/24/22 10:23:00.582
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":216,"skipped":3880,"failed":0}
------------------------------
• [SLOW TEST] [12.671 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:22:47.926
    Aug 24 10:22:47.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:22:47.93
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:22:47.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:22:47.96
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-4426 08/24/22 10:22:47.964
    STEP: creating service affinity-nodeport in namespace services-4426 08/24/22 10:22:47.964
    STEP: creating replication controller affinity-nodeport in namespace services-4426 08/24/22 10:22:47.999
    I0824 10:22:48.016740      14 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4426, replica count: 3
    I0824 10:22:51.068311      14 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:22:51.086: INFO: Creating new exec pod
    Aug 24 10:22:51.096: INFO: Waiting up to 5m0s for pod "execpod-affinitypp6fq" in namespace "services-4426" to be "running"
    Aug 24 10:22:51.100: INFO: Pod "execpod-affinitypp6fq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.738348ms
    Aug 24 10:22:53.112: INFO: Pod "execpod-affinitypp6fq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016457808s
    Aug 24 10:22:55.107: INFO: Pod "execpod-affinitypp6fq": Phase="Running", Reason="", readiness=true. Elapsed: 4.011409755s
    Aug 24 10:22:55.108: INFO: Pod "execpod-affinitypp6fq" satisfied condition "running"
    Aug 24 10:22:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Aug 24 10:22:56.360: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Aug 24 10:22:56.360: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:22:56.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.15.136 80'
    Aug 24 10:22:56.616: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.15.136 80\nConnection to 10.233.15.136 80 port [tcp/http] succeeded!\n"
    Aug 24 10:22:56.616: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:22:56.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.54 31755'
    Aug 24 10:22:56.845: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.54 31755\nConnection to 192.168.121.54 31755 port [tcp/*] succeeded!\n"
    Aug 24 10:22:56.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:22:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.119 31755'
    Aug 24 10:22:57.349: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.119 31755\nConnection to 192.168.121.119 31755 port [tcp/*] succeeded!\n"
    Aug 24 10:22:57.349: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:22:57.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-4426 exec execpod-affinitypp6fq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.119:31755/ ; done'
    Aug 24 10:22:57.923: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.119:31755/\n"
    Aug 24 10:22:57.923: INFO: stdout: "\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx\naffinity-nodeport-hw4sx"
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Received response from host: affinity-nodeport-hw4sx
    Aug 24 10:22:57.923: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4426, will wait for the garbage collector to delete the pods 08/24/22 10:22:57.953
    Aug 24 10:22:58.024: INFO: Deleting ReplicationController affinity-nodeport took: 10.307673ms
    Aug 24 10:22:58.124: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.311286ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:23:00.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4426" for this suite. 08/24/22 10:23:00.582
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:23:00.598
Aug 24 10:23:00.599: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:23:00.603
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:00.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:00.642
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 08/24/22 10:23:00.646
STEP: Getting a ResourceQuota 08/24/22 10:23:00.654
STEP: Listing all ResourceQuotas with LabelSelector 08/24/22 10:23:00.665
STEP: Patching the ResourceQuota 08/24/22 10:23:00.677
STEP: Deleting a Collection of ResourceQuotas 08/24/22 10:23:00.696
STEP: Verifying the deleted ResourceQuota 08/24/22 10:23:00.717
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:23:00.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4975" for this suite. 08/24/22 10:23:00.733
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":217,"skipped":3881,"failed":0}
------------------------------
• [0.148 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:23:00.598
    Aug 24 10:23:00.599: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:23:00.603
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:00.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:00.642
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 08/24/22 10:23:00.646
    STEP: Getting a ResourceQuota 08/24/22 10:23:00.654
    STEP: Listing all ResourceQuotas with LabelSelector 08/24/22 10:23:00.665
    STEP: Patching the ResourceQuota 08/24/22 10:23:00.677
    STEP: Deleting a Collection of ResourceQuotas 08/24/22 10:23:00.696
    STEP: Verifying the deleted ResourceQuota 08/24/22 10:23:00.717
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:23:00.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4975" for this suite. 08/24/22 10:23:00.733
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:23:00.758
Aug 24 10:23:00.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename containers 08/24/22 10:23:00.76
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:00.786
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:00.791
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 08/24/22 10:23:00.795
Aug 24 10:23:00.812: INFO: Waiting up to 5m0s for pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43" in namespace "containers-6155" to be "Succeeded or Failed"
Aug 24 10:23:00.820: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Pending", Reason="", readiness=false. Elapsed: 7.13471ms
Aug 24 10:23:02.827: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014105268s
Aug 24 10:23:04.825: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012614792s
STEP: Saw pod success 08/24/22 10:23:04.825
Aug 24 10:23:04.826: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43" satisfied condition "Succeeded or Failed"
Aug 24 10:23:04.832: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:23:04.858
Aug 24 10:23:04.877: INFO: Waiting for pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 to disappear
Aug 24 10:23:04.885: INFO: Pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 24 10:23:04.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6155" for this suite. 08/24/22 10:23:04.902
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":218,"skipped":3898,"failed":0}
------------------------------
• [4.156 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:23:00.758
    Aug 24 10:23:00.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename containers 08/24/22 10:23:00.76
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:00.786
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:00.791
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 08/24/22 10:23:00.795
    Aug 24 10:23:00.812: INFO: Waiting up to 5m0s for pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43" in namespace "containers-6155" to be "Succeeded or Failed"
    Aug 24 10:23:00.820: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Pending", Reason="", readiness=false. Elapsed: 7.13471ms
    Aug 24 10:23:02.827: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014105268s
    Aug 24 10:23:04.825: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012614792s
    STEP: Saw pod success 08/24/22 10:23:04.825
    Aug 24 10:23:04.826: INFO: Pod "client-containers-52441842-9f7e-4199-ae03-e15310469f43" satisfied condition "Succeeded or Failed"
    Aug 24 10:23:04.832: INFO: Trying to get logs from node kah9uighaagh-3 pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:23:04.858
    Aug 24 10:23:04.877: INFO: Waiting for pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 to disappear
    Aug 24 10:23:04.885: INFO: Pod client-containers-52441842-9f7e-4199-ae03-e15310469f43 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 24 10:23:04.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6155" for this suite. 08/24/22 10:23:04.902
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:23:04.92
Aug 24 10:23:04.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:23:04.922
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:04.949
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:04.953
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 08/24/22 10:23:04.957
Aug 24 10:23:04.971: INFO: Waiting up to 5m0s for pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd" in namespace "emptydir-5293" to be "Succeeded or Failed"
Aug 24 10:23:04.976: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.555135ms
Aug 24 10:23:06.987: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.015381644s
Aug 24 10:23:08.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Running", Reason="", readiness=false. Elapsed: 4.012917585s
Aug 24 10:23:10.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012189012s
STEP: Saw pod success 08/24/22 10:23:10.984
Aug 24 10:23:10.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd" satisfied condition "Succeeded or Failed"
Aug 24 10:23:10.988: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-3c11762a-f037-488f-b36c-9394e478dfdd container test-container: <nil>
STEP: delete the pod 08/24/22 10:23:11.027
Aug 24 10:23:11.043: INFO: Waiting for pod pod-3c11762a-f037-488f-b36c-9394e478dfdd to disappear
Aug 24 10:23:11.049: INFO: Pod pod-3c11762a-f037-488f-b36c-9394e478dfdd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:23:11.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5293" for this suite. 08/24/22 10:23:11.056
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":219,"skipped":3923,"failed":0}
------------------------------
• [SLOW TEST] [6.147 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:23:04.92
    Aug 24 10:23:04.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:23:04.922
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:04.949
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:04.953
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/24/22 10:23:04.957
    Aug 24 10:23:04.971: INFO: Waiting up to 5m0s for pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd" in namespace "emptydir-5293" to be "Succeeded or Failed"
    Aug 24 10:23:04.976: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.555135ms
    Aug 24 10:23:06.987: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.015381644s
    Aug 24 10:23:08.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Running", Reason="", readiness=false. Elapsed: 4.012917585s
    Aug 24 10:23:10.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012189012s
    STEP: Saw pod success 08/24/22 10:23:10.984
    Aug 24 10:23:10.984: INFO: Pod "pod-3c11762a-f037-488f-b36c-9394e478dfdd" satisfied condition "Succeeded or Failed"
    Aug 24 10:23:10.988: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-3c11762a-f037-488f-b36c-9394e478dfdd container test-container: <nil>
    STEP: delete the pod 08/24/22 10:23:11.027
    Aug 24 10:23:11.043: INFO: Waiting for pod pod-3c11762a-f037-488f-b36c-9394e478dfdd to disappear
    Aug 24 10:23:11.049: INFO: Pod pod-3c11762a-f037-488f-b36c-9394e478dfdd no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:23:11.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5293" for this suite. 08/24/22 10:23:11.056
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:23:11.069
Aug 24 10:23:11.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:23:11.071
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:11.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:11.097
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:23:11.126
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:23:11.897
STEP: Deploying the webhook pod 08/24/22 10:23:11.914
STEP: Wait for the deployment to be ready 08/24/22 10:23:11.933
Aug 24 10:23:11.946: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:23:13.961
STEP: Verifying the service has paired with the endpoint 08/24/22 10:23:13.979
Aug 24 10:23:14.980: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 08/24/22 10:23:14.988
STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.011
STEP: Updating a validating webhook configuration's rules to not include the create operation 08/24/22 10:23:15.025
STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.039
STEP: Patching a validating webhook configuration's rules to include the create operation 08/24/22 10:23:15.058
STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.071
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:23:15.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8620" for this suite. 08/24/22 10:23:15.093
STEP: Destroying namespace "webhook-8620-markers" for this suite. 08/24/22 10:23:15.103
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":220,"skipped":3924,"failed":0}
------------------------------
• [4.145 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:23:11.069
    Aug 24 10:23:11.069: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:23:11.071
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:11.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:11.097
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:23:11.126
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:23:11.897
    STEP: Deploying the webhook pod 08/24/22 10:23:11.914
    STEP: Wait for the deployment to be ready 08/24/22 10:23:11.933
    Aug 24 10:23:11.946: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:23:13.961
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:23:13.979
    Aug 24 10:23:14.980: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 08/24/22 10:23:14.988
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.011
    STEP: Updating a validating webhook configuration's rules to not include the create operation 08/24/22 10:23:15.025
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.039
    STEP: Patching a validating webhook configuration's rules to include the create operation 08/24/22 10:23:15.058
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/24/22 10:23:15.071
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:23:15.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8620" for this suite. 08/24/22 10:23:15.093
    STEP: Destroying namespace "webhook-8620-markers" for this suite. 08/24/22 10:23:15.103
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:23:15.217
Aug 24 10:23:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:23:15.22
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:15.258
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:15.265
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 24 10:23:15.295: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 10:24:15.341: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 08/24/22 10:24:15.349
Aug 24 10:24:15.402: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 24 10:24:15.428: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 24 10:24:15.526: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 24 10:24:15.560: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 24 10:24:15.593: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 24 10:24:15.615: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/24/22 10:24:15.615
Aug 24 10:24:15.615: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:15.629: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.331631ms
Aug 24 10:24:17.637: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.021762578s
Aug 24 10:24:17.637: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 24 10:24:17.637: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.642: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.269718ms
Aug 24 10:24:17.642: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:24:17.642: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.648: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.331298ms
Aug 24 10:24:17.649: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:24:17.649: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.654: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.002449ms
Aug 24 10:24:17.654: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:24:17.654: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.659: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.803718ms
Aug 24 10:24:17.660: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 24 10:24:17.660: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.666: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.304175ms
Aug 24 10:24:17.666: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/24/22 10:24:17.666
Aug 24 10:24:17.676: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5067" to be "running"
Aug 24 10:24:17.691: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.189476ms
Aug 24 10:24:19.698: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022365829s
Aug 24 10:24:21.700: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024239259s
Aug 24 10:24:23.698: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02245832s
Aug 24 10:24:25.700: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.023646406s
Aug 24 10:24:25.700: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:24:25.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5067" for this suite. 08/24/22 10:24:25.759
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":221,"skipped":3928,"failed":0}
------------------------------
• [SLOW TEST] [70.697 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:23:15.217
    Aug 24 10:23:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:23:15.22
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:23:15.258
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:23:15.265
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 24 10:23:15.295: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 10:24:15.341: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 08/24/22 10:24:15.349
    Aug 24 10:24:15.402: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 24 10:24:15.428: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 24 10:24:15.526: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 24 10:24:15.560: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Aug 24 10:24:15.593: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Aug 24 10:24:15.615: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/24/22 10:24:15.615
    Aug 24 10:24:15.615: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:15.629: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.331631ms
    Aug 24 10:24:17.637: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.021762578s
    Aug 24 10:24:17.637: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 24 10:24:17.637: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.642: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.269718ms
    Aug 24 10:24:17.642: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:24:17.642: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.648: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.331298ms
    Aug 24 10:24:17.649: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:24:17.649: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.654: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.002449ms
    Aug 24 10:24:17.654: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:24:17.654: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.659: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.803718ms
    Aug 24 10:24:17.660: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 24 10:24:17.660: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.666: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.304175ms
    Aug 24 10:24:17.666: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/24/22 10:24:17.666
    Aug 24 10:24:17.676: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5067" to be "running"
    Aug 24 10:24:17.691: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.189476ms
    Aug 24 10:24:19.698: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022365829s
    Aug 24 10:24:21.700: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024239259s
    Aug 24 10:24:23.698: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02245832s
    Aug 24 10:24:25.700: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.023646406s
    Aug 24 10:24:25.700: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:24:25.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5067" for this suite. 08/24/22 10:24:25.759
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:24:25.919
Aug 24 10:24:25.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:24:25.922
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:25.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:25.95
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:24:25.973
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:24:27.288
STEP: Deploying the webhook pod 08/24/22 10:24:27.299
STEP: Wait for the deployment to be ready 08/24/22 10:24:27.319
Aug 24 10:24:27.328: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:24:29.35
STEP: Verifying the service has paired with the endpoint 08/24/22 10:24:29.367
Aug 24 10:24:30.368: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 08/24/22 10:24:30.483
STEP: Creating a configMap that should be mutated 08/24/22 10:24:30.513
STEP: Deleting the collection of validation webhooks 08/24/22 10:24:30.566
STEP: Creating a configMap that should not be mutated 08/24/22 10:24:30.647
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:24:30.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-698" for this suite. 08/24/22 10:24:30.686
STEP: Destroying namespace "webhook-698-markers" for this suite. 08/24/22 10:24:30.713
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":222,"skipped":3934,"failed":0}
------------------------------
• [4.983 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:24:25.919
    Aug 24 10:24:25.920: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:24:25.922
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:25.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:25.95
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:24:25.973
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:24:27.288
    STEP: Deploying the webhook pod 08/24/22 10:24:27.299
    STEP: Wait for the deployment to be ready 08/24/22 10:24:27.319
    Aug 24 10:24:27.328: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:24:29.35
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:24:29.367
    Aug 24 10:24:30.368: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 08/24/22 10:24:30.483
    STEP: Creating a configMap that should be mutated 08/24/22 10:24:30.513
    STEP: Deleting the collection of validation webhooks 08/24/22 10:24:30.566
    STEP: Creating a configMap that should not be mutated 08/24/22 10:24:30.647
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:24:30.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-698" for this suite. 08/24/22 10:24:30.686
    STEP: Destroying namespace "webhook-698-markers" for this suite. 08/24/22 10:24:30.713
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:24:30.906
Aug 24 10:24:30.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 10:24:30.914
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:30.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:30.969
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 08/24/22 10:24:30.999
STEP: Patching the Job 08/24/22 10:24:31.033
STEP: Watching for Job to be patched 08/24/22 10:24:31.053
Aug 24 10:24:31.058: INFO: Event ADDED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf] and annotations: map[batch.kubernetes.io/job-tracking:]
Aug 24 10:24:31.058: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf] and annotations: map[batch.kubernetes.io/job-tracking:]
Aug 24 10:24:31.058: INFO: Event MODIFIED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 08/24/22 10:24:31.058
STEP: Watching for Job to be updated 08/24/22 10:24:31.101
Aug 24 10:24:31.105: INFO: Event MODIFIED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:31.105: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 08/24/22 10:24:31.105
Aug 24 10:24:31.112: INFO: Job: e2e-vgwgf as labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched]
STEP: Waiting for job to complete 08/24/22 10:24:31.112
STEP: Delete a job collection with a labelselector 08/24/22 10:24:43.119
STEP: Watching for Job to be deleted 08/24/22 10:24:43.134
Aug 24 10:24:43.138: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:43.138: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 24 10:24:43.139: INFO: Event DELETED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 08/24/22 10:24:43.139
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 10:24:43.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6901" for this suite. 08/24/22 10:24:43.154
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":223,"skipped":3946,"failed":0}
------------------------------
• [SLOW TEST] [12.272 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:24:30.906
    Aug 24 10:24:30.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 10:24:30.914
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:30.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:30.969
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 08/24/22 10:24:30.999
    STEP: Patching the Job 08/24/22 10:24:31.033
    STEP: Watching for Job to be patched 08/24/22 10:24:31.053
    Aug 24 10:24:31.058: INFO: Event ADDED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf] and annotations: map[batch.kubernetes.io/job-tracking:]
    Aug 24 10:24:31.058: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf] and annotations: map[batch.kubernetes.io/job-tracking:]
    Aug 24 10:24:31.058: INFO: Event MODIFIED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 08/24/22 10:24:31.058
    STEP: Watching for Job to be updated 08/24/22 10:24:31.101
    Aug 24 10:24:31.105: INFO: Event MODIFIED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:31.105: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 08/24/22 10:24:31.105
    Aug 24 10:24:31.112: INFO: Job: e2e-vgwgf as labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched]
    STEP: Waiting for job to complete 08/24/22 10:24:31.112
    STEP: Delete a job collection with a labelselector 08/24/22 10:24:43.119
    STEP: Watching for Job to be deleted 08/24/22 10:24:43.134
    Aug 24 10:24:43.138: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:43.138: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:43.139: INFO: Event MODIFIED observed for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 24 10:24:43.139: INFO: Event DELETED found for Job e2e-vgwgf in namespace job-6901 with labels: map[e2e-job-label:e2e-vgwgf e2e-vgwgf:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 08/24/22 10:24:43.139
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 10:24:43.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6901" for this suite. 08/24/22 10:24:43.154
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:24:43.186
Aug 24 10:24:43.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:24:43.188
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:43.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:43.223
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 08/24/22 10:24:43.227
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7140;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7140;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +notcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_tcp@PTR;sleep 1; done
 08/24/22 10:24:43.265
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7140;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7140;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +notcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_tcp@PTR;sleep 1; done
 08/24/22 10:24:43.266
STEP: creating a pod to probe DNS 08/24/22 10:24:43.266
STEP: submitting the pod to kubernetes 08/24/22 10:24:43.266
Aug 24 10:24:43.307: INFO: Waiting up to 15m0s for pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76" in namespace "dns-7140" to be "running"
Aug 24 10:24:43.326: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Pending", Reason="", readiness=false. Elapsed: 19.046865ms
Aug 24 10:24:45.333: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026452272s
Aug 24 10:24:47.334: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Running", Reason="", readiness=true. Elapsed: 4.026689251s
Aug 24 10:24:47.335: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:24:47.335
STEP: looking for the results for each expected name from probers 08/24/22 10:24:47.342
Aug 24 10:24:47.359: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.380: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.390: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.424: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.430: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.452: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.461: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.516: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.523: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.531: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.539: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.547: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.559: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.568: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.577: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:47.621: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:24:52.633: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.644: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.653: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.662: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.684: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.697: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.706: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.759: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.771: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.779: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.789: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.797: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.804: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.817: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.825: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:52.866: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:24:57.648: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.654: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.661: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.667: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.673: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.689: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.701: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.777: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.786: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.796: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.803: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.810: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.815: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.821: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.828: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:24:57.871: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:25:02.635: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.645: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.661: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.671: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.678: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.685: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.721: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.733: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.773: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.779: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.788: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.819: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.825: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.829: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.840: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.849: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:02.903: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:25:07.632: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.647: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.656: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.663: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.693: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.702: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.770: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.780: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.787: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.795: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.807: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.816: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.822: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.832: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:07.881: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:25:12.630: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.636: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.641: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.647: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.653: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.658: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.664: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.673: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.709: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.716: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.721: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.727: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.734: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.744: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.752: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.759: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
Aug 24 10:25:12.790: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

Aug 24 10:25:17.817: INFO: DNS probes using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 succeeded

STEP: deleting the pod 08/24/22 10:25:17.818
STEP: deleting the test service 08/24/22 10:25:17.854
STEP: deleting the test headless service 08/24/22 10:25:17.99
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:25:18.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7140" for this suite. 08/24/22 10:25:18.065
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":224,"skipped":4021,"failed":0}
------------------------------
• [SLOW TEST] [34.903 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:24:43.186
    Aug 24 10:24:43.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:24:43.188
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:24:43.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:24:43.223
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 08/24/22 10:24:43.227
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7140;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7140;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +notcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_tcp@PTR;sleep 1; done
     08/24/22 10:24:43.265
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7140;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7140;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7140.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7140.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7140.svc;check="$$(dig +notcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.33_tcp@PTR;sleep 1; done
     08/24/22 10:24:43.266
    STEP: creating a pod to probe DNS 08/24/22 10:24:43.266
    STEP: submitting the pod to kubernetes 08/24/22 10:24:43.266
    Aug 24 10:24:43.307: INFO: Waiting up to 15m0s for pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76" in namespace "dns-7140" to be "running"
    Aug 24 10:24:43.326: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Pending", Reason="", readiness=false. Elapsed: 19.046865ms
    Aug 24 10:24:45.333: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026452272s
    Aug 24 10:24:47.334: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76": Phase="Running", Reason="", readiness=true. Elapsed: 4.026689251s
    Aug 24 10:24:47.335: INFO: Pod "dns-test-2f60880d-58ce-481b-b346-48e3004ecd76" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:24:47.335
    STEP: looking for the results for each expected name from probers 08/24/22 10:24:47.342
    Aug 24 10:24:47.359: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.380: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.390: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.424: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.430: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.452: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.461: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.516: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.523: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.531: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.539: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.547: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.559: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.568: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.577: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:47.621: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:24:52.633: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.644: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.653: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.662: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.675: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.684: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.697: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.706: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.759: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.771: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.779: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.789: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.797: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.804: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.817: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.825: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:52.866: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:24:57.648: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.654: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.661: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.667: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.673: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.679: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.689: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.701: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.777: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.786: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.796: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.803: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.810: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.815: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.821: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.828: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:24:57.871: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:25:02.635: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.645: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.661: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.671: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.678: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.685: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.721: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.733: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.773: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.779: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.788: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.819: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.825: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.829: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.840: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.849: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:02.903: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:25:07.632: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.647: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.656: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.663: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.670: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.693: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.702: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.770: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.780: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.787: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.795: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.807: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.816: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.822: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.832: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:07.881: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:25:12.630: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.636: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.641: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.647: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.653: INFO: Unable to read wheezy_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.658: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.664: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.673: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.709: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.716: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.721: INFO: Unable to read jessie_udp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.727: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140 from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.734: INFO: Unable to read jessie_udp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.744: INFO: Unable to read jessie_tcp@dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.752: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.759: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc from pod dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76: the server could not find the requested resource (get pods dns-test-2f60880d-58ce-481b-b346-48e3004ecd76)
    Aug 24 10:25:12.790: INFO: Lookups using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7140 wheezy_tcp@dns-test-service.dns-7140 wheezy_udp@dns-test-service.dns-7140.svc wheezy_tcp@dns-test-service.dns-7140.svc wheezy_udp@_http._tcp.dns-test-service.dns-7140.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7140.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7140 jessie_tcp@dns-test-service.dns-7140 jessie_udp@dns-test-service.dns-7140.svc jessie_tcp@dns-test-service.dns-7140.svc jessie_udp@_http._tcp.dns-test-service.dns-7140.svc jessie_tcp@_http._tcp.dns-test-service.dns-7140.svc]

    Aug 24 10:25:17.817: INFO: DNS probes using dns-7140/dns-test-2f60880d-58ce-481b-b346-48e3004ecd76 succeeded

    STEP: deleting the pod 08/24/22 10:25:17.818
    STEP: deleting the test service 08/24/22 10:25:17.854
    STEP: deleting the test headless service 08/24/22 10:25:17.99
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:25:18.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7140" for this suite. 08/24/22 10:25:18.065
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:25:18.094
Aug 24 10:25:18.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:25:18.103
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:25:18.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:25:18.147
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 24 10:25:18.198: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 10:26:18.240: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:26:18.248
Aug 24 10:26:18.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption-path 08/24/22 10:26:18.251
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:18.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:18.288
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 08/24/22 10:26:18.292
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:26:18.292
Aug 24 10:26:18.308: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4646" to be "running"
Aug 24 10:26:18.318: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.735647ms
Aug 24 10:26:20.325: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.016954436s
Aug 24 10:26:20.325: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:26:20.33
Aug 24 10:26:20.352: INFO: found a healthy node: kah9uighaagh-3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Aug 24 10:26:36.521: INFO: pods created so far: [1 1 1]
Aug 24 10:26:36.522: INFO: length of pods created so far: 3
Aug 24 10:26:42.547: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Aug 24 10:26:49.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4646" for this suite. 08/24/22 10:26:49.559
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:26:49.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7603" for this suite. 08/24/22 10:26:49.65
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":225,"skipped":4028,"failed":0}
------------------------------
• [SLOW TEST] [91.643 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:25:18.094
    Aug 24 10:25:18.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption 08/24/22 10:25:18.103
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:25:18.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:25:18.147
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 24 10:25:18.198: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 10:26:18.240: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:26:18.248
    Aug 24 10:26:18.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption-path 08/24/22 10:26:18.251
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:18.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:18.288
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 08/24/22 10:26:18.292
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/24/22 10:26:18.292
    Aug 24 10:26:18.308: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4646" to be "running"
    Aug 24 10:26:18.318: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.735647ms
    Aug 24 10:26:20.325: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.016954436s
    Aug 24 10:26:20.325: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/24/22 10:26:20.33
    Aug 24 10:26:20.352: INFO: found a healthy node: kah9uighaagh-3
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Aug 24 10:26:36.521: INFO: pods created so far: [1 1 1]
    Aug 24 10:26:36.522: INFO: length of pods created so far: 3
    Aug 24 10:26:42.547: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Aug 24 10:26:49.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-4646" for this suite. 08/24/22 10:26:49.559
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:26:49.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7603" for this suite. 08/24/22 10:26:49.65
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:26:49.75
Aug 24 10:26:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename lease-test 08/24/22 10:26:49.76
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:49.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:49.794
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Aug 24 10:26:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-9457" for this suite. 08/24/22 10:26:49.94
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":226,"skipped":4084,"failed":0}
------------------------------
• [0.200 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:26:49.75
    Aug 24 10:26:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename lease-test 08/24/22 10:26:49.76
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:49.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:49.794
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Aug 24 10:26:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-9457" for this suite. 08/24/22 10:26:49.94
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:26:49.977
Aug 24 10:26:49.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:26:49.98
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:50.003
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:50.007
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 08/24/22 10:26:50.011
Aug 24 10:26:50.026: INFO: Waiting up to 5m0s for pod "pod-qllqs" in namespace "pods-8137" to be "running"
Aug 24 10:26:50.033: INFO: Pod "pod-qllqs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.824917ms
Aug 24 10:26:52.044: INFO: Pod "pod-qllqs": Phase="Running", Reason="", readiness=true. Elapsed: 2.018003395s
Aug 24 10:26:52.044: INFO: Pod "pod-qllqs" satisfied condition "running"
STEP: patching /status 08/24/22 10:26:52.045
Aug 24 10:26:52.056: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:26:52.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8137" for this suite. 08/24/22 10:26:52.063
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":227,"skipped":4101,"failed":0}
------------------------------
• [2.094 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:26:49.977
    Aug 24 10:26:49.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:26:49.98
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:50.003
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:50.007
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 08/24/22 10:26:50.011
    Aug 24 10:26:50.026: INFO: Waiting up to 5m0s for pod "pod-qllqs" in namespace "pods-8137" to be "running"
    Aug 24 10:26:50.033: INFO: Pod "pod-qllqs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.824917ms
    Aug 24 10:26:52.044: INFO: Pod "pod-qllqs": Phase="Running", Reason="", readiness=true. Elapsed: 2.018003395s
    Aug 24 10:26:52.044: INFO: Pod "pod-qllqs" satisfied condition "running"
    STEP: patching /status 08/24/22 10:26:52.045
    Aug 24 10:26:52.056: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:26:52.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8137" for this suite. 08/24/22 10:26:52.063
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:26:52.075
Aug 24 10:26:52.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-webhook 08/24/22 10:26:52.077
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:52.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:52.104
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/24/22 10:26:52.108
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/24/22 10:26:52.998
STEP: Deploying the custom resource conversion webhook pod 08/24/22 10:26:53.017
STEP: Wait for the deployment to be ready 08/24/22 10:26:53.042
Aug 24 10:26:53.058: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Aug 24 10:26:55.136: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:26:57.15
STEP: Verifying the service has paired with the endpoint 08/24/22 10:26:57.177
Aug 24 10:26:58.177: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Aug 24 10:26:58.183: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Creating a v1 custom resource 08/24/22 10:27:01.188
STEP: Create a v2 custom resource 08/24/22 10:27:01.221
STEP: List CRs in v1 08/24/22 10:27:01.437
STEP: List CRs in v2 08/24/22 10:27:01.446
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:27:01.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5586" for this suite. 08/24/22 10:27:01.991
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":228,"skipped":4106,"failed":0}
------------------------------
• [SLOW TEST] [10.076 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:26:52.075
    Aug 24 10:26:52.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-webhook 08/24/22 10:26:52.077
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:26:52.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:26:52.104
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/24/22 10:26:52.108
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/24/22 10:26:52.998
    STEP: Deploying the custom resource conversion webhook pod 08/24/22 10:26:53.017
    STEP: Wait for the deployment to be ready 08/24/22 10:26:53.042
    Aug 24 10:26:53.058: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    Aug 24 10:26:55.136: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 26, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:26:57.15
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:26:57.177
    Aug 24 10:26:58.177: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Aug 24 10:26:58.183: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Creating a v1 custom resource 08/24/22 10:27:01.188
    STEP: Create a v2 custom resource 08/24/22 10:27:01.221
    STEP: List CRs in v1 08/24/22 10:27:01.437
    STEP: List CRs in v2 08/24/22 10:27:01.446
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:27:01.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-5586" for this suite. 08/24/22 10:27:01.991
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:02.154
Aug 24 10:27:02.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context 08/24/22 10:27:02.159
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:02.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:02.243
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/24/22 10:27:02.253
Aug 24 10:27:02.302: INFO: Waiting up to 5m0s for pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794" in namespace "security-context-4292" to be "Succeeded or Failed"
Aug 24 10:27:02.310: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Pending", Reason="", readiness=false. Elapsed: 7.805736ms
Aug 24 10:27:04.317: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014960657s
Aug 24 10:27:06.323: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021524034s
STEP: Saw pod success 08/24/22 10:27:06.323
Aug 24 10:27:06.324: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794" satisfied condition "Succeeded or Failed"
Aug 24 10:27:06.330: INFO: Trying to get logs from node kah9uighaagh-3 pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 container test-container: <nil>
STEP: delete the pod 08/24/22 10:27:06.359
Aug 24 10:27:06.400: INFO: Waiting for pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 to disappear
Aug 24 10:27:06.406: INFO: Pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:27:06.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4292" for this suite. 08/24/22 10:27:06.424
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":229,"skipped":4128,"failed":0}
------------------------------
• [4.285 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:02.154
    Aug 24 10:27:02.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context 08/24/22 10:27:02.159
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:02.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:02.243
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/24/22 10:27:02.253
    Aug 24 10:27:02.302: INFO: Waiting up to 5m0s for pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794" in namespace "security-context-4292" to be "Succeeded or Failed"
    Aug 24 10:27:02.310: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Pending", Reason="", readiness=false. Elapsed: 7.805736ms
    Aug 24 10:27:04.317: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014960657s
    Aug 24 10:27:06.323: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021524034s
    STEP: Saw pod success 08/24/22 10:27:06.323
    Aug 24 10:27:06.324: INFO: Pod "security-context-db91c4b2-a898-4d3e-994b-565cdf416794" satisfied condition "Succeeded or Failed"
    Aug 24 10:27:06.330: INFO: Trying to get logs from node kah9uighaagh-3 pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:27:06.359
    Aug 24 10:27:06.400: INFO: Waiting for pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 to disappear
    Aug 24 10:27:06.406: INFO: Pod security-context-db91c4b2-a898-4d3e-994b-565cdf416794 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:27:06.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4292" for this suite. 08/24/22 10:27:06.424
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:06.44
Aug 24 10:27:06.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:27:06.445
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:06.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:06.492
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Aug 24 10:27:06.500: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:27:07.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1861" for this suite. 08/24/22 10:27:07.622
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":230,"skipped":4129,"failed":0}
------------------------------
• [1.231 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:06.44
    Aug 24 10:27:06.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:27:06.445
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:06.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:06.492
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Aug 24 10:27:06.500: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:27:07.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1861" for this suite. 08/24/22 10:27:07.622
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:07.677
Aug 24 10:27:07.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:27:07.679
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:07.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:07.75
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:27:07.754
Aug 24 10:27:07.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5" in namespace "downward-api-7311" to be "Succeeded or Failed"
Aug 24 10:27:07.817: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.655071ms
Aug 24 10:27:09.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019113329s
Aug 24 10:27:11.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019773449s
STEP: Saw pod success 08/24/22 10:27:11.826
Aug 24 10:27:11.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5" satisfied condition "Succeeded or Failed"
Aug 24 10:27:11.850: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 container client-container: <nil>
STEP: delete the pod 08/24/22 10:27:11.867
Aug 24 10:27:11.924: INFO: Waiting for pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 to disappear
Aug 24 10:27:11.931: INFO: Pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:27:11.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7311" for this suite. 08/24/22 10:27:11.938
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":231,"skipped":4130,"failed":0}
------------------------------
• [4.286 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:07.677
    Aug 24 10:27:07.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:27:07.679
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:07.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:07.75
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:27:07.754
    Aug 24 10:27:07.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5" in namespace "downward-api-7311" to be "Succeeded or Failed"
    Aug 24 10:27:07.817: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.655071ms
    Aug 24 10:27:09.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019113329s
    Aug 24 10:27:11.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019773449s
    STEP: Saw pod success 08/24/22 10:27:11.826
    Aug 24 10:27:11.826: INFO: Pod "downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5" satisfied condition "Succeeded or Failed"
    Aug 24 10:27:11.850: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:27:11.867
    Aug 24 10:27:11.924: INFO: Waiting for pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 to disappear
    Aug 24 10:27:11.931: INFO: Pod downwardapi-volume-63e050e2-6085-491a-91e9-0f9644df3ec5 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:27:11.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7311" for this suite. 08/24/22 10:27:11.938
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:11.963
Aug 24 10:27:11.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:27:11.967
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:11.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:12.002
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 08/24/22 10:27:12.008
STEP: Getting a ResourceQuota 08/24/22 10:27:12.016
STEP: Updating a ResourceQuota 08/24/22 10:27:12.022
STEP: Verifying a ResourceQuota was modified 08/24/22 10:27:12.078
STEP: Deleting a ResourceQuota 08/24/22 10:27:12.09
STEP: Verifying the deleted ResourceQuota 08/24/22 10:27:12.107
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:27:12.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9117" for this suite. 08/24/22 10:27:12.127
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":232,"skipped":4133,"failed":0}
------------------------------
• [0.191 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:11.963
    Aug 24 10:27:11.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:27:11.967
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:11.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:12.002
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 08/24/22 10:27:12.008
    STEP: Getting a ResourceQuota 08/24/22 10:27:12.016
    STEP: Updating a ResourceQuota 08/24/22 10:27:12.022
    STEP: Verifying a ResourceQuota was modified 08/24/22 10:27:12.078
    STEP: Deleting a ResourceQuota 08/24/22 10:27:12.09
    STEP: Verifying the deleted ResourceQuota 08/24/22 10:27:12.107
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:27:12.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9117" for this suite. 08/24/22 10:27:12.127
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:12.171
Aug 24 10:27:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:27:12.173
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:12.2
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:12.204
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 08/24/22 10:27:12.214
STEP: watching for Pod to be ready 08/24/22 10:27:12.231
Aug 24 10:27:12.238: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions []
Aug 24 10:27:12.241: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
Aug 24 10:27:12.266: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
Aug 24 10:27:13.724: INFO: Found Pod pod-test in namespace pods-6440 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 08/24/22 10:27:13.733
STEP: getting the Pod and ensuring that it's patched 08/24/22 10:27:13.75
STEP: replacing the Pod's status Ready condition to False 08/24/22 10:27:13.759
STEP: check the Pod again to ensure its Ready conditions are False 08/24/22 10:27:13.786
STEP: deleting the Pod via a Collection with a LabelSelector 08/24/22 10:27:13.787
STEP: watching for the Pod to be deleted 08/24/22 10:27:13.804
Aug 24 10:27:13.807: INFO: observed event type MODIFIED
Aug 24 10:27:15.731: INFO: observed event type MODIFIED
Aug 24 10:27:16.737: INFO: observed event type MODIFIED
Aug 24 10:27:16.768: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:27:16.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6440" for this suite. 08/24/22 10:27:16.787
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":233,"skipped":4166,"failed":0}
------------------------------
• [4.628 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:12.171
    Aug 24 10:27:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:27:12.173
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:12.2
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:12.204
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 08/24/22 10:27:12.214
    STEP: watching for Pod to be ready 08/24/22 10:27:12.231
    Aug 24 10:27:12.238: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Aug 24 10:27:12.241: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
    Aug 24 10:27:12.266: INFO: observed Pod pod-test in namespace pods-6440 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
    Aug 24 10:27:13.724: INFO: Found Pod pod-test in namespace pods-6440 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 10:27:12 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 08/24/22 10:27:13.733
    STEP: getting the Pod and ensuring that it's patched 08/24/22 10:27:13.75
    STEP: replacing the Pod's status Ready condition to False 08/24/22 10:27:13.759
    STEP: check the Pod again to ensure its Ready conditions are False 08/24/22 10:27:13.786
    STEP: deleting the Pod via a Collection with a LabelSelector 08/24/22 10:27:13.787
    STEP: watching for the Pod to be deleted 08/24/22 10:27:13.804
    Aug 24 10:27:13.807: INFO: observed event type MODIFIED
    Aug 24 10:27:15.731: INFO: observed event type MODIFIED
    Aug 24 10:27:16.737: INFO: observed event type MODIFIED
    Aug 24 10:27:16.768: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:27:16.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6440" for this suite. 08/24/22 10:27:16.787
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:16.801
Aug 24 10:27:16.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename watch 08/24/22 10:27:16.805
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:16.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:16.831
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 08/24/22 10:27:16.835
STEP: modifying the configmap once 08/24/22 10:27:16.842
STEP: modifying the configmap a second time 08/24/22 10:27:16.854
STEP: deleting the configmap 08/24/22 10:27:16.865
STEP: creating a watch on configmaps from the resource version returned by the first update 08/24/22 10:27:16.874
STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/24/22 10:27:16.876
Aug 24 10:27:16.877: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4189  d371d63b-e945-47c0-b37a-60afcdb5d958 24823 0 2022-08-24 10:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-24 10:27:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:27:16.877: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4189  d371d63b-e945-47c0-b37a-60afcdb5d958 24824 0 2022-08-24 10:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-24 10:27:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 24 10:27:16.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4189" for this suite. 08/24/22 10:27:16.883
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":234,"skipped":4168,"failed":0}
------------------------------
• [0.101 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:16.801
    Aug 24 10:27:16.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename watch 08/24/22 10:27:16.805
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:16.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:16.831
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 08/24/22 10:27:16.835
    STEP: modifying the configmap once 08/24/22 10:27:16.842
    STEP: modifying the configmap a second time 08/24/22 10:27:16.854
    STEP: deleting the configmap 08/24/22 10:27:16.865
    STEP: creating a watch on configmaps from the resource version returned by the first update 08/24/22 10:27:16.874
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/24/22 10:27:16.876
    Aug 24 10:27:16.877: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4189  d371d63b-e945-47c0-b37a-60afcdb5d958 24823 0 2022-08-24 10:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-24 10:27:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:27:16.877: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4189  d371d63b-e945-47c0-b37a-60afcdb5d958 24824 0 2022-08-24 10:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-24 10:27:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 24 10:27:16.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4189" for this suite. 08/24/22 10:27:16.883
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:27:16.902
Aug 24 10:27:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:27:16.908
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:16.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:16.939
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9427 08/24/22 10:27:16.944
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 08/24/22 10:27:16.951
Aug 24 10:27:16.970: INFO: Found 0 stateful pods, waiting for 3
Aug 24 10:27:26.983: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:27:26.983: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:27:26.983: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/24/22 10:27:27.02
Aug 24 10:27:27.072: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/24/22 10:27:27.072
STEP: Not applying an update when the partition is greater than the number of replicas 08/24/22 10:27:37.104
STEP: Performing a canary update 08/24/22 10:27:37.104
Aug 24 10:27:37.132: INFO: Updating stateful set ss2
Aug 24 10:27:37.144: INFO: Waiting for Pod statefulset-9427/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 08/24/22 10:27:47.159
Aug 24 10:27:47.237: INFO: Found 1 stateful pods, waiting for 3
Aug 24 10:27:57.250: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:27:57.250: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:27:57.250: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 08/24/22 10:27:57.262
Aug 24 10:27:57.288: INFO: Updating stateful set ss2
Aug 24 10:27:57.302: INFO: Waiting for Pod statefulset-9427/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Aug 24 10:28:07.352: INFO: Updating stateful set ss2
Aug 24 10:28:07.378: INFO: Waiting for StatefulSet statefulset-9427/ss2 to complete update
Aug 24 10:28:07.378: INFO: Waiting for Pod statefulset-9427/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Aug 24 10:28:17.408: INFO: Waiting for StatefulSet statefulset-9427/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:28:27.432: INFO: Deleting all statefulset in ns statefulset-9427
Aug 24 10:28:27.442: INFO: Scaling statefulset ss2 to 0
Aug 24 10:28:37.486: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:28:37.490: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:28:37.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9427" for this suite. 08/24/22 10:28:37.574
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":235,"skipped":4176,"failed":0}
------------------------------
• [SLOW TEST] [80.692 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:27:16.902
    Aug 24 10:27:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:27:16.908
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:27:16.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:27:16.939
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9427 08/24/22 10:27:16.944
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 08/24/22 10:27:16.951
    Aug 24 10:27:16.970: INFO: Found 0 stateful pods, waiting for 3
    Aug 24 10:27:26.983: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:27:26.983: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:27:26.983: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/24/22 10:27:27.02
    Aug 24 10:27:27.072: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/24/22 10:27:27.072
    STEP: Not applying an update when the partition is greater than the number of replicas 08/24/22 10:27:37.104
    STEP: Performing a canary update 08/24/22 10:27:37.104
    Aug 24 10:27:37.132: INFO: Updating stateful set ss2
    Aug 24 10:27:37.144: INFO: Waiting for Pod statefulset-9427/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 08/24/22 10:27:47.159
    Aug 24 10:27:47.237: INFO: Found 1 stateful pods, waiting for 3
    Aug 24 10:27:57.250: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:27:57.250: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:27:57.250: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 08/24/22 10:27:57.262
    Aug 24 10:27:57.288: INFO: Updating stateful set ss2
    Aug 24 10:27:57.302: INFO: Waiting for Pod statefulset-9427/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Aug 24 10:28:07.352: INFO: Updating stateful set ss2
    Aug 24 10:28:07.378: INFO: Waiting for StatefulSet statefulset-9427/ss2 to complete update
    Aug 24 10:28:07.378: INFO: Waiting for Pod statefulset-9427/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Aug 24 10:28:17.408: INFO: Waiting for StatefulSet statefulset-9427/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:28:27.432: INFO: Deleting all statefulset in ns statefulset-9427
    Aug 24 10:28:27.442: INFO: Scaling statefulset ss2 to 0
    Aug 24 10:28:37.486: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:28:37.490: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:28:37.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9427" for this suite. 08/24/22 10:28:37.574
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:28:37.596
Aug 24 10:28:37.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename init-container 08/24/22 10:28:37.599
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:37.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:37.659
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 08/24/22 10:28:37.664
Aug 24 10:28:37.664: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 10:28:42.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5993" for this suite. 08/24/22 10:28:42.057
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":236,"skipped":4185,"failed":0}
------------------------------
• [4.470 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:28:37.596
    Aug 24 10:28:37.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename init-container 08/24/22 10:28:37.599
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:37.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:37.659
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 08/24/22 10:28:37.664
    Aug 24 10:28:37.664: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 10:28:42.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5993" for this suite. 08/24/22 10:28:42.057
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:28:42.071
Aug 24 10:28:42.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:28:42.074
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:42.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:42.101
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-b7d3be88-e72f-44a6-a77e-67a233b34045 08/24/22 10:28:42.105
STEP: Creating a pod to test consume configMaps 08/24/22 10:28:42.111
Aug 24 10:28:42.125: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3" in namespace "projected-6118" to be "Succeeded or Failed"
Aug 24 10:28:42.130: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130845ms
Aug 24 10:28:44.137: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011580714s
Aug 24 10:28:46.136: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010801631s
STEP: Saw pod success 08/24/22 10:28:46.136
Aug 24 10:28:46.137: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3" satisfied condition "Succeeded or Failed"
Aug 24 10:28:46.141: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:28:46.17
Aug 24 10:28:46.187: INFO: Waiting for pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 to disappear
Aug 24 10:28:46.198: INFO: Pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:28:46.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6118" for this suite. 08/24/22 10:28:46.204
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":237,"skipped":4207,"failed":0}
------------------------------
• [4.145 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:28:42.071
    Aug 24 10:28:42.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:28:42.074
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:42.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:42.101
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-b7d3be88-e72f-44a6-a77e-67a233b34045 08/24/22 10:28:42.105
    STEP: Creating a pod to test consume configMaps 08/24/22 10:28:42.111
    Aug 24 10:28:42.125: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3" in namespace "projected-6118" to be "Succeeded or Failed"
    Aug 24 10:28:42.130: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130845ms
    Aug 24 10:28:44.137: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011580714s
    Aug 24 10:28:46.136: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010801631s
    STEP: Saw pod success 08/24/22 10:28:46.136
    Aug 24 10:28:46.137: INFO: Pod "pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3" satisfied condition "Succeeded or Failed"
    Aug 24 10:28:46.141: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:28:46.17
    Aug 24 10:28:46.187: INFO: Waiting for pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 to disappear
    Aug 24 10:28:46.198: INFO: Pod pod-projected-configmaps-1eef7f70-3dd4-4991-bd4f-7879e204ffc3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:28:46.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6118" for this suite. 08/24/22 10:28:46.204
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:28:46.22
Aug 24 10:28:46.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:28:46.222
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:46.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:46.252
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 08/24/22 10:28:46.255
Aug 24 10:28:46.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: mark a version not serverd 08/24/22 10:28:56.838
STEP: check the unserved version gets removed 08/24/22 10:28:56.874
STEP: check the other version is not changed 08/24/22 10:29:01.291
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:29:11.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5220" for this suite. 08/24/22 10:29:11.078
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":238,"skipped":4247,"failed":0}
------------------------------
• [SLOW TEST] [24.866 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:28:46.22
    Aug 24 10:28:46.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:28:46.222
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:28:46.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:28:46.252
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 08/24/22 10:28:46.255
    Aug 24 10:28:46.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: mark a version not serverd 08/24/22 10:28:56.838
    STEP: check the unserved version gets removed 08/24/22 10:28:56.874
    STEP: check the other version is not changed 08/24/22 10:29:01.291
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:29:11.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5220" for this suite. 08/24/22 10:29:11.078
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:29:11.088
Aug 24 10:29:11.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:29:11.092
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:11.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:11.129
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Aug 24 10:29:11.155: INFO: created pod
Aug 24 10:29:11.155: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8450" to be "Succeeded or Failed"
Aug 24 10:29:11.165: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 9.908058ms
Aug 24 10:29:13.174: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019350907s
Aug 24 10:29:15.174: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019452025s
STEP: Saw pod success 08/24/22 10:29:15.175
Aug 24 10:29:15.175: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Aug 24 10:29:45.176: INFO: polling logs
Aug 24 10:29:45.200: INFO: Pod logs: 
I0824 10:29:12.644310       1 log.go:195] OK: Got token
I0824 10:29:12.645009       1 log.go:195] validating with in-cluster discovery
I0824 10:29:12.646687       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0824 10:29:12.646879       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8450:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661337551, NotBefore:1661336951, IssuedAt:1661336951, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8450", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"0a0f559a-397f-4c3a-b526-24d9d32baa87"}}}
I0824 10:29:12.676353       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0824 10:29:12.688455       1 log.go:195] OK: Validated signature on JWT
I0824 10:29:12.688694       1 log.go:195] OK: Got valid claims from token!
I0824 10:29:12.688799       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8450:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661337551, NotBefore:1661336951, IssuedAt:1661336951, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8450", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"0a0f559a-397f-4c3a-b526-24d9d32baa87"}}}

Aug 24 10:29:45.200: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 10:29:45.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8450" for this suite. 08/24/22 10:29:45.22
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":239,"skipped":4265,"failed":0}
------------------------------
• [SLOW TEST] [34.143 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:29:11.088
    Aug 24 10:29:11.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:29:11.092
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:11.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:11.129
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Aug 24 10:29:11.155: INFO: created pod
    Aug 24 10:29:11.155: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8450" to be "Succeeded or Failed"
    Aug 24 10:29:11.165: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 9.908058ms
    Aug 24 10:29:13.174: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019350907s
    Aug 24 10:29:15.174: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019452025s
    STEP: Saw pod success 08/24/22 10:29:15.175
    Aug 24 10:29:15.175: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Aug 24 10:29:45.176: INFO: polling logs
    Aug 24 10:29:45.200: INFO: Pod logs: 
    I0824 10:29:12.644310       1 log.go:195] OK: Got token
    I0824 10:29:12.645009       1 log.go:195] validating with in-cluster discovery
    I0824 10:29:12.646687       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0824 10:29:12.646879       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8450:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661337551, NotBefore:1661336951, IssuedAt:1661336951, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8450", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"0a0f559a-397f-4c3a-b526-24d9d32baa87"}}}
    I0824 10:29:12.676353       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0824 10:29:12.688455       1 log.go:195] OK: Validated signature on JWT
    I0824 10:29:12.688694       1 log.go:195] OK: Got valid claims from token!
    I0824 10:29:12.688799       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8450:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661337551, NotBefore:1661336951, IssuedAt:1661336951, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8450", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"0a0f559a-397f-4c3a-b526-24d9d32baa87"}}}

    Aug 24 10:29:45.200: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 10:29:45.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8450" for this suite. 08/24/22 10:29:45.22
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:29:45.234
Aug 24 10:29:45.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:29:45.242
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:45.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:45.277
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:29:45.31
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:29:47.183
STEP: Deploying the webhook pod 08/24/22 10:29:47.198
STEP: Wait for the deployment to be ready 08/24/22 10:29:47.217
Aug 24 10:29:47.229: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 10:29:49.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:29:51.257
STEP: Verifying the service has paired with the endpoint 08/24/22 10:29:51.292
Aug 24 10:29:52.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Aug 24 10:29:52.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5379-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:29:52.825
STEP: Creating a custom resource that should be mutated by the webhook 08/24/22 10:29:52.867
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:29:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-38" for this suite. 08/24/22 10:29:55.731
STEP: Destroying namespace "webhook-38-markers" for this suite. 08/24/22 10:29:55.749
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":240,"skipped":4294,"failed":0}
------------------------------
• [SLOW TEST] [10.713 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:29:45.234
    Aug 24 10:29:45.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:29:45.242
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:45.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:45.277
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:29:45.31
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:29:47.183
    STEP: Deploying the webhook pod 08/24/22 10:29:47.198
    STEP: Wait for the deployment to be ready 08/24/22 10:29:47.217
    Aug 24 10:29:47.229: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 10:29:49.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 29, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:29:51.257
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:29:51.292
    Aug 24 10:29:52.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Aug 24 10:29:52.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5379-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:29:52.825
    STEP: Creating a custom resource that should be mutated by the webhook 08/24/22 10:29:52.867
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:29:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-38" for this suite. 08/24/22 10:29:55.731
    STEP: Destroying namespace "webhook-38-markers" for this suite. 08/24/22 10:29:55.749
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:29:55.949
Aug 24 10:29:55.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:29:55.96
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:56.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:56.008
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-40384325-93a1-4523-8d7f-519bb385710a 08/24/22 10:29:56.015
STEP: Creating a pod to test consume secrets 08/24/22 10:29:56.034
Aug 24 10:29:56.072: INFO: Waiting up to 5m0s for pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a" in namespace "secrets-6783" to be "Succeeded or Failed"
Aug 24 10:29:56.081: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.171476ms
Aug 24 10:29:58.090: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Running", Reason="", readiness=false. Elapsed: 2.01805072s
Aug 24 10:30:00.095: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Running", Reason="", readiness=false. Elapsed: 4.022316967s
Aug 24 10:30:02.089: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01633828s
STEP: Saw pod success 08/24/22 10:30:02.089
Aug 24 10:30:02.089: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a" satisfied condition "Succeeded or Failed"
Aug 24 10:30:02.095: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:30:02.118
Aug 24 10:30:02.134: INFO: Waiting for pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a to disappear
Aug 24 10:30:02.140: INFO: Pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:30:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6783" for this suite. 08/24/22 10:30:02.147
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":241,"skipped":4295,"failed":0}
------------------------------
• [SLOW TEST] [6.207 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:29:55.949
    Aug 24 10:29:55.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:29:55.96
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:29:56.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:29:56.008
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-40384325-93a1-4523-8d7f-519bb385710a 08/24/22 10:29:56.015
    STEP: Creating a pod to test consume secrets 08/24/22 10:29:56.034
    Aug 24 10:29:56.072: INFO: Waiting up to 5m0s for pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a" in namespace "secrets-6783" to be "Succeeded or Failed"
    Aug 24 10:29:56.081: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.171476ms
    Aug 24 10:29:58.090: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Running", Reason="", readiness=false. Elapsed: 2.01805072s
    Aug 24 10:30:00.095: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Running", Reason="", readiness=false. Elapsed: 4.022316967s
    Aug 24 10:30:02.089: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01633828s
    STEP: Saw pod success 08/24/22 10:30:02.089
    Aug 24 10:30:02.089: INFO: Pod "pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a" satisfied condition "Succeeded or Failed"
    Aug 24 10:30:02.095: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:30:02.118
    Aug 24 10:30:02.134: INFO: Waiting for pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a to disappear
    Aug 24 10:30:02.140: INFO: Pod pod-secrets-a8fb518a-3f8a-4db8-84e2-b4f4f9229f3a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:30:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6783" for this suite. 08/24/22 10:30:02.147
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:02.165
Aug 24 10:30:02.165: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:30:02.167
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:02.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:02.195
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 24 10:30:02.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7694" for this suite. 08/24/22 10:30:02.251
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":242,"skipped":4342,"failed":0}
------------------------------
• [0.099 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:02.165
    Aug 24 10:30:02.165: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:30:02.167
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:02.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:02.195
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 24 10:30:02.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7694" for this suite. 08/24/22 10:30:02.251
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:02.267
Aug 24 10:30:02.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:30:02.271
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:02.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:02.3
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:30:02.347
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:30:03.913
STEP: Deploying the webhook pod 08/24/22 10:30:03.925
STEP: Wait for the deployment to be ready 08/24/22 10:30:03.951
Aug 24 10:30:03.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/24/22 10:30:05.981
STEP: Verifying the service has paired with the endpoint 08/24/22 10:30:05.997
Aug 24 10:30:06.997: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/24/22 10:30:07.042
Aug 24 10:30:07.161: INFO: Waiting for webhook configuration to be ready...
Aug 24 10:30:07.324: INFO: Waiting for webhook configuration to be ready...
Aug 24 10:30:07.400: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook 08/24/22 10:30:07.509
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:30:07.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-776" for this suite. 08/24/22 10:30:07.581
STEP: Destroying namespace "webhook-776-markers" for this suite. 08/24/22 10:30:07.598
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":243,"skipped":4365,"failed":0}
------------------------------
• [SLOW TEST] [5.500 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:02.267
    Aug 24 10:30:02.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:30:02.271
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:02.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:02.3
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:30:02.347
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:30:03.913
    STEP: Deploying the webhook pod 08/24/22 10:30:03.925
    STEP: Wait for the deployment to be ready 08/24/22 10:30:03.951
    Aug 24 10:30:03.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/24/22 10:30:05.981
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:30:05.997
    Aug 24 10:30:06.997: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/24/22 10:30:07.042
    Aug 24 10:30:07.161: INFO: Waiting for webhook configuration to be ready...
    Aug 24 10:30:07.324: INFO: Waiting for webhook configuration to be ready...
    Aug 24 10:30:07.400: INFO: Waiting for webhook configuration to be ready...
    STEP: create a configmap that should be updated by the webhook 08/24/22 10:30:07.509
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:30:07.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-776" for this suite. 08/24/22 10:30:07.581
    STEP: Destroying namespace "webhook-776-markers" for this suite. 08/24/22 10:30:07.598
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:07.773
Aug 24 10:30:07.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:30:07.778
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:07.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:07.855
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Aug 24 10:30:07.897: INFO: Waiting up to 5m0s for pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3" in namespace "pods-222" to be "running and ready"
Aug 24 10:30:07.908: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.54465ms
Aug 24 10:30:07.908: INFO: The phase of Pod server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:30:09.915: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3": Phase="Running", Reason="", readiness=true. Elapsed: 2.017691806s
Aug 24 10:30:09.915: INFO: The phase of Pod server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3 is Running (Ready = true)
Aug 24 10:30:09.915: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3" satisfied condition "running and ready"
Aug 24 10:30:09.963: INFO: Waiting up to 5m0s for pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229" in namespace "pods-222" to be "Succeeded or Failed"
Aug 24 10:30:09.969: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 6.702725ms
Aug 24 10:30:11.977: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014392681s
Aug 24 10:30:13.977: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013969426s
Aug 24 10:30:15.978: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01507896s
STEP: Saw pod success 08/24/22 10:30:15.978
Aug 24 10:30:15.978: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229" satisfied condition "Succeeded or Failed"
Aug 24 10:30:15.985: INFO: Trying to get logs from node kah9uighaagh-3 pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 container env3cont: <nil>
STEP: delete the pod 08/24/22 10:30:15.995
Aug 24 10:30:16.018: INFO: Waiting for pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 to disappear
Aug 24 10:30:16.025: INFO: Pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:30:16.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-222" for this suite. 08/24/22 10:30:16.032
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":244,"skipped":4379,"failed":0}
------------------------------
• [SLOW TEST] [8.296 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:07.773
    Aug 24 10:30:07.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:30:07.778
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:07.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:07.855
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Aug 24 10:30:07.897: INFO: Waiting up to 5m0s for pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3" in namespace "pods-222" to be "running and ready"
    Aug 24 10:30:07.908: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.54465ms
    Aug 24 10:30:07.908: INFO: The phase of Pod server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:30:09.915: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3": Phase="Running", Reason="", readiness=true. Elapsed: 2.017691806s
    Aug 24 10:30:09.915: INFO: The phase of Pod server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3 is Running (Ready = true)
    Aug 24 10:30:09.915: INFO: Pod "server-envvars-47bbd991-c81e-43de-85cd-97d56b4555f3" satisfied condition "running and ready"
    Aug 24 10:30:09.963: INFO: Waiting up to 5m0s for pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229" in namespace "pods-222" to be "Succeeded or Failed"
    Aug 24 10:30:09.969: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 6.702725ms
    Aug 24 10:30:11.977: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014392681s
    Aug 24 10:30:13.977: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013969426s
    Aug 24 10:30:15.978: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01507896s
    STEP: Saw pod success 08/24/22 10:30:15.978
    Aug 24 10:30:15.978: INFO: Pod "client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229" satisfied condition "Succeeded or Failed"
    Aug 24 10:30:15.985: INFO: Trying to get logs from node kah9uighaagh-3 pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 container env3cont: <nil>
    STEP: delete the pod 08/24/22 10:30:15.995
    Aug 24 10:30:16.018: INFO: Waiting for pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 to disappear
    Aug 24 10:30:16.025: INFO: Pod client-envvars-396b977d-0c37-4835-aaf5-364fdcbbd229 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:30:16.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-222" for this suite. 08/24/22 10:30:16.032
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:16.073
Aug 24 10:30:16.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:30:16.076
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:16.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:16.103
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Aug 24 10:30:16.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 create -f -'
Aug 24 10:30:16.654: INFO: stderr: ""
Aug 24 10:30:16.654: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug 24 10:30:16.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 create -f -'
Aug 24 10:30:18.292: INFO: stderr: ""
Aug 24 10:30:18.292: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/24/22 10:30:18.292
Aug 24 10:30:19.302: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 10:30:19.302: INFO: Found 1 / 1
Aug 24 10:30:19.302: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 24 10:30:19.309: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 10:30:19.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 10:30:19.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe pod agnhost-primary-6rt2n'
Aug 24 10:30:19.547: INFO: stderr: ""
Aug 24 10:30:19.547: INFO: stdout: "Name:             agnhost-primary-6rt2n\nNamespace:        kubectl-2552\nPriority:         0\nService Account:  default\nNode:             kah9uighaagh-3/192.168.121.54\nStart Time:       Wed, 24 Aug 2022 10:30:16 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.65\nIPs:\n  IP:           10.233.66.65\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://2ffa43001a2ea00940045037215edb0cb2b92060398e558db5b84e5e2910c5d8\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 24 Aug 2022 10:30:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bbc6j (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-bbc6j:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-2552/agnhost-primary-6rt2n to kah9uighaagh-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Aug 24 10:30:19.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe rc agnhost-primary'
Aug 24 10:30:19.800: INFO: stderr: ""
Aug 24 10:30:19.800: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2552\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-6rt2n\n"
Aug 24 10:30:19.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe service agnhost-primary'
Aug 24 10:30:19.974: INFO: stderr: ""
Aug 24 10:30:19.974: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2552\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.39.200\nIPs:               10.233.39.200\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.65:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 24 10:30:19.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe node kah9uighaagh-1'
Aug 24 10:30:20.180: INFO: stderr: ""
Aug 24 10:30:20.180: INFO: stdout: "Name:               kah9uighaagh-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=kah9uighaagh-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"7a:67:c8:f5:2e:a0\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.119\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 24 Aug 2022 08:54:20 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  kah9uighaagh-1\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 24 Aug 2022 10:30:18 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 24 Aug 2022 09:12:11 +0000   Wed, 24 Aug 2022 09:12:11 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 09:06:28 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.119\n  Hostname:    kah9uighaagh-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  122749536Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140768Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  119410748528\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3291104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f0176bf155264728b7d14ac68e1013f6\n  System UUID:                f0176bf1-5526-4728-b7d1-4ac68e1013f6\n  Boot ID:                    e1841c4c-327b-4cd3-a3f5-5376340a5e67\n  Kernel Version:             5.15.0-46-generic\n  OS Image:                   Ubuntu 22.04.1 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.25.0\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-v9ltq                                      100m (6%)     100m (6%)   50Mi (1%)        50Mi (1%)      85m\n  kube-system                 coredns-565d847f94-l25vk                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     95m\n  kube-system                 coredns-565d847f94-l5p5g                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     95m\n  kube-system                 kube-addon-manager-kah9uighaagh-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         86m\n  kube-system                 kube-apiserver-kah9uighaagh-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-controller-manager-kah9uighaagh-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-proxy-thfcl                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-scheduler-kah9uighaagh-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         95m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                855m (53%)  100m (6%)\n  memory             240Mi (7%)  390Mi (12%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug 24 10:30:20.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe namespace kubectl-2552'
Aug 24 10:30:20.309: INFO: stderr: ""
Aug 24 10:30:20.310: INFO: stdout: "Name:         kubectl-2552\nLabels:       e2e-framework=kubectl\n              e2e-run=e1f158d7-4c48-4d0f-8c7b-65e2c1188e50\n              kubernetes.io/metadata.name=kubectl-2552\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:30:20.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2552" for this suite. 08/24/22 10:30:20.316
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":245,"skipped":4382,"failed":0}
------------------------------
• [4.253 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:16.073
    Aug 24 10:30:16.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:30:16.076
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:16.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:16.103
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Aug 24 10:30:16.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 create -f -'
    Aug 24 10:30:16.654: INFO: stderr: ""
    Aug 24 10:30:16.654: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Aug 24 10:30:16.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 create -f -'
    Aug 24 10:30:18.292: INFO: stderr: ""
    Aug 24 10:30:18.292: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/24/22 10:30:18.292
    Aug 24 10:30:19.302: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 10:30:19.302: INFO: Found 1 / 1
    Aug 24 10:30:19.302: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 24 10:30:19.309: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 10:30:19.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 24 10:30:19.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe pod agnhost-primary-6rt2n'
    Aug 24 10:30:19.547: INFO: stderr: ""
    Aug 24 10:30:19.547: INFO: stdout: "Name:             agnhost-primary-6rt2n\nNamespace:        kubectl-2552\nPriority:         0\nService Account:  default\nNode:             kah9uighaagh-3/192.168.121.54\nStart Time:       Wed, 24 Aug 2022 10:30:16 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.65\nIPs:\n  IP:           10.233.66.65\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://2ffa43001a2ea00940045037215edb0cb2b92060398e558db5b84e5e2910c5d8\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:37dd9ad84b34913b4bc57e00b0a28e8b00f18ca6a5ecec69461aa57402e5c787\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 24 Aug 2022 10:30:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bbc6j (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-bbc6j:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-2552/agnhost-primary-6rt2n to kah9uighaagh-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    Aug 24 10:30:19.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe rc agnhost-primary'
    Aug 24 10:30:19.800: INFO: stderr: ""
    Aug 24 10:30:19.800: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2552\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-6rt2n\n"
    Aug 24 10:30:19.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe service agnhost-primary'
    Aug 24 10:30:19.974: INFO: stderr: ""
    Aug 24 10:30:19.974: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2552\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.39.200\nIPs:               10.233.39.200\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.65:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Aug 24 10:30:19.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe node kah9uighaagh-1'
    Aug 24 10:30:20.180: INFO: stderr: ""
    Aug 24 10:30:20.180: INFO: stdout: "Name:               kah9uighaagh-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=kah9uighaagh-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"7a:67:c8:f5:2e:a0\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.119\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 24 Aug 2022 08:54:20 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  kah9uighaagh-1\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 24 Aug 2022 10:30:18 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 24 Aug 2022 09:12:11 +0000   Wed, 24 Aug 2022 09:12:11 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 08:54:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 24 Aug 2022 10:27:57 +0000   Wed, 24 Aug 2022 09:06:28 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.119\n  Hostname:    kah9uighaagh-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  122749536Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140768Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  119410748528\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3291104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f0176bf155264728b7d14ac68e1013f6\n  System UUID:                f0176bf1-5526-4728-b7d1-4ac68e1013f6\n  Boot ID:                    e1841c4c-327b-4cd3-a3f5-5376340a5e67\n  Kernel Version:             5.15.0-46-generic\n  OS Image:                   Ubuntu 22.04.1 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.25.0\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-v9ltq                                      100m (6%)     100m (6%)   50Mi (1%)        50Mi (1%)      85m\n  kube-system                 coredns-565d847f94-l25vk                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     95m\n  kube-system                 coredns-565d847f94-l5p5g                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     95m\n  kube-system                 kube-addon-manager-kah9uighaagh-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         86m\n  kube-system                 kube-apiserver-kah9uighaagh-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-controller-manager-kah9uighaagh-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-proxy-thfcl                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                 kube-scheduler-kah9uighaagh-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         95m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-931304e6ede74452-7lsf9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                855m (53%)  100m (6%)\n  memory             240Mi (7%)  390Mi (12%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    Aug 24 10:30:20.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-2552 describe namespace kubectl-2552'
    Aug 24 10:30:20.309: INFO: stderr: ""
    Aug 24 10:30:20.310: INFO: stdout: "Name:         kubectl-2552\nLabels:       e2e-framework=kubectl\n              e2e-run=e1f158d7-4c48-4d0f-8c7b-65e2c1188e50\n              kubernetes.io/metadata.name=kubectl-2552\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:30:20.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2552" for this suite. 08/24/22 10:30:20.316
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:20.328
Aug 24 10:30:20.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:30:20.33
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:20.347
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:20.358
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 08/24/22 10:30:20.362
STEP: Creating a ResourceQuota 08/24/22 10:30:25.368
STEP: Ensuring resource quota status is calculated 08/24/22 10:30:25.385
STEP: Creating a Pod that fits quota 08/24/22 10:30:27.42
STEP: Ensuring ResourceQuota status captures the pod usage 08/24/22 10:30:27.452
STEP: Not allowing a pod to be created that exceeds remaining quota 08/24/22 10:30:29.462
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/24/22 10:30:29.467
STEP: Ensuring a pod cannot update its resource requirements 08/24/22 10:30:29.471
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/24/22 10:30:29.481
STEP: Deleting the pod 08/24/22 10:30:31.491
STEP: Ensuring resource quota status released the pod usage 08/24/22 10:30:31.524
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:30:33.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9794" for this suite. 08/24/22 10:30:33.538
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":246,"skipped":4400,"failed":0}
------------------------------
• [SLOW TEST] [13.223 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:20.328
    Aug 24 10:30:20.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:30:20.33
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:20.347
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:20.358
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 08/24/22 10:30:20.362
    STEP: Creating a ResourceQuota 08/24/22 10:30:25.368
    STEP: Ensuring resource quota status is calculated 08/24/22 10:30:25.385
    STEP: Creating a Pod that fits quota 08/24/22 10:30:27.42
    STEP: Ensuring ResourceQuota status captures the pod usage 08/24/22 10:30:27.452
    STEP: Not allowing a pod to be created that exceeds remaining quota 08/24/22 10:30:29.462
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/24/22 10:30:29.467
    STEP: Ensuring a pod cannot update its resource requirements 08/24/22 10:30:29.471
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/24/22 10:30:29.481
    STEP: Deleting the pod 08/24/22 10:30:31.491
    STEP: Ensuring resource quota status released the pod usage 08/24/22 10:30:31.524
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:30:33.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9794" for this suite. 08/24/22 10:30:33.538
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:33.557
Aug 24 10:30:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:30:33.559
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:33.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:33.593
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 08/24/22 10:30:33.597
Aug 24 10:30:33.598: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-1688 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 08/24/22 10:30:33.704
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:30:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1688" for this suite. 08/24/22 10:30:33.727
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":247,"skipped":4421,"failed":0}
------------------------------
• [0.191 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:33.557
    Aug 24 10:30:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:30:33.559
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:33.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:33.593
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 08/24/22 10:30:33.597
    Aug 24 10:30:33.598: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-1688 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 08/24/22 10:30:33.704
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:30:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1688" for this suite. 08/24/22 10:30:33.727
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:33.763
Aug 24 10:30:33.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename proxy 08/24/22 10:30:33.766
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:33.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:33.812
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Aug 24 10:30:33.818: INFO: Creating pod...
Aug 24 10:30:33.840: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9375" to be "running"
Aug 24 10:30:33.852: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 12.094402ms
Aug 24 10:30:35.860: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.020184634s
Aug 24 10:30:35.860: INFO: Pod "agnhost" satisfied condition "running"
Aug 24 10:30:35.860: INFO: Creating service...
Aug 24 10:30:35.883: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=DELETE
Aug 24 10:30:35.904: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 10:30:35.904: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=OPTIONS
Aug 24 10:30:35.916: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 10:30:35.916: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=PATCH
Aug 24 10:30:35.923: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 10:30:35.923: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=POST
Aug 24 10:30:35.941: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 10:30:35.941: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=PUT
Aug 24 10:30:35.958: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 24 10:30:35.958: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=DELETE
Aug 24 10:30:35.965: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 10:30:35.965: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=OPTIONS
Aug 24 10:30:35.981: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 10:30:35.981: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=PATCH
Aug 24 10:30:35.994: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 10:30:35.994: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=POST
Aug 24 10:30:36.006: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 10:30:36.006: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=PUT
Aug 24 10:30:36.024: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 24 10:30:36.024: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=GET
Aug 24 10:30:36.029: INFO: http.Client request:GET StatusCode:301
Aug 24 10:30:36.029: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=GET
Aug 24 10:30:36.036: INFO: http.Client request:GET StatusCode:301
Aug 24 10:30:36.036: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=HEAD
Aug 24 10:30:36.042: INFO: http.Client request:HEAD StatusCode:301
Aug 24 10:30:36.042: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=HEAD
Aug 24 10:30:36.049: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 24 10:30:36.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9375" for this suite. 08/24/22 10:30:36.056
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":248,"skipped":4481,"failed":0}
------------------------------
• [2.307 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:33.763
    Aug 24 10:30:33.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename proxy 08/24/22 10:30:33.766
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:33.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:33.812
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Aug 24 10:30:33.818: INFO: Creating pod...
    Aug 24 10:30:33.840: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9375" to be "running"
    Aug 24 10:30:33.852: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 12.094402ms
    Aug 24 10:30:35.860: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.020184634s
    Aug 24 10:30:35.860: INFO: Pod "agnhost" satisfied condition "running"
    Aug 24 10:30:35.860: INFO: Creating service...
    Aug 24 10:30:35.883: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=DELETE
    Aug 24 10:30:35.904: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 24 10:30:35.904: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=OPTIONS
    Aug 24 10:30:35.916: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 24 10:30:35.916: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=PATCH
    Aug 24 10:30:35.923: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 24 10:30:35.923: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=POST
    Aug 24 10:30:35.941: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 24 10:30:35.941: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=PUT
    Aug 24 10:30:35.958: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 24 10:30:35.958: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=DELETE
    Aug 24 10:30:35.965: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 24 10:30:35.965: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Aug 24 10:30:35.981: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 24 10:30:35.981: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=PATCH
    Aug 24 10:30:35.994: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 24 10:30:35.994: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=POST
    Aug 24 10:30:36.006: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 24 10:30:36.006: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=PUT
    Aug 24 10:30:36.024: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 24 10:30:36.024: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=GET
    Aug 24 10:30:36.029: INFO: http.Client request:GET StatusCode:301
    Aug 24 10:30:36.029: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=GET
    Aug 24 10:30:36.036: INFO: http.Client request:GET StatusCode:301
    Aug 24 10:30:36.036: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/pods/agnhost/proxy?method=HEAD
    Aug 24 10:30:36.042: INFO: http.Client request:HEAD StatusCode:301
    Aug 24 10:30:36.042: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9375/services/e2e-proxy-test-service/proxy?method=HEAD
    Aug 24 10:30:36.049: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 24 10:30:36.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9375" for this suite. 08/24/22 10:30:36.056
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:30:36.085
Aug 24 10:30:36.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:30:36.09
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:36.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:36.172
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9870 08/24/22 10:30:36.176
STEP: creating a selector 08/24/22 10:30:36.176
STEP: Creating the service pods in kubernetes 08/24/22 10:30:36.176
Aug 24 10:30:36.176: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 10:30:36.234: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9870" to be "running and ready"
Aug 24 10:30:36.249: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.715067ms
Aug 24 10:30:36.249: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:30:38.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.02302375s
Aug 24 10:30:38.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:40.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.021864883s
Aug 24 10:30:40.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:42.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.022984465s
Aug 24 10:30:42.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:44.260: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.025310846s
Aug 24 10:30:44.260: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:46.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021829073s
Aug 24 10:30:46.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:48.258: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.023282345s
Aug 24 10:30:48.258: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:50.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021922527s
Aug 24 10:30:50.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:52.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022739465s
Aug 24 10:30:52.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:54.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022718284s
Aug 24 10:30:54.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:56.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021645891s
Aug 24 10:30:56.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:30:58.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022559011s
Aug 24 10:30:58.257: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 24 10:30:58.257: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 24 10:30:58.263: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9870" to be "running and ready"
Aug 24 10:30:58.267: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.896029ms
Aug 24 10:30:58.267: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 24 10:30:58.267: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 24 10:30:58.272: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9870" to be "running and ready"
Aug 24 10:30:58.277: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.790091ms
Aug 24 10:30:58.277: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 24 10:30:58.277: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/24/22 10:30:58.282
Aug 24 10:30:58.306: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9870" to be "running"
Aug 24 10:30:58.335: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 28.488927ms
Aug 24 10:31:00.342: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.036052846s
Aug 24 10:31:00.343: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 24 10:31:00.349: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9870" to be "running"
Aug 24 10:31:00.365: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 16.028889ms
Aug 24 10:31:00.365: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 24 10:31:00.370: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 10:31:00.371: INFO: Going to poll 10.233.64.104 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:31:00.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.104:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:31:00.376: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:31:00.378: INFO: ExecWithOptions: Clientset creation
Aug 24 10:31:00.378: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.104%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:31:00.533: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 24 10:31:00.533: INFO: Going to poll 10.233.65.125 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:31:00.539: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.125:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:31:00.539: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:31:00.541: INFO: ExecWithOptions: Clientset creation
Aug 24 10:31:00.541: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.125%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:31:00.657: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 24 10:31:00.657: INFO: Going to poll 10.233.66.67 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:31:00.665: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.67:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:31:00.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:31:00.667: INFO: ExecWithOptions: Clientset creation
Aug 24 10:31:00.668: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.67%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:31:00.790: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 24 10:31:00.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9870" for this suite. 08/24/22 10:31:00.801
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":249,"skipped":4514,"failed":0}
------------------------------
• [SLOW TEST] [24.731 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:30:36.085
    Aug 24 10:30:36.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:30:36.09
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:30:36.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:30:36.172
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9870 08/24/22 10:30:36.176
    STEP: creating a selector 08/24/22 10:30:36.176
    STEP: Creating the service pods in kubernetes 08/24/22 10:30:36.176
    Aug 24 10:30:36.176: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 24 10:30:36.234: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9870" to be "running and ready"
    Aug 24 10:30:36.249: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.715067ms
    Aug 24 10:30:36.249: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:30:38.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.02302375s
    Aug 24 10:30:38.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:40.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.021864883s
    Aug 24 10:30:40.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:42.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.022984465s
    Aug 24 10:30:42.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:44.260: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.025310846s
    Aug 24 10:30:44.260: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:46.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021829073s
    Aug 24 10:30:46.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:48.258: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.023282345s
    Aug 24 10:30:48.258: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:50.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021922527s
    Aug 24 10:30:50.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:52.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022739465s
    Aug 24 10:30:52.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:54.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022718284s
    Aug 24 10:30:54.257: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:56.256: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021645891s
    Aug 24 10:30:56.256: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:30:58.257: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022559011s
    Aug 24 10:30:58.257: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 24 10:30:58.257: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 24 10:30:58.263: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9870" to be "running and ready"
    Aug 24 10:30:58.267: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.896029ms
    Aug 24 10:30:58.267: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 24 10:30:58.267: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 24 10:30:58.272: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9870" to be "running and ready"
    Aug 24 10:30:58.277: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.790091ms
    Aug 24 10:30:58.277: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 24 10:30:58.277: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/24/22 10:30:58.282
    Aug 24 10:30:58.306: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9870" to be "running"
    Aug 24 10:30:58.335: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 28.488927ms
    Aug 24 10:31:00.342: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.036052846s
    Aug 24 10:31:00.343: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 24 10:31:00.349: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9870" to be "running"
    Aug 24 10:31:00.365: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 16.028889ms
    Aug 24 10:31:00.365: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 24 10:31:00.370: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 24 10:31:00.371: INFO: Going to poll 10.233.64.104 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:31:00.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.104:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:31:00.376: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:31:00.378: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:31:00.378: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.104%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:31:00.533: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 24 10:31:00.533: INFO: Going to poll 10.233.65.125 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:31:00.539: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.125:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:31:00.539: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:31:00.541: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:31:00.541: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.125%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:31:00.657: INFO: Found all 1 expected endpoints: [netserver-1]
    Aug 24 10:31:00.657: INFO: Going to poll 10.233.66.67 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:31:00.665: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.67:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9870 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:31:00.665: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:31:00.667: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:31:00.668: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9870/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.67%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:31:00.790: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 24 10:31:00.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9870" for this suite. 08/24/22 10:31:00.801
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:00.822
Aug 24 10:31:00.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 10:31:00.825
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:00.854
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:00.859
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Aug 24 10:31:00.941: INFO: Create a RollingUpdate DaemonSet
Aug 24 10:31:00.952: INFO: Check that daemon pods launch on every node of the cluster
Aug 24 10:31:00.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:31:00.970: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:31:01.990: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:31:01.990: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
Aug 24 10:31:02.991: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 10:31:02.991: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:31:03.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 10:31:03.993: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Aug 24 10:31:03.993: INFO: Update the DaemonSet to trigger a rollout
Aug 24 10:31:04.019: INFO: Updating DaemonSet daemon-set
Aug 24 10:31:06.077: INFO: Roll back the DaemonSet before rollout is complete
Aug 24 10:31:06.106: INFO: Updating DaemonSet daemon-set
Aug 24 10:31:06.106: INFO: Make sure DaemonSet rollback is complete
Aug 24 10:31:06.122: INFO: Wrong image for pod: daemon-set-b57rb. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Aug 24 10:31:06.122: INFO: Pod daemon-set-b57rb is not available
Aug 24 10:31:12.142: INFO: Pod daemon-set-s7xqd is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:31:12.162
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6515, will wait for the garbage collector to delete the pods 08/24/22 10:31:12.164
Aug 24 10:31:12.233: INFO: Deleting DaemonSet.extensions daemon-set took: 11.566518ms
Aug 24 10:31:12.335: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.660985ms
Aug 24 10:31:13.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:31:13.643: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 10:31:13.649: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26125"},"items":null}

Aug 24 10:31:13.657: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26125"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:31:13.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6515" for this suite. 08/24/22 10:31:13.704
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":250,"skipped":4527,"failed":0}
------------------------------
• [SLOW TEST] [12.899 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:00.822
    Aug 24 10:31:00.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 10:31:00.825
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:00.854
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:00.859
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Aug 24 10:31:00.941: INFO: Create a RollingUpdate DaemonSet
    Aug 24 10:31:00.952: INFO: Check that daemon pods launch on every node of the cluster
    Aug 24 10:31:00.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:31:00.970: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:31:01.990: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:31:01.990: INFO: Node kah9uighaagh-1 is running 0 daemon pod, expected 1
    Aug 24 10:31:02.991: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 24 10:31:02.991: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:31:03.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 24 10:31:03.993: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Aug 24 10:31:03.993: INFO: Update the DaemonSet to trigger a rollout
    Aug 24 10:31:04.019: INFO: Updating DaemonSet daemon-set
    Aug 24 10:31:06.077: INFO: Roll back the DaemonSet before rollout is complete
    Aug 24 10:31:06.106: INFO: Updating DaemonSet daemon-set
    Aug 24 10:31:06.106: INFO: Make sure DaemonSet rollback is complete
    Aug 24 10:31:06.122: INFO: Wrong image for pod: daemon-set-b57rb. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Aug 24 10:31:06.122: INFO: Pod daemon-set-b57rb is not available
    Aug 24 10:31:12.142: INFO: Pod daemon-set-s7xqd is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:31:12.162
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6515, will wait for the garbage collector to delete the pods 08/24/22 10:31:12.164
    Aug 24 10:31:12.233: INFO: Deleting DaemonSet.extensions daemon-set took: 11.566518ms
    Aug 24 10:31:12.335: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.660985ms
    Aug 24 10:31:13.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:31:13.643: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 10:31:13.649: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26125"},"items":null}

    Aug 24 10:31:13.657: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26125"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:31:13.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6515" for this suite. 08/24/22 10:31:13.704
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:13.726
Aug 24 10:31:13.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename watch 08/24/22 10:31:13.728
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:13.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:13.795
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 08/24/22 10:31:13.799
STEP: creating a new configmap 08/24/22 10:31:13.8
STEP: modifying the configmap once 08/24/22 10:31:13.819
STEP: changing the label value of the configmap 08/24/22 10:31:13.842
STEP: Expecting to observe a delete notification for the watched object 08/24/22 10:31:13.86
Aug 24 10:31:13.860: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26131 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:31:13.861: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26132 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:31:13.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26133 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 08/24/22 10:31:13.861
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/24/22 10:31:13.876
STEP: changing the label value of the configmap back 08/24/22 10:31:23.877
STEP: modifying the configmap a third time 08/24/22 10:31:23.894
STEP: deleting the configmap 08/24/22 10:31:23.91
STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/24/22 10:31:23.919
Aug 24 10:31:23.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26186 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:31:23.920: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26187 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 10:31:23.920: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26188 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 24 10:31:23.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5695" for this suite. 08/24/22 10:31:23.928
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":251,"skipped":4539,"failed":0}
------------------------------
• [SLOW TEST] [10.212 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:13.726
    Aug 24 10:31:13.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename watch 08/24/22 10:31:13.728
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:13.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:13.795
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 08/24/22 10:31:13.799
    STEP: creating a new configmap 08/24/22 10:31:13.8
    STEP: modifying the configmap once 08/24/22 10:31:13.819
    STEP: changing the label value of the configmap 08/24/22 10:31:13.842
    STEP: Expecting to observe a delete notification for the watched object 08/24/22 10:31:13.86
    Aug 24 10:31:13.860: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26131 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:31:13.861: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26132 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:31:13.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26133 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 08/24/22 10:31:13.861
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/24/22 10:31:13.876
    STEP: changing the label value of the configmap back 08/24/22 10:31:23.877
    STEP: modifying the configmap a third time 08/24/22 10:31:23.894
    STEP: deleting the configmap 08/24/22 10:31:23.91
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/24/22 10:31:23.919
    Aug 24 10:31:23.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26186 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:31:23.920: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26187 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 24 10:31:23.920: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5695  51265b17-c054-4c44-98d8-9a7d439416c8 26188 0 2022-08-24 10:31:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-24 10:31:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 24 10:31:23.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5695" for this suite. 08/24/22 10:31:23.928
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:23.946
Aug 24 10:31:23.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename subpath 08/24/22 10:31:23.949
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:23.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:23.984
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/24/22 10:31:23.988
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-g4ns 08/24/22 10:31:24.017
STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:31:24.017
Aug 24 10:31:24.030: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-g4ns" in namespace "subpath-6175" to be "Succeeded or Failed"
Aug 24 10:31:24.043: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Pending", Reason="", readiness=false. Elapsed: 12.928221ms
Aug 24 10:31:26.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 2.020941992s
Aug 24 10:31:28.057: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 4.026996803s
Aug 24 10:31:30.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 6.020899292s
Aug 24 10:31:32.050: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 8.019784995s
Aug 24 10:31:34.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 10.020564733s
Aug 24 10:31:36.053: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 12.023150326s
Aug 24 10:31:38.052: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 14.021975394s
Aug 24 10:31:40.052: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 16.021778776s
Aug 24 10:31:42.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 18.02094998s
Aug 24 10:31:44.053: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 20.022372437s
Aug 24 10:31:46.049: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=false. Elapsed: 22.018840551s
Aug 24 10:31:48.054: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023945023s
STEP: Saw pod success 08/24/22 10:31:48.054
Aug 24 10:31:48.055: INFO: Pod "pod-subpath-test-configmap-g4ns" satisfied condition "Succeeded or Failed"
Aug 24 10:31:48.064: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-configmap-g4ns container test-container-subpath-configmap-g4ns: <nil>
STEP: delete the pod 08/24/22 10:31:48.104
Aug 24 10:31:48.122: INFO: Waiting for pod pod-subpath-test-configmap-g4ns to disappear
Aug 24 10:31:48.126: INFO: Pod pod-subpath-test-configmap-g4ns no longer exists
STEP: Deleting pod pod-subpath-test-configmap-g4ns 08/24/22 10:31:48.126
Aug 24 10:31:48.127: INFO: Deleting pod "pod-subpath-test-configmap-g4ns" in namespace "subpath-6175"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 24 10:31:48.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6175" for this suite. 08/24/22 10:31:48.14
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":252,"skipped":4582,"failed":0}
------------------------------
• [SLOW TEST] [24.204 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:23.946
    Aug 24 10:31:23.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename subpath 08/24/22 10:31:23.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:23.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:23.984
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/24/22 10:31:23.988
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-g4ns 08/24/22 10:31:24.017
    STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:31:24.017
    Aug 24 10:31:24.030: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-g4ns" in namespace "subpath-6175" to be "Succeeded or Failed"
    Aug 24 10:31:24.043: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Pending", Reason="", readiness=false. Elapsed: 12.928221ms
    Aug 24 10:31:26.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 2.020941992s
    Aug 24 10:31:28.057: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 4.026996803s
    Aug 24 10:31:30.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 6.020899292s
    Aug 24 10:31:32.050: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 8.019784995s
    Aug 24 10:31:34.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 10.020564733s
    Aug 24 10:31:36.053: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 12.023150326s
    Aug 24 10:31:38.052: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 14.021975394s
    Aug 24 10:31:40.052: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 16.021778776s
    Aug 24 10:31:42.051: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 18.02094998s
    Aug 24 10:31:44.053: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=true. Elapsed: 20.022372437s
    Aug 24 10:31:46.049: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Running", Reason="", readiness=false. Elapsed: 22.018840551s
    Aug 24 10:31:48.054: INFO: Pod "pod-subpath-test-configmap-g4ns": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023945023s
    STEP: Saw pod success 08/24/22 10:31:48.054
    Aug 24 10:31:48.055: INFO: Pod "pod-subpath-test-configmap-g4ns" satisfied condition "Succeeded or Failed"
    Aug 24 10:31:48.064: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-configmap-g4ns container test-container-subpath-configmap-g4ns: <nil>
    STEP: delete the pod 08/24/22 10:31:48.104
    Aug 24 10:31:48.122: INFO: Waiting for pod pod-subpath-test-configmap-g4ns to disappear
    Aug 24 10:31:48.126: INFO: Pod pod-subpath-test-configmap-g4ns no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-g4ns 08/24/22 10:31:48.126
    Aug 24 10:31:48.127: INFO: Deleting pod "pod-subpath-test-configmap-g4ns" in namespace "subpath-6175"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 24 10:31:48.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6175" for this suite. 08/24/22 10:31:48.14
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:48.153
Aug 24 10:31:48.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:31:48.158
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:48.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:48.184
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-f5e9bf13-ab81-446f-8b4f-72566dedf3dd 08/24/22 10:31:48.188
STEP: Creating a pod to test consume configMaps 08/24/22 10:31:48.194
Aug 24 10:31:48.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b" in namespace "projected-6696" to be "Succeeded or Failed"
Aug 24 10:31:48.218: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.676336ms
Aug 24 10:31:50.224: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016437754s
Aug 24 10:31:52.226: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018707715s
STEP: Saw pod success 08/24/22 10:31:52.226
Aug 24 10:31:52.227: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b" satisfied condition "Succeeded or Failed"
Aug 24 10:31:52.231: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:31:52.242
Aug 24 10:31:52.260: INFO: Waiting for pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b to disappear
Aug 24 10:31:52.277: INFO: Pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:31:52.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6696" for this suite. 08/24/22 10:31:52.285
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":253,"skipped":4587,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:48.153
    Aug 24 10:31:48.154: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:31:48.158
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:48.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:48.184
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-f5e9bf13-ab81-446f-8b4f-72566dedf3dd 08/24/22 10:31:48.188
    STEP: Creating a pod to test consume configMaps 08/24/22 10:31:48.194
    Aug 24 10:31:48.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b" in namespace "projected-6696" to be "Succeeded or Failed"
    Aug 24 10:31:48.218: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.676336ms
    Aug 24 10:31:50.224: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016437754s
    Aug 24 10:31:52.226: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018707715s
    STEP: Saw pod success 08/24/22 10:31:52.226
    Aug 24 10:31:52.227: INFO: Pod "pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b" satisfied condition "Succeeded or Failed"
    Aug 24 10:31:52.231: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:31:52.242
    Aug 24 10:31:52.260: INFO: Waiting for pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b to disappear
    Aug 24 10:31:52.277: INFO: Pod pod-projected-configmaps-5a5a55d8-77e5-449d-a9c9-9a4f3ebdaa1b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:31:52.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6696" for this suite. 08/24/22 10:31:52.285
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:52.298
Aug 24 10:31:52.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:31:52.302
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:52.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:52.329
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/24/22 10:31:52.333
Aug 24 10:31:52.345: INFO: Waiting up to 5m0s for pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f" in namespace "emptydir-1382" to be "Succeeded or Failed"
Aug 24 10:31:52.369: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.326533ms
Aug 24 10:31:54.378: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032338608s
Aug 24 10:31:56.376: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030451352s
STEP: Saw pod success 08/24/22 10:31:56.376
Aug 24 10:31:56.376: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f" satisfied condition "Succeeded or Failed"
Aug 24 10:31:56.385: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f container test-container: <nil>
STEP: delete the pod 08/24/22 10:31:56.395
Aug 24 10:31:56.412: INFO: Waiting for pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f to disappear
Aug 24 10:31:56.418: INFO: Pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:31:56.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1382" for this suite. 08/24/22 10:31:56.427
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":254,"skipped":4595,"failed":0}
------------------------------
• [4.142 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:52.298
    Aug 24 10:31:52.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:31:52.302
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:52.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:52.329
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/24/22 10:31:52.333
    Aug 24 10:31:52.345: INFO: Waiting up to 5m0s for pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f" in namespace "emptydir-1382" to be "Succeeded or Failed"
    Aug 24 10:31:52.369: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.326533ms
    Aug 24 10:31:54.378: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032338608s
    Aug 24 10:31:56.376: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030451352s
    STEP: Saw pod success 08/24/22 10:31:56.376
    Aug 24 10:31:56.376: INFO: Pod "pod-ad48256c-721c-4144-8b0c-c6f1715b544f" satisfied condition "Succeeded or Failed"
    Aug 24 10:31:56.385: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f container test-container: <nil>
    STEP: delete the pod 08/24/22 10:31:56.395
    Aug 24 10:31:56.412: INFO: Waiting for pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f to disappear
    Aug 24 10:31:56.418: INFO: Pod pod-ad48256c-721c-4144-8b0c-c6f1715b544f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:31:56.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1382" for this suite. 08/24/22 10:31:56.427
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:31:56.459
Aug 24 10:31:56.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename ephemeral-containers-test 08/24/22 10:31:56.463
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:56.488
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:56.495
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 08/24/22 10:31:56.5
Aug 24 10:31:56.511: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4019" to be "running and ready"
Aug 24 10:31:56.516: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.664905ms
Aug 24 10:31:56.516: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:31:58.526: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015039882s
Aug 24 10:31:58.526: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Aug 24 10:31:58.526: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 08/24/22 10:31:58.533
Aug 24 10:31:58.554: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4019" to be "container debugger running"
Aug 24 10:31:58.563: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.23054ms
Aug 24 10:32:00.571: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016633036s
Aug 24 10:32:02.570: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016093663s
Aug 24 10:32:02.570: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 08/24/22 10:32:02.571
Aug 24 10:32:02.571: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4019 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:32:02.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:32:02.574: INFO: ExecWithOptions: Clientset creation
Aug 24 10:32:02.574: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-4019/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Aug 24 10:32:02.675: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 10:32:02.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-4019" for this suite. 08/24/22 10:32:02.706
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":255,"skipped":4623,"failed":0}
------------------------------
• [SLOW TEST] [6.258 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:31:56.459
    Aug 24 10:31:56.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename ephemeral-containers-test 08/24/22 10:31:56.463
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:31:56.488
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:31:56.495
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 08/24/22 10:31:56.5
    Aug 24 10:31:56.511: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4019" to be "running and ready"
    Aug 24 10:31:56.516: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.664905ms
    Aug 24 10:31:56.516: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:31:58.526: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015039882s
    Aug 24 10:31:58.526: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Aug 24 10:31:58.526: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 08/24/22 10:31:58.533
    Aug 24 10:31:58.554: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4019" to be "container debugger running"
    Aug 24 10:31:58.563: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.23054ms
    Aug 24 10:32:00.571: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016633036s
    Aug 24 10:32:02.570: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016093663s
    Aug 24 10:32:02.570: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 08/24/22 10:32:02.571
    Aug 24 10:32:02.571: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4019 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:32:02.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:32:02.574: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:32:02.574: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-4019/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Aug 24 10:32:02.675: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 10:32:02.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-4019" for this suite. 08/24/22 10:32:02.706
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:02.722
Aug 24 10:32:02.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:32:02.724
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:02.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:02.751
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2577 08/24/22 10:32:02.755
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/24/22 10:32:02.783
STEP: creating service externalsvc in namespace services-2577 08/24/22 10:32:02.783
STEP: creating replication controller externalsvc in namespace services-2577 08/24/22 10:32:02.808
I0824 10:32:02.830325      14 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2577, replica count: 2
I0824 10:32:05.882174      14 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 08/24/22 10:32:05.89
Aug 24 10:32:05.922: INFO: Creating new exec pod
Aug 24 10:32:05.941: INFO: Waiting up to 5m0s for pod "execpodv5b66" in namespace "services-2577" to be "running"
Aug 24 10:32:05.953: INFO: Pod "execpodv5b66": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82143ms
Aug 24 10:32:07.966: INFO: Pod "execpodv5b66": Phase="Running", Reason="", readiness=true. Elapsed: 2.024828551s
Aug 24 10:32:07.966: INFO: Pod "execpodv5b66" satisfied condition "running"
Aug 24 10:32:07.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2577 exec execpodv5b66 -- /bin/sh -x -c nslookup nodeport-service.services-2577.svc.cluster.local'
Aug 24 10:32:08.420: INFO: stderr: "+ nslookup nodeport-service.services-2577.svc.cluster.local\n"
Aug 24 10:32:08.420: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-2577.svc.cluster.local\tcanonical name = externalsvc.services-2577.svc.cluster.local.\nName:\texternalsvc.services-2577.svc.cluster.local\nAddress: 10.233.38.88\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2577, will wait for the garbage collector to delete the pods 08/24/22 10:32:08.42
Aug 24 10:32:08.493: INFO: Deleting ReplicationController externalsvc took: 15.414082ms
Aug 24 10:32:08.594: INFO: Terminating ReplicationController externalsvc pods took: 100.868033ms
Aug 24 10:32:10.985: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:32:11.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2577" for this suite. 08/24/22 10:32:11.045
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":256,"skipped":4653,"failed":0}
------------------------------
• [SLOW TEST] [8.366 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:02.722
    Aug 24 10:32:02.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:32:02.724
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:02.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:02.751
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-2577 08/24/22 10:32:02.755
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/24/22 10:32:02.783
    STEP: creating service externalsvc in namespace services-2577 08/24/22 10:32:02.783
    STEP: creating replication controller externalsvc in namespace services-2577 08/24/22 10:32:02.808
    I0824 10:32:02.830325      14 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2577, replica count: 2
    I0824 10:32:05.882174      14 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 08/24/22 10:32:05.89
    Aug 24 10:32:05.922: INFO: Creating new exec pod
    Aug 24 10:32:05.941: INFO: Waiting up to 5m0s for pod "execpodv5b66" in namespace "services-2577" to be "running"
    Aug 24 10:32:05.953: INFO: Pod "execpodv5b66": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82143ms
    Aug 24 10:32:07.966: INFO: Pod "execpodv5b66": Phase="Running", Reason="", readiness=true. Elapsed: 2.024828551s
    Aug 24 10:32:07.966: INFO: Pod "execpodv5b66" satisfied condition "running"
    Aug 24 10:32:07.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-2577 exec execpodv5b66 -- /bin/sh -x -c nslookup nodeport-service.services-2577.svc.cluster.local'
    Aug 24 10:32:08.420: INFO: stderr: "+ nslookup nodeport-service.services-2577.svc.cluster.local\n"
    Aug 24 10:32:08.420: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-2577.svc.cluster.local\tcanonical name = externalsvc.services-2577.svc.cluster.local.\nName:\texternalsvc.services-2577.svc.cluster.local\nAddress: 10.233.38.88\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2577, will wait for the garbage collector to delete the pods 08/24/22 10:32:08.42
    Aug 24 10:32:08.493: INFO: Deleting ReplicationController externalsvc took: 15.414082ms
    Aug 24 10:32:08.594: INFO: Terminating ReplicationController externalsvc pods took: 100.868033ms
    Aug 24 10:32:10.985: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:32:11.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2577" for this suite. 08/24/22 10:32:11.045
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:11.09
Aug 24 10:32:11.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename ingress 08/24/22 10:32:11.093
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:11.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:11.137
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 08/24/22 10:32:11.141
STEP: getting /apis/networking.k8s.io 08/24/22 10:32:11.144
STEP: getting /apis/networking.k8s.iov1 08/24/22 10:32:11.145
STEP: creating 08/24/22 10:32:11.147
STEP: getting 08/24/22 10:32:11.183
STEP: listing 08/24/22 10:32:11.188
STEP: watching 08/24/22 10:32:11.196
Aug 24 10:32:11.196: INFO: starting watch
STEP: cluster-wide listing 08/24/22 10:32:11.198
STEP: cluster-wide watching 08/24/22 10:32:11.202
Aug 24 10:32:11.203: INFO: starting watch
STEP: patching 08/24/22 10:32:11.204
STEP: updating 08/24/22 10:32:11.213
Aug 24 10:32:11.227: INFO: waiting for watch events with expected annotations
Aug 24 10:32:11.227: INFO: saw patched and updated annotations
STEP: patching /status 08/24/22 10:32:11.227
STEP: updating /status 08/24/22 10:32:11.238
STEP: get /status 08/24/22 10:32:11.255
STEP: deleting 08/24/22 10:32:11.26
STEP: deleting a collection 08/24/22 10:32:11.279
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Aug 24 10:32:11.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-7680" for this suite. 08/24/22 10:32:11.307
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":257,"skipped":4657,"failed":0}
------------------------------
• [0.224 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:11.09
    Aug 24 10:32:11.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename ingress 08/24/22 10:32:11.093
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:11.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:11.137
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 08/24/22 10:32:11.141
    STEP: getting /apis/networking.k8s.io 08/24/22 10:32:11.144
    STEP: getting /apis/networking.k8s.iov1 08/24/22 10:32:11.145
    STEP: creating 08/24/22 10:32:11.147
    STEP: getting 08/24/22 10:32:11.183
    STEP: listing 08/24/22 10:32:11.188
    STEP: watching 08/24/22 10:32:11.196
    Aug 24 10:32:11.196: INFO: starting watch
    STEP: cluster-wide listing 08/24/22 10:32:11.198
    STEP: cluster-wide watching 08/24/22 10:32:11.202
    Aug 24 10:32:11.203: INFO: starting watch
    STEP: patching 08/24/22 10:32:11.204
    STEP: updating 08/24/22 10:32:11.213
    Aug 24 10:32:11.227: INFO: waiting for watch events with expected annotations
    Aug 24 10:32:11.227: INFO: saw patched and updated annotations
    STEP: patching /status 08/24/22 10:32:11.227
    STEP: updating /status 08/24/22 10:32:11.238
    STEP: get /status 08/24/22 10:32:11.255
    STEP: deleting 08/24/22 10:32:11.26
    STEP: deleting a collection 08/24/22 10:32:11.279
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Aug 24 10:32:11.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-7680" for this suite. 08/24/22 10:32:11.307
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:11.319
Aug 24 10:32:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:32:11.326
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:11.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:11.416
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:32:11.438
Aug 24 10:32:11.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f" in namespace "projected-7683" to be "Succeeded or Failed"
Aug 24 10:32:11.514: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412358ms
Aug 24 10:32:13.520: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011763426s
Aug 24 10:32:15.521: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013045675s
STEP: Saw pod success 08/24/22 10:32:15.521
Aug 24 10:32:15.522: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f" satisfied condition "Succeeded or Failed"
Aug 24 10:32:15.527: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f container client-container: <nil>
STEP: delete the pod 08/24/22 10:32:15.535
Aug 24 10:32:15.564: INFO: Waiting for pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f to disappear
Aug 24 10:32:15.569: INFO: Pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 10:32:15.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7683" for this suite. 08/24/22 10:32:15.577
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":258,"skipped":4688,"failed":0}
------------------------------
• [4.269 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:11.319
    Aug 24 10:32:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:32:11.326
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:11.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:11.416
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:32:11.438
    Aug 24 10:32:11.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f" in namespace "projected-7683" to be "Succeeded or Failed"
    Aug 24 10:32:11.514: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412358ms
    Aug 24 10:32:13.520: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011763426s
    Aug 24 10:32:15.521: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013045675s
    STEP: Saw pod success 08/24/22 10:32:15.521
    Aug 24 10:32:15.522: INFO: Pod "downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f" satisfied condition "Succeeded or Failed"
    Aug 24 10:32:15.527: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f container client-container: <nil>
    STEP: delete the pod 08/24/22 10:32:15.535
    Aug 24 10:32:15.564: INFO: Waiting for pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f to disappear
    Aug 24 10:32:15.569: INFO: Pod downwardapi-volume-7e8c8147-e10f-45db-b9b6-7c82ef32bb2f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 10:32:15.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7683" for this suite. 08/24/22 10:32:15.577
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:15.592
Aug 24 10:32:15.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:32:15.595
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:15.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:15.622
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-ebcd29a9-162e-44d1-b275-fa0a25a183eb 08/24/22 10:32:15.626
STEP: Creating a pod to test consume secrets 08/24/22 10:32:15.639
Aug 24 10:32:15.672: INFO: Waiting up to 5m0s for pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25" in namespace "secrets-6136" to be "Succeeded or Failed"
Aug 24 10:32:15.681: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.072589ms
Aug 24 10:32:17.688: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016412898s
Aug 24 10:32:19.689: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017343945s
STEP: Saw pod success 08/24/22 10:32:19.689
Aug 24 10:32:19.690: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25" satisfied condition "Succeeded or Failed"
Aug 24 10:32:19.696: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:32:19.708
Aug 24 10:32:19.734: INFO: Waiting for pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 to disappear
Aug 24 10:32:19.739: INFO: Pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:32:19.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6136" for this suite. 08/24/22 10:32:19.754
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":259,"skipped":4700,"failed":0}
------------------------------
• [4.176 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:15.592
    Aug 24 10:32:15.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:32:15.595
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:15.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:15.622
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-ebcd29a9-162e-44d1-b275-fa0a25a183eb 08/24/22 10:32:15.626
    STEP: Creating a pod to test consume secrets 08/24/22 10:32:15.639
    Aug 24 10:32:15.672: INFO: Waiting up to 5m0s for pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25" in namespace "secrets-6136" to be "Succeeded or Failed"
    Aug 24 10:32:15.681: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.072589ms
    Aug 24 10:32:17.688: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016412898s
    Aug 24 10:32:19.689: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017343945s
    STEP: Saw pod success 08/24/22 10:32:19.689
    Aug 24 10:32:19.690: INFO: Pod "pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25" satisfied condition "Succeeded or Failed"
    Aug 24 10:32:19.696: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:32:19.708
    Aug 24 10:32:19.734: INFO: Waiting for pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 to disappear
    Aug 24 10:32:19.739: INFO: Pod pod-secrets-7b9e421a-9bff-4cd5-94cc-a3140c03ba25 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:32:19.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6136" for this suite. 08/24/22 10:32:19.754
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:19.78
Aug 24 10:32:19.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename podtemplate 08/24/22 10:32:19.785
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:19.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:19.825
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 08/24/22 10:32:19.83
Aug 24 10:32:19.840: INFO: created test-podtemplate-1
Aug 24 10:32:19.849: INFO: created test-podtemplate-2
Aug 24 10:32:19.855: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 08/24/22 10:32:19.856
STEP: delete collection of pod templates 08/24/22 10:32:19.862
Aug 24 10:32:19.862: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 08/24/22 10:32:19.904
Aug 24 10:32:19.904: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 24 10:32:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-121" for this suite. 08/24/22 10:32:19.929
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":260,"skipped":4737,"failed":0}
------------------------------
• [0.165 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:19.78
    Aug 24 10:32:19.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename podtemplate 08/24/22 10:32:19.785
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:19.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:19.825
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 08/24/22 10:32:19.83
    Aug 24 10:32:19.840: INFO: created test-podtemplate-1
    Aug 24 10:32:19.849: INFO: created test-podtemplate-2
    Aug 24 10:32:19.855: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 08/24/22 10:32:19.856
    STEP: delete collection of pod templates 08/24/22 10:32:19.862
    Aug 24 10:32:19.862: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 08/24/22 10:32:19.904
    Aug 24 10:32:19.904: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 24 10:32:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-121" for this suite. 08/24/22 10:32:19.929
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:19.948
Aug 24 10:32:19.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename job 08/24/22 10:32:19.95
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:19.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:19.979
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 08/24/22 10:32:19.983
STEP: Ensuring job reaches completions 08/24/22 10:32:19.992
STEP: Ensuring pods with index for job exist 08/24/22 10:32:30
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 24 10:32:30.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4284" for this suite. 08/24/22 10:32:30.013
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":261,"skipped":4742,"failed":0}
------------------------------
• [SLOW TEST] [10.077 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:19.948
    Aug 24 10:32:19.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename job 08/24/22 10:32:19.95
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:19.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:19.979
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 08/24/22 10:32:19.983
    STEP: Ensuring job reaches completions 08/24/22 10:32:19.992
    STEP: Ensuring pods with index for job exist 08/24/22 10:32:30
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 24 10:32:30.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4284" for this suite. 08/24/22 10:32:30.013
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:30.031
Aug 24 10:32:30.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:32:30.033
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:30.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:30.07
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 08/24/22 10:32:30.078
Aug 24 10:32:30.122: INFO: Waiting up to 5m0s for pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f" in namespace "downward-api-6154" to be "Succeeded or Failed"
Aug 24 10:32:30.131: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.64152ms
Aug 24 10:32:32.138: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016360044s
Aug 24 10:32:34.140: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018217539s
STEP: Saw pod success 08/24/22 10:32:34.14
Aug 24 10:32:34.141: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f" satisfied condition "Succeeded or Failed"
Aug 24 10:32:34.147: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:32:34.161
Aug 24 10:32:34.183: INFO: Waiting for pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f to disappear
Aug 24 10:32:34.189: INFO: Pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 24 10:32:34.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6154" for this suite. 08/24/22 10:32:34.197
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":262,"skipped":4763,"failed":0}
------------------------------
• [4.179 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:30.031
    Aug 24 10:32:30.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:32:30.033
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:30.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:30.07
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 08/24/22 10:32:30.078
    Aug 24 10:32:30.122: INFO: Waiting up to 5m0s for pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f" in namespace "downward-api-6154" to be "Succeeded or Failed"
    Aug 24 10:32:30.131: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.64152ms
    Aug 24 10:32:32.138: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016360044s
    Aug 24 10:32:34.140: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018217539s
    STEP: Saw pod success 08/24/22 10:32:34.14
    Aug 24 10:32:34.141: INFO: Pod "downward-api-45213deb-287a-4ba1-b69d-067580dae00f" satisfied condition "Succeeded or Failed"
    Aug 24 10:32:34.147: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:32:34.161
    Aug 24 10:32:34.183: INFO: Waiting for pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f to disappear
    Aug 24 10:32:34.189: INFO: Pod downward-api-45213deb-287a-4ba1-b69d-067580dae00f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 24 10:32:34.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6154" for this suite. 08/24/22 10:32:34.197
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:34.212
Aug 24 10:32:34.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:32:34.215
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:34.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:34.251
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/24/22 10:32:34.257
Aug 24 10:32:34.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:32:38.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:32:54.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4494" for this suite. 08/24/22 10:32:54.206
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":263,"skipped":4770,"failed":0}
------------------------------
• [SLOW TEST] [20.004 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:34.212
    Aug 24 10:32:34.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:32:34.215
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:34.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:34.251
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/24/22 10:32:34.257
    Aug 24 10:32:34.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:32:38.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:32:54.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4494" for this suite. 08/24/22 10:32:54.206
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:54.22
Aug 24 10:32:54.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:32:54.224
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:54.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:54.249
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:32:54.252
Aug 24 10:32:54.264: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6" in namespace "downward-api-3009" to be "Succeeded or Failed"
Aug 24 10:32:54.274: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022169ms
Aug 24 10:32:56.283: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018511536s
Aug 24 10:32:58.284: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019604835s
STEP: Saw pod success 08/24/22 10:32:58.284
Aug 24 10:32:58.284: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6" satisfied condition "Succeeded or Failed"
Aug 24 10:32:58.289: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 container client-container: <nil>
STEP: delete the pod 08/24/22 10:32:58.299
Aug 24 10:32:58.323: INFO: Waiting for pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 to disappear
Aug 24 10:32:58.328: INFO: Pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:32:58.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3009" for this suite. 08/24/22 10:32:58.334
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":264,"skipped":4785,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:54.22
    Aug 24 10:32:54.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:32:54.224
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:54.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:54.249
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:32:54.252
    Aug 24 10:32:54.264: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6" in namespace "downward-api-3009" to be "Succeeded or Failed"
    Aug 24 10:32:54.274: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022169ms
    Aug 24 10:32:56.283: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018511536s
    Aug 24 10:32:58.284: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019604835s
    STEP: Saw pod success 08/24/22 10:32:58.284
    Aug 24 10:32:58.284: INFO: Pod "downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6" satisfied condition "Succeeded or Failed"
    Aug 24 10:32:58.289: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:32:58.299
    Aug 24 10:32:58.323: INFO: Waiting for pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 to disappear
    Aug 24 10:32:58.328: INFO: Pod downwardapi-volume-64781a32-9d33-4287-8950-8d978f8ce9a6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:32:58.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3009" for this suite. 08/24/22 10:32:58.334
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:32:58.35
Aug 24 10:32:58.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir-wrapper 08/24/22 10:32:58.352
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:58.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:58.41
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 08/24/22 10:32:58.419
STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:32:58.925
Aug 24 10:32:59.010: INFO: Pod name wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4: Found 0 pods out of 5
Aug 24 10:33:04.043: INFO: Pod name wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/24/22 10:33:04.043
Aug 24 10:33:04.044: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:04.053: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.385062ms
Aug 24 10:33:06.061: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017113657s
Aug 24 10:33:08.070: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02580068s
Aug 24 10:33:10.068: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023782419s
Aug 24 10:33:12.076: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032267093s
Aug 24 10:33:14.064: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Running", Reason="", readiness=true. Elapsed: 10.019759279s
Aug 24 10:33:14.064: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt" satisfied condition "running"
Aug 24 10:33:14.064: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:14.071: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg": Phase="Running", Reason="", readiness=true. Elapsed: 6.967092ms
Aug 24 10:33:14.071: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg" satisfied condition "running"
Aug 24 10:33:14.071: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:14.078: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls": Phase="Running", Reason="", readiness=true. Elapsed: 7.169358ms
Aug 24 10:33:14.078: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls" satisfied condition "running"
Aug 24 10:33:14.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:14.086: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.604143ms
Aug 24 10:33:16.095: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw": Phase="Running", Reason="", readiness=true. Elapsed: 2.016951488s
Aug 24 10:33:16.096: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw" satisfied condition "running"
Aug 24 10:33:16.096: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:16.128: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24": Phase="Running", Reason="", readiness=true. Elapsed: 32.049656ms
Aug 24 10:33:16.128: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:16.128
Aug 24 10:33:16.201: INFO: Deleting ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 took: 14.701567ms
Aug 24 10:33:16.402: INFO: Terminating ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 pods took: 200.529708ms
STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:33:20.01
Aug 24 10:33:20.044: INFO: Pod name wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3: Found 0 pods out of 5
Aug 24 10:33:25.059: INFO: Pod name wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/24/22 10:33:25.059
Aug 24 10:33:25.060: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:25.067: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.683034ms
Aug 24 10:33:27.075: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015581989s
Aug 24 10:33:29.075: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015446901s
Aug 24 10:33:31.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018096761s
Aug 24 10:33:33.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Running", Reason="", readiness=true. Elapsed: 8.018231956s
Aug 24 10:33:33.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8" satisfied condition "running"
Aug 24 10:33:33.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:33.089: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx": Phase="Pending", Reason="", readiness=false. Elapsed: 11.194092ms
Aug 24 10:33:35.099: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx": Phase="Running", Reason="", readiness=true. Elapsed: 2.020940898s
Aug 24 10:33:35.099: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx" satisfied condition "running"
Aug 24 10:33:35.099: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:35.105: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl": Phase="Running", Reason="", readiness=true. Elapsed: 6.359868ms
Aug 24 10:33:35.105: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl" satisfied condition "running"
Aug 24 10:33:35.105: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:35.116: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg": Phase="Running", Reason="", readiness=true. Elapsed: 10.695144ms
Aug 24 10:33:35.116: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg" satisfied condition "running"
Aug 24 10:33:35.116: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:35.124: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q": Phase="Running", Reason="", readiness=true. Elapsed: 7.839911ms
Aug 24 10:33:35.124: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:35.124
Aug 24 10:33:35.206: INFO: Deleting ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 took: 20.159588ms
Aug 24 10:33:35.406: INFO: Terminating ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 pods took: 200.584968ms
STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:33:39.217
Aug 24 10:33:39.246: INFO: Pod name wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5: Found 0 pods out of 5
Aug 24 10:33:44.263: INFO: Pod name wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/24/22 10:33:44.264
Aug 24 10:33:44.264: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:44.270: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026891ms
Aug 24 10:33:46.280: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016207322s
Aug 24 10:33:48.281: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016542104s
Aug 24 10:33:50.278: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013716373s
Aug 24 10:33:52.282: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018006191s
Aug 24 10:33:54.279: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Running", Reason="", readiness=true. Elapsed: 10.014644446s
Aug 24 10:33:54.279: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc" satisfied condition "running"
Aug 24 10:33:54.279: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:54.286: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7": Phase="Running", Reason="", readiness=true. Elapsed: 7.095324ms
Aug 24 10:33:54.286: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7" satisfied condition "running"
Aug 24 10:33:54.286: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:54.295: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.194069ms
Aug 24 10:33:56.307: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb": Phase="Running", Reason="", readiness=true. Elapsed: 2.020566053s
Aug 24 10:33:56.307: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb" satisfied condition "running"
Aug 24 10:33:56.307: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:56.315: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5": Phase="Running", Reason="", readiness=true. Elapsed: 8.572381ms
Aug 24 10:33:56.316: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5" satisfied condition "running"
Aug 24 10:33:56.316: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569" in namespace "emptydir-wrapper-714" to be "running"
Aug 24 10:33:56.321: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569": Phase="Running", Reason="", readiness=true. Elapsed: 5.105212ms
Aug 24 10:33:56.321: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:56.321
Aug 24 10:33:56.407: INFO: Deleting ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 took: 23.395133ms
Aug 24 10:33:56.607: INFO: Terminating ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 pods took: 200.634438ms
STEP: Cleaning up the configMaps 08/24/22 10:34:00.608
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 24 10:34:01.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-714" for this suite. 08/24/22 10:34:01.192
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":265,"skipped":4800,"failed":0}
------------------------------
• [SLOW TEST] [62.863 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:32:58.35
    Aug 24 10:32:58.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir-wrapper 08/24/22 10:32:58.352
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:32:58.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:32:58.41
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 08/24/22 10:32:58.419
    STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:32:58.925
    Aug 24 10:32:59.010: INFO: Pod name wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4: Found 0 pods out of 5
    Aug 24 10:33:04.043: INFO: Pod name wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/24/22 10:33:04.043
    Aug 24 10:33:04.044: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:04.053: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.385062ms
    Aug 24 10:33:06.061: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017113657s
    Aug 24 10:33:08.070: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02580068s
    Aug 24 10:33:10.068: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023782419s
    Aug 24 10:33:12.076: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032267093s
    Aug 24 10:33:14.064: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt": Phase="Running", Reason="", readiness=true. Elapsed: 10.019759279s
    Aug 24 10:33:14.064: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-5bfgt" satisfied condition "running"
    Aug 24 10:33:14.064: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:14.071: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg": Phase="Running", Reason="", readiness=true. Elapsed: 6.967092ms
    Aug 24 10:33:14.071: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-9nvsg" satisfied condition "running"
    Aug 24 10:33:14.071: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:14.078: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls": Phase="Running", Reason="", readiness=true. Elapsed: 7.169358ms
    Aug 24 10:33:14.078: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-gj2ls" satisfied condition "running"
    Aug 24 10:33:14.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:14.086: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.604143ms
    Aug 24 10:33:16.095: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw": Phase="Running", Reason="", readiness=true. Elapsed: 2.016951488s
    Aug 24 10:33:16.096: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-kw6xw" satisfied condition "running"
    Aug 24 10:33:16.096: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:16.128: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24": Phase="Running", Reason="", readiness=true. Elapsed: 32.049656ms
    Aug 24 10:33:16.128: INFO: Pod "wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4-n4t24" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:16.128
    Aug 24 10:33:16.201: INFO: Deleting ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 took: 14.701567ms
    Aug 24 10:33:16.402: INFO: Terminating ReplicationController wrapped-volume-race-a92c11a8-f091-4f6c-8957-bafab1ac97f4 pods took: 200.529708ms
    STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:33:20.01
    Aug 24 10:33:20.044: INFO: Pod name wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3: Found 0 pods out of 5
    Aug 24 10:33:25.059: INFO: Pod name wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/24/22 10:33:25.059
    Aug 24 10:33:25.060: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:25.067: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.683034ms
    Aug 24 10:33:27.075: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015581989s
    Aug 24 10:33:29.075: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015446901s
    Aug 24 10:33:31.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018096761s
    Aug 24 10:33:33.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8": Phase="Running", Reason="", readiness=true. Elapsed: 8.018231956s
    Aug 24 10:33:33.078: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-4tds8" satisfied condition "running"
    Aug 24 10:33:33.078: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:33.089: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx": Phase="Pending", Reason="", readiness=false. Elapsed: 11.194092ms
    Aug 24 10:33:35.099: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx": Phase="Running", Reason="", readiness=true. Elapsed: 2.020940898s
    Aug 24 10:33:35.099: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-bbjfx" satisfied condition "running"
    Aug 24 10:33:35.099: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:35.105: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl": Phase="Running", Reason="", readiness=true. Elapsed: 6.359868ms
    Aug 24 10:33:35.105: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-jvrjl" satisfied condition "running"
    Aug 24 10:33:35.105: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:35.116: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg": Phase="Running", Reason="", readiness=true. Elapsed: 10.695144ms
    Aug 24 10:33:35.116: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-nvvhg" satisfied condition "running"
    Aug 24 10:33:35.116: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:35.124: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q": Phase="Running", Reason="", readiness=true. Elapsed: 7.839911ms
    Aug 24 10:33:35.124: INFO: Pod "wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3-zdt6q" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:35.124
    Aug 24 10:33:35.206: INFO: Deleting ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 took: 20.159588ms
    Aug 24 10:33:35.406: INFO: Terminating ReplicationController wrapped-volume-race-89185104-193c-4a8b-8834-5045dd6d77f3 pods took: 200.584968ms
    STEP: Creating RC which spawns configmap-volume pods 08/24/22 10:33:39.217
    Aug 24 10:33:39.246: INFO: Pod name wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5: Found 0 pods out of 5
    Aug 24 10:33:44.263: INFO: Pod name wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/24/22 10:33:44.264
    Aug 24 10:33:44.264: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:44.270: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026891ms
    Aug 24 10:33:46.280: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016207322s
    Aug 24 10:33:48.281: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016542104s
    Aug 24 10:33:50.278: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013716373s
    Aug 24 10:33:52.282: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018006191s
    Aug 24 10:33:54.279: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc": Phase="Running", Reason="", readiness=true. Elapsed: 10.014644446s
    Aug 24 10:33:54.279: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6l2gc" satisfied condition "running"
    Aug 24 10:33:54.279: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:54.286: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7": Phase="Running", Reason="", readiness=true. Elapsed: 7.095324ms
    Aug 24 10:33:54.286: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6sfj7" satisfied condition "running"
    Aug 24 10:33:54.286: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:54.295: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.194069ms
    Aug 24 10:33:56.307: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb": Phase="Running", Reason="", readiness=true. Elapsed: 2.020566053s
    Aug 24 10:33:56.307: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-6zlvb" satisfied condition "running"
    Aug 24 10:33:56.307: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:56.315: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5": Phase="Running", Reason="", readiness=true. Elapsed: 8.572381ms
    Aug 24 10:33:56.316: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-9jtf5" satisfied condition "running"
    Aug 24 10:33:56.316: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569" in namespace "emptydir-wrapper-714" to be "running"
    Aug 24 10:33:56.321: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569": Phase="Running", Reason="", readiness=true. Elapsed: 5.105212ms
    Aug 24 10:33:56.321: INFO: Pod "wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5-bx569" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 in namespace emptydir-wrapper-714, will wait for the garbage collector to delete the pods 08/24/22 10:33:56.321
    Aug 24 10:33:56.407: INFO: Deleting ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 took: 23.395133ms
    Aug 24 10:33:56.607: INFO: Terminating ReplicationController wrapped-volume-race-eabbee74-e3b4-498b-ab5f-118acbbd72d5 pods took: 200.634438ms
    STEP: Cleaning up the configMaps 08/24/22 10:34:00.608
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:34:01.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-714" for this suite. 08/24/22 10:34:01.192
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:01.241
Aug 24 10:34:01.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:34:01.243
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:01.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:01.283
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-f7fbf60a-8b5a-4cde-b309-294ae11cf2db 08/24/22 10:34:01.286
STEP: Creating a pod to test consume secrets 08/24/22 10:34:01.304
Aug 24 10:34:01.321: INFO: Waiting up to 5m0s for pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7" in namespace "secrets-9037" to be "Succeeded or Failed"
Aug 24 10:34:01.327: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.961298ms
Aug 24 10:34:03.335: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013904655s
Aug 24 10:34:05.336: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015302441s
Aug 24 10:34:07.336: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015566133s
STEP: Saw pod success 08/24/22 10:34:07.337
Aug 24 10:34:07.337: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7" satisfied condition "Succeeded or Failed"
Aug 24 10:34:07.344: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:34:07.374
Aug 24 10:34:07.440: INFO: Waiting for pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 to disappear
Aug 24 10:34:07.446: INFO: Pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:34:07.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9037" for this suite. 08/24/22 10:34:07.485
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":266,"skipped":4863,"failed":0}
------------------------------
• [SLOW TEST] [6.265 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:01.241
    Aug 24 10:34:01.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:34:01.243
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:01.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:01.283
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-f7fbf60a-8b5a-4cde-b309-294ae11cf2db 08/24/22 10:34:01.286
    STEP: Creating a pod to test consume secrets 08/24/22 10:34:01.304
    Aug 24 10:34:01.321: INFO: Waiting up to 5m0s for pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7" in namespace "secrets-9037" to be "Succeeded or Failed"
    Aug 24 10:34:01.327: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.961298ms
    Aug 24 10:34:03.335: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013904655s
    Aug 24 10:34:05.336: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015302441s
    Aug 24 10:34:07.336: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015566133s
    STEP: Saw pod success 08/24/22 10:34:07.337
    Aug 24 10:34:07.337: INFO: Pod "pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7" satisfied condition "Succeeded or Failed"
    Aug 24 10:34:07.344: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:34:07.374
    Aug 24 10:34:07.440: INFO: Waiting for pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 to disappear
    Aug 24 10:34:07.446: INFO: Pod pod-secrets-dd535cea-acf7-4b4a-b9a9-4c78856f57e7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:34:07.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9037" for this suite. 08/24/22 10:34:07.485
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:07.509
Aug 24 10:34:07.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename disruption 08/24/22 10:34:07.516
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:07.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:07.573
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 08/24/22 10:34:07.579
STEP: Waiting for the pdb to be processed 08/24/22 10:34:07.587
STEP: updating the pdb 08/24/22 10:34:09.609
STEP: Waiting for the pdb to be processed 08/24/22 10:34:09.628
STEP: patching the pdb 08/24/22 10:34:11.644
STEP: Waiting for the pdb to be processed 08/24/22 10:34:11.662
STEP: Waiting for the pdb to be deleted 08/24/22 10:34:11.695
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 24 10:34:11.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8751" for this suite. 08/24/22 10:34:11.719
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":267,"skipped":4865,"failed":0}
------------------------------
• [4.221 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:07.509
    Aug 24 10:34:07.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename disruption 08/24/22 10:34:07.516
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:07.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:07.573
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 08/24/22 10:34:07.579
    STEP: Waiting for the pdb to be processed 08/24/22 10:34:07.587
    STEP: updating the pdb 08/24/22 10:34:09.609
    STEP: Waiting for the pdb to be processed 08/24/22 10:34:09.628
    STEP: patching the pdb 08/24/22 10:34:11.644
    STEP: Waiting for the pdb to be processed 08/24/22 10:34:11.662
    STEP: Waiting for the pdb to be deleted 08/24/22 10:34:11.695
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 24 10:34:11.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8751" for this suite. 08/24/22 10:34:11.719
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:11.734
Aug 24 10:34:11.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:34:11.738
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:11.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:11.765
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:34:11.797
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:34:12.589
STEP: Deploying the webhook pod 08/24/22 10:34:12.603
STEP: Wait for the deployment to be ready 08/24/22 10:34:12.641
Aug 24 10:34:12.660: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/24/22 10:34:14.685
STEP: Verifying the service has paired with the endpoint 08/24/22 10:34:14.707
Aug 24 10:34:15.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/24/22 10:34:15.716
STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:15.717
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/24/22 10:34:15.757
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/24/22 10:34:16.774
STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:16.774
STEP: Having no error when timeout is longer than webhook latency 08/24/22 10:34:17.824
STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:17.824
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/24/22 10:34:22.886
STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:22.886
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:34:27.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5635" for this suite. 08/24/22 10:34:27.948
STEP: Destroying namespace "webhook-5635-markers" for this suite. 08/24/22 10:34:27.961
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":268,"skipped":4901,"failed":0}
------------------------------
• [SLOW TEST] [16.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:11.734
    Aug 24 10:34:11.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:34:11.738
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:11.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:11.765
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:34:11.797
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:34:12.589
    STEP: Deploying the webhook pod 08/24/22 10:34:12.603
    STEP: Wait for the deployment to be ready 08/24/22 10:34:12.641
    Aug 24 10:34:12.660: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/24/22 10:34:14.685
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:34:14.707
    Aug 24 10:34:15.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/24/22 10:34:15.716
    STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:15.717
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/24/22 10:34:15.757
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/24/22 10:34:16.774
    STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:16.774
    STEP: Having no error when timeout is longer than webhook latency 08/24/22 10:34:17.824
    STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:17.824
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/24/22 10:34:22.886
    STEP: Registering slow webhook via the AdmissionRegistration API 08/24/22 10:34:22.886
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:34:27.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5635" for this suite. 08/24/22 10:34:27.948
    STEP: Destroying namespace "webhook-5635-markers" for this suite. 08/24/22 10:34:27.961
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:28.226
Aug 24 10:34:28.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:34:28.234
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:28.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:28.332
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:34:28.366
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:34:29.175
STEP: Deploying the webhook pod 08/24/22 10:34:29.188
STEP: Wait for the deployment to be ready 08/24/22 10:34:29.205
Aug 24 10:34:29.223: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 10:34:31.253: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:34:33.261
STEP: Verifying the service has paired with the endpoint 08/24/22 10:34:33.279
Aug 24 10:34:34.280: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Aug 24 10:34:34.287: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/24/22 10:34:34.81
STEP: Creating a custom resource that should be denied by the webhook 08/24/22 10:34:34.837
STEP: Creating a custom resource whose deletion would be denied by the webhook 08/24/22 10:34:36.957
STEP: Updating the custom resource with disallowed data should be denied 08/24/22 10:34:36.971
STEP: Deleting the custom resource should be denied 08/24/22 10:34:36.99
STEP: Remove the offending key and value from the custom resource data 08/24/22 10:34:37.001
STEP: Deleting the updated custom resource should be successful 08/24/22 10:34:37.015
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:34:37.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7978" for this suite. 08/24/22 10:34:37.566
STEP: Destroying namespace "webhook-7978-markers" for this suite. 08/24/22 10:34:37.581
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":269,"skipped":4929,"failed":0}
------------------------------
• [SLOW TEST] [9.546 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:28.226
    Aug 24 10:34:28.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:34:28.234
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:28.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:28.332
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:34:28.366
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:34:29.175
    STEP: Deploying the webhook pod 08/24/22 10:34:29.188
    STEP: Wait for the deployment to be ready 08/24/22 10:34:29.205
    Aug 24 10:34:29.223: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 10:34:31.253: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 34, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:34:33.261
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:34:33.279
    Aug 24 10:34:34.280: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Aug 24 10:34:34.287: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/24/22 10:34:34.81
    STEP: Creating a custom resource that should be denied by the webhook 08/24/22 10:34:34.837
    STEP: Creating a custom resource whose deletion would be denied by the webhook 08/24/22 10:34:36.957
    STEP: Updating the custom resource with disallowed data should be denied 08/24/22 10:34:36.971
    STEP: Deleting the custom resource should be denied 08/24/22 10:34:36.99
    STEP: Remove the offending key and value from the custom resource data 08/24/22 10:34:37.001
    STEP: Deleting the updated custom resource should be successful 08/24/22 10:34:37.015
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:34:37.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7978" for this suite. 08/24/22 10:34:37.566
    STEP: Destroying namespace "webhook-7978-markers" for this suite. 08/24/22 10:34:37.581
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:37.774
Aug 24 10:34:37.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replication-controller 08/24/22 10:34:37.787
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:37.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:37.929
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Aug 24 10:34:37.939: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/24/22 10:34:37.992
STEP: Checking rc "condition-test" has the desired failure condition set 08/24/22 10:34:38.013
STEP: Scaling down rc "condition-test" to satisfy pod quota 08/24/22 10:34:39.031
Aug 24 10:34:39.047: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 08/24/22 10:34:39.047
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 24 10:34:40.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4395" for this suite. 08/24/22 10:34:40.125
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":270,"skipped":4933,"failed":0}
------------------------------
• [2.367 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:37.774
    Aug 24 10:34:37.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replication-controller 08/24/22 10:34:37.787
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:37.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:37.929
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Aug 24 10:34:37.939: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/24/22 10:34:37.992
    STEP: Checking rc "condition-test" has the desired failure condition set 08/24/22 10:34:38.013
    STEP: Scaling down rc "condition-test" to satisfy pod quota 08/24/22 10:34:39.031
    Aug 24 10:34:39.047: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 08/24/22 10:34:39.047
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 24 10:34:40.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4395" for this suite. 08/24/22 10:34:40.125
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:40.142
Aug 24 10:34:40.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:34:40.147
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:40.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:40.186
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 08/24/22 10:34:40.191
Aug 24 10:34:40.203: INFO: Waiting up to 5m0s for pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274" in namespace "emptydir-1386" to be "Succeeded or Failed"
Aug 24 10:34:40.212: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 8.172626ms
Aug 24 10:34:42.220: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016080244s
Aug 24 10:34:44.219: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015278227s
Aug 24 10:34:46.221: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017207427s
STEP: Saw pod success 08/24/22 10:34:46.221
Aug 24 10:34:46.221: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274" satisfied condition "Succeeded or Failed"
Aug 24 10:34:46.227: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 container test-container: <nil>
STEP: delete the pod 08/24/22 10:34:46.243
Aug 24 10:34:46.298: INFO: Waiting for pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 to disappear
Aug 24 10:34:46.304: INFO: Pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:34:46.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1386" for this suite. 08/24/22 10:34:46.314
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":271,"skipped":4933,"failed":0}
------------------------------
• [SLOW TEST] [6.183 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:40.142
    Aug 24 10:34:40.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:34:40.147
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:40.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:40.186
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 08/24/22 10:34:40.191
    Aug 24 10:34:40.203: INFO: Waiting up to 5m0s for pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274" in namespace "emptydir-1386" to be "Succeeded or Failed"
    Aug 24 10:34:40.212: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 8.172626ms
    Aug 24 10:34:42.220: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016080244s
    Aug 24 10:34:44.219: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015278227s
    Aug 24 10:34:46.221: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017207427s
    STEP: Saw pod success 08/24/22 10:34:46.221
    Aug 24 10:34:46.221: INFO: Pod "pod-ddd36035-0170-43f2-9d94-86be26ab3274" satisfied condition "Succeeded or Failed"
    Aug 24 10:34:46.227: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:34:46.243
    Aug 24 10:34:46.298: INFO: Waiting for pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 to disappear
    Aug 24 10:34:46.304: INFO: Pod pod-ddd36035-0170-43f2-9d94-86be26ab3274 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:34:46.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1386" for this suite. 08/24/22 10:34:46.314
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:46.33
Aug 24 10:34:46.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:34:46.334
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:46.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:46.383
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-f63ecc7d-2d79-4bb1-8298-d7280316c5e1 08/24/22 10:34:46.393
STEP: Creating the pod 08/24/22 10:34:46.402
Aug 24 10:34:46.416: INFO: Waiting up to 5m0s for pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6" in namespace "configmap-9080" to be "running and ready"
Aug 24 10:34:46.424: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.865406ms
Aug 24 10:34:46.425: INFO: The phase of Pod pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:34:48.432: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014962777s
Aug 24 10:34:48.432: INFO: The phase of Pod pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6 is Running (Ready = true)
Aug 24 10:34:48.432: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-f63ecc7d-2d79-4bb1-8298-d7280316c5e1 08/24/22 10:34:48.446
STEP: waiting to observe update in volume 08/24/22 10:34:48.456
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:34:50.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9080" for this suite. 08/24/22 10:34:50.498
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":272,"skipped":4955,"failed":0}
------------------------------
• [4.187 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:46.33
    Aug 24 10:34:46.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:34:46.334
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:46.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:46.383
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-f63ecc7d-2d79-4bb1-8298-d7280316c5e1 08/24/22 10:34:46.393
    STEP: Creating the pod 08/24/22 10:34:46.402
    Aug 24 10:34:46.416: INFO: Waiting up to 5m0s for pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6" in namespace "configmap-9080" to be "running and ready"
    Aug 24 10:34:46.424: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.865406ms
    Aug 24 10:34:46.425: INFO: The phase of Pod pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:34:48.432: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014962777s
    Aug 24 10:34:48.432: INFO: The phase of Pod pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6 is Running (Ready = true)
    Aug 24 10:34:48.432: INFO: Pod "pod-configmaps-b47537aa-3bc3-45b8-9716-6a1c89d86da6" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-f63ecc7d-2d79-4bb1-8298-d7280316c5e1 08/24/22 10:34:48.446
    STEP: waiting to observe update in volume 08/24/22 10:34:48.456
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:34:50.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9080" for this suite. 08/24/22 10:34:50.498
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:50.519
Aug 24 10:34:50.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename init-container 08/24/22 10:34:50.526
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:50.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:50.576
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 08/24/22 10:34:50.581
Aug 24 10:34:50.581: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 24 10:34:53.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6861" for this suite. 08/24/22 10:34:53.821
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":273,"skipped":4964,"failed":0}
------------------------------
• [3.313 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:50.519
    Aug 24 10:34:50.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename init-container 08/24/22 10:34:50.526
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:50.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:50.576
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 08/24/22 10:34:50.581
    Aug 24 10:34:50.581: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 24 10:34:53.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6861" for this suite. 08/24/22 10:34:53.821
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:53.835
Aug 24 10:34:53.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:34:53.839
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:53.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:53.881
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Aug 24 10:34:53.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:34:54.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1708" for this suite. 08/24/22 10:34:54.498
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":274,"skipped":4965,"failed":0}
------------------------------
• [0.681 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:53.835
    Aug 24 10:34:53.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename custom-resource-definition 08/24/22 10:34:53.839
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:53.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:53.881
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Aug 24 10:34:53.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:34:54.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1708" for this suite. 08/24/22 10:34:54.498
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:54.544
Aug 24 10:34:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:34:54.546
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:54.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:54.59
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Aug 24 10:34:54.630: INFO: Waiting up to 2m0s for pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" in namespace "var-expansion-4919" to be "container 0 failed with reason CreateContainerConfigError"
Aug 24 10:34:54.641: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.329537ms
Aug 24 10:34:56.664: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034603505s
Aug 24 10:34:56.665: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 24 10:34:56.665: INFO: Deleting pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" in namespace "var-expansion-4919"
Aug 24 10:34:56.677: INFO: Wait up to 5m0s for pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:34:58.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4919" for this suite. 08/24/22 10:34:58.717
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":275,"skipped":4999,"failed":0}
------------------------------
• [4.188 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:54.544
    Aug 24 10:34:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:34:54.546
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:54.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:54.59
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Aug 24 10:34:54.630: INFO: Waiting up to 2m0s for pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" in namespace "var-expansion-4919" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 24 10:34:54.641: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.329537ms
    Aug 24 10:34:56.664: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034603505s
    Aug 24 10:34:56.665: INFO: Pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 24 10:34:56.665: INFO: Deleting pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" in namespace "var-expansion-4919"
    Aug 24 10:34:56.677: INFO: Wait up to 5m0s for pod "var-expansion-b8f0e561-abff-4a55-a1dc-adf7d87116eb" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:34:58.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4919" for this suite. 08/24/22 10:34:58.717
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:34:58.742
Aug 24 10:34:58.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:34:58.746
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:58.781
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:58.789
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:34:58.83
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:35:00.044
STEP: Deploying the webhook pod 08/24/22 10:35:00.058
STEP: Wait for the deployment to be ready 08/24/22 10:35:00.145
Aug 24 10:35:00.191: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 10:35:02.212: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:35:04.22
STEP: Verifying the service has paired with the endpoint 08/24/22 10:35:04.252
Aug 24 10:35:05.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 08/24/22 10:35:05.258
Aug 24 10:35:05.288: INFO: Waiting for webhook configuration to be ready...
STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/24/22 10:35:05.411
STEP: Creating a configMap that should not be mutated 08/24/22 10:35:05.42
STEP: Patching a mutating webhook configuration's rules to include the create operation 08/24/22 10:35:05.574
STEP: Creating a configMap that should be mutated 08/24/22 10:35:05.59
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:35:05.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-480" for this suite. 08/24/22 10:35:05.641
STEP: Destroying namespace "webhook-480-markers" for this suite. 08/24/22 10:35:05.656
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":276,"skipped":5002,"failed":0}
------------------------------
• [SLOW TEST] [7.104 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:34:58.742
    Aug 24 10:34:58.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:34:58.746
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:34:58.781
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:34:58.789
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:34:58.83
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:35:00.044
    STEP: Deploying the webhook pod 08/24/22 10:35:00.058
    STEP: Wait for the deployment to be ready 08/24/22 10:35:00.145
    Aug 24 10:35:00.191: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 10:35:02.212: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 35, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:35:04.22
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:35:04.252
    Aug 24 10:35:05.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 08/24/22 10:35:05.258
    Aug 24 10:35:05.288: INFO: Waiting for webhook configuration to be ready...
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/24/22 10:35:05.411
    STEP: Creating a configMap that should not be mutated 08/24/22 10:35:05.42
    STEP: Patching a mutating webhook configuration's rules to include the create operation 08/24/22 10:35:05.574
    STEP: Creating a configMap that should be mutated 08/24/22 10:35:05.59
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:35:05.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-480" for this suite. 08/24/22 10:35:05.641
    STEP: Destroying namespace "webhook-480-markers" for this suite. 08/24/22 10:35:05.656
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:05.845
Aug 24 10:35:05.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 10:35:05.852
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:05.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:05.896
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/24/22 10:35:05.911
Aug 24 10:35:05.932: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 10:35:10.940: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 10:35:10.94
STEP: getting scale subresource 08/24/22 10:35:10.94
STEP: updating a scale subresource 08/24/22 10:35:10.945
STEP: verifying the replicaset Spec.Replicas was modified 08/24/22 10:35:10.962
STEP: Patch a scale subresource 08/24/22 10:35:10.995
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 10:35:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4266" for this suite. 08/24/22 10:35:11.114
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":277,"skipped":5003,"failed":0}
------------------------------
• [SLOW TEST] [5.317 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:05.845
    Aug 24 10:35:05.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 10:35:05.852
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:05.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:05.896
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/24/22 10:35:05.911
    Aug 24 10:35:05.932: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 24 10:35:10.940: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 10:35:10.94
    STEP: getting scale subresource 08/24/22 10:35:10.94
    STEP: updating a scale subresource 08/24/22 10:35:10.945
    STEP: verifying the replicaset Spec.Replicas was modified 08/24/22 10:35:10.962
    STEP: Patch a scale subresource 08/24/22 10:35:10.995
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 10:35:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4266" for this suite. 08/24/22 10:35:11.114
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:11.164
Aug 24 10:35:11.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:35:11.168
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:11.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:11.258
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-b08e3c3a-e3a4-4aea-a6fa-bed8d00671d0 08/24/22 10:35:11.27
STEP: Creating a pod to test consume secrets 08/24/22 10:35:11.275
Aug 24 10:35:11.302: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee" in namespace "projected-2226" to be "Succeeded or Failed"
Aug 24 10:35:11.311: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.783928ms
Aug 24 10:35:13.319: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01675775s
Aug 24 10:35:15.317: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01563571s
Aug 24 10:35:17.318: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016384843s
STEP: Saw pod success 08/24/22 10:35:17.318
Aug 24 10:35:17.319: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee" satisfied condition "Succeeded or Failed"
Aug 24 10:35:17.325: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee container projected-secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:35:17.336
Aug 24 10:35:17.355: INFO: Waiting for pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee to disappear
Aug 24 10:35:17.360: INFO: Pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:35:17.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2226" for this suite. 08/24/22 10:35:17.366
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":278,"skipped":5006,"failed":0}
------------------------------
• [SLOW TEST] [6.212 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:11.164
    Aug 24 10:35:11.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:35:11.168
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:11.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:11.258
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-b08e3c3a-e3a4-4aea-a6fa-bed8d00671d0 08/24/22 10:35:11.27
    STEP: Creating a pod to test consume secrets 08/24/22 10:35:11.275
    Aug 24 10:35:11.302: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee" in namespace "projected-2226" to be "Succeeded or Failed"
    Aug 24 10:35:11.311: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.783928ms
    Aug 24 10:35:13.319: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01675775s
    Aug 24 10:35:15.317: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01563571s
    Aug 24 10:35:17.318: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016384843s
    STEP: Saw pod success 08/24/22 10:35:17.318
    Aug 24 10:35:17.319: INFO: Pod "pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee" satisfied condition "Succeeded or Failed"
    Aug 24 10:35:17.325: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:35:17.336
    Aug 24 10:35:17.355: INFO: Waiting for pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee to disappear
    Aug 24 10:35:17.360: INFO: Pod pod-projected-secrets-db690fa1-058c-4bf8-8677-167ba76cd8ee no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:35:17.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2226" for this suite. 08/24/22 10:35:17.366
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:17.392
Aug 24 10:35:17.392: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:35:17.394
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:17.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:17.436
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Aug 24 10:35:17.457: INFO: Waiting up to 5m0s for pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed" in namespace "kubelet-test-559" to be "running and ready"
Aug 24 10:35:17.479: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 21.558278ms
Aug 24 10:35:17.479: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:35:19.484: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026777061s
Aug 24 10:35:19.484: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:35:21.485: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.027939611s
Aug 24 10:35:21.485: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Running (Ready = true)
Aug 24 10:35:21.485: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 24 10:35:21.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-559" for this suite. 08/24/22 10:35:21.51
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":279,"skipped":5043,"failed":0}
------------------------------
• [4.127 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:17.392
    Aug 24 10:35:17.392: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubelet-test 08/24/22 10:35:17.394
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:17.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:17.436
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Aug 24 10:35:17.457: INFO: Waiting up to 5m0s for pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed" in namespace "kubelet-test-559" to be "running and ready"
    Aug 24 10:35:17.479: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 21.558278ms
    Aug 24 10:35:17.479: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:35:19.484: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026777061s
    Aug 24 10:35:19.484: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:35:21.485: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.027939611s
    Aug 24 10:35:21.485: INFO: The phase of Pod busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed is Running (Ready = true)
    Aug 24 10:35:21.485: INFO: Pod "busybox-scheduling-d951f093-1339-420e-bd68-94d3a537f0ed" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 24 10:35:21.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-559" for this suite. 08/24/22 10:35:21.51
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:21.554
Aug 24 10:35:21.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:35:21.557
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:21.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:21.589
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 08/24/22 10:35:21.593
Aug 24 10:35:21.615: INFO: Waiting up to 5m0s for pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948" in namespace "downward-api-9997" to be "running and ready"
Aug 24 10:35:21.630: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948": Phase="Pending", Reason="", readiness=false. Elapsed: 14.82945ms
Aug 24 10:35:21.630: INFO: The phase of Pod labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:35:23.638: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948": Phase="Running", Reason="", readiness=true. Elapsed: 2.022201887s
Aug 24 10:35:23.638: INFO: The phase of Pod labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948 is Running (Ready = true)
Aug 24 10:35:23.638: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948" satisfied condition "running and ready"
Aug 24 10:35:24.176: INFO: Successfully updated pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:35:28.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9997" for this suite. 08/24/22 10:35:28.22
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":280,"skipped":5167,"failed":0}
------------------------------
• [SLOW TEST] [6.679 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:21.554
    Aug 24 10:35:21.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:35:21.557
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:21.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:21.589
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 08/24/22 10:35:21.593
    Aug 24 10:35:21.615: INFO: Waiting up to 5m0s for pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948" in namespace "downward-api-9997" to be "running and ready"
    Aug 24 10:35:21.630: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948": Phase="Pending", Reason="", readiness=false. Elapsed: 14.82945ms
    Aug 24 10:35:21.630: INFO: The phase of Pod labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:35:23.638: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948": Phase="Running", Reason="", readiness=true. Elapsed: 2.022201887s
    Aug 24 10:35:23.638: INFO: The phase of Pod labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948 is Running (Ready = true)
    Aug 24 10:35:23.638: INFO: Pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948" satisfied condition "running and ready"
    Aug 24 10:35:24.176: INFO: Successfully updated pod "labelsupdatea3ce8dc4-de60-4fd5-830b-ece6379cd948"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:35:28.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9997" for this suite. 08/24/22 10:35:28.22
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:28.235
Aug 24 10:35:28.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename events 08/24/22 10:35:28.239
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:28.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:28.275
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 08/24/22 10:35:28.28
STEP: listing all events in all namespaces 08/24/22 10:35:28.286
STEP: patching the test event 08/24/22 10:35:28.294
STEP: fetching the test event 08/24/22 10:35:28.305
STEP: updating the test event 08/24/22 10:35:28.311
STEP: getting the test event 08/24/22 10:35:28.329
STEP: deleting the test event 08/24/22 10:35:28.335
STEP: listing all events in all namespaces 08/24/22 10:35:28.353
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 24 10:35:28.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-839" for this suite. 08/24/22 10:35:28.386
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":281,"skipped":5168,"failed":0}
------------------------------
• [0.165 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:28.235
    Aug 24 10:35:28.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename events 08/24/22 10:35:28.239
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:28.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:28.275
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 08/24/22 10:35:28.28
    STEP: listing all events in all namespaces 08/24/22 10:35:28.286
    STEP: patching the test event 08/24/22 10:35:28.294
    STEP: fetching the test event 08/24/22 10:35:28.305
    STEP: updating the test event 08/24/22 10:35:28.311
    STEP: getting the test event 08/24/22 10:35:28.329
    STEP: deleting the test event 08/24/22 10:35:28.335
    STEP: listing all events in all namespaces 08/24/22 10:35:28.353
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 24 10:35:28.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-839" for this suite. 08/24/22 10:35:28.386
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:28.404
Aug 24 10:35:28.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:35:28.407
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:28.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:28.432
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-f3adbfc1-d01e-4f25-a80b-986bdb3d3a29 08/24/22 10:35:28.436
STEP: Creating a pod to test consume secrets 08/24/22 10:35:28.443
Aug 24 10:35:28.459: INFO: Waiting up to 5m0s for pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b" in namespace "secrets-2197" to be "Succeeded or Failed"
Aug 24 10:35:28.466: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.447786ms
Aug 24 10:35:30.473: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014067651s
Aug 24 10:35:32.474: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014515089s
STEP: Saw pod success 08/24/22 10:35:32.474
Aug 24 10:35:32.474: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b" satisfied condition "Succeeded or Failed"
Aug 24 10:35:32.482: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b container secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:35:32.493
Aug 24 10:35:32.511: INFO: Waiting for pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b to disappear
Aug 24 10:35:32.517: INFO: Pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:35:32.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2197" for this suite. 08/24/22 10:35:32.528
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":282,"skipped":5168,"failed":0}
------------------------------
• [4.136 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:28.404
    Aug 24 10:35:28.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:35:28.407
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:28.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:28.432
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-f3adbfc1-d01e-4f25-a80b-986bdb3d3a29 08/24/22 10:35:28.436
    STEP: Creating a pod to test consume secrets 08/24/22 10:35:28.443
    Aug 24 10:35:28.459: INFO: Waiting up to 5m0s for pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b" in namespace "secrets-2197" to be "Succeeded or Failed"
    Aug 24 10:35:28.466: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.447786ms
    Aug 24 10:35:30.473: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014067651s
    Aug 24 10:35:32.474: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014515089s
    STEP: Saw pod success 08/24/22 10:35:32.474
    Aug 24 10:35:32.474: INFO: Pod "pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b" satisfied condition "Succeeded or Failed"
    Aug 24 10:35:32.482: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b container secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:35:32.493
    Aug 24 10:35:32.511: INFO: Waiting for pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b to disappear
    Aug 24 10:35:32.517: INFO: Pod pod-secrets-18908e85-a259-4cf1-b6b3-b7ee18439e5b no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:35:32.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2197" for this suite. 08/24/22 10:35:32.528
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:32.563
Aug 24 10:35:32.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:35:32.566
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:32.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:32.602
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/24/22 10:35:32.607
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/24/22 10:35:32.607
STEP: creating a pod to probe DNS 08/24/22 10:35:32.607
STEP: submitting the pod to kubernetes 08/24/22 10:35:32.608
Aug 24 10:35:32.624: INFO: Waiting up to 15m0s for pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9" in namespace "dns-3210" to be "running"
Aug 24 10:35:32.643: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.173548ms
Aug 24 10:35:34.655: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030680356s
Aug 24 10:35:36.651: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Running", Reason="", readiness=true. Elapsed: 4.026987913s
Aug 24 10:35:36.651: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:35:36.651
STEP: looking for the results for each expected name from probers 08/24/22 10:35:36.658
Aug 24 10:35:36.692: INFO: DNS probes using dns-3210/dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9 succeeded

STEP: deleting the pod 08/24/22 10:35:36.692
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:35:36.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3210" for this suite. 08/24/22 10:35:36.74
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":283,"skipped":5211,"failed":0}
------------------------------
• [4.198 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:32.563
    Aug 24 10:35:32.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:35:32.566
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:32.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:32.602
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/24/22 10:35:32.607
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/24/22 10:35:32.607
    STEP: creating a pod to probe DNS 08/24/22 10:35:32.607
    STEP: submitting the pod to kubernetes 08/24/22 10:35:32.608
    Aug 24 10:35:32.624: INFO: Waiting up to 15m0s for pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9" in namespace "dns-3210" to be "running"
    Aug 24 10:35:32.643: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.173548ms
    Aug 24 10:35:34.655: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030680356s
    Aug 24 10:35:36.651: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9": Phase="Running", Reason="", readiness=true. Elapsed: 4.026987913s
    Aug 24 10:35:36.651: INFO: Pod "dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:35:36.651
    STEP: looking for the results for each expected name from probers 08/24/22 10:35:36.658
    Aug 24 10:35:36.692: INFO: DNS probes using dns-3210/dns-test-fce956cd-a16f-4fc5-9c25-928eafcb28e9 succeeded

    STEP: deleting the pod 08/24/22 10:35:36.692
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:35:36.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3210" for this suite. 08/24/22 10:35:36.74
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:36.765
Aug 24 10:35:36.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:35:36.767
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:36.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:36.796
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 08/24/22 10:35:36.803
Aug 24 10:35:36.826: INFO: Waiting up to 5m0s for pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4" in namespace "downward-api-4168" to be "Succeeded or Failed"
Aug 24 10:35:36.845: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.494038ms
Aug 24 10:35:38.850: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024054176s
Aug 24 10:35:40.853: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026834049s
STEP: Saw pod success 08/24/22 10:35:40.853
Aug 24 10:35:40.853: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4" satisfied condition "Succeeded or Failed"
Aug 24 10:35:40.858: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:35:40.871
Aug 24 10:35:40.901: INFO: Waiting for pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 to disappear
Aug 24 10:35:40.907: INFO: Pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 24 10:35:40.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4168" for this suite. 08/24/22 10:35:40.917
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":284,"skipped":5227,"failed":0}
------------------------------
• [4.236 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:36.765
    Aug 24 10:35:36.765: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:35:36.767
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:36.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:36.796
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 08/24/22 10:35:36.803
    Aug 24 10:35:36.826: INFO: Waiting up to 5m0s for pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4" in namespace "downward-api-4168" to be "Succeeded or Failed"
    Aug 24 10:35:36.845: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.494038ms
    Aug 24 10:35:38.850: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024054176s
    Aug 24 10:35:40.853: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026834049s
    STEP: Saw pod success 08/24/22 10:35:40.853
    Aug 24 10:35:40.853: INFO: Pod "downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4" satisfied condition "Succeeded or Failed"
    Aug 24 10:35:40.858: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:35:40.871
    Aug 24 10:35:40.901: INFO: Waiting for pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 to disappear
    Aug 24 10:35:40.907: INFO: Pod downward-api-c24250c9-27b5-401d-8d1f-54ded23a95a4 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 24 10:35:40.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4168" for this suite. 08/24/22 10:35:40.917
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:41.013
Aug 24 10:35:41.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:35:41.016
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:41.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:41.049
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 08/24/22 10:35:41.053
Aug 24 10:35:41.068: INFO: Waiting up to 5m0s for pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6" in namespace "emptydir-5940" to be "Succeeded or Failed"
Aug 24 10:35:41.074: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.786864ms
Aug 24 10:35:43.082: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014258185s
Aug 24 10:35:45.079: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011313539s
STEP: Saw pod success 08/24/22 10:35:45.079
Aug 24 10:35:45.080: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6" satisfied condition "Succeeded or Failed"
Aug 24 10:35:45.084: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 container test-container: <nil>
STEP: delete the pod 08/24/22 10:35:45.252
Aug 24 10:35:45.271: INFO: Waiting for pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 to disappear
Aug 24 10:35:45.277: INFO: Pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:35:45.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5940" for this suite. 08/24/22 10:35:45.288
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":285,"skipped":5244,"failed":0}
------------------------------
• [4.284 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:41.013
    Aug 24 10:35:41.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:35:41.016
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:41.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:41.049
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/24/22 10:35:41.053
    Aug 24 10:35:41.068: INFO: Waiting up to 5m0s for pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6" in namespace "emptydir-5940" to be "Succeeded or Failed"
    Aug 24 10:35:41.074: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.786864ms
    Aug 24 10:35:43.082: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014258185s
    Aug 24 10:35:45.079: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011313539s
    STEP: Saw pod success 08/24/22 10:35:45.079
    Aug 24 10:35:45.080: INFO: Pod "pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6" satisfied condition "Succeeded or Failed"
    Aug 24 10:35:45.084: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:35:45.252
    Aug 24 10:35:45.271: INFO: Waiting for pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 to disappear
    Aug 24 10:35:45.277: INFO: Pod pod-f6a303cc-1a8a-46ff-8275-d6836c99b7d6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:35:45.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5940" for this suite. 08/24/22 10:35:45.288
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:45.302
Aug 24 10:35:45.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:35:45.306
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:45.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:45.337
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 08/24/22 10:35:45.341
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:35:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7610" for this suite. 08/24/22 10:35:45.358
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":286,"skipped":5254,"failed":0}
------------------------------
• [0.073 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:45.302
    Aug 24 10:35:45.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:35:45.306
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:45.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:45.337
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 08/24/22 10:35:45.341
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:35:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7610" for this suite. 08/24/22 10:35:45.358
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:45.377
Aug 24 10:35:45.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context-test 08/24/22 10:35:45.38
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:45.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:45.424
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Aug 24 10:35:45.441: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490" in namespace "security-context-test-9167" to be "Succeeded or Failed"
Aug 24 10:35:45.447: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 5.938333ms
Aug 24 10:35:47.454: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012631617s
Aug 24 10:35:49.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015263335s
Aug 24 10:35:51.455: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013591964s
Aug 24 10:35:53.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014562207s
Aug 24 10:35:53.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:35:53.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9167" for this suite. 08/24/22 10:35:53.473
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":287,"skipped":5254,"failed":0}
------------------------------
• [SLOW TEST] [8.108 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:45.377
    Aug 24 10:35:45.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context-test 08/24/22 10:35:45.38
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:45.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:45.424
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Aug 24 10:35:45.441: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490" in namespace "security-context-test-9167" to be "Succeeded or Failed"
    Aug 24 10:35:45.447: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 5.938333ms
    Aug 24 10:35:47.454: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012631617s
    Aug 24 10:35:49.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015263335s
    Aug 24 10:35:51.455: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013591964s
    Aug 24 10:35:53.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014562207s
    Aug 24 10:35:53.456: INFO: Pod "alpine-nnp-false-575687a5-31b2-4e40-92b2-3b12df178490" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:35:53.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9167" for this suite. 08/24/22 10:35:53.473
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:53.515
Aug 24 10:35:53.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-runtime 08/24/22 10:35:53.522
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:53.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:53.557
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 08/24/22 10:35:53.566
STEP: wait for the container to reach Succeeded 08/24/22 10:35:53.594
STEP: get the container status 08/24/22 10:35:57.645
STEP: the container should be terminated 08/24/22 10:35:57.65
STEP: the termination message should be set 08/24/22 10:35:57.651
Aug 24 10:35:57.651: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 08/24/22 10:35:57.652
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 24 10:35:57.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3855" for this suite. 08/24/22 10:35:57.693
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":288,"skipped":5321,"failed":0}
------------------------------
• [4.192 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:53.515
    Aug 24 10:35:53.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-runtime 08/24/22 10:35:53.522
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:53.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:53.557
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 08/24/22 10:35:53.566
    STEP: wait for the container to reach Succeeded 08/24/22 10:35:53.594
    STEP: get the container status 08/24/22 10:35:57.645
    STEP: the container should be terminated 08/24/22 10:35:57.65
    STEP: the termination message should be set 08/24/22 10:35:57.651
    Aug 24 10:35:57.651: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 08/24/22 10:35:57.652
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 24 10:35:57.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3855" for this suite. 08/24/22 10:35:57.693
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:35:57.71
Aug 24 10:35:57.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:35:57.713
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:57.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:57.762
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-297 08/24/22 10:35:57.768
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/24/22 10:35:57.791
STEP: creating service externalsvc in namespace services-297 08/24/22 10:35:57.791
STEP: creating replication controller externalsvc in namespace services-297 08/24/22 10:35:57.858
I0824 10:35:57.902907      14 runners.go:193] Created replication controller with name: externalsvc, namespace: services-297, replica count: 2
I0824 10:36:00.954165      14 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 08/24/22 10:36:00.963
Aug 24 10:36:00.991: INFO: Creating new exec pod
Aug 24 10:36:01.003: INFO: Waiting up to 5m0s for pod "execpodw4x7r" in namespace "services-297" to be "running"
Aug 24 10:36:01.010: INFO: Pod "execpodw4x7r": Phase="Pending", Reason="", readiness=false. Elapsed: 7.09261ms
Aug 24 10:36:03.018: INFO: Pod "execpodw4x7r": Phase="Running", Reason="", readiness=true. Elapsed: 2.014952012s
Aug 24 10:36:03.018: INFO: Pod "execpodw4x7r" satisfied condition "running"
Aug 24 10:36:03.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-297 exec execpodw4x7r -- /bin/sh -x -c nslookup clusterip-service.services-297.svc.cluster.local'
Aug 24 10:36:03.768: INFO: stderr: "+ nslookup clusterip-service.services-297.svc.cluster.local\n"
Aug 24 10:36:03.768: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-297.svc.cluster.local\tcanonical name = externalsvc.services-297.svc.cluster.local.\nName:\texternalsvc.services-297.svc.cluster.local\nAddress: 10.233.61.50\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-297, will wait for the garbage collector to delete the pods 08/24/22 10:36:03.768
Aug 24 10:36:03.839: INFO: Deleting ReplicationController externalsvc took: 13.24512ms
Aug 24 10:36:03.940: INFO: Terminating ReplicationController externalsvc pods took: 101.098964ms
Aug 24 10:36:06.488: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:36:06.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-297" for this suite. 08/24/22 10:36:06.554
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":289,"skipped":5325,"failed":0}
------------------------------
• [SLOW TEST] [8.860 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:35:57.71
    Aug 24 10:35:57.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:35:57.713
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:35:57.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:35:57.762
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-297 08/24/22 10:35:57.768
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/24/22 10:35:57.791
    STEP: creating service externalsvc in namespace services-297 08/24/22 10:35:57.791
    STEP: creating replication controller externalsvc in namespace services-297 08/24/22 10:35:57.858
    I0824 10:35:57.902907      14 runners.go:193] Created replication controller with name: externalsvc, namespace: services-297, replica count: 2
    I0824 10:36:00.954165      14 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 08/24/22 10:36:00.963
    Aug 24 10:36:00.991: INFO: Creating new exec pod
    Aug 24 10:36:01.003: INFO: Waiting up to 5m0s for pod "execpodw4x7r" in namespace "services-297" to be "running"
    Aug 24 10:36:01.010: INFO: Pod "execpodw4x7r": Phase="Pending", Reason="", readiness=false. Elapsed: 7.09261ms
    Aug 24 10:36:03.018: INFO: Pod "execpodw4x7r": Phase="Running", Reason="", readiness=true. Elapsed: 2.014952012s
    Aug 24 10:36:03.018: INFO: Pod "execpodw4x7r" satisfied condition "running"
    Aug 24 10:36:03.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-297 exec execpodw4x7r -- /bin/sh -x -c nslookup clusterip-service.services-297.svc.cluster.local'
    Aug 24 10:36:03.768: INFO: stderr: "+ nslookup clusterip-service.services-297.svc.cluster.local\n"
    Aug 24 10:36:03.768: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-297.svc.cluster.local\tcanonical name = externalsvc.services-297.svc.cluster.local.\nName:\texternalsvc.services-297.svc.cluster.local\nAddress: 10.233.61.50\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-297, will wait for the garbage collector to delete the pods 08/24/22 10:36:03.768
    Aug 24 10:36:03.839: INFO: Deleting ReplicationController externalsvc took: 13.24512ms
    Aug 24 10:36:03.940: INFO: Terminating ReplicationController externalsvc pods took: 101.098964ms
    Aug 24 10:36:06.488: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:36:06.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-297" for this suite. 08/24/22 10:36:06.554
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:06.572
Aug 24 10:36:06.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-runtime 08/24/22 10:36:06.574
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:06.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:06.632
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 08/24/22 10:36:06.65
STEP: wait for the container to reach Failed 08/24/22 10:36:06.678
STEP: get the container status 08/24/22 10:36:10.713
STEP: the container should be terminated 08/24/22 10:36:10.719
STEP: the termination message should be set 08/24/22 10:36:10.719
Aug 24 10:36:10.719: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/24/22 10:36:10.719
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 24 10:36:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7390" for this suite. 08/24/22 10:36:10.773
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":290,"skipped":5347,"failed":0}
------------------------------
• [4.232 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:06.572
    Aug 24 10:36:06.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-runtime 08/24/22 10:36:06.574
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:06.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:06.632
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 08/24/22 10:36:06.65
    STEP: wait for the container to reach Failed 08/24/22 10:36:06.678
    STEP: get the container status 08/24/22 10:36:10.713
    STEP: the container should be terminated 08/24/22 10:36:10.719
    STEP: the termination message should be set 08/24/22 10:36:10.719
    Aug 24 10:36:10.719: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/24/22 10:36:10.719
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 24 10:36:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7390" for this suite. 08/24/22 10:36:10.773
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:10.81
Aug 24 10:36:10.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:36:10.812
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:10.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:10.864
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 08/24/22 10:36:10.868
STEP: setting up watch 08/24/22 10:36:10.869
STEP: submitting the pod to kubernetes 08/24/22 10:36:10.975
STEP: verifying the pod is in kubernetes 08/24/22 10:36:10.99
STEP: verifying pod creation was observed 08/24/22 10:36:10.998
Aug 24 10:36:10.998: INFO: Waiting up to 5m0s for pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02" in namespace "pods-9169" to be "running"
Aug 24 10:36:11.004: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.17076ms
Aug 24 10:36:13.019: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020960928s
Aug 24 10:36:15.020: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Running", Reason="", readiness=true. Elapsed: 4.021944127s
Aug 24 10:36:15.020: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02" satisfied condition "running"
STEP: deleting the pod gracefully 08/24/22 10:36:15.032
STEP: verifying pod deletion was observed 08/24/22 10:36:15.046
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:36:16.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9169" for this suite. 08/24/22 10:36:16.418
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":291,"skipped":5362,"failed":0}
------------------------------
• [SLOW TEST] [5.616 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:10.81
    Aug 24 10:36:10.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:36:10.812
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:10.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:10.864
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 08/24/22 10:36:10.868
    STEP: setting up watch 08/24/22 10:36:10.869
    STEP: submitting the pod to kubernetes 08/24/22 10:36:10.975
    STEP: verifying the pod is in kubernetes 08/24/22 10:36:10.99
    STEP: verifying pod creation was observed 08/24/22 10:36:10.998
    Aug 24 10:36:10.998: INFO: Waiting up to 5m0s for pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02" in namespace "pods-9169" to be "running"
    Aug 24 10:36:11.004: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.17076ms
    Aug 24 10:36:13.019: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020960928s
    Aug 24 10:36:15.020: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02": Phase="Running", Reason="", readiness=true. Elapsed: 4.021944127s
    Aug 24 10:36:15.020: INFO: Pod "pod-submit-remove-5d4a407e-0103-4f27-8cf3-312810b96a02" satisfied condition "running"
    STEP: deleting the pod gracefully 08/24/22 10:36:15.032
    STEP: verifying pod deletion was observed 08/24/22 10:36:15.046
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:36:16.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9169" for this suite. 08/24/22 10:36:16.418
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:16.436
Aug 24 10:36:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:36:16.439
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:16.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:16.503
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-5b90f567-e4fe-4c91-afc8-ded0e1705a17 08/24/22 10:36:16.514
STEP: Creating a pod to test consume configMaps 08/24/22 10:36:16.522
Aug 24 10:36:16.552: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788" in namespace "projected-4071" to be "Succeeded or Failed"
Aug 24 10:36:16.558: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 5.713344ms
Aug 24 10:36:18.566: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013429181s
Aug 24 10:36:20.565: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01328915s
Aug 24 10:36:22.565: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012603146s
STEP: Saw pod success 08/24/22 10:36:22.565
Aug 24 10:36:22.566: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788" satisfied condition "Succeeded or Failed"
Aug 24 10:36:22.571: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:36:22.585
Aug 24 10:36:22.608: INFO: Waiting for pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 to disappear
Aug 24 10:36:22.613: INFO: Pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:36:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4071" for this suite. 08/24/22 10:36:22.621
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":292,"skipped":5371,"failed":0}
------------------------------
• [SLOW TEST] [6.204 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:16.436
    Aug 24 10:36:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:36:16.439
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:16.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:16.503
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-5b90f567-e4fe-4c91-afc8-ded0e1705a17 08/24/22 10:36:16.514
    STEP: Creating a pod to test consume configMaps 08/24/22 10:36:16.522
    Aug 24 10:36:16.552: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788" in namespace "projected-4071" to be "Succeeded or Failed"
    Aug 24 10:36:16.558: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 5.713344ms
    Aug 24 10:36:18.566: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013429181s
    Aug 24 10:36:20.565: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01328915s
    Aug 24 10:36:22.565: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012603146s
    STEP: Saw pod success 08/24/22 10:36:22.565
    Aug 24 10:36:22.566: INFO: Pod "pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788" satisfied condition "Succeeded or Failed"
    Aug 24 10:36:22.571: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:36:22.585
    Aug 24 10:36:22.608: INFO: Waiting for pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 to disappear
    Aug 24 10:36:22.613: INFO: Pod pod-projected-configmaps-1b48be6a-667b-467b-9994-1cde7cbf6788 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:36:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4071" for this suite. 08/24/22 10:36:22.621
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:22.641
Aug 24 10:36:22.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:36:22.644
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:22.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:22.669
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 08/24/22 10:36:22.675
Aug 24 10:36:22.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6162 cluster-info'
Aug 24 10:36:22.841: INFO: stderr: ""
Aug 24 10:36:22.841: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:36:22.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6162" for this suite. 08/24/22 10:36:22.848
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":293,"skipped":5375,"failed":0}
------------------------------
• [0.216 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:22.641
    Aug 24 10:36:22.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:36:22.644
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:22.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:22.669
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 08/24/22 10:36:22.675
    Aug 24 10:36:22.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-6162 cluster-info'
    Aug 24 10:36:22.841: INFO: stderr: ""
    Aug 24 10:36:22.841: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:36:22.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6162" for this suite. 08/24/22 10:36:22.848
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:22.867
Aug 24 10:36:22.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:36:22.871
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:22.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:22.902
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 08/24/22 10:36:22.936
Aug 24 10:36:22.936: INFO: namespace kubectl-909
Aug 24 10:36:22.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 create -f -'
Aug 24 10:36:24.672: INFO: stderr: ""
Aug 24 10:36:24.672: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/24/22 10:36:24.672
Aug 24 10:36:25.691: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 10:36:25.691: INFO: Found 0 / 1
Aug 24 10:36:26.681: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 10:36:26.682: INFO: Found 1 / 1
Aug 24 10:36:26.682: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 24 10:36:26.712: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 10:36:26.712: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 10:36:26.712: INFO: wait on agnhost-primary startup in kubectl-909 
Aug 24 10:36:26.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 logs agnhost-primary-bkdlr agnhost-primary'
Aug 24 10:36:26.873: INFO: stderr: ""
Aug 24 10:36:26.873: INFO: stdout: "Paused\n"
STEP: exposing RC 08/24/22 10:36:26.873
Aug 24 10:36:26.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Aug 24 10:36:27.083: INFO: stderr: ""
Aug 24 10:36:27.083: INFO: stdout: "service/rm2 exposed\n"
Aug 24 10:36:27.091: INFO: Service rm2 in namespace kubectl-909 found.
STEP: exposing service 08/24/22 10:36:29.102
Aug 24 10:36:29.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Aug 24 10:36:29.282: INFO: stderr: ""
Aug 24 10:36:29.282: INFO: stdout: "service/rm3 exposed\n"
Aug 24 10:36:29.290: INFO: Service rm3 in namespace kubectl-909 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:36:31.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-909" for this suite. 08/24/22 10:36:31.307
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":294,"skipped":5406,"failed":0}
------------------------------
• [SLOW TEST] [8.450 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:22.867
    Aug 24 10:36:22.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:36:22.871
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:22.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:22.902
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 08/24/22 10:36:22.936
    Aug 24 10:36:22.936: INFO: namespace kubectl-909
    Aug 24 10:36:22.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 create -f -'
    Aug 24 10:36:24.672: INFO: stderr: ""
    Aug 24 10:36:24.672: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/24/22 10:36:24.672
    Aug 24 10:36:25.691: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 10:36:25.691: INFO: Found 0 / 1
    Aug 24 10:36:26.681: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 10:36:26.682: INFO: Found 1 / 1
    Aug 24 10:36:26.682: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 24 10:36:26.712: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 24 10:36:26.712: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 24 10:36:26.712: INFO: wait on agnhost-primary startup in kubectl-909 
    Aug 24 10:36:26.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 logs agnhost-primary-bkdlr agnhost-primary'
    Aug 24 10:36:26.873: INFO: stderr: ""
    Aug 24 10:36:26.873: INFO: stdout: "Paused\n"
    STEP: exposing RC 08/24/22 10:36:26.873
    Aug 24 10:36:26.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Aug 24 10:36:27.083: INFO: stderr: ""
    Aug 24 10:36:27.083: INFO: stdout: "service/rm2 exposed\n"
    Aug 24 10:36:27.091: INFO: Service rm2 in namespace kubectl-909 found.
    STEP: exposing service 08/24/22 10:36:29.102
    Aug 24 10:36:29.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-909 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Aug 24 10:36:29.282: INFO: stderr: ""
    Aug 24 10:36:29.282: INFO: stdout: "service/rm3 exposed\n"
    Aug 24 10:36:29.290: INFO: Service rm3 in namespace kubectl-909 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:36:31.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-909" for this suite. 08/24/22 10:36:31.307
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:36:31.332
Aug 24 10:36:31.332: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:36:31.335
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:31.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:31.371
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4397 08/24/22 10:36:31.375
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 08/24/22 10:36:31.389
Aug 24 10:36:31.489: INFO: Found 0 stateful pods, waiting for 3
Aug 24 10:36:41.496: INFO: Found 1 stateful pods, waiting for 3
Aug 24 10:36:51.502: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:36:51.502: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:36:51.502: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:36:51.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:36:51.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:36:51.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:36:51.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/24/22 10:37:01.86
Aug 24 10:37:01.890: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/24/22 10:37:01.89
STEP: Updating Pods in reverse ordinal order 08/24/22 10:37:11.935
Aug 24 10:37:11.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:37:12.226: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:37:12.226: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:37:12.226: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 08/24/22 10:37:22.265
Aug 24 10:37:22.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:37:22.564: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:37:22.564: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:37:22.564: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:37:32.634: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 08/24/22 10:37:42.675
Aug 24 10:37:42.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:37:42.953: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:37:42.953: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:37:42.953: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:37:52.998: INFO: Deleting all statefulset in ns statefulset-4397
Aug 24 10:37:53.003: INFO: Scaling statefulset ss2 to 0
Aug 24 10:38:03.035: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:38:03.041: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:38:03.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4397" for this suite. 08/24/22 10:38:03.082
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":295,"skipped":5420,"failed":0}
------------------------------
• [SLOW TEST] [91.763 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:36:31.332
    Aug 24 10:36:31.332: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:36:31.335
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:36:31.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:36:31.371
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4397 08/24/22 10:36:31.375
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 08/24/22 10:36:31.389
    Aug 24 10:36:31.489: INFO: Found 0 stateful pods, waiting for 3
    Aug 24 10:36:41.496: INFO: Found 1 stateful pods, waiting for 3
    Aug 24 10:36:51.502: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:36:51.502: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:36:51.502: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:36:51.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:36:51.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:36:51.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:36:51.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/24/22 10:37:01.86
    Aug 24 10:37:01.890: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/24/22 10:37:01.89
    STEP: Updating Pods in reverse ordinal order 08/24/22 10:37:11.935
    Aug 24 10:37:11.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:37:12.226: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:37:12.226: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:37:12.226: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 08/24/22 10:37:22.265
    Aug 24 10:37:22.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:37:22.564: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:37:22.564: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:37:22.564: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:37:32.634: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 08/24/22 10:37:42.675
    Aug 24 10:37:42.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-4397 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:37:42.953: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:37:42.953: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:37:42.953: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:37:52.998: INFO: Deleting all statefulset in ns statefulset-4397
    Aug 24 10:37:53.003: INFO: Scaling statefulset ss2 to 0
    Aug 24 10:38:03.035: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:38:03.041: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:38:03.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4397" for this suite. 08/24/22 10:38:03.082
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:03.095
Aug 24 10:38:03.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context-test 08/24/22 10:38:03.099
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:03.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:03.126
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Aug 24 10:38:03.144: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d" in namespace "security-context-test-4179" to be "Succeeded or Failed"
Aug 24 10:38:03.152: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.980742ms
Aug 24 10:38:05.163: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019083643s
Aug 24 10:38:07.160: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01599404s
Aug 24 10:38:09.171: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027011626s
Aug 24 10:38:09.171: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d" satisfied condition "Succeeded or Failed"
Aug 24 10:38:09.343: INFO: Got logs for pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:38:09.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4179" for this suite. 08/24/22 10:38:09.354
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":296,"skipped":5424,"failed":0}
------------------------------
• [SLOW TEST] [6.270 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:03.095
    Aug 24 10:38:03.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context-test 08/24/22 10:38:03.099
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:03.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:03.126
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Aug 24 10:38:03.144: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d" in namespace "security-context-test-4179" to be "Succeeded or Failed"
    Aug 24 10:38:03.152: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.980742ms
    Aug 24 10:38:05.163: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019083643s
    Aug 24 10:38:07.160: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01599404s
    Aug 24 10:38:09.171: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027011626s
    Aug 24 10:38:09.171: INFO: Pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d" satisfied condition "Succeeded or Failed"
    Aug 24 10:38:09.343: INFO: Got logs for pod "busybox-privileged-false-35f3dd31-6bd8-4fde-b4df-58497f04d47d": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:38:09.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4179" for this suite. 08/24/22 10:38:09.354
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:09.368
Aug 24 10:38:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:38:09.371
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:09.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:09.42
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-8a460910-8b4e-40d5-8bbc-1e0481072214 08/24/22 10:38:09.432
STEP: Creating a pod to test consume secrets 08/24/22 10:38:09.442
Aug 24 10:38:09.466: INFO: Waiting up to 5m0s for pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f" in namespace "secrets-8174" to be "Succeeded or Failed"
Aug 24 10:38:09.477: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.377651ms
Aug 24 10:38:11.486: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019890168s
Aug 24 10:38:13.485: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01909545s
Aug 24 10:38:15.483: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017278131s
STEP: Saw pod success 08/24/22 10:38:15.483
Aug 24 10:38:15.483: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f" satisfied condition "Succeeded or Failed"
Aug 24 10:38:15.492: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f container secret-env-test: <nil>
STEP: delete the pod 08/24/22 10:38:15.504
Aug 24 10:38:15.523: INFO: Waiting for pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f to disappear
Aug 24 10:38:15.530: INFO: Pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:38:15.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8174" for this suite. 08/24/22 10:38:15.536
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":297,"skipped":5435,"failed":0}
------------------------------
• [SLOW TEST] [6.182 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:09.368
    Aug 24 10:38:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:38:09.371
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:09.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:09.42
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-8a460910-8b4e-40d5-8bbc-1e0481072214 08/24/22 10:38:09.432
    STEP: Creating a pod to test consume secrets 08/24/22 10:38:09.442
    Aug 24 10:38:09.466: INFO: Waiting up to 5m0s for pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f" in namespace "secrets-8174" to be "Succeeded or Failed"
    Aug 24 10:38:09.477: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.377651ms
    Aug 24 10:38:11.486: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019890168s
    Aug 24 10:38:13.485: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01909545s
    Aug 24 10:38:15.483: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017278131s
    STEP: Saw pod success 08/24/22 10:38:15.483
    Aug 24 10:38:15.483: INFO: Pod "pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f" satisfied condition "Succeeded or Failed"
    Aug 24 10:38:15.492: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f container secret-env-test: <nil>
    STEP: delete the pod 08/24/22 10:38:15.504
    Aug 24 10:38:15.523: INFO: Waiting for pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f to disappear
    Aug 24 10:38:15.530: INFO: Pod pod-secrets-257f3c74-3ac9-441a-b936-64eade655f0f no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:38:15.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8174" for this suite. 08/24/22 10:38:15.536
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:15.556
Aug 24 10:38:15.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename daemonsets 08/24/22 10:38:15.558
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:15.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:15.591
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Aug 24 10:38:15.629: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 08/24/22 10:38:15.638
Aug 24 10:38:15.645: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:15.645: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 08/24/22 10:38:15.645
Aug 24 10:38:15.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:15.692: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:38:16.701: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:16.701: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:38:17.700: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 10:38:17.700: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 08/24/22 10:38:17.712
Aug 24 10:38:17.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 10:38:17.761: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Aug 24 10:38:18.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:18.769: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/24/22 10:38:18.769
Aug 24 10:38:18.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:18.788: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:38:19.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:19.796: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:38:20.801: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:20.801: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
Aug 24 10:38:21.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 10:38:21.796: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:38:21.806
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2669, will wait for the garbage collector to delete the pods 08/24/22 10:38:21.806
Aug 24 10:38:21.878: INFO: Deleting DaemonSet.extensions daemon-set took: 15.999765ms
Aug 24 10:38:21.979: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.181729ms
Aug 24 10:38:24.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 10:38:24.330: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 10:38:24.336: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29630"},"items":null}

Aug 24 10:38:24.341: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29630"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:38:24.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2669" for this suite. 08/24/22 10:38:24.423
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":298,"skipped":5465,"failed":0}
------------------------------
• [SLOW TEST] [8.882 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:15.556
    Aug 24 10:38:15.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename daemonsets 08/24/22 10:38:15.558
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:15.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:15.591
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Aug 24 10:38:15.629: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 08/24/22 10:38:15.638
    Aug 24 10:38:15.645: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:15.645: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 08/24/22 10:38:15.645
    Aug 24 10:38:15.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:15.692: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:38:16.701: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:16.701: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:38:17.700: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 24 10:38:17.700: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 08/24/22 10:38:17.712
    Aug 24 10:38:17.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 24 10:38:17.761: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Aug 24 10:38:18.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:18.769: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/24/22 10:38:18.769
    Aug 24 10:38:18.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:18.788: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:38:19.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:19.796: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:38:20.801: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:20.801: INFO: Node kah9uighaagh-2 is running 0 daemon pod, expected 1
    Aug 24 10:38:21.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 24 10:38:21.796: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/24/22 10:38:21.806
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2669, will wait for the garbage collector to delete the pods 08/24/22 10:38:21.806
    Aug 24 10:38:21.878: INFO: Deleting DaemonSet.extensions daemon-set took: 15.999765ms
    Aug 24 10:38:21.979: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.181729ms
    Aug 24 10:38:24.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 24 10:38:24.330: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 24 10:38:24.336: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29630"},"items":null}

    Aug 24 10:38:24.341: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29630"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:38:24.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2669" for this suite. 08/24/22 10:38:24.423
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:24.44
Aug 24 10:38:24.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename namespaces 08/24/22 10:38:24.442
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:24.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:24.477
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 08/24/22 10:38:24.48
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:24.502
STEP: Creating a service in the namespace 08/24/22 10:38:24.507
STEP: Deleting the namespace 08/24/22 10:38:24.529
STEP: Waiting for the namespace to be removed. 08/24/22 10:38:24.546
STEP: Recreating the namespace 08/24/22 10:38:30.557
STEP: Verifying there is no service in the namespace 08/24/22 10:38:30.597
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:38:30.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2060" for this suite. 08/24/22 10:38:30.619
STEP: Destroying namespace "nsdeletetest-4462" for this suite. 08/24/22 10:38:30.629
Aug 24 10:38:30.635: INFO: Namespace nsdeletetest-4462 was already deleted
STEP: Destroying namespace "nsdeletetest-2094" for this suite. 08/24/22 10:38:30.635
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":299,"skipped":5482,"failed":0}
------------------------------
• [SLOW TEST] [6.210 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:24.44
    Aug 24 10:38:24.440: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename namespaces 08/24/22 10:38:24.442
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:24.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:24.477
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 08/24/22 10:38:24.48
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:24.502
    STEP: Creating a service in the namespace 08/24/22 10:38:24.507
    STEP: Deleting the namespace 08/24/22 10:38:24.529
    STEP: Waiting for the namespace to be removed. 08/24/22 10:38:24.546
    STEP: Recreating the namespace 08/24/22 10:38:30.557
    STEP: Verifying there is no service in the namespace 08/24/22 10:38:30.597
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:38:30.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2060" for this suite. 08/24/22 10:38:30.619
    STEP: Destroying namespace "nsdeletetest-4462" for this suite. 08/24/22 10:38:30.629
    Aug 24 10:38:30.635: INFO: Namespace nsdeletetest-4462 was already deleted
    STEP: Destroying namespace "nsdeletetest-2094" for this suite. 08/24/22 10:38:30.635
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:30.651
Aug 24 10:38:30.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:38:30.656
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:30.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:30.708
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:38:30.714
Aug 24 10:38:30.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1" in namespace "projected-608" to be "Succeeded or Failed"
Aug 24 10:38:30.760: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.287281ms
Aug 24 10:38:32.780: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043976873s
Aug 24 10:38:34.770: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033613702s
STEP: Saw pod success 08/24/22 10:38:34.77
Aug 24 10:38:34.770: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1" satisfied condition "Succeeded or Failed"
Aug 24 10:38:34.776: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 container client-container: <nil>
STEP: delete the pod 08/24/22 10:38:34.792
Aug 24 10:38:34.817: INFO: Waiting for pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 to disappear
Aug 24 10:38:34.822: INFO: Pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 10:38:34.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-608" for this suite. 08/24/22 10:38:34.832
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":300,"skipped":5501,"failed":0}
------------------------------
• [4.190 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:30.651
    Aug 24 10:38:30.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:38:30.656
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:30.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:30.708
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:38:30.714
    Aug 24 10:38:30.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1" in namespace "projected-608" to be "Succeeded or Failed"
    Aug 24 10:38:30.760: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.287281ms
    Aug 24 10:38:32.780: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043976873s
    Aug 24 10:38:34.770: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033613702s
    STEP: Saw pod success 08/24/22 10:38:34.77
    Aug 24 10:38:34.770: INFO: Pod "downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1" satisfied condition "Succeeded or Failed"
    Aug 24 10:38:34.776: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:38:34.792
    Aug 24 10:38:34.817: INFO: Waiting for pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 to disappear
    Aug 24 10:38:34.822: INFO: Pod downwardapi-volume-55da4663-b3f7-4eca-a2a4-a7007bb344e1 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 10:38:34.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-608" for this suite. 08/24/22 10:38:34.832
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:34.842
Aug 24 10:38:34.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:38:34.848
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:34.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:34.877
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Aug 24 10:38:34.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:38:39.081
Aug 24 10:38:39.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 create -f -'
Aug 24 10:38:40.814: INFO: stderr: ""
Aug 24 10:38:40.814: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 24 10:38:40.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 delete e2e-test-crd-publish-openapi-6415-crds test-cr'
Aug 24 10:38:40.994: INFO: stderr: ""
Aug 24 10:38:40.994: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 24 10:38:40.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 apply -f -'
Aug 24 10:38:42.227: INFO: stderr: ""
Aug 24 10:38:42.227: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 24 10:38:42.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 delete e2e-test-crd-publish-openapi-6415-crds test-cr'
Aug 24 10:38:42.408: INFO: stderr: ""
Aug 24 10:38:42.408: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/24/22 10:38:42.408
Aug 24 10:38:42.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 explain e2e-test-crd-publish-openapi-6415-crds'
Aug 24 10:38:42.774: INFO: stderr: ""
Aug 24 10:38:42.774: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6415-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:38:46.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1827" for this suite. 08/24/22 10:38:46.137
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":301,"skipped":5501,"failed":0}
------------------------------
• [SLOW TEST] [11.304 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:34.842
    Aug 24 10:38:34.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:38:34.848
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:34.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:34.877
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Aug 24 10:38:34.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:38:39.081
    Aug 24 10:38:39.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 create -f -'
    Aug 24 10:38:40.814: INFO: stderr: ""
    Aug 24 10:38:40.814: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 24 10:38:40.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 delete e2e-test-crd-publish-openapi-6415-crds test-cr'
    Aug 24 10:38:40.994: INFO: stderr: ""
    Aug 24 10:38:40.994: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Aug 24 10:38:40.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 apply -f -'
    Aug 24 10:38:42.227: INFO: stderr: ""
    Aug 24 10:38:42.227: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 24 10:38:42.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 --namespace=crd-publish-openapi-1827 delete e2e-test-crd-publish-openapi-6415-crds test-cr'
    Aug 24 10:38:42.408: INFO: stderr: ""
    Aug 24 10:38:42.408: INFO: stdout: "e2e-test-crd-publish-openapi-6415-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/24/22 10:38:42.408
    Aug 24 10:38:42.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-1827 explain e2e-test-crd-publish-openapi-6415-crds'
    Aug 24 10:38:42.774: INFO: stderr: ""
    Aug 24 10:38:42.774: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6415-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:38:46.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1827" for this suite. 08/24/22 10:38:46.137
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:46.146
Aug 24 10:38:46.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:38:46.149
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:46.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:46.185
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:38:46.187
Aug 24 10:38:46.199: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29" in namespace "downward-api-1327" to be "Succeeded or Failed"
Aug 24 10:38:46.205: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450139ms
Aug 24 10:38:48.211: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01177103s
Aug 24 10:38:50.210: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011071195s
STEP: Saw pod success 08/24/22 10:38:50.21
Aug 24 10:38:50.211: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29" satisfied condition "Succeeded or Failed"
Aug 24 10:38:50.217: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 container client-container: <nil>
STEP: delete the pod 08/24/22 10:38:50.242
Aug 24 10:38:50.259: INFO: Waiting for pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 to disappear
Aug 24 10:38:50.265: INFO: Pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:38:50.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1327" for this suite. 08/24/22 10:38:50.273
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":302,"skipped":5501,"failed":0}
------------------------------
• [4.135 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:46.146
    Aug 24 10:38:46.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:38:46.149
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:46.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:46.185
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:38:46.187
    Aug 24 10:38:46.199: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29" in namespace "downward-api-1327" to be "Succeeded or Failed"
    Aug 24 10:38:46.205: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450139ms
    Aug 24 10:38:48.211: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01177103s
    Aug 24 10:38:50.210: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011071195s
    STEP: Saw pod success 08/24/22 10:38:50.21
    Aug 24 10:38:50.211: INFO: Pod "downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29" satisfied condition "Succeeded or Failed"
    Aug 24 10:38:50.217: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 container client-container: <nil>
    STEP: delete the pod 08/24/22 10:38:50.242
    Aug 24 10:38:50.259: INFO: Waiting for pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 to disappear
    Aug 24 10:38:50.265: INFO: Pod downwardapi-volume-54d1e983-80a0-45e5-82f3-142f0819aa29 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:38:50.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1327" for this suite. 08/24/22 10:38:50.273
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:50.283
Aug 24 10:38:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:38:50.286
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:50.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:50.318
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-2dc06b76-fd29-42c6-9e20-0a02407f5898 08/24/22 10:38:50.322
STEP: Creating a pod to test consume configMaps 08/24/22 10:38:50.332
Aug 24 10:38:50.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1" in namespace "projected-8578" to be "Succeeded or Failed"
Aug 24 10:38:50.350: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.850824ms
Aug 24 10:38:52.358: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013355714s
Aug 24 10:38:54.362: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01713984s
STEP: Saw pod success 08/24/22 10:38:54.362
Aug 24 10:38:54.363: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1" satisfied condition "Succeeded or Failed"
Aug 24 10:38:54.367: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:38:54.377
Aug 24 10:38:54.395: INFO: Waiting for pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 to disappear
Aug 24 10:38:54.401: INFO: Pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:38:54.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8578" for this suite. 08/24/22 10:38:54.409
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":303,"skipped":5517,"failed":0}
------------------------------
• [4.136 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:50.283
    Aug 24 10:38:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:38:50.286
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:50.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:50.318
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-2dc06b76-fd29-42c6-9e20-0a02407f5898 08/24/22 10:38:50.322
    STEP: Creating a pod to test consume configMaps 08/24/22 10:38:50.332
    Aug 24 10:38:50.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1" in namespace "projected-8578" to be "Succeeded or Failed"
    Aug 24 10:38:50.350: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.850824ms
    Aug 24 10:38:52.358: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013355714s
    Aug 24 10:38:54.362: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01713984s
    STEP: Saw pod success 08/24/22 10:38:54.362
    Aug 24 10:38:54.363: INFO: Pod "pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1" satisfied condition "Succeeded or Failed"
    Aug 24 10:38:54.367: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:38:54.377
    Aug 24 10:38:54.395: INFO: Waiting for pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 to disappear
    Aug 24 10:38:54.401: INFO: Pod pod-projected-configmaps-d9f6c817-d45f-446c-9da9-9450b7eb55d1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:38:54.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8578" for this suite. 08/24/22 10:38:54.409
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:38:54.438
Aug 24 10:38:54.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:38:54.441
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:54.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:54.475
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-4970 08/24/22 10:38:54.481
STEP: creating a selector 08/24/22 10:38:54.481
STEP: Creating the service pods in kubernetes 08/24/22 10:38:54.482
Aug 24 10:38:54.482: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 10:38:54.533: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4970" to be "running and ready"
Aug 24 10:38:54.541: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.702806ms
Aug 24 10:38:54.541: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:38:56.550: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017023766s
Aug 24 10:38:56.550: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:38:58.551: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018016375s
Aug 24 10:38:58.551: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:39:00.546: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01342129s
Aug 24 10:39:00.547: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:39:02.552: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019369107s
Aug 24 10:39:02.553: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:39:04.547: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014097149s
Aug 24 10:39:04.547: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:39:06.549: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.01613798s
Aug 24 10:39:06.549: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 24 10:39:06.549: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 24 10:39:06.557: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4970" to be "running and ready"
Aug 24 10:39:06.562: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.649487ms
Aug 24 10:39:06.562: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:39:08.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.012663743s
Aug 24 10:39:08.569: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:39:10.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.012134912s
Aug 24 10:39:10.569: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:39:12.571: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.014002923s
Aug 24 10:39:12.571: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:39:14.567: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.01073899s
Aug 24 10:39:14.568: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:39:16.572: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.015139878s
Aug 24 10:39:16.572: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 24 10:39:16.572: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 24 10:39:16.579: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4970" to be "running and ready"
Aug 24 10:39:16.586: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.900746ms
Aug 24 10:39:16.586: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Aug 24 10:39:18.594: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.014857891s
Aug 24 10:39:18.594: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Aug 24 10:39:20.595: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.015600618s
Aug 24 10:39:20.595: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 24 10:39:20.595: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/24/22 10:39:20.602
Aug 24 10:39:20.614: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4970" to be "running"
Aug 24 10:39:20.623: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.699697ms
Aug 24 10:39:22.632: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018507564s
Aug 24 10:39:22.633: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 24 10:39:22.647: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 10:39:22.648: INFO: Breadth first check of 10.233.64.121 on host 192.168.121.119...
Aug 24 10:39:22.652: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.64.121&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:39:22.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:39:22.654: INFO: ExecWithOptions: Clientset creation
Aug 24 10:39:22.655: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.121%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 10:39:22.815: INFO: Waiting for responses: map[]
Aug 24 10:39:22.815: INFO: reached 10.233.64.121 after 0/1 tries
Aug 24 10:39:22.815: INFO: Breadth first check of 10.233.65.140 on host 192.168.121.214...
Aug 24 10:39:22.821: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.65.140&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:39:22.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:39:22.823: INFO: ExecWithOptions: Clientset creation
Aug 24 10:39:22.824: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.140%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 10:39:23.243: INFO: Waiting for responses: map[]
Aug 24 10:39:23.243: INFO: reached 10.233.65.140 after 0/1 tries
Aug 24 10:39:23.243: INFO: Breadth first check of 10.233.66.117 on host 192.168.121.54...
Aug 24 10:39:23.249: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.66.117&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:39:23.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:39:23.251: INFO: ExecWithOptions: Clientset creation
Aug 24 10:39:23.251: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.117%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 24 10:39:23.487: INFO: Waiting for responses: map[]
Aug 24 10:39:23.487: INFO: reached 10.233.66.117 after 0/1 tries
Aug 24 10:39:23.487: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 24 10:39:23.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4970" for this suite. 08/24/22 10:39:23.496
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":304,"skipped":5551,"failed":0}
------------------------------
• [SLOW TEST] [29.069 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:38:54.438
    Aug 24 10:38:54.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:38:54.441
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:38:54.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:38:54.475
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-4970 08/24/22 10:38:54.481
    STEP: creating a selector 08/24/22 10:38:54.481
    STEP: Creating the service pods in kubernetes 08/24/22 10:38:54.482
    Aug 24 10:38:54.482: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 24 10:38:54.533: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4970" to be "running and ready"
    Aug 24 10:38:54.541: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.702806ms
    Aug 24 10:38:54.541: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:38:56.550: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017023766s
    Aug 24 10:38:56.550: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:38:58.551: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018016375s
    Aug 24 10:38:58.551: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:39:00.546: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01342129s
    Aug 24 10:39:00.547: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:39:02.552: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019369107s
    Aug 24 10:39:02.553: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:39:04.547: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014097149s
    Aug 24 10:39:04.547: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:39:06.549: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.01613798s
    Aug 24 10:39:06.549: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 24 10:39:06.549: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 24 10:39:06.557: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4970" to be "running and ready"
    Aug 24 10:39:06.562: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.649487ms
    Aug 24 10:39:06.562: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:39:08.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.012663743s
    Aug 24 10:39:08.569: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:39:10.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.012134912s
    Aug 24 10:39:10.569: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:39:12.571: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.014002923s
    Aug 24 10:39:12.571: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:39:14.567: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.01073899s
    Aug 24 10:39:14.568: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:39:16.572: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.015139878s
    Aug 24 10:39:16.572: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 24 10:39:16.572: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 24 10:39:16.579: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4970" to be "running and ready"
    Aug 24 10:39:16.586: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.900746ms
    Aug 24 10:39:16.586: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Aug 24 10:39:18.594: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.014857891s
    Aug 24 10:39:18.594: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Aug 24 10:39:20.595: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.015600618s
    Aug 24 10:39:20.595: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 24 10:39:20.595: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/24/22 10:39:20.602
    Aug 24 10:39:20.614: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4970" to be "running"
    Aug 24 10:39:20.623: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.699697ms
    Aug 24 10:39:22.632: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018507564s
    Aug 24 10:39:22.633: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 24 10:39:22.647: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 24 10:39:22.648: INFO: Breadth first check of 10.233.64.121 on host 192.168.121.119...
    Aug 24 10:39:22.652: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.64.121&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:39:22.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:39:22.654: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:39:22.655: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.121%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 10:39:22.815: INFO: Waiting for responses: map[]
    Aug 24 10:39:22.815: INFO: reached 10.233.64.121 after 0/1 tries
    Aug 24 10:39:22.815: INFO: Breadth first check of 10.233.65.140 on host 192.168.121.214...
    Aug 24 10:39:22.821: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.65.140&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:39:22.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:39:22.823: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:39:22.824: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.140%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 10:39:23.243: INFO: Waiting for responses: map[]
    Aug 24 10:39:23.243: INFO: reached 10.233.65.140 after 0/1 tries
    Aug 24 10:39:23.243: INFO: Breadth first check of 10.233.66.117 on host 192.168.121.54...
    Aug 24 10:39:23.249: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.118:9080/dial?request=hostname&protocol=http&host=10.233.66.117&port=8083&tries=1'] Namespace:pod-network-test-4970 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:39:23.249: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:39:23.251: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:39:23.251: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4970/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.118%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.117%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 24 10:39:23.487: INFO: Waiting for responses: map[]
    Aug 24 10:39:23.487: INFO: reached 10.233.66.117 after 0/1 tries
    Aug 24 10:39:23.487: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 24 10:39:23.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4970" for this suite. 08/24/22 10:39:23.496
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:39:23.517
Aug 24 10:39:23.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename endpointslicemirroring 08/24/22 10:39:23.521
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:23.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:23.559
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 08/24/22 10:39:23.586
Aug 24 10:39:23.596: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 08/24/22 10:39:25.604
Aug 24 10:39:25.621: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 08/24/22 10:39:27.631
Aug 24 10:39:27.663: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Aug 24 10:39:29.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-9353" for this suite. 08/24/22 10:39:29.685
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":305,"skipped":5580,"failed":0}
------------------------------
• [SLOW TEST] [6.184 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:39:23.517
    Aug 24 10:39:23.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename endpointslicemirroring 08/24/22 10:39:23.521
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:23.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:23.559
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 08/24/22 10:39:23.586
    Aug 24 10:39:23.596: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 08/24/22 10:39:25.604
    Aug 24 10:39:25.621: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 08/24/22 10:39:27.631
    Aug 24 10:39:27.663: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Aug 24 10:39:29.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-9353" for this suite. 08/24/22 10:39:29.685
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:39:29.704
Aug 24 10:39:29.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:39:29.718
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:29.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:29.764
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/24/22 10:39:29.769
Aug 24 10:39:29.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:39:35.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:39:52.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-189" for this suite. 08/24/22 10:39:52.295
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":306,"skipped":5588,"failed":0}
------------------------------
• [SLOW TEST] [22.619 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:39:29.704
    Aug 24 10:39:29.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:39:29.718
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:29.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:29.764
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/24/22 10:39:29.769
    Aug 24 10:39:29.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:39:35.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:39:52.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-189" for this suite. 08/24/22 10:39:52.295
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:39:52.329
Aug 24 10:39:52.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-webhook 08/24/22 10:39:52.334
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:52.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:52.393
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/24/22 10:39:52.399
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/24/22 10:39:53.559
STEP: Deploying the custom resource conversion webhook pod 08/24/22 10:39:53.572
STEP: Wait for the deployment to be ready 08/24/22 10:39:53.593
Aug 24 10:39:53.607: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Aug 24 10:39:55.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:39:57.638
STEP: Verifying the service has paired with the endpoint 08/24/22 10:39:57.661
Aug 24 10:39:58.662: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Aug 24 10:39:58.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Creating a v1 custom resource 08/24/22 10:40:01.511
STEP: v2 custom resource should be converted 08/24/22 10:40:01.52
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:40:02.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7514" for this suite. 08/24/22 10:40:02.104
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":307,"skipped":5595,"failed":0}
------------------------------
• [SLOW TEST] [9.852 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:39:52.329
    Aug 24 10:39:52.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-webhook 08/24/22 10:39:52.334
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:39:52.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:39:52.393
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/24/22 10:39:52.399
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/24/22 10:39:53.559
    STEP: Deploying the custom resource conversion webhook pod 08/24/22 10:39:53.572
    STEP: Wait for the deployment to be ready 08/24/22 10:39:53.593
    Aug 24 10:39:53.607: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    Aug 24 10:39:55.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 39, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:39:57.638
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:39:57.661
    Aug 24 10:39:58.662: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Aug 24 10:39:58.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Creating a v1 custom resource 08/24/22 10:40:01.511
    STEP: v2 custom resource should be converted 08/24/22 10:40:01.52
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:40:02.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7514" for this suite. 08/24/22 10:40:02.104
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:40:02.184
Aug 24 10:40:02.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:40:02.189
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:02.249
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:02.253
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:40:02.258
Aug 24 10:40:02.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc" in namespace "projected-1833" to be "Succeeded or Failed"
Aug 24 10:40:02.283: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.974588ms
Aug 24 10:40:04.292: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017111142s
Aug 24 10:40:06.291: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015847053s
STEP: Saw pod success 08/24/22 10:40:06.291
Aug 24 10:40:06.291: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc" satisfied condition "Succeeded or Failed"
Aug 24 10:40:06.296: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc container client-container: <nil>
STEP: delete the pod 08/24/22 10:40:06.309
Aug 24 10:40:06.328: INFO: Waiting for pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc to disappear
Aug 24 10:40:06.332: INFO: Pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 10:40:06.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1833" for this suite. 08/24/22 10:40:06.338
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":308,"skipped":5603,"failed":0}
------------------------------
• [4.165 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:40:02.184
    Aug 24 10:40:02.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:40:02.189
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:02.249
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:02.253
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:40:02.258
    Aug 24 10:40:02.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc" in namespace "projected-1833" to be "Succeeded or Failed"
    Aug 24 10:40:02.283: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.974588ms
    Aug 24 10:40:04.292: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017111142s
    Aug 24 10:40:06.291: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015847053s
    STEP: Saw pod success 08/24/22 10:40:06.291
    Aug 24 10:40:06.291: INFO: Pod "downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc" satisfied condition "Succeeded or Failed"
    Aug 24 10:40:06.296: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc container client-container: <nil>
    STEP: delete the pod 08/24/22 10:40:06.309
    Aug 24 10:40:06.328: INFO: Waiting for pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc to disappear
    Aug 24 10:40:06.332: INFO: Pod downwardapi-volume-0da45a9e-d5c1-4dbf-a088-1e8697bc71bc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 10:40:06.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1833" for this suite. 08/24/22 10:40:06.338
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:40:06.353
Aug 24 10:40:06.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:40:06.354
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:06.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:06.422
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-4841/configmap-test-afc9972f-1554-4c9b-b53b-8c46ae3a0d7f 08/24/22 10:40:06.426
STEP: Creating a pod to test consume configMaps 08/24/22 10:40:06.433
Aug 24 10:40:06.444: INFO: Waiting up to 5m0s for pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835" in namespace "configmap-4841" to be "Succeeded or Failed"
Aug 24 10:40:06.451: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Pending", Reason="", readiness=false. Elapsed: 6.081467ms
Aug 24 10:40:08.460: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015267576s
Aug 24 10:40:10.458: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013161205s
STEP: Saw pod success 08/24/22 10:40:10.458
Aug 24 10:40:10.458: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835" satisfied condition "Succeeded or Failed"
Aug 24 10:40:10.465: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 container env-test: <nil>
STEP: delete the pod 08/24/22 10:40:10.474
Aug 24 10:40:10.490: INFO: Waiting for pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 to disappear
Aug 24 10:40:10.496: INFO: Pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:40:10.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4841" for this suite. 08/24/22 10:40:10.502
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":309,"skipped":5627,"failed":0}
------------------------------
• [4.158 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:40:06.353
    Aug 24 10:40:06.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:40:06.354
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:06.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:06.422
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-4841/configmap-test-afc9972f-1554-4c9b-b53b-8c46ae3a0d7f 08/24/22 10:40:06.426
    STEP: Creating a pod to test consume configMaps 08/24/22 10:40:06.433
    Aug 24 10:40:06.444: INFO: Waiting up to 5m0s for pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835" in namespace "configmap-4841" to be "Succeeded or Failed"
    Aug 24 10:40:06.451: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Pending", Reason="", readiness=false. Elapsed: 6.081467ms
    Aug 24 10:40:08.460: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015267576s
    Aug 24 10:40:10.458: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013161205s
    STEP: Saw pod success 08/24/22 10:40:10.458
    Aug 24 10:40:10.458: INFO: Pod "pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835" satisfied condition "Succeeded or Failed"
    Aug 24 10:40:10.465: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 container env-test: <nil>
    STEP: delete the pod 08/24/22 10:40:10.474
    Aug 24 10:40:10.490: INFO: Waiting for pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 to disappear
    Aug 24 10:40:10.496: INFO: Pod pod-configmaps-20bdb08a-08be-452e-ad5f-07305ed84835 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:40:10.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4841" for this suite. 08/24/22 10:40:10.502
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:40:10.519
Aug 24 10:40:10.519: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:40:10.522
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:10.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:10.553
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-b109d6dc-2411-4425-baac-dd5faa002d00 08/24/22 10:40:10.557
STEP: Creating a pod to test consume configMaps 08/24/22 10:40:10.565
Aug 24 10:40:10.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb" in namespace "configmap-5857" to be "Succeeded or Failed"
Aug 24 10:40:10.583: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.144762ms
Aug 24 10:40:12.592: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013204667s
Aug 24 10:40:14.592: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013887444s
STEP: Saw pod success 08/24/22 10:40:14.592
Aug 24 10:40:14.593: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb" satisfied condition "Succeeded or Failed"
Aug 24 10:40:14.599: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:40:14.61
Aug 24 10:40:14.633: INFO: Waiting for pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb to disappear
Aug 24 10:40:14.637: INFO: Pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:40:14.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5857" for this suite. 08/24/22 10:40:14.652
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":310,"skipped":5649,"failed":0}
------------------------------
• [4.167 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:40:10.519
    Aug 24 10:40:10.519: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:40:10.522
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:10.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:10.553
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-b109d6dc-2411-4425-baac-dd5faa002d00 08/24/22 10:40:10.557
    STEP: Creating a pod to test consume configMaps 08/24/22 10:40:10.565
    Aug 24 10:40:10.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb" in namespace "configmap-5857" to be "Succeeded or Failed"
    Aug 24 10:40:10.583: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.144762ms
    Aug 24 10:40:12.592: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013204667s
    Aug 24 10:40:14.592: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013887444s
    STEP: Saw pod success 08/24/22 10:40:14.592
    Aug 24 10:40:14.593: INFO: Pod "pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb" satisfied condition "Succeeded or Failed"
    Aug 24 10:40:14.599: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:40:14.61
    Aug 24 10:40:14.633: INFO: Waiting for pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb to disappear
    Aug 24 10:40:14.637: INFO: Pod pod-configmaps-c0e2997c-2150-4cb6-8184-2cc885d126eb no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:40:14.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5857" for this suite. 08/24/22 10:40:14.652
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:40:14.687
Aug 24 10:40:14.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename certificates 08/24/22 10:40:14.689
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:14.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:14.722
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 08/24/22 10:40:17.35
STEP: getting /apis/certificates.k8s.io 08/24/22 10:40:17.355
STEP: getting /apis/certificates.k8s.io/v1 08/24/22 10:40:17.356
STEP: creating 08/24/22 10:40:17.358
STEP: getting 08/24/22 10:40:17.379
STEP: listing 08/24/22 10:40:17.388
STEP: watching 08/24/22 10:40:17.401
Aug 24 10:40:17.401: INFO: starting watch
STEP: patching 08/24/22 10:40:17.402
STEP: updating 08/24/22 10:40:17.411
Aug 24 10:40:17.422: INFO: waiting for watch events with expected annotations
Aug 24 10:40:17.422: INFO: saw patched and updated annotations
STEP: getting /approval 08/24/22 10:40:17.422
STEP: patching /approval 08/24/22 10:40:17.429
STEP: updating /approval 08/24/22 10:40:17.437
STEP: getting /status 08/24/22 10:40:17.445
STEP: patching /status 08/24/22 10:40:17.45
STEP: updating /status 08/24/22 10:40:17.464
STEP: deleting 08/24/22 10:40:17.474
STEP: deleting a collection 08/24/22 10:40:17.489
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:40:17.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-1423" for this suite. 08/24/22 10:40:17.519
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":311,"skipped":5652,"failed":0}
------------------------------
• [2.841 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:40:14.687
    Aug 24 10:40:14.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename certificates 08/24/22 10:40:14.689
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:14.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:14.722
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 08/24/22 10:40:17.35
    STEP: getting /apis/certificates.k8s.io 08/24/22 10:40:17.355
    STEP: getting /apis/certificates.k8s.io/v1 08/24/22 10:40:17.356
    STEP: creating 08/24/22 10:40:17.358
    STEP: getting 08/24/22 10:40:17.379
    STEP: listing 08/24/22 10:40:17.388
    STEP: watching 08/24/22 10:40:17.401
    Aug 24 10:40:17.401: INFO: starting watch
    STEP: patching 08/24/22 10:40:17.402
    STEP: updating 08/24/22 10:40:17.411
    Aug 24 10:40:17.422: INFO: waiting for watch events with expected annotations
    Aug 24 10:40:17.422: INFO: saw patched and updated annotations
    STEP: getting /approval 08/24/22 10:40:17.422
    STEP: patching /approval 08/24/22 10:40:17.429
    STEP: updating /approval 08/24/22 10:40:17.437
    STEP: getting /status 08/24/22 10:40:17.445
    STEP: patching /status 08/24/22 10:40:17.45
    STEP: updating /status 08/24/22 10:40:17.464
    STEP: deleting 08/24/22 10:40:17.474
    STEP: deleting a collection 08/24/22 10:40:17.489
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:40:17.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-1423" for this suite. 08/24/22 10:40:17.519
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:40:17.531
Aug 24 10:40:17.531: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:40:17.533
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:17.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:17.559
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 08/24/22 10:40:17.563
Aug 24 10:40:17.582: INFO: Waiting up to 2m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876" to be "running"
Aug 24 10:40:17.590: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.89131ms
Aug 24 10:40:19.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01871593s
Aug 24 10:40:21.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013860818s
Aug 24 10:40:23.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015327467s
Aug 24 10:40:25.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01495411s
Aug 24 10:40:27.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014277424s
Aug 24 10:40:29.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016758325s
Aug 24 10:40:31.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017258047s
Aug 24 10:40:33.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016076443s
Aug 24 10:40:35.607: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024978594s
Aug 24 10:40:37.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015802973s
Aug 24 10:40:39.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015363526s
Aug 24 10:40:41.606: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023406827s
Aug 24 10:40:43.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018649278s
Aug 24 10:40:45.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014828846s
Aug 24 10:40:47.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015466164s
Aug 24 10:40:49.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016385814s
Aug 24 10:40:51.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014103589s
Aug 24 10:40:53.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015743s
Aug 24 10:40:55.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015969636s
Aug 24 10:40:57.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.014768153s
Aug 24 10:40:59.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.016832842s
Aug 24 10:41:01.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014964303s
Aug 24 10:41:03.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014608092s
Aug 24 10:41:05.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.015740059s
Aug 24 10:41:07.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014530334s
Aug 24 10:41:09.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01550685s
Aug 24 10:41:11.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015537157s
Aug 24 10:41:13.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01742607s
Aug 24 10:41:15.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017879746s
Aug 24 10:41:17.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015531228s
Aug 24 10:41:19.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015644566s
Aug 24 10:41:21.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.016811896s
Aug 24 10:41:23.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013818182s
Aug 24 10:41:25.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.016529658s
Aug 24 10:41:27.622: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.039906348s
Aug 24 10:41:29.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.016877078s
Aug 24 10:41:31.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014438814s
Aug 24 10:41:33.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.015833112s
Aug 24 10:41:35.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.017330475s
Aug 24 10:41:37.613: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.0304199s
Aug 24 10:41:39.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.018067576s
Aug 24 10:41:41.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.015660982s
Aug 24 10:41:43.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.016242595s
Aug 24 10:41:45.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.016027983s
Aug 24 10:41:47.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.018908166s
Aug 24 10:41:49.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.01646045s
Aug 24 10:41:51.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.015757734s
Aug 24 10:41:53.616: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.033757206s
Aug 24 10:41:55.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015944531s
Aug 24 10:41:57.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015499166s
Aug 24 10:41:59.602: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019442454s
Aug 24 10:42:01.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013932986s
Aug 24 10:42:03.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.0161223s
Aug 24 10:42:05.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.016436947s
Aug 24 10:42:07.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.015555829s
Aug 24 10:42:09.604: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.021234155s
Aug 24 10:42:11.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017763644s
Aug 24 10:42:13.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.018313476s
Aug 24 10:42:15.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014609124s
Aug 24 10:42:17.602: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019905756s
Aug 24 10:42:17.609: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.026660895s
STEP: updating the pod 08/24/22 10:42:17.609
Aug 24 10:42:18.130: INFO: Successfully updated pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b"
STEP: waiting for pod running 08/24/22 10:42:18.13
Aug 24 10:42:18.130: INFO: Waiting up to 2m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876" to be "running"
Aug 24 10:42:18.139: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.365904ms
Aug 24 10:42:20.146: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Running", Reason="", readiness=true. Elapsed: 2.015980548s
Aug 24 10:42:20.147: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" satisfied condition "running"
STEP: deleting the pod gracefully 08/24/22 10:42:20.147
Aug 24 10:42:20.147: INFO: Deleting pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876"
Aug 24 10:42:20.157: INFO: Wait up to 5m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:42:52.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-876" for this suite. 08/24/22 10:42:52.18
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":312,"skipped":5663,"failed":0}
------------------------------
• [SLOW TEST] [154.659 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:40:17.531
    Aug 24 10:40:17.531: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:40:17.533
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:40:17.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:40:17.559
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 08/24/22 10:40:17.563
    Aug 24 10:40:17.582: INFO: Waiting up to 2m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876" to be "running"
    Aug 24 10:40:17.590: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.89131ms
    Aug 24 10:40:19.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01871593s
    Aug 24 10:40:21.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013860818s
    Aug 24 10:40:23.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015327467s
    Aug 24 10:40:25.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01495411s
    Aug 24 10:40:27.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014277424s
    Aug 24 10:40:29.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016758325s
    Aug 24 10:40:31.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017258047s
    Aug 24 10:40:33.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016076443s
    Aug 24 10:40:35.607: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024978594s
    Aug 24 10:40:37.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015802973s
    Aug 24 10:40:39.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015363526s
    Aug 24 10:40:41.606: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023406827s
    Aug 24 10:40:43.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018649278s
    Aug 24 10:40:45.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014828846s
    Aug 24 10:40:47.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015466164s
    Aug 24 10:40:49.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016385814s
    Aug 24 10:40:51.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014103589s
    Aug 24 10:40:53.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015743s
    Aug 24 10:40:55.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015969636s
    Aug 24 10:40:57.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.014768153s
    Aug 24 10:40:59.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.016832842s
    Aug 24 10:41:01.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014964303s
    Aug 24 10:41:03.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014608092s
    Aug 24 10:41:05.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.015740059s
    Aug 24 10:41:07.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014530334s
    Aug 24 10:41:09.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01550685s
    Aug 24 10:41:11.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015537157s
    Aug 24 10:41:13.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01742607s
    Aug 24 10:41:15.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017879746s
    Aug 24 10:41:17.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015531228s
    Aug 24 10:41:19.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015644566s
    Aug 24 10:41:21.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.016811896s
    Aug 24 10:41:23.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013818182s
    Aug 24 10:41:25.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.016529658s
    Aug 24 10:41:27.622: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.039906348s
    Aug 24 10:41:29.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.016877078s
    Aug 24 10:41:31.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014438814s
    Aug 24 10:41:33.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.015833112s
    Aug 24 10:41:35.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.017330475s
    Aug 24 10:41:37.613: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.0304199s
    Aug 24 10:41:39.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.018067576s
    Aug 24 10:41:41.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.015660982s
    Aug 24 10:41:43.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.016242595s
    Aug 24 10:41:45.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.016027983s
    Aug 24 10:41:47.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.018908166s
    Aug 24 10:41:49.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.01646045s
    Aug 24 10:41:51.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.015757734s
    Aug 24 10:41:53.616: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.033757206s
    Aug 24 10:41:55.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.015944531s
    Aug 24 10:41:57.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015499166s
    Aug 24 10:41:59.602: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019442454s
    Aug 24 10:42:01.596: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013932986s
    Aug 24 10:42:03.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.0161223s
    Aug 24 10:42:05.599: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.016436947s
    Aug 24 10:42:07.598: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.015555829s
    Aug 24 10:42:09.604: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.021234155s
    Aug 24 10:42:11.600: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017763644s
    Aug 24 10:42:13.601: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.018313476s
    Aug 24 10:42:15.597: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014609124s
    Aug 24 10:42:17.602: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019905756s
    Aug 24 10:42:17.609: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.026660895s
    STEP: updating the pod 08/24/22 10:42:17.609
    Aug 24 10:42:18.130: INFO: Successfully updated pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b"
    STEP: waiting for pod running 08/24/22 10:42:18.13
    Aug 24 10:42:18.130: INFO: Waiting up to 2m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876" to be "running"
    Aug 24 10:42:18.139: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.365904ms
    Aug 24 10:42:20.146: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b": Phase="Running", Reason="", readiness=true. Elapsed: 2.015980548s
    Aug 24 10:42:20.147: INFO: Pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" satisfied condition "running"
    STEP: deleting the pod gracefully 08/24/22 10:42:20.147
    Aug 24 10:42:20.147: INFO: Deleting pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" in namespace "var-expansion-876"
    Aug 24 10:42:20.157: INFO: Wait up to 5m0s for pod "var-expansion-facd9d14-3972-49a6-b740-3dd9dae1d52b" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:42:52.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-876" for this suite. 08/24/22 10:42:52.18
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:42:52.194
Aug 24 10:42:52.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename discovery 08/24/22 10:42:52.199
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:52.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:52.237
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 08/24/22 10:42:52.244
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Aug 24 10:42:53.354: INFO: Checking APIGroup: apiregistration.k8s.io
Aug 24 10:42:53.356: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug 24 10:42:53.356: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Aug 24 10:42:53.356: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug 24 10:42:53.356: INFO: Checking APIGroup: apps
Aug 24 10:42:53.361: INFO: PreferredVersion.GroupVersion: apps/v1
Aug 24 10:42:53.361: INFO: Versions found [{apps/v1 v1}]
Aug 24 10:42:53.361: INFO: apps/v1 matches apps/v1
Aug 24 10:42:53.361: INFO: Checking APIGroup: events.k8s.io
Aug 24 10:42:53.362: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug 24 10:42:53.362: INFO: Versions found [{events.k8s.io/v1 v1}]
Aug 24 10:42:53.362: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug 24 10:42:53.362: INFO: Checking APIGroup: authentication.k8s.io
Aug 24 10:42:53.363: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug 24 10:42:53.363: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Aug 24 10:42:53.363: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug 24 10:42:53.363: INFO: Checking APIGroup: authorization.k8s.io
Aug 24 10:42:53.364: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug 24 10:42:53.364: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Aug 24 10:42:53.364: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug 24 10:42:53.364: INFO: Checking APIGroup: autoscaling
Aug 24 10:42:53.365: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Aug 24 10:42:53.365: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Aug 24 10:42:53.365: INFO: autoscaling/v2 matches autoscaling/v2
Aug 24 10:42:53.365: INFO: Checking APIGroup: batch
Aug 24 10:42:53.366: INFO: PreferredVersion.GroupVersion: batch/v1
Aug 24 10:42:53.366: INFO: Versions found [{batch/v1 v1}]
Aug 24 10:42:53.366: INFO: batch/v1 matches batch/v1
Aug 24 10:42:53.366: INFO: Checking APIGroup: certificates.k8s.io
Aug 24 10:42:53.368: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug 24 10:42:53.368: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Aug 24 10:42:53.368: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug 24 10:42:53.368: INFO: Checking APIGroup: networking.k8s.io
Aug 24 10:42:53.369: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug 24 10:42:53.369: INFO: Versions found [{networking.k8s.io/v1 v1}]
Aug 24 10:42:53.369: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug 24 10:42:53.369: INFO: Checking APIGroup: policy
Aug 24 10:42:53.371: INFO: PreferredVersion.GroupVersion: policy/v1
Aug 24 10:42:53.371: INFO: Versions found [{policy/v1 v1}]
Aug 24 10:42:53.371: INFO: policy/v1 matches policy/v1
Aug 24 10:42:53.371: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug 24 10:42:53.371: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug 24 10:42:53.371: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Aug 24 10:42:53.371: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug 24 10:42:53.371: INFO: Checking APIGroup: storage.k8s.io
Aug 24 10:42:53.373: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug 24 10:42:53.373: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug 24 10:42:53.373: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug 24 10:42:53.373: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug 24 10:42:53.374: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug 24 10:42:53.374: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Aug 24 10:42:53.374: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug 24 10:42:53.374: INFO: Checking APIGroup: apiextensions.k8s.io
Aug 24 10:42:53.376: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug 24 10:42:53.376: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Aug 24 10:42:53.376: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug 24 10:42:53.376: INFO: Checking APIGroup: scheduling.k8s.io
Aug 24 10:42:53.377: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug 24 10:42:53.377: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Aug 24 10:42:53.377: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug 24 10:42:53.377: INFO: Checking APIGroup: coordination.k8s.io
Aug 24 10:42:53.378: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug 24 10:42:53.378: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Aug 24 10:42:53.378: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug 24 10:42:53.378: INFO: Checking APIGroup: node.k8s.io
Aug 24 10:42:53.380: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Aug 24 10:42:53.380: INFO: Versions found [{node.k8s.io/v1 v1}]
Aug 24 10:42:53.380: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Aug 24 10:42:53.380: INFO: Checking APIGroup: discovery.k8s.io
Aug 24 10:42:53.381: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Aug 24 10:42:53.381: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Aug 24 10:42:53.381: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Aug 24 10:42:53.381: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Aug 24 10:42:53.383: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Aug 24 10:42:53.383: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Aug 24 10:42:53.383: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Aug 24 10:42:53.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-5511" for this suite. 08/24/22 10:42:53.401
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":313,"skipped":5687,"failed":0}
------------------------------
• [1.240 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:42:52.194
    Aug 24 10:42:52.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename discovery 08/24/22 10:42:52.199
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:52.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:52.237
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 08/24/22 10:42:52.244
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Aug 24 10:42:53.354: INFO: Checking APIGroup: apiregistration.k8s.io
    Aug 24 10:42:53.356: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Aug 24 10:42:53.356: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Aug 24 10:42:53.356: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Aug 24 10:42:53.356: INFO: Checking APIGroup: apps
    Aug 24 10:42:53.361: INFO: PreferredVersion.GroupVersion: apps/v1
    Aug 24 10:42:53.361: INFO: Versions found [{apps/v1 v1}]
    Aug 24 10:42:53.361: INFO: apps/v1 matches apps/v1
    Aug 24 10:42:53.361: INFO: Checking APIGroup: events.k8s.io
    Aug 24 10:42:53.362: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Aug 24 10:42:53.362: INFO: Versions found [{events.k8s.io/v1 v1}]
    Aug 24 10:42:53.362: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Aug 24 10:42:53.362: INFO: Checking APIGroup: authentication.k8s.io
    Aug 24 10:42:53.363: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Aug 24 10:42:53.363: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Aug 24 10:42:53.363: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Aug 24 10:42:53.363: INFO: Checking APIGroup: authorization.k8s.io
    Aug 24 10:42:53.364: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Aug 24 10:42:53.364: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Aug 24 10:42:53.364: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Aug 24 10:42:53.364: INFO: Checking APIGroup: autoscaling
    Aug 24 10:42:53.365: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Aug 24 10:42:53.365: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Aug 24 10:42:53.365: INFO: autoscaling/v2 matches autoscaling/v2
    Aug 24 10:42:53.365: INFO: Checking APIGroup: batch
    Aug 24 10:42:53.366: INFO: PreferredVersion.GroupVersion: batch/v1
    Aug 24 10:42:53.366: INFO: Versions found [{batch/v1 v1}]
    Aug 24 10:42:53.366: INFO: batch/v1 matches batch/v1
    Aug 24 10:42:53.366: INFO: Checking APIGroup: certificates.k8s.io
    Aug 24 10:42:53.368: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Aug 24 10:42:53.368: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Aug 24 10:42:53.368: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Aug 24 10:42:53.368: INFO: Checking APIGroup: networking.k8s.io
    Aug 24 10:42:53.369: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Aug 24 10:42:53.369: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Aug 24 10:42:53.369: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Aug 24 10:42:53.369: INFO: Checking APIGroup: policy
    Aug 24 10:42:53.371: INFO: PreferredVersion.GroupVersion: policy/v1
    Aug 24 10:42:53.371: INFO: Versions found [{policy/v1 v1}]
    Aug 24 10:42:53.371: INFO: policy/v1 matches policy/v1
    Aug 24 10:42:53.371: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Aug 24 10:42:53.371: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Aug 24 10:42:53.371: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Aug 24 10:42:53.371: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Aug 24 10:42:53.371: INFO: Checking APIGroup: storage.k8s.io
    Aug 24 10:42:53.373: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Aug 24 10:42:53.373: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Aug 24 10:42:53.373: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Aug 24 10:42:53.373: INFO: Checking APIGroup: admissionregistration.k8s.io
    Aug 24 10:42:53.374: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Aug 24 10:42:53.374: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Aug 24 10:42:53.374: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Aug 24 10:42:53.374: INFO: Checking APIGroup: apiextensions.k8s.io
    Aug 24 10:42:53.376: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Aug 24 10:42:53.376: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Aug 24 10:42:53.376: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Aug 24 10:42:53.376: INFO: Checking APIGroup: scheduling.k8s.io
    Aug 24 10:42:53.377: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Aug 24 10:42:53.377: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Aug 24 10:42:53.377: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Aug 24 10:42:53.377: INFO: Checking APIGroup: coordination.k8s.io
    Aug 24 10:42:53.378: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Aug 24 10:42:53.378: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Aug 24 10:42:53.378: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Aug 24 10:42:53.378: INFO: Checking APIGroup: node.k8s.io
    Aug 24 10:42:53.380: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Aug 24 10:42:53.380: INFO: Versions found [{node.k8s.io/v1 v1}]
    Aug 24 10:42:53.380: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Aug 24 10:42:53.380: INFO: Checking APIGroup: discovery.k8s.io
    Aug 24 10:42:53.381: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Aug 24 10:42:53.381: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Aug 24 10:42:53.381: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Aug 24 10:42:53.381: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Aug 24 10:42:53.383: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Aug 24 10:42:53.383: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Aug 24 10:42:53.383: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Aug 24 10:42:53.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-5511" for this suite. 08/24/22 10:42:53.401
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:42:53.437
Aug 24 10:42:53.437: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 10:42:53.439
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:53.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:53.475
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/24/22 10:42:53.478
Aug 24 10:42:53.490: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7453" to be "running and ready"
Aug 24 10:42:53.495: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 4.996651ms
Aug 24 10:42:53.495: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:42:55.500: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009977835s
Aug 24 10:42:55.500: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:42:57.501: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.011551763s
Aug 24 10:42:57.501: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Aug 24 10:42:57.501: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 08/24/22 10:42:57.507
STEP: Then the orphan pod is adopted 08/24/22 10:42:57.52
STEP: When the matched label of one of its pods change 08/24/22 10:42:58.532
Aug 24 10:42:58.540: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 08/24/22 10:42:58.559
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 10:42:59.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7453" for this suite. 08/24/22 10:42:59.589
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":314,"skipped":5697,"failed":0}
------------------------------
• [SLOW TEST] [6.169 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:42:53.437
    Aug 24 10:42:53.437: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 10:42:53.439
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:53.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:53.475
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/24/22 10:42:53.478
    Aug 24 10:42:53.490: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7453" to be "running and ready"
    Aug 24 10:42:53.495: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 4.996651ms
    Aug 24 10:42:53.495: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:42:55.500: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009977835s
    Aug 24 10:42:55.500: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:42:57.501: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.011551763s
    Aug 24 10:42:57.501: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Aug 24 10:42:57.501: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 08/24/22 10:42:57.507
    STEP: Then the orphan pod is adopted 08/24/22 10:42:57.52
    STEP: When the matched label of one of its pods change 08/24/22 10:42:58.532
    Aug 24 10:42:58.540: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/24/22 10:42:58.559
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 10:42:59.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7453" for this suite. 08/24/22 10:42:59.589
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:42:59.615
Aug 24 10:42:59.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:42:59.619
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:59.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:59.678
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6039 08/24/22 10:42:59.681
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-6039 08/24/22 10:42:59.705
Aug 24 10:42:59.747: INFO: Found 0 stateful pods, waiting for 1
Aug 24 10:43:09.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 08/24/22 10:43:09.771
STEP: Getting /status 08/24/22 10:43:09.79
Aug 24 10:43:09.804: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 08/24/22 10:43:09.804
Aug 24 10:43:09.824: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 08/24/22 10:43:09.824
Aug 24 10:43:09.827: INFO: Observed &StatefulSet event: ADDED
Aug 24 10:43:09.827: INFO: Found Statefulset ss in namespace statefulset-6039 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 10:43:09.827: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 08/24/22 10:43:09.827
Aug 24 10:43:09.827: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 10:43:09.840: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 08/24/22 10:43:09.84
Aug 24 10:43:09.843: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:43:09.843: INFO: Deleting all statefulset in ns statefulset-6039
Aug 24 10:43:09.848: INFO: Scaling statefulset ss to 0
Aug 24 10:43:19.876: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:43:19.880: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:43:19.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6039" for this suite. 08/24/22 10:43:19.928
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":315,"skipped":5698,"failed":0}
------------------------------
• [SLOW TEST] [20.326 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:42:59.615
    Aug 24 10:42:59.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:42:59.619
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:42:59.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:42:59.678
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6039 08/24/22 10:42:59.681
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-6039 08/24/22 10:42:59.705
    Aug 24 10:42:59.747: INFO: Found 0 stateful pods, waiting for 1
    Aug 24 10:43:09.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 08/24/22 10:43:09.771
    STEP: Getting /status 08/24/22 10:43:09.79
    Aug 24 10:43:09.804: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 08/24/22 10:43:09.804
    Aug 24 10:43:09.824: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 08/24/22 10:43:09.824
    Aug 24 10:43:09.827: INFO: Observed &StatefulSet event: ADDED
    Aug 24 10:43:09.827: INFO: Found Statefulset ss in namespace statefulset-6039 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 24 10:43:09.827: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 08/24/22 10:43:09.827
    Aug 24 10:43:09.827: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 24 10:43:09.840: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 08/24/22 10:43:09.84
    Aug 24 10:43:09.843: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:43:09.843: INFO: Deleting all statefulset in ns statefulset-6039
    Aug 24 10:43:09.848: INFO: Scaling statefulset ss to 0
    Aug 24 10:43:19.876: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:43:19.880: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:43:19.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6039" for this suite. 08/24/22 10:43:19.928
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:43:19.944
Aug 24 10:43:19.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pods 08/24/22 10:43:19.948
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:43:19.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:43:19.979
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 08/24/22 10:43:19.983
Aug 24 10:43:19.995: INFO: Waiting up to 5m0s for pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9" in namespace "pods-6420" to be "running and ready"
Aug 24 10:43:19.999: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.163508ms
Aug 24 10:43:19.999: INFO: The phase of Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:43:22.007: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01145223s
Aug 24 10:43:22.007: INFO: The phase of Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 is Running (Ready = true)
Aug 24 10:43:22.007: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9" satisfied condition "running and ready"
Aug 24 10:43:22.015: INFO: Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 has hostIP: 192.168.121.54
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 24 10:43:22.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6420" for this suite. 08/24/22 10:43:22.022
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":316,"skipped":5700,"failed":0}
------------------------------
• [2.088 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:43:19.944
    Aug 24 10:43:19.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pods 08/24/22 10:43:19.948
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:43:19.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:43:19.979
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 08/24/22 10:43:19.983
    Aug 24 10:43:19.995: INFO: Waiting up to 5m0s for pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9" in namespace "pods-6420" to be "running and ready"
    Aug 24 10:43:19.999: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.163508ms
    Aug 24 10:43:19.999: INFO: The phase of Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:43:22.007: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01145223s
    Aug 24 10:43:22.007: INFO: The phase of Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 is Running (Ready = true)
    Aug 24 10:43:22.007: INFO: Pod "pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9" satisfied condition "running and ready"
    Aug 24 10:43:22.015: INFO: Pod pod-hostip-ce3f1a94-e059-4210-a3a0-259357f2bfd9 has hostIP: 192.168.121.54
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 24 10:43:22.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6420" for this suite. 08/24/22 10:43:22.022
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:43:22.047
Aug 24 10:43:22.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename taint-single-pod 08/24/22 10:43:22.049
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:43:22.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:43:22.086
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Aug 24 10:43:22.090: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 10:44:22.141: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Aug 24 10:44:22.148: INFO: Starting informer...
STEP: Starting pod... 08/24/22 10:44:22.149
Aug 24 10:44:22.378: INFO: Pod is running on kah9uighaagh-3. Tainting Node
STEP: Trying to apply a taint on the Node 08/24/22 10:44:22.378
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 10:44:22.399
STEP: Waiting short time to make sure Pod is queued for deletion 08/24/22 10:44:22.411
Aug 24 10:44:22.411: INFO: Pod wasn't evicted. Proceeding
Aug 24 10:44:22.411: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 10:44:22.443
STEP: Waiting some time to make sure that toleration time passed. 08/24/22 10:44:22.457
Aug 24 10:45:37.458: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:45:37.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3046" for this suite. 08/24/22 10:45:37.476
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":317,"skipped":5792,"failed":0}
------------------------------
• [SLOW TEST] [135.445 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:43:22.047
    Aug 24 10:43:22.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename taint-single-pod 08/24/22 10:43:22.049
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:43:22.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:43:22.086
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Aug 24 10:43:22.090: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 10:44:22.141: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Aug 24 10:44:22.148: INFO: Starting informer...
    STEP: Starting pod... 08/24/22 10:44:22.149
    Aug 24 10:44:22.378: INFO: Pod is running on kah9uighaagh-3. Tainting Node
    STEP: Trying to apply a taint on the Node 08/24/22 10:44:22.378
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 10:44:22.399
    STEP: Waiting short time to make sure Pod is queued for deletion 08/24/22 10:44:22.411
    Aug 24 10:44:22.411: INFO: Pod wasn't evicted. Proceeding
    Aug 24 10:44:22.411: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/24/22 10:44:22.443
    STEP: Waiting some time to make sure that toleration time passed. 08/24/22 10:44:22.457
    Aug 24 10:45:37.458: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:45:37.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-3046" for this suite. 08/24/22 10:45:37.476
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:45:37.499
Aug 24 10:45:37.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:45:37.512
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:37.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:37.562
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 08/24/22 10:45:37.565
STEP: watching for the ServiceAccount to be added 08/24/22 10:45:37.575
STEP: patching the ServiceAccount 08/24/22 10:45:37.577
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/24/22 10:45:37.587
STEP: deleting the ServiceAccount 08/24/22 10:45:37.593
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 24 10:45:37.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2890" for this suite. 08/24/22 10:45:37.623
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":318,"skipped":5808,"failed":0}
------------------------------
• [0.149 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:45:37.499
    Aug 24 10:45:37.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename svcaccounts 08/24/22 10:45:37.512
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:37.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:37.562
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 08/24/22 10:45:37.565
    STEP: watching for the ServiceAccount to be added 08/24/22 10:45:37.575
    STEP: patching the ServiceAccount 08/24/22 10:45:37.577
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/24/22 10:45:37.587
    STEP: deleting the ServiceAccount 08/24/22 10:45:37.593
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 24 10:45:37.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2890" for this suite. 08/24/22 10:45:37.623
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:45:37.649
Aug 24 10:45:37.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename gc 08/24/22 10:45:37.653
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:37.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:37.686
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 08/24/22 10:45:37.697
STEP: delete the rc 08/24/22 10:45:42.733
STEP: wait for the rc to be deleted 08/24/22 10:45:42.836
Aug 24 10:45:43.903: INFO: 86 pods remaining
Aug 24 10:45:43.903: INFO: 83 pods has nil DeletionTimestamp
Aug 24 10:45:43.903: INFO: 
Aug 24 10:45:44.920: INFO: 71 pods remaining
Aug 24 10:45:44.920: INFO: 70 pods has nil DeletionTimestamp
Aug 24 10:45:44.920: INFO: 
Aug 24 10:45:45.910: INFO: 60 pods remaining
Aug 24 10:45:45.910: INFO: 58 pods has nil DeletionTimestamp
Aug 24 10:45:45.910: INFO: 
Aug 24 10:45:46.945: INFO: 44 pods remaining
Aug 24 10:45:46.946: INFO: 43 pods has nil DeletionTimestamp
Aug 24 10:45:46.946: INFO: 
Aug 24 10:45:47.937: INFO: 31 pods remaining
Aug 24 10:45:47.937: INFO: 28 pods has nil DeletionTimestamp
Aug 24 10:45:47.937: INFO: 
Aug 24 10:45:48.881: INFO: 19 pods remaining
Aug 24 10:45:48.881: INFO: 18 pods has nil DeletionTimestamp
Aug 24 10:45:48.881: INFO: 
Aug 24 10:45:49.950: INFO: 0 pods remaining
Aug 24 10:45:49.950: INFO: 0 pods has nil DeletionTimestamp
Aug 24 10:45:49.950: INFO: 
STEP: Gathering metrics 08/24/22 10:45:50.859
Aug 24 10:45:51.187: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
Aug 24 10:45:51.207: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 19.985907ms
Aug 24 10:45:51.207: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
Aug 24 10:45:51.208: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
Aug 24 10:45:52.086: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 24 10:45:52.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2609" for this suite. 08/24/22 10:45:52.166
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":319,"skipped":5813,"failed":0}
------------------------------
• [SLOW TEST] [14.575 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:45:37.649
    Aug 24 10:45:37.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename gc 08/24/22 10:45:37.653
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:37.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:37.686
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 08/24/22 10:45:37.697
    STEP: delete the rc 08/24/22 10:45:42.733
    STEP: wait for the rc to be deleted 08/24/22 10:45:42.836
    Aug 24 10:45:43.903: INFO: 86 pods remaining
    Aug 24 10:45:43.903: INFO: 83 pods has nil DeletionTimestamp
    Aug 24 10:45:43.903: INFO: 
    Aug 24 10:45:44.920: INFO: 71 pods remaining
    Aug 24 10:45:44.920: INFO: 70 pods has nil DeletionTimestamp
    Aug 24 10:45:44.920: INFO: 
    Aug 24 10:45:45.910: INFO: 60 pods remaining
    Aug 24 10:45:45.910: INFO: 58 pods has nil DeletionTimestamp
    Aug 24 10:45:45.910: INFO: 
    Aug 24 10:45:46.945: INFO: 44 pods remaining
    Aug 24 10:45:46.946: INFO: 43 pods has nil DeletionTimestamp
    Aug 24 10:45:46.946: INFO: 
    Aug 24 10:45:47.937: INFO: 31 pods remaining
    Aug 24 10:45:47.937: INFO: 28 pods has nil DeletionTimestamp
    Aug 24 10:45:47.937: INFO: 
    Aug 24 10:45:48.881: INFO: 19 pods remaining
    Aug 24 10:45:48.881: INFO: 18 pods has nil DeletionTimestamp
    Aug 24 10:45:48.881: INFO: 
    Aug 24 10:45:49.950: INFO: 0 pods remaining
    Aug 24 10:45:49.950: INFO: 0 pods has nil DeletionTimestamp
    Aug 24 10:45:49.950: INFO: 
    STEP: Gathering metrics 08/24/22 10:45:50.859
    Aug 24 10:45:51.187: INFO: Waiting up to 5m0s for pod "kube-controller-manager-kah9uighaagh-2" in namespace "kube-system" to be "running and ready"
    Aug 24 10:45:51.207: INFO: Pod "kube-controller-manager-kah9uighaagh-2": Phase="Running", Reason="", readiness=true. Elapsed: 19.985907ms
    Aug 24 10:45:51.207: INFO: The phase of Pod kube-controller-manager-kah9uighaagh-2 is Running (Ready = true)
    Aug 24 10:45:51.208: INFO: Pod "kube-controller-manager-kah9uighaagh-2" satisfied condition "running and ready"
    Aug 24 10:45:52.086: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 24 10:45:52.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2609" for this suite. 08/24/22 10:45:52.166
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:45:52.225
Aug 24 10:45:52.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:45:52.243
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:52.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:52.45
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:45:52.638
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:45:53.572
STEP: Deploying the webhook pod 08/24/22 10:45:53.603
STEP: Wait for the deployment to be ready 08/24/22 10:45:53.66
Aug 24 10:45:53.701: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 10:45:55.728: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:45:57.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:45:59.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:01.755: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:03.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:05.734: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:07.743: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:09.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:11.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:13.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:15.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:17.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:19.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:21.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:23.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:25.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:27.744: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:29.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:31.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:33.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:35.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:37.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:39.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:41.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:43.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:45.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:47.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:49.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:46:51.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:46:53.735
STEP: Verifying the service has paired with the endpoint 08/24/22 10:46:53.777
Aug 24 10:46:54.778: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/24/22 10:46:54.787
STEP: create a namespace for the webhook 08/24/22 10:46:54.821
STEP: create a configmap should be unconditionally rejected by the webhook 08/24/22 10:46:54.834
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:46:54.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5761" for this suite. 08/24/22 10:46:54.891
STEP: Destroying namespace "webhook-5761-markers" for this suite. 08/24/22 10:46:54.917
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":320,"skipped":5813,"failed":0}
------------------------------
• [SLOW TEST] [62.854 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:45:52.225
    Aug 24 10:45:52.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:45:52.243
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:45:52.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:45:52.45
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:45:52.638
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:45:53.572
    STEP: Deploying the webhook pod 08/24/22 10:45:53.603
    STEP: Wait for the deployment to be ready 08/24/22 10:45:53.66
    Aug 24 10:45:53.701: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 24 10:45:55.728: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:45:57.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:45:59.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:01.755: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:03.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:05.734: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:07.743: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:09.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:11.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:13.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:15.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:17.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:19.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:21.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:23.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:25.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:27.744: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:29.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:31.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:33.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:35.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:37.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:39.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:41.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:43.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:45.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:47.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:49.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:46:51.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 45, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:46:53.735
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:46:53.777
    Aug 24 10:46:54.778: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/24/22 10:46:54.787
    STEP: create a namespace for the webhook 08/24/22 10:46:54.821
    STEP: create a configmap should be unconditionally rejected by the webhook 08/24/22 10:46:54.834
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:46:54.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5761" for this suite. 08/24/22 10:46:54.891
    STEP: Destroying namespace "webhook-5761-markers" for this suite. 08/24/22 10:46:54.917
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:46:55.087
Aug 24 10:46:55.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:46:55.091
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:46:55.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:46:55.162
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-e60234f7-0d6b-4f47-be30-904aa45b79d4 08/24/22 10:46:55.174
STEP: Creating a pod to test consume configMaps 08/24/22 10:46:55.201
Aug 24 10:46:55.226: INFO: Waiting up to 5m0s for pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11" in namespace "configmap-6185" to be "Succeeded or Failed"
Aug 24 10:46:55.233: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549101ms
Aug 24 10:46:57.240: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013268203s
Aug 24 10:46:59.239: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012838963s
Aug 24 10:47:01.241: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014073398s
STEP: Saw pod success 08/24/22 10:47:01.241
Aug 24 10:47:01.241: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11" satisfied condition "Succeeded or Failed"
Aug 24 10:47:01.246: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:47:01.418
Aug 24 10:47:01.450: INFO: Waiting for pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 to disappear
Aug 24 10:47:01.458: INFO: Pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:47:01.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6185" for this suite. 08/24/22 10:47:01.473
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":321,"skipped":5823,"failed":0}
------------------------------
• [SLOW TEST] [6.399 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:46:55.087
    Aug 24 10:46:55.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:46:55.091
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:46:55.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:46:55.162
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-e60234f7-0d6b-4f47-be30-904aa45b79d4 08/24/22 10:46:55.174
    STEP: Creating a pod to test consume configMaps 08/24/22 10:46:55.201
    Aug 24 10:46:55.226: INFO: Waiting up to 5m0s for pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11" in namespace "configmap-6185" to be "Succeeded or Failed"
    Aug 24 10:46:55.233: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549101ms
    Aug 24 10:46:57.240: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013268203s
    Aug 24 10:46:59.239: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012838963s
    Aug 24 10:47:01.241: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014073398s
    STEP: Saw pod success 08/24/22 10:47:01.241
    Aug 24 10:47:01.241: INFO: Pod "pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11" satisfied condition "Succeeded or Failed"
    Aug 24 10:47:01.246: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:47:01.418
    Aug 24 10:47:01.450: INFO: Waiting for pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 to disappear
    Aug 24 10:47:01.458: INFO: Pod pod-configmaps-51463bde-3290-41f5-8e3f-03347c6edd11 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:47:01.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6185" for this suite. 08/24/22 10:47:01.473
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:47:01.489
Aug 24 10:47:01.489: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename webhook 08/24/22 10:47:01.493
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:01.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:01.541
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/24/22 10:47:01.573
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:47:03.115
STEP: Deploying the webhook pod 08/24/22 10:47:03.131
STEP: Wait for the deployment to be ready 08/24/22 10:47:03.147
Aug 24 10:47:03.158: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Aug 24 10:47:05.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/24/22 10:47:07.183
STEP: Verifying the service has paired with the endpoint 08/24/22 10:47:07.214
Aug 24 10:47:08.216: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Aug 24 10:47:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6464-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:47:08.752
STEP: Creating a custom resource while v1 is storage version 08/24/22 10:47:08.786
STEP: Patching Custom Resource Definition to set v2 as storage 08/24/22 10:47:11.107
STEP: Patching the custom resource while v2 is storage version 08/24/22 10:47:11.157
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:47:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8371" for this suite. 08/24/22 10:47:11.988
STEP: Destroying namespace "webhook-8371-markers" for this suite. 08/24/22 10:47:12.001
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":322,"skipped":5837,"failed":0}
------------------------------
• [SLOW TEST] [10.760 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:47:01.489
    Aug 24 10:47:01.489: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename webhook 08/24/22 10:47:01.493
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:01.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:01.541
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/24/22 10:47:01.573
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/24/22 10:47:03.115
    STEP: Deploying the webhook pod 08/24/22 10:47:03.131
    STEP: Wait for the deployment to be ready 08/24/22 10:47:03.147
    Aug 24 10:47:03.158: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Aug 24 10:47:05.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/24/22 10:47:07.183
    STEP: Verifying the service has paired with the endpoint 08/24/22 10:47:07.214
    Aug 24 10:47:08.216: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Aug 24 10:47:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6464-crds.webhook.example.com via the AdmissionRegistration API 08/24/22 10:47:08.752
    STEP: Creating a custom resource while v1 is storage version 08/24/22 10:47:08.786
    STEP: Patching Custom Resource Definition to set v2 as storage 08/24/22 10:47:11.107
    STEP: Patching the custom resource while v2 is storage version 08/24/22 10:47:11.157
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:47:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8371" for this suite. 08/24/22 10:47:11.988
    STEP: Destroying namespace "webhook-8371-markers" for this suite. 08/24/22 10:47:12.001
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:47:12.269
Aug 24 10:47:12.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replicaset 08/24/22 10:47:12.282
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:12.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:12.416
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 08/24/22 10:47:12.431
STEP: Verify that the required pods have come up. 08/24/22 10:47:12.439
Aug 24 10:47:12.450: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 10:47:17.460: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 10:47:17.46
STEP: Getting /status 08/24/22 10:47:17.461
Aug 24 10:47:17.470: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 08/24/22 10:47:17.47
Aug 24 10:47:17.489: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 08/24/22 10:47:17.489
Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: ADDED
Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.494: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.494: INFO: Found replicaset test-rs in namespace replicaset-2743 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 10:47:17.494: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 08/24/22 10:47:17.494
Aug 24 10:47:17.494: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 10:47:17.508: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 08/24/22 10:47:17.508
Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: ADDED
Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.512: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.512: INFO: Observed replicaset test-rs in namespace replicaset-2743 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 10:47:17.512: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 10:47:17.512: INFO: Found replicaset test-rs in namespace replicaset-2743 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Aug 24 10:47:17.512: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 24 10:47:17.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2743" for this suite. 08/24/22 10:47:17.531
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":323,"skipped":5875,"failed":0}
------------------------------
• [SLOW TEST] [5.270 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:47:12.269
    Aug 24 10:47:12.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replicaset 08/24/22 10:47:12.282
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:12.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:12.416
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 08/24/22 10:47:12.431
    STEP: Verify that the required pods have come up. 08/24/22 10:47:12.439
    Aug 24 10:47:12.450: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 24 10:47:17.460: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 10:47:17.46
    STEP: Getting /status 08/24/22 10:47:17.461
    Aug 24 10:47:17.470: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 08/24/22 10:47:17.47
    Aug 24 10:47:17.489: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 08/24/22 10:47:17.489
    Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: ADDED
    Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.493: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.494: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.494: INFO: Found replicaset test-rs in namespace replicaset-2743 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 24 10:47:17.494: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 08/24/22 10:47:17.494
    Aug 24 10:47:17.494: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 24 10:47:17.508: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 08/24/22 10:47:17.508
    Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: ADDED
    Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.511: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.512: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.512: INFO: Observed replicaset test-rs in namespace replicaset-2743 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 24 10:47:17.512: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 24 10:47:17.512: INFO: Found replicaset test-rs in namespace replicaset-2743 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Aug 24 10:47:17.512: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 24 10:47:17.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2743" for this suite. 08/24/22 10:47:17.531
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:47:17.541
Aug 24 10:47:17.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 10:47:17.544
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:17.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:17.579
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Aug 24 10:47:17.582: INFO: Creating deployment "test-recreate-deployment"
Aug 24 10:47:17.588: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 24 10:47:17.600: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 24 10:47:19.614: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 24 10:47:19.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:47:21.626: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 24 10:47:21.645: INFO: Updating deployment test-recreate-deployment
Aug 24 10:47:21.645: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 10:47:21.843: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6937  fe40b9bc-3cb1-4016-acd9-355161affec9 32483 2 2022-08-24 10:47:17 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e8ecd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 10:47:21 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-08-24 10:47:21 +0000 UTC,LastTransitionTime:2022-08-24 10:47:17 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 24 10:47:21.856: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-6937  5a59e7ab-f1fe-4723-b54b-428fda77fd69 32481 1 2022-08-24 10:47:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fe40b9bc-3cb1-4016-acd9-355161affec9 0xc0060f9f80 0xc0060f9f81}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fe40b9bc-3cb1-4016-acd9-355161affec9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0001e5c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 10:47:21.856: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 24 10:47:21.857: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-6937  bcd2198e-ec09-4850-8424-222410fc7320 32469 2 2022-08-24 10:47:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fe40b9bc-3cb1-4016-acd9-355161affec9 0xc0060f9e57 0xc0060f9e58}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fe40b9bc-3cb1-4016-acd9-355161affec9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0060f9f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 10:47:21.867: INFO: Pod "test-recreate-deployment-9d58999df-mpcht" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-mpcht test-recreate-deployment-9d58999df- deployment-6937  7e4c9e9a-9b33-414c-ac2a-689b9eddbfbc 32480 0 2022-08-24 10:47:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 5a59e7ab-f1fe-4723-b54b-428fda77fd69 0xc003e8f080 0xc003e8f081}] [] [{kube-controller-manager Update v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a59e7ab-f1fe-4723-b54b-428fda77fd69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt988,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt988,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 10:47:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 10:47:21.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6937" for this suite. 08/24/22 10:47:21.874
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":324,"skipped":5878,"failed":0}
------------------------------
• [4.347 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:47:17.541
    Aug 24 10:47:17.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 10:47:17.544
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:17.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:17.579
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Aug 24 10:47:17.582: INFO: Creating deployment "test-recreate-deployment"
    Aug 24 10:47:17.588: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Aug 24 10:47:17.600: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Aug 24 10:47:19.614: INFO: Waiting deployment "test-recreate-deployment" to complete
    Aug 24 10:47:19.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 47, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:47:21.626: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Aug 24 10:47:21.645: INFO: Updating deployment test-recreate-deployment
    Aug 24 10:47:21.645: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 10:47:21.843: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-6937  fe40b9bc-3cb1-4016-acd9-355161affec9 32483 2 2022-08-24 10:47:17 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e8ecd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 10:47:21 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-08-24 10:47:21 +0000 UTC,LastTransitionTime:2022-08-24 10:47:17 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 24 10:47:21.856: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-6937  5a59e7ab-f1fe-4723-b54b-428fda77fd69 32481 1 2022-08-24 10:47:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fe40b9bc-3cb1-4016-acd9-355161affec9 0xc0060f9f80 0xc0060f9f81}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fe40b9bc-3cb1-4016-acd9-355161affec9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0001e5c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 10:47:21.856: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Aug 24 10:47:21.857: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-6937  bcd2198e-ec09-4850-8424-222410fc7320 32469 2 2022-08-24 10:47:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fe40b9bc-3cb1-4016-acd9-355161affec9 0xc0060f9e57 0xc0060f9e58}] [] [{kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fe40b9bc-3cb1-4016-acd9-355161affec9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0060f9f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 10:47:21.867: INFO: Pod "test-recreate-deployment-9d58999df-mpcht" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-mpcht test-recreate-deployment-9d58999df- deployment-6937  7e4c9e9a-9b33-414c-ac2a-689b9eddbfbc 32480 0 2022-08-24 10:47:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 5a59e7ab-f1fe-4723-b54b-428fda77fd69 0xc003e8f080 0xc003e8f081}] [] [{kube-controller-manager Update v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a59e7ab-f1fe-4723-b54b-428fda77fd69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:47:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt988,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt988,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:47:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:,StartTime:2022-08-24 10:47:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 10:47:21.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6937" for this suite. 08/24/22 10:47:21.874
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:47:21.904
Aug 24 10:47:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename cronjob 08/24/22 10:47:21.906
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:21.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:21.938
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 08/24/22 10:47:21.942
STEP: Ensuring a job is scheduled 08/24/22 10:47:21.958
STEP: Ensuring exactly one is scheduled 08/24/22 10:48:01.969
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/24/22 10:48:01.976
STEP: Ensuring the job is replaced with a new one 08/24/22 10:48:01.981
STEP: Removing cronjob 08/24/22 10:49:01.989
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 24 10:49:02.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4465" for this suite. 08/24/22 10:49:02.011
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":325,"skipped":5955,"failed":0}
------------------------------
• [SLOW TEST] [100.153 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:47:21.904
    Aug 24 10:47:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename cronjob 08/24/22 10:47:21.906
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:47:21.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:47:21.938
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 08/24/22 10:47:21.942
    STEP: Ensuring a job is scheduled 08/24/22 10:47:21.958
    STEP: Ensuring exactly one is scheduled 08/24/22 10:48:01.969
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/24/22 10:48:01.976
    STEP: Ensuring the job is replaced with a new one 08/24/22 10:48:01.981
    STEP: Removing cronjob 08/24/22 10:49:01.989
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 24 10:49:02.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4465" for this suite. 08/24/22 10:49:02.011
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:02.06
Aug 24 10:49:02.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:49:02.065
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:02.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:02.102
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 08/24/22 10:49:02.106
Aug 24 10:49:02.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d" in namespace "downward-api-2920" to be "Succeeded or Failed"
Aug 24 10:49:02.140: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.957737ms
Aug 24 10:49:04.149: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019641404s
Aug 24 10:49:06.149: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019378913s
Aug 24 10:49:08.148: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018498012s
STEP: Saw pod success 08/24/22 10:49:08.148
Aug 24 10:49:08.148: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d" satisfied condition "Succeeded or Failed"
Aug 24 10:49:08.154: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d container client-container: <nil>
STEP: delete the pod 08/24/22 10:49:08.191
Aug 24 10:49:08.219: INFO: Waiting for pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d to disappear
Aug 24 10:49:08.225: INFO: Pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 24 10:49:08.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2920" for this suite. 08/24/22 10:49:08.232
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":326,"skipped":5969,"failed":0}
------------------------------
• [SLOW TEST] [6.190 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:02.06
    Aug 24 10:49:02.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:49:02.065
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:02.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:02.102
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 08/24/22 10:49:02.106
    Aug 24 10:49:02.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d" in namespace "downward-api-2920" to be "Succeeded or Failed"
    Aug 24 10:49:02.140: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.957737ms
    Aug 24 10:49:04.149: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019641404s
    Aug 24 10:49:06.149: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019378913s
    Aug 24 10:49:08.148: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018498012s
    STEP: Saw pod success 08/24/22 10:49:08.148
    Aug 24 10:49:08.148: INFO: Pod "downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d" satisfied condition "Succeeded or Failed"
    Aug 24 10:49:08.154: INFO: Trying to get logs from node kah9uighaagh-3 pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d container client-container: <nil>
    STEP: delete the pod 08/24/22 10:49:08.191
    Aug 24 10:49:08.219: INFO: Waiting for pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d to disappear
    Aug 24 10:49:08.225: INFO: Pod downwardapi-volume-11df197a-dff7-4d2a-ae77-9ba53233ef6d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 24 10:49:08.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2920" for this suite. 08/24/22 10:49:08.232
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:08.256
Aug 24 10:49:08.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename namespaces 08/24/22 10:49:08.258
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:08.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:08.293
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 08/24/22 10:49:08.298
Aug 24 10:49:08.306: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 08/24/22 10:49:08.306
Aug 24 10:49:08.321: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 08/24/22 10:49:08.321
Aug 24 10:49:08.351: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:49:08.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2000" for this suite. 08/24/22 10:49:08.358
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":327,"skipped":5984,"failed":0}
------------------------------
• [0.126 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:08.256
    Aug 24 10:49:08.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename namespaces 08/24/22 10:49:08.258
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:08.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:08.293
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 08/24/22 10:49:08.298
    Aug 24 10:49:08.306: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 08/24/22 10:49:08.306
    Aug 24 10:49:08.321: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 08/24/22 10:49:08.321
    Aug 24 10:49:08.351: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:49:08.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2000" for this suite. 08/24/22 10:49:08.358
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:08.385
Aug 24 10:49:08.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:49:08.387
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:08.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:08.439
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-a5d21fa4-bf8b-422d-8123-b317bca969c3 08/24/22 10:49:08.444
STEP: Creating a pod to test consume secrets 08/24/22 10:49:08.462
Aug 24 10:49:08.483: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90" in namespace "projected-2994" to be "Succeeded or Failed"
Aug 24 10:49:08.493: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 9.509843ms
Aug 24 10:49:10.506: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022799371s
Aug 24 10:49:12.505: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021757033s
Aug 24 10:49:14.502: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018456787s
STEP: Saw pod success 08/24/22 10:49:14.502
Aug 24 10:49:14.502: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90" satisfied condition "Succeeded or Failed"
Aug 24 10:49:14.507: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/24/22 10:49:14.521
Aug 24 10:49:14.539: INFO: Waiting for pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 to disappear
Aug 24 10:49:14.545: INFO: Pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 24 10:49:14.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2994" for this suite. 08/24/22 10:49:14.554
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":328,"skipped":5987,"failed":0}
------------------------------
• [SLOW TEST] [6.185 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:08.385
    Aug 24 10:49:08.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:49:08.387
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:08.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:08.439
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-a5d21fa4-bf8b-422d-8123-b317bca969c3 08/24/22 10:49:08.444
    STEP: Creating a pod to test consume secrets 08/24/22 10:49:08.462
    Aug 24 10:49:08.483: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90" in namespace "projected-2994" to be "Succeeded or Failed"
    Aug 24 10:49:08.493: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 9.509843ms
    Aug 24 10:49:10.506: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022799371s
    Aug 24 10:49:12.505: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021757033s
    Aug 24 10:49:14.502: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018456787s
    STEP: Saw pod success 08/24/22 10:49:14.502
    Aug 24 10:49:14.502: INFO: Pod "pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90" satisfied condition "Succeeded or Failed"
    Aug 24 10:49:14.507: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:49:14.521
    Aug 24 10:49:14.539: INFO: Waiting for pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 to disappear
    Aug 24 10:49:14.545: INFO: Pod pod-projected-secrets-21f97768-98e4-4e7e-84bc-aa103822da90 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 24 10:49:14.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2994" for this suite. 08/24/22 10:49:14.554
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:14.571
Aug 24 10:49:14.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename secrets 08/24/22 10:49:14.589
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:14.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:14.633
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-0e781112-b3dd-4fe7-8643-244fff718155 08/24/22 10:49:14.637
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 24 10:49:14.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7738" for this suite. 08/24/22 10:49:14.651
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":329,"skipped":5990,"failed":0}
------------------------------
• [0.091 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:14.571
    Aug 24 10:49:14.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename secrets 08/24/22 10:49:14.589
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:14.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:14.633
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-0e781112-b3dd-4fe7-8643-244fff718155 08/24/22 10:49:14.637
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 24 10:49:14.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7738" for this suite. 08/24/22 10:49:14.651
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:14.663
Aug 24 10:49:14.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:49:14.666
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:14.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:14.702
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 08/24/22 10:49:14.713
STEP: watching for the Service to be added 08/24/22 10:49:14.766
Aug 24 10:49:14.770: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Aug 24 10:49:14.770: INFO: Service test-service-9zzp8 created
STEP: Getting /status 08/24/22 10:49:14.77
Aug 24 10:49:14.778: INFO: Service test-service-9zzp8 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 08/24/22 10:49:14.778
STEP: watching for the Service to be patched 08/24/22 10:49:14.796
Aug 24 10:49:14.799: INFO: observed Service test-service-9zzp8 in namespace services-2144 with annotations: map[] & LoadBalancer: {[]}
Aug 24 10:49:14.800: INFO: Found Service test-service-9zzp8 in namespace services-2144 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Aug 24 10:49:14.800: INFO: Service test-service-9zzp8 has service status patched
STEP: updating the ServiceStatus 08/24/22 10:49:14.8
Aug 24 10:49:14.864: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 08/24/22 10:49:14.864
Aug 24 10:49:14.867: INFO: Observed Service test-service-9zzp8 in namespace services-2144 with annotations: map[] & Conditions: {[]}
Aug 24 10:49:14.867: INFO: Observed event: &Service{ObjectMeta:{test-service-9zzp8  services-2144  bc8ee0c1-b312-45ba-ab03-f210bef4f331 32806 0 2022-08-24 10:49:14 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-08-24 10:49:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-24 10:49:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.42.245,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.42.245],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Aug 24 10:49:14.868: INFO: Found Service test-service-9zzp8 in namespace services-2144 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 10:49:14.868: INFO: Service test-service-9zzp8 has service status updated
STEP: patching the service 08/24/22 10:49:14.868
STEP: watching for the Service to be patched 08/24/22 10:49:14.898
Aug 24 10:49:14.904: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
Aug 24 10:49:14.905: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
Aug 24 10:49:14.905: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
Aug 24 10:49:14.905: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service:patched test-service-static:true]
Aug 24 10:49:14.905: INFO: Service test-service-9zzp8 patched
STEP: deleting the service 08/24/22 10:49:14.905
STEP: watching for the Service to be deleted 08/24/22 10:49:14.951
Aug 24 10:49:14.953: INFO: Observed event: ADDED
Aug 24 10:49:14.953: INFO: Observed event: MODIFIED
Aug 24 10:49:14.954: INFO: Observed event: MODIFIED
Aug 24 10:49:14.954: INFO: Observed event: MODIFIED
Aug 24 10:49:14.954: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Aug 24 10:49:14.954: INFO: Service test-service-9zzp8 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:49:14.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2144" for this suite. 08/24/22 10:49:14.972
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":330,"skipped":5995,"failed":0}
------------------------------
• [0.325 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:14.663
    Aug 24 10:49:14.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:49:14.666
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:14.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:14.702
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 08/24/22 10:49:14.713
    STEP: watching for the Service to be added 08/24/22 10:49:14.766
    Aug 24 10:49:14.770: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Aug 24 10:49:14.770: INFO: Service test-service-9zzp8 created
    STEP: Getting /status 08/24/22 10:49:14.77
    Aug 24 10:49:14.778: INFO: Service test-service-9zzp8 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 08/24/22 10:49:14.778
    STEP: watching for the Service to be patched 08/24/22 10:49:14.796
    Aug 24 10:49:14.799: INFO: observed Service test-service-9zzp8 in namespace services-2144 with annotations: map[] & LoadBalancer: {[]}
    Aug 24 10:49:14.800: INFO: Found Service test-service-9zzp8 in namespace services-2144 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Aug 24 10:49:14.800: INFO: Service test-service-9zzp8 has service status patched
    STEP: updating the ServiceStatus 08/24/22 10:49:14.8
    Aug 24 10:49:14.864: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 08/24/22 10:49:14.864
    Aug 24 10:49:14.867: INFO: Observed Service test-service-9zzp8 in namespace services-2144 with annotations: map[] & Conditions: {[]}
    Aug 24 10:49:14.867: INFO: Observed event: &Service{ObjectMeta:{test-service-9zzp8  services-2144  bc8ee0c1-b312-45ba-ab03-f210bef4f331 32806 0 2022-08-24 10:49:14 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-08-24 10:49:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-24 10:49:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.42.245,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.42.245],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Aug 24 10:49:14.868: INFO: Found Service test-service-9zzp8 in namespace services-2144 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 24 10:49:14.868: INFO: Service test-service-9zzp8 has service status updated
    STEP: patching the service 08/24/22 10:49:14.868
    STEP: watching for the Service to be patched 08/24/22 10:49:14.898
    Aug 24 10:49:14.904: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
    Aug 24 10:49:14.905: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
    Aug 24 10:49:14.905: INFO: observed Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service-static:true]
    Aug 24 10:49:14.905: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service:patched test-service-static:true]
    Aug 24 10:49:14.905: INFO: Service test-service-9zzp8 patched
    STEP: deleting the service 08/24/22 10:49:14.905
    STEP: watching for the Service to be deleted 08/24/22 10:49:14.951
    Aug 24 10:49:14.953: INFO: Observed event: ADDED
    Aug 24 10:49:14.953: INFO: Observed event: MODIFIED
    Aug 24 10:49:14.954: INFO: Observed event: MODIFIED
    Aug 24 10:49:14.954: INFO: Observed event: MODIFIED
    Aug 24 10:49:14.954: INFO: Found Service test-service-9zzp8 in namespace services-2144 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Aug 24 10:49:14.954: INFO: Service test-service-9zzp8 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:49:14.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2144" for this suite. 08/24/22 10:49:14.972
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:14.993
Aug 24 10:49:14.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename subpath 08/24/22 10:49:14.997
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:15.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:15.068
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/24/22 10:49:15.072
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-hmtq 08/24/22 10:49:15.178
STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:49:15.178
Aug 24 10:49:15.198: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hmtq" in namespace "subpath-2130" to be "Succeeded or Failed"
Aug 24 10:49:15.210: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Pending", Reason="", readiness=false. Elapsed: 11.928723ms
Aug 24 10:49:17.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019803355s
Aug 24 10:49:19.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 4.01922545s
Aug 24 10:49:21.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 6.019232052s
Aug 24 10:49:23.221: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 8.022794653s
Aug 24 10:49:25.220: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 10.021444771s
Aug 24 10:49:27.222: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 12.023151703s
Aug 24 10:49:29.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 14.019321654s
Aug 24 10:49:31.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 16.020131546s
Aug 24 10:49:33.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 18.020384316s
Aug 24 10:49:35.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 20.020307606s
Aug 24 10:49:37.217: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 22.018908898s
Aug 24 10:49:39.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=false. Elapsed: 24.020844494s
Aug 24 10:49:41.227: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.028257392s
STEP: Saw pod success 08/24/22 10:49:41.227
Aug 24 10:49:41.228: INFO: Pod "pod-subpath-test-projected-hmtq" satisfied condition "Succeeded or Failed"
Aug 24 10:49:41.234: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-projected-hmtq container test-container-subpath-projected-hmtq: <nil>
STEP: delete the pod 08/24/22 10:49:41.45
Aug 24 10:49:41.479: INFO: Waiting for pod pod-subpath-test-projected-hmtq to disappear
Aug 24 10:49:41.486: INFO: Pod pod-subpath-test-projected-hmtq no longer exists
STEP: Deleting pod pod-subpath-test-projected-hmtq 08/24/22 10:49:41.486
Aug 24 10:49:41.486: INFO: Deleting pod "pod-subpath-test-projected-hmtq" in namespace "subpath-2130"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 24 10:49:41.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2130" for this suite. 08/24/22 10:49:41.5
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":331,"skipped":6004,"failed":0}
------------------------------
• [SLOW TEST] [26.519 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:14.993
    Aug 24 10:49:14.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename subpath 08/24/22 10:49:14.997
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:15.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:15.068
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/24/22 10:49:15.072
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-hmtq 08/24/22 10:49:15.178
    STEP: Creating a pod to test atomic-volume-subpath 08/24/22 10:49:15.178
    Aug 24 10:49:15.198: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hmtq" in namespace "subpath-2130" to be "Succeeded or Failed"
    Aug 24 10:49:15.210: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Pending", Reason="", readiness=false. Elapsed: 11.928723ms
    Aug 24 10:49:17.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019803355s
    Aug 24 10:49:19.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 4.01922545s
    Aug 24 10:49:21.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 6.019232052s
    Aug 24 10:49:23.221: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 8.022794653s
    Aug 24 10:49:25.220: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 10.021444771s
    Aug 24 10:49:27.222: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 12.023151703s
    Aug 24 10:49:29.218: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 14.019321654s
    Aug 24 10:49:31.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 16.020131546s
    Aug 24 10:49:33.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 18.020384316s
    Aug 24 10:49:35.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 20.020307606s
    Aug 24 10:49:37.217: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=true. Elapsed: 22.018908898s
    Aug 24 10:49:39.219: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Running", Reason="", readiness=false. Elapsed: 24.020844494s
    Aug 24 10:49:41.227: INFO: Pod "pod-subpath-test-projected-hmtq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.028257392s
    STEP: Saw pod success 08/24/22 10:49:41.227
    Aug 24 10:49:41.228: INFO: Pod "pod-subpath-test-projected-hmtq" satisfied condition "Succeeded or Failed"
    Aug 24 10:49:41.234: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-projected-hmtq container test-container-subpath-projected-hmtq: <nil>
    STEP: delete the pod 08/24/22 10:49:41.45
    Aug 24 10:49:41.479: INFO: Waiting for pod pod-subpath-test-projected-hmtq to disappear
    Aug 24 10:49:41.486: INFO: Pod pod-subpath-test-projected-hmtq no longer exists
    STEP: Deleting pod pod-subpath-test-projected-hmtq 08/24/22 10:49:41.486
    Aug 24 10:49:41.486: INFO: Deleting pod "pod-subpath-test-projected-hmtq" in namespace "subpath-2130"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 24 10:49:41.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2130" for this suite. 08/24/22 10:49:41.5
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:49:41.513
Aug 24 10:49:41.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 10:49:41.52
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:41.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:41.559
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a7b20bd0-2d93-4422-bea5-a0bb6af695ff 08/24/22 10:49:41.57
STEP: Creating the pod 08/24/22 10:49:41.58
Aug 24 10:49:41.593: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930" in namespace "projected-5764" to be "running and ready"
Aug 24 10:49:41.601: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Pending", Reason="", readiness=false. Elapsed: 8.333513ms
Aug 24 10:49:41.601: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:49:43.618: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025288454s
Aug 24 10:49:43.618: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:49:45.616: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Running", Reason="", readiness=true. Elapsed: 4.023114835s
Aug 24 10:49:45.616: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Running (Ready = true)
Aug 24 10:49:45.616: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-a7b20bd0-2d93-4422-bea5-a0bb6af695ff 08/24/22 10:49:45.637
STEP: waiting to observe update in volume 08/24/22 10:49:45.662
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 24 10:51:14.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5764" for this suite. 08/24/22 10:51:14.452
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":332,"skipped":6008,"failed":0}
------------------------------
• [SLOW TEST] [92.952 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:49:41.513
    Aug 24 10:49:41.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 10:49:41.52
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:49:41.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:49:41.559
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-a7b20bd0-2d93-4422-bea5-a0bb6af695ff 08/24/22 10:49:41.57
    STEP: Creating the pod 08/24/22 10:49:41.58
    Aug 24 10:49:41.593: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930" in namespace "projected-5764" to be "running and ready"
    Aug 24 10:49:41.601: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Pending", Reason="", readiness=false. Elapsed: 8.333513ms
    Aug 24 10:49:41.601: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:49:43.618: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025288454s
    Aug 24 10:49:43.618: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:49:45.616: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930": Phase="Running", Reason="", readiness=true. Elapsed: 4.023114835s
    Aug 24 10:49:45.616: INFO: The phase of Pod pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930 is Running (Ready = true)
    Aug 24 10:49:45.616: INFO: Pod "pod-projected-configmaps-a74e4379-465b-4c0c-8d12-7cfa7eaff930" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-a7b20bd0-2d93-4422-bea5-a0bb6af695ff 08/24/22 10:49:45.637
    STEP: waiting to observe update in volume 08/24/22 10:49:45.662
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 24 10:51:14.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5764" for this suite. 08/24/22 10:51:14.452
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:51:14.468
Aug 24 10:51:14.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename downward-api 08/24/22 10:51:14.474
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:51:14.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:51:14.513
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 08/24/22 10:51:14.517
Aug 24 10:51:14.534: INFO: Waiting up to 5m0s for pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9" in namespace "downward-api-337" to be "Succeeded or Failed"
Aug 24 10:51:14.552: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.624317ms
Aug 24 10:51:16.560: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025480446s
Aug 24 10:51:18.565: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030347689s
Aug 24 10:51:20.561: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026148817s
STEP: Saw pod success 08/24/22 10:51:20.561
Aug 24 10:51:20.561: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9" satisfied condition "Succeeded or Failed"
Aug 24 10:51:20.567: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:51:20.583
Aug 24 10:51:20.622: INFO: Waiting for pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 to disappear
Aug 24 10:51:20.631: INFO: Pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 24 10:51:20.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-337" for this suite. 08/24/22 10:51:20.641
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":333,"skipped":6013,"failed":0}
------------------------------
• [SLOW TEST] [6.191 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:51:14.468
    Aug 24 10:51:14.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename downward-api 08/24/22 10:51:14.474
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:51:14.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:51:14.513
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 08/24/22 10:51:14.517
    Aug 24 10:51:14.534: INFO: Waiting up to 5m0s for pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9" in namespace "downward-api-337" to be "Succeeded or Failed"
    Aug 24 10:51:14.552: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.624317ms
    Aug 24 10:51:16.560: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025480446s
    Aug 24 10:51:18.565: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030347689s
    Aug 24 10:51:20.561: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026148817s
    STEP: Saw pod success 08/24/22 10:51:20.561
    Aug 24 10:51:20.561: INFO: Pod "downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9" satisfied condition "Succeeded or Failed"
    Aug 24 10:51:20.567: INFO: Trying to get logs from node kah9uighaagh-3 pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:51:20.583
    Aug 24 10:51:20.622: INFO: Waiting for pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 to disappear
    Aug 24 10:51:20.631: INFO: Pod downward-api-f7cf22a0-3dbd-4bd5-8073-6441c9e058c9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 24 10:51:20.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-337" for this suite. 08/24/22 10:51:20.641
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:51:20.662
Aug 24 10:51:20.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 10:51:20.663
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:51:20.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:51:20.706
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 in namespace container-probe-9918 08/24/22 10:51:20.712
Aug 24 10:51:20.727: INFO: Waiting up to 5m0s for pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332" in namespace "container-probe-9918" to be "not pending"
Aug 24 10:51:20.733: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Pending", Reason="", readiness=false. Elapsed: 5.345623ms
Aug 24 10:51:22.748: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020158712s
Aug 24 10:51:24.747: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Running", Reason="", readiness=true. Elapsed: 4.019602029s
Aug 24 10:51:24.748: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332" satisfied condition "not pending"
Aug 24 10:51:24.748: INFO: Started pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 in namespace container-probe-9918
STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 10:51:24.748
Aug 24 10:51:24.755: INFO: Initial restart count of pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 is 0
Aug 24 10:52:13.008: INFO: Restart count of pod container-probe-9918/busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 is now 1 (48.252902175s elapsed)
STEP: deleting the pod 08/24/22 10:52:13.008
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 10:52:13.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9918" for this suite. 08/24/22 10:52:13.071
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":334,"skipped":6059,"failed":0}
------------------------------
• [SLOW TEST] [52.420 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:51:20.662
    Aug 24 10:51:20.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 10:51:20.663
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:51:20.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:51:20.706
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 in namespace container-probe-9918 08/24/22 10:51:20.712
    Aug 24 10:51:20.727: INFO: Waiting up to 5m0s for pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332" in namespace "container-probe-9918" to be "not pending"
    Aug 24 10:51:20.733: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Pending", Reason="", readiness=false. Elapsed: 5.345623ms
    Aug 24 10:51:22.748: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020158712s
    Aug 24 10:51:24.747: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332": Phase="Running", Reason="", readiness=true. Elapsed: 4.019602029s
    Aug 24 10:51:24.748: INFO: Pod "busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332" satisfied condition "not pending"
    Aug 24 10:51:24.748: INFO: Started pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 in namespace container-probe-9918
    STEP: checking the pod's current state and verifying that restartCount is present 08/24/22 10:51:24.748
    Aug 24 10:51:24.755: INFO: Initial restart count of pod busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 is 0
    Aug 24 10:52:13.008: INFO: Restart count of pod container-probe-9918/busybox-f5801fa0-cf6f-41ef-aa7f-d94ac95e1332 is now 1 (48.252902175s elapsed)
    STEP: deleting the pod 08/24/22 10:52:13.008
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 10:52:13.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9918" for this suite. 08/24/22 10:52:13.071
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:52:13.095
Aug 24 10:52:13.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:52:13.103
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:13.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:13.141
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-2751 08/24/22 10:52:13.145
STEP: creating a selector 08/24/22 10:52:13.145
STEP: Creating the service pods in kubernetes 08/24/22 10:52:13.145
Aug 24 10:52:13.146: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 10:52:13.220: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2751" to be "running and ready"
Aug 24 10:52:13.255: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 34.626635ms
Aug 24 10:52:13.255: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:52:15.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.044500411s
Aug 24 10:52:15.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:52:17.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.042273171s
Aug 24 10:52:17.263: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:52:19.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.041407113s
Aug 24 10:52:19.262: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:52:21.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.043075585s
Aug 24 10:52:21.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:52:23.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.041573427s
Aug 24 10:52:23.262: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 24 10:52:25.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.041758847s
Aug 24 10:52:25.262: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 24 10:52:25.262: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 24 10:52:25.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2751" to be "running and ready"
Aug 24 10:52:25.273: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.263366ms
Aug 24 10:52:25.274: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:52:27.283: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.014714529s
Aug 24 10:52:27.283: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:52:29.282: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.013857504s
Aug 24 10:52:29.282: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:52:31.282: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.0136458s
Aug 24 10:52:31.282: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:52:33.279: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.011220582s
Aug 24 10:52:33.279: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 24 10:52:35.280: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.011565033s
Aug 24 10:52:35.280: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 24 10:52:35.280: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 24 10:52:35.285: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2751" to be "running and ready"
Aug 24 10:52:35.290: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.493641ms
Aug 24 10:52:35.290: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Aug 24 10:52:37.299: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013322304s
Aug 24 10:52:37.299: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 24 10:52:37.299: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/24/22 10:52:37.305
Aug 24 10:52:37.336: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2751" to be "running"
Aug 24 10:52:37.344: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.839985ms
Aug 24 10:52:39.351: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015205885s
Aug 24 10:52:41.352: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.015753727s
Aug 24 10:52:41.352: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 24 10:52:41.358: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2751" to be "running"
Aug 24 10:52:41.365: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.642478ms
Aug 24 10:52:41.365: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 24 10:52:41.373: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 10:52:41.374: INFO: Going to poll 10.233.64.152 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:52:41.379: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.152 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:52:41.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:52:41.381: INFO: ExecWithOptions: Clientset creation
Aug 24 10:52:41.382: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.152+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:52:42.605: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 24 10:52:42.606: INFO: Going to poll 10.233.65.172 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:52:42.614: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.172 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:52:42.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:52:42.619: INFO: ExecWithOptions: Clientset creation
Aug 24 10:52:42.619: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.172+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:52:43.746: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 24 10:52:43.746: INFO: Going to poll 10.233.66.178 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 10:52:43.762: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.178 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 10:52:43.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 10:52:43.763: INFO: ExecWithOptions: Clientset creation
Aug 24 10:52:43.763: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.178+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 24 10:52:44.932: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 24 10:52:44.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2751" for this suite. 08/24/22 10:52:44.942
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":335,"skipped":6115,"failed":0}
------------------------------
• [SLOW TEST] [31.869 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:52:13.095
    Aug 24 10:52:13.095: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename pod-network-test 08/24/22 10:52:13.103
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:13.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:13.141
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-2751 08/24/22 10:52:13.145
    STEP: creating a selector 08/24/22 10:52:13.145
    STEP: Creating the service pods in kubernetes 08/24/22 10:52:13.145
    Aug 24 10:52:13.146: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 24 10:52:13.220: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2751" to be "running and ready"
    Aug 24 10:52:13.255: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 34.626635ms
    Aug 24 10:52:13.255: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:52:15.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.044500411s
    Aug 24 10:52:15.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:52:17.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.042273171s
    Aug 24 10:52:17.263: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:52:19.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.041407113s
    Aug 24 10:52:19.262: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:52:21.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.043075585s
    Aug 24 10:52:21.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:52:23.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.041573427s
    Aug 24 10:52:23.262: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 24 10:52:25.262: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.041758847s
    Aug 24 10:52:25.262: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 24 10:52:25.262: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 24 10:52:25.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2751" to be "running and ready"
    Aug 24 10:52:25.273: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.263366ms
    Aug 24 10:52:25.274: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:52:27.283: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.014714529s
    Aug 24 10:52:27.283: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:52:29.282: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.013857504s
    Aug 24 10:52:29.282: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:52:31.282: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.0136458s
    Aug 24 10:52:31.282: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:52:33.279: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.011220582s
    Aug 24 10:52:33.279: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 24 10:52:35.280: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.011565033s
    Aug 24 10:52:35.280: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 24 10:52:35.280: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 24 10:52:35.285: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2751" to be "running and ready"
    Aug 24 10:52:35.290: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.493641ms
    Aug 24 10:52:35.290: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Aug 24 10:52:37.299: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013322304s
    Aug 24 10:52:37.299: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 24 10:52:37.299: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/24/22 10:52:37.305
    Aug 24 10:52:37.336: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2751" to be "running"
    Aug 24 10:52:37.344: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.839985ms
    Aug 24 10:52:39.351: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015205885s
    Aug 24 10:52:41.352: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.015753727s
    Aug 24 10:52:41.352: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 24 10:52:41.358: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2751" to be "running"
    Aug 24 10:52:41.365: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.642478ms
    Aug 24 10:52:41.365: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 24 10:52:41.373: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 24 10:52:41.374: INFO: Going to poll 10.233.64.152 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:52:41.379: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.152 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:52:41.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:52:41.381: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:52:41.382: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.152+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:52:42.605: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 24 10:52:42.606: INFO: Going to poll 10.233.65.172 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:52:42.614: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.172 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:52:42.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:52:42.619: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:52:42.619: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.172+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:52:43.746: INFO: Found all 1 expected endpoints: [netserver-1]
    Aug 24 10:52:43.746: INFO: Going to poll 10.233.66.178 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 24 10:52:43.762: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.178 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2751 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 10:52:43.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 10:52:43.763: INFO: ExecWithOptions: Clientset creation
    Aug 24 10:52:43.763: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2751/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.178+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 24 10:52:44.932: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 24 10:52:44.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2751" for this suite. 08/24/22 10:52:44.942
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:52:44.966
Aug 24 10:52:44.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename var-expansion 08/24/22 10:52:44.971
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:45.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:45.019
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 08/24/22 10:52:45.025
Aug 24 10:52:45.042: INFO: Waiting up to 5m0s for pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29" in namespace "var-expansion-2188" to be "Succeeded or Failed"
Aug 24 10:52:45.050: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 8.458824ms
Aug 24 10:52:47.067: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024647681s
Aug 24 10:52:49.056: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01448536s
Aug 24 10:52:51.062: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020291806s
STEP: Saw pod success 08/24/22 10:52:51.062
Aug 24 10:52:51.063: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29" satisfied condition "Succeeded or Failed"
Aug 24 10:52:51.071: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 container dapi-container: <nil>
STEP: delete the pod 08/24/22 10:52:51.355
Aug 24 10:52:51.420: INFO: Waiting for pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 to disappear
Aug 24 10:52:51.428: INFO: Pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 24 10:52:51.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2188" for this suite. 08/24/22 10:52:51.443
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":336,"skipped":6121,"failed":0}
------------------------------
• [SLOW TEST] [6.542 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:52:44.966
    Aug 24 10:52:44.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename var-expansion 08/24/22 10:52:44.971
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:45.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:45.019
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 08/24/22 10:52:45.025
    Aug 24 10:52:45.042: INFO: Waiting up to 5m0s for pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29" in namespace "var-expansion-2188" to be "Succeeded or Failed"
    Aug 24 10:52:45.050: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 8.458824ms
    Aug 24 10:52:47.067: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024647681s
    Aug 24 10:52:49.056: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01448536s
    Aug 24 10:52:51.062: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020291806s
    STEP: Saw pod success 08/24/22 10:52:51.062
    Aug 24 10:52:51.063: INFO: Pod "var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29" satisfied condition "Succeeded or Failed"
    Aug 24 10:52:51.071: INFO: Trying to get logs from node kah9uighaagh-3 pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 container dapi-container: <nil>
    STEP: delete the pod 08/24/22 10:52:51.355
    Aug 24 10:52:51.420: INFO: Waiting for pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 to disappear
    Aug 24 10:52:51.428: INFO: Pod var-expansion-5dd9610e-0eab-44fb-ab5b-90712e073a29 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 24 10:52:51.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2188" for this suite. 08/24/22 10:52:51.443
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:52:51.526
Aug 24 10:52:51.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:52:51.528
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:51.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:51.565
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9061 08/24/22 10:52:51.577
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 08/24/22 10:52:51.585
STEP: Creating stateful set ss in namespace statefulset-9061 08/24/22 10:52:51.592
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9061 08/24/22 10:52:51.604
Aug 24 10:52:51.634: INFO: Found 0 stateful pods, waiting for 1
Aug 24 10:53:01.647: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/24/22 10:53:01.647
Aug 24 10:53:01.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:53:02.045: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:53:02.045: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:53:02.045: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:53:02.056: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 24 10:53:12.085: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:53:12.087: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:53:12.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999518s
Aug 24 10:53:13.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991174058s
Aug 24 10:53:14.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982555373s
Aug 24 10:53:15.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97446935s
Aug 24 10:53:16.142: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968305778s
Aug 24 10:53:17.153: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.96286845s
Aug 24 10:53:18.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.951715139s
Aug 24 10:53:19.169: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.945083885s
Aug 24 10:53:20.177: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.935487136s
Aug 24 10:53:21.184: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.667298ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9061 08/24/22 10:53:22.186
Aug 24 10:53:22.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:53:22.592: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:53:22.592: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:53:22.592: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:53:22.598: INFO: Found 1 stateful pods, waiting for 3
Aug 24 10:53:32.612: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:53:32.612: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 10:53:32.612: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 08/24/22 10:53:32.612
STEP: Scale down will halt with unhealthy stateful pod 08/24/22 10:53:32.613
Aug 24 10:53:32.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:53:33.081: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:53:33.081: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:53:33.081: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:53:33.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:53:33.340: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:53:33.340: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:53:33.340: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:53:33.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 10:53:33.664: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 10:53:33.664: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 10:53:33.664: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 10:53:33.664: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:53:33.674: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 24 10:53:43.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:53:43.688: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:53:43.688: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 10:53:43.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999356s
Aug 24 10:53:44.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991716052s
Aug 24 10:53:45.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981276097s
Aug 24 10:53:46.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969918058s
Aug 24 10:53:47.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960399696s
Aug 24 10:53:48.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.952235287s
Aug 24 10:53:49.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.942160525s
Aug 24 10:53:50.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.933565466s
Aug 24 10:53:51.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.921661703s
Aug 24 10:53:52.798: INFO: Verifying statefulset ss doesn't scale past 3 for another 914.289248ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9061 08/24/22 10:53:53.798
Aug 24 10:53:53.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:53:54.206: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:53:54.206: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:53:54.206: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:53:54.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:53:54.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:53:54.476: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:53:54.476: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:53:54.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 10:53:54.903: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 10:53:54.903: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 10:53:54.903: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 10:53:54.903: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 08/24/22 10:54:04.938
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:54:04.938: INFO: Deleting all statefulset in ns statefulset-9061
Aug 24 10:54:04.945: INFO: Scaling statefulset ss to 0
Aug 24 10:54:04.966: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:54:04.972: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:54:04.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9061" for this suite. 08/24/22 10:54:05.004
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":337,"skipped":6142,"failed":0}
------------------------------
• [SLOW TEST] [73.489 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:52:51.526
    Aug 24 10:52:51.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:52:51.528
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:52:51.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:52:51.565
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9061 08/24/22 10:52:51.577
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 08/24/22 10:52:51.585
    STEP: Creating stateful set ss in namespace statefulset-9061 08/24/22 10:52:51.592
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9061 08/24/22 10:52:51.604
    Aug 24 10:52:51.634: INFO: Found 0 stateful pods, waiting for 1
    Aug 24 10:53:01.647: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/24/22 10:53:01.647
    Aug 24 10:53:01.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:53:02.045: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:53:02.045: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:53:02.045: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:53:02.056: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 24 10:53:12.085: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:53:12.087: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:53:12.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999518s
    Aug 24 10:53:13.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991174058s
    Aug 24 10:53:14.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982555373s
    Aug 24 10:53:15.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97446935s
    Aug 24 10:53:16.142: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968305778s
    Aug 24 10:53:17.153: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.96286845s
    Aug 24 10:53:18.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.951715139s
    Aug 24 10:53:19.169: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.945083885s
    Aug 24 10:53:20.177: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.935487136s
    Aug 24 10:53:21.184: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.667298ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9061 08/24/22 10:53:22.186
    Aug 24 10:53:22.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:53:22.592: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:53:22.592: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:53:22.592: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:53:22.598: INFO: Found 1 stateful pods, waiting for 3
    Aug 24 10:53:32.612: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:53:32.612: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 24 10:53:32.612: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 08/24/22 10:53:32.612
    STEP: Scale down will halt with unhealthy stateful pod 08/24/22 10:53:32.613
    Aug 24 10:53:32.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:53:33.081: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:53:33.081: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:53:33.081: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:53:33.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:53:33.340: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:53:33.340: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:53:33.340: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:53:33.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 24 10:53:33.664: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 24 10:53:33.664: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 24 10:53:33.664: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 24 10:53:33.664: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:53:33.674: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Aug 24 10:53:43.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:53:43.688: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:53:43.688: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 24 10:53:43.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999356s
    Aug 24 10:53:44.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991716052s
    Aug 24 10:53:45.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981276097s
    Aug 24 10:53:46.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969918058s
    Aug 24 10:53:47.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960399696s
    Aug 24 10:53:48.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.952235287s
    Aug 24 10:53:49.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.942160525s
    Aug 24 10:53:50.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.933565466s
    Aug 24 10:53:51.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.921661703s
    Aug 24 10:53:52.798: INFO: Verifying statefulset ss doesn't scale past 3 for another 914.289248ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9061 08/24/22 10:53:53.798
    Aug 24 10:53:53.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:53:54.206: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:53:54.206: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:53:54.206: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:53:54.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:53:54.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:53:54.476: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:53:54.476: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:53:54.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=statefulset-9061 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 24 10:53:54.903: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 24 10:53:54.903: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 24 10:53:54.903: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 24 10:53:54.903: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 08/24/22 10:54:04.938
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:54:04.938: INFO: Deleting all statefulset in ns statefulset-9061
    Aug 24 10:54:04.945: INFO: Scaling statefulset ss to 0
    Aug 24 10:54:04.966: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:54:04.972: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:54:04.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9061" for this suite. 08/24/22 10:54:05.004
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:05.021
Aug 24 10:54:05.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:54:05.027
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:05.076
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:05.08
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-1c9f2034-2a4d-465a-8caa-2b23ee682c08 08/24/22 10:54:05.084
STEP: Creating a pod to test consume configMaps 08/24/22 10:54:05.092
Aug 24 10:54:05.110: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59" in namespace "configmap-3262" to be "Succeeded or Failed"
Aug 24 10:54:05.116: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 5.892765ms
Aug 24 10:54:07.125: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014921658s
Aug 24 10:54:09.126: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015134747s
Aug 24 10:54:11.126: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015398002s
Aug 24 10:54:13.124: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013300906s
STEP: Saw pod success 08/24/22 10:54:13.124
Aug 24 10:54:13.124: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59" satisfied condition "Succeeded or Failed"
Aug 24 10:54:13.130: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 container configmap-volume-test: <nil>
STEP: delete the pod 08/24/22 10:54:13.265
Aug 24 10:54:13.285: INFO: Waiting for pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 to disappear
Aug 24 10:54:13.291: INFO: Pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:54:13.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3262" for this suite. 08/24/22 10:54:13.298
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":338,"skipped":6160,"failed":0}
------------------------------
• [SLOW TEST] [8.288 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:05.021
    Aug 24 10:54:05.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:54:05.027
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:05.076
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:05.08
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-1c9f2034-2a4d-465a-8caa-2b23ee682c08 08/24/22 10:54:05.084
    STEP: Creating a pod to test consume configMaps 08/24/22 10:54:05.092
    Aug 24 10:54:05.110: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59" in namespace "configmap-3262" to be "Succeeded or Failed"
    Aug 24 10:54:05.116: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 5.892765ms
    Aug 24 10:54:07.125: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014921658s
    Aug 24 10:54:09.126: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015134747s
    Aug 24 10:54:11.126: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015398002s
    Aug 24 10:54:13.124: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013300906s
    STEP: Saw pod success 08/24/22 10:54:13.124
    Aug 24 10:54:13.124: INFO: Pod "pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59" satisfied condition "Succeeded or Failed"
    Aug 24 10:54:13.130: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 container configmap-volume-test: <nil>
    STEP: delete the pod 08/24/22 10:54:13.265
    Aug 24 10:54:13.285: INFO: Waiting for pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 to disappear
    Aug 24 10:54:13.291: INFO: Pod pod-configmaps-fb32c0ef-9f8b-4c6f-9dfc-2a8332d87b59 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:54:13.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3262" for this suite. 08/24/22 10:54:13.298
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:13.311
Aug 24 10:54:13.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename endpointslice 08/24/22 10:54:13.314
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:13.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:13.341
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 08/24/22 10:54:13.347
STEP: getting /apis/discovery.k8s.io 08/24/22 10:54:13.352
STEP: getting /apis/discovery.k8s.iov1 08/24/22 10:54:13.353
STEP: creating 08/24/22 10:54:13.355
STEP: getting 08/24/22 10:54:13.383
STEP: listing 08/24/22 10:54:13.39
STEP: watching 08/24/22 10:54:13.423
Aug 24 10:54:13.423: INFO: starting watch
STEP: cluster-wide listing 08/24/22 10:54:13.425
STEP: cluster-wide watching 08/24/22 10:54:13.431
Aug 24 10:54:13.431: INFO: starting watch
STEP: patching 08/24/22 10:54:13.433
STEP: updating 08/24/22 10:54:13.444
Aug 24 10:54:13.459: INFO: waiting for watch events with expected annotations
Aug 24 10:54:13.459: INFO: saw patched and updated annotations
STEP: deleting 08/24/22 10:54:13.459
STEP: deleting a collection 08/24/22 10:54:13.483
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 24 10:54:13.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9507" for this suite. 08/24/22 10:54:13.534
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":339,"skipped":6160,"failed":0}
------------------------------
• [0.237 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:13.311
    Aug 24 10:54:13.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename endpointslice 08/24/22 10:54:13.314
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:13.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:13.341
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 08/24/22 10:54:13.347
    STEP: getting /apis/discovery.k8s.io 08/24/22 10:54:13.352
    STEP: getting /apis/discovery.k8s.iov1 08/24/22 10:54:13.353
    STEP: creating 08/24/22 10:54:13.355
    STEP: getting 08/24/22 10:54:13.383
    STEP: listing 08/24/22 10:54:13.39
    STEP: watching 08/24/22 10:54:13.423
    Aug 24 10:54:13.423: INFO: starting watch
    STEP: cluster-wide listing 08/24/22 10:54:13.425
    STEP: cluster-wide watching 08/24/22 10:54:13.431
    Aug 24 10:54:13.431: INFO: starting watch
    STEP: patching 08/24/22 10:54:13.433
    STEP: updating 08/24/22 10:54:13.444
    Aug 24 10:54:13.459: INFO: waiting for watch events with expected annotations
    Aug 24 10:54:13.459: INFO: saw patched and updated annotations
    STEP: deleting 08/24/22 10:54:13.459
    STEP: deleting a collection 08/24/22 10:54:13.483
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 24 10:54:13.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9507" for this suite. 08/24/22 10:54:13.534
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:13.553
Aug 24 10:54:13.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:54:13.559
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:13.595
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:13.6
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 08/24/22 10:54:13.604
STEP: Ensuring ResourceQuota status is calculated 08/24/22 10:54:13.612
STEP: Creating a ResourceQuota with not terminating scope 08/24/22 10:54:15.621
STEP: Ensuring ResourceQuota status is calculated 08/24/22 10:54:15.633
STEP: Creating a long running pod 08/24/22 10:54:17.641
STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/24/22 10:54:17.667
STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/24/22 10:54:19.673
STEP: Deleting the pod 08/24/22 10:54:21.682
STEP: Ensuring resource quota status released the pod usage 08/24/22 10:54:21.727
STEP: Creating a terminating pod 08/24/22 10:54:23.734
STEP: Ensuring resource quota with terminating scope captures the pod usage 08/24/22 10:54:23.763
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/24/22 10:54:25.77
STEP: Deleting the pod 08/24/22 10:54:27.776
STEP: Ensuring resource quota status released the pod usage 08/24/22 10:54:27.8
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:54:29.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4099" for this suite. 08/24/22 10:54:29.819
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":340,"skipped":6171,"failed":0}
------------------------------
• [SLOW TEST] [16.277 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:13.553
    Aug 24 10:54:13.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:54:13.559
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:13.595
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:13.6
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 08/24/22 10:54:13.604
    STEP: Ensuring ResourceQuota status is calculated 08/24/22 10:54:13.612
    STEP: Creating a ResourceQuota with not terminating scope 08/24/22 10:54:15.621
    STEP: Ensuring ResourceQuota status is calculated 08/24/22 10:54:15.633
    STEP: Creating a long running pod 08/24/22 10:54:17.641
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/24/22 10:54:17.667
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/24/22 10:54:19.673
    STEP: Deleting the pod 08/24/22 10:54:21.682
    STEP: Ensuring resource quota status released the pod usage 08/24/22 10:54:21.727
    STEP: Creating a terminating pod 08/24/22 10:54:23.734
    STEP: Ensuring resource quota with terminating scope captures the pod usage 08/24/22 10:54:23.763
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/24/22 10:54:25.77
    STEP: Deleting the pod 08/24/22 10:54:27.776
    STEP: Ensuring resource quota status released the pod usage 08/24/22 10:54:27.8
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:54:29.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4099" for this suite. 08/24/22 10:54:29.819
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:29.836
Aug 24 10:54:29.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:54:29.84
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:29.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:29.881
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:54:29.891
Aug 24 10:54:29.906: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8247" to be "running and ready"
Aug 24 10:54:29.916: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.843858ms
Aug 24 10:54:29.916: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:54:31.923: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016578348s
Aug 24 10:54:31.923: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 24 10:54:31.923: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 08/24/22 10:54:31.929
Aug 24 10:54:31.938: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8247" to be "running and ready"
Aug 24 10:54:31.947: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.756261ms
Aug 24 10:54:31.947: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:54:33.955: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.01612527s
Aug 24 10:54:33.955: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Aug 24 10:54:33.955: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/24/22 10:54:33.96
Aug 24 10:54:33.972: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 24 10:54:33.980: INFO: Pod pod-with-prestop-http-hook still exists
Aug 24 10:54:35.981: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 24 10:54:35.989: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 08/24/22 10:54:35.99
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 24 10:54:36.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8247" for this suite. 08/24/22 10:54:36.058
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":341,"skipped":6210,"failed":0}
------------------------------
• [SLOW TEST] [6.305 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:29.836
    Aug 24 10:54:29.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:54:29.84
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:29.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:29.881
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:54:29.891
    Aug 24 10:54:29.906: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8247" to be "running and ready"
    Aug 24 10:54:29.916: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.843858ms
    Aug 24 10:54:29.916: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:54:31.923: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016578348s
    Aug 24 10:54:31.923: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 24 10:54:31.923: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 08/24/22 10:54:31.929
    Aug 24 10:54:31.938: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8247" to be "running and ready"
    Aug 24 10:54:31.947: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.756261ms
    Aug 24 10:54:31.947: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:54:33.955: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.01612527s
    Aug 24 10:54:33.955: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Aug 24 10:54:33.955: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/24/22 10:54:33.96
    Aug 24 10:54:33.972: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 24 10:54:33.980: INFO: Pod pod-with-prestop-http-hook still exists
    Aug 24 10:54:35.981: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 24 10:54:35.989: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 08/24/22 10:54:35.99
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 24 10:54:36.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8247" for this suite. 08/24/22 10:54:36.058
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:36.164
Aug 24 10:54:36.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename deployment 08/24/22 10:54:36.177
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:36.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:36.218
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Aug 24 10:54:36.239: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 24 10:54:41.252: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/24/22 10:54:41.252
Aug 24 10:54:41.252: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/24/22 10:54:41.27
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 24 10:54:41.289: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1444  a7b5fe7a-536a-44fa-81d4-fe39805809c3 33890 1 2022-08-24 10:54:41 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-08-24 10:54:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043bacb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug 24 10:54:41.296: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Aug 24 10:54:41.296: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 24 10:54:41.297: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1444  03a4c802-525a-4e03-bca3-6166db4b3fd9 33891 1 2022-08-24 10:54:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a7b5fe7a-536a-44fa-81d4-fe39805809c3 0xc003cd3af7 0xc003cd3af8}] [] [{e2e.test Update apps/v1 2022-08-24 10:54:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:54:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 10:54:41 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a7b5fe7a-536a-44fa-81d4-fe39805809c3\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003cd3bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 10:54:41.303: INFO: Pod "test-cleanup-controller-s4mm8" is available:
&Pod{ObjectMeta:{test-cleanup-controller-s4mm8 test-cleanup-controller- deployment-1444  0ec7354a-c334-4cc1-a149-46c27fd31e2f 33880 0 2022-08-24 10:54:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 03a4c802-525a-4e03-bca3-6166db4b3fd9 0xc0043baff7 0xc0043baff8}] [] [{kube-controller-manager Update v1 2022-08-24 10:54:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"03a4c802-525a-4e03-bca3-6166db4b3fd9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:54:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6rkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6rkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.183,StartTime:2022-08-24 10:54:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 10:54:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://023e7a9850b7f139bbbc30ff2470246ae2f673ab662e09757905d6a07eecd15c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 24 10:54:41.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1444" for this suite. 08/24/22 10:54:41.311
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":342,"skipped":6215,"failed":0}
------------------------------
• [SLOW TEST] [5.159 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:36.164
    Aug 24 10:54:36.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename deployment 08/24/22 10:54:36.177
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:36.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:36.218
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Aug 24 10:54:36.239: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Aug 24 10:54:41.252: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/24/22 10:54:41.252
    Aug 24 10:54:41.252: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/24/22 10:54:41.27
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 24 10:54:41.289: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1444  a7b5fe7a-536a-44fa-81d4-fe39805809c3 33890 1 2022-08-24 10:54:41 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-08-24 10:54:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043bacb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 24 10:54:41.296: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Aug 24 10:54:41.296: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Aug 24 10:54:41.297: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1444  03a4c802-525a-4e03-bca3-6166db4b3fd9 33891 1 2022-08-24 10:54:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a7b5fe7a-536a-44fa-81d4-fe39805809c3 0xc003cd3af7 0xc003cd3af8}] [] [{e2e.test Update apps/v1 2022-08-24 10:54:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 10:54:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-24 10:54:41 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a7b5fe7a-536a-44fa-81d4-fe39805809c3\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003cd3bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 24 10:54:41.303: INFO: Pod "test-cleanup-controller-s4mm8" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-s4mm8 test-cleanup-controller- deployment-1444  0ec7354a-c334-4cc1-a149-46c27fd31e2f 33880 0 2022-08-24 10:54:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 03a4c802-525a-4e03-bca3-6166db4b3fd9 0xc0043baff7 0xc0043baff8}] [] [{kube-controller-manager Update v1 2022-08-24 10:54:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"03a4c802-525a-4e03-bca3-6166db4b3fd9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 10:54:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6rkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6rkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kah9uighaagh-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 10:54:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.54,PodIP:10.233.66.183,StartTime:2022-08-24 10:54:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 10:54:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://023e7a9850b7f139bbbc30ff2470246ae2f673ab662e09757905d6a07eecd15c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 24 10:54:41.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1444" for this suite. 08/24/22 10:54:41.311
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:41.333
Aug 24 10:54:41.334: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename security-context-test 08/24/22 10:54:41.336
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:41.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:41.391
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Aug 24 10:54:41.442: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6" in namespace "security-context-test-9989" to be "Succeeded or Failed"
Aug 24 10:54:41.460: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.794896ms
Aug 24 10:54:43.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026753637s
Aug 24 10:54:45.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026009775s
Aug 24 10:54:47.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026480014s
Aug 24 10:54:47.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 24 10:54:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9989" for this suite. 08/24/22 10:54:47.478
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":343,"skipped":6263,"failed":0}
------------------------------
• [SLOW TEST] [6.158 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:41.333
    Aug 24 10:54:41.334: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename security-context-test 08/24/22 10:54:41.336
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:41.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:41.391
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Aug 24 10:54:41.442: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6" in namespace "security-context-test-9989" to be "Succeeded or Failed"
    Aug 24 10:54:41.460: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.794896ms
    Aug 24 10:54:43.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026753637s
    Aug 24 10:54:45.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026009775s
    Aug 24 10:54:47.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026480014s
    Aug 24 10:54:47.469: INFO: Pod "busybox-readonly-false-25af6f69-e8d5-4691-a74d-bfd35f665ba6" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 24 10:54:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9989" for this suite. 08/24/22 10:54:47.478
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:54:47.496
Aug 24 10:54:47.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:54:47.499
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:47.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:47.539
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1722 08/24/22 10:54:47.542
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 08/24/22 10:54:47.552
STEP: Creating pod with conflicting port in namespace statefulset-1722 08/24/22 10:54:47.561
STEP: Waiting until pod test-pod will start running in namespace statefulset-1722 08/24/22 10:54:47.586
Aug 24 10:54:47.587: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1722" to be "running"
Aug 24 10:54:47.592: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.908296ms
Aug 24 10:54:49.601: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014313065s
Aug 24 10:54:49.601: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-1722 08/24/22 10:54:49.601
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1722 08/24/22 10:54:49.613
Aug 24 10:54:49.643: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Pending. Waiting for statefulset controller to delete.
Aug 24 10:54:49.698: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Failed. Waiting for statefulset controller to delete.
Aug 24 10:54:49.728: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Failed. Waiting for statefulset controller to delete.
Aug 24 10:54:49.736: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1722
STEP: Removing pod with conflicting port in namespace statefulset-1722 08/24/22 10:54:49.737
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1722 and will be in running state 08/24/22 10:54:49.773
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:55:05.850: INFO: Deleting all statefulset in ns statefulset-1722
Aug 24 10:55:05.855: INFO: Scaling statefulset ss to 0
Aug 24 10:55:15.898: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:55:15.903: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:55:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1722" for this suite. 08/24/22 10:55:15.933
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":344,"skipped":6272,"failed":0}
------------------------------
• [SLOW TEST] [28.448 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:54:47.496
    Aug 24 10:54:47.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:54:47.499
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:54:47.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:54:47.539
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1722 08/24/22 10:54:47.542
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 08/24/22 10:54:47.552
    STEP: Creating pod with conflicting port in namespace statefulset-1722 08/24/22 10:54:47.561
    STEP: Waiting until pod test-pod will start running in namespace statefulset-1722 08/24/22 10:54:47.586
    Aug 24 10:54:47.587: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1722" to be "running"
    Aug 24 10:54:47.592: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.908296ms
    Aug 24 10:54:49.601: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014313065s
    Aug 24 10:54:49.601: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-1722 08/24/22 10:54:49.601
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1722 08/24/22 10:54:49.613
    Aug 24 10:54:49.643: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Pending. Waiting for statefulset controller to delete.
    Aug 24 10:54:49.698: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 24 10:54:49.728: INFO: Observed stateful pod in namespace: statefulset-1722, name: ss-0, uid: 7dcb8e2d-012d-4989-9325-b5e1c56f4859, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 24 10:54:49.736: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1722
    STEP: Removing pod with conflicting port in namespace statefulset-1722 08/24/22 10:54:49.737
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1722 and will be in running state 08/24/22 10:54:49.773
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:55:05.850: INFO: Deleting all statefulset in ns statefulset-1722
    Aug 24 10:55:05.855: INFO: Scaling statefulset ss to 0
    Aug 24 10:55:15.898: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:55:15.903: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:55:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1722" for this suite. 08/24/22 10:55:15.933
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:55:15.946
Aug 24 10:55:15.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename resourcequota 08/24/22 10:55:15.955
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:16.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:16.024
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 08/24/22 10:55:16.029
STEP: Creating a ResourceQuota 08/24/22 10:55:21.036
STEP: Ensuring resource quota status is calculated 08/24/22 10:55:21.045
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 24 10:55:23.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1587" for this suite. 08/24/22 10:55:23.062
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":345,"skipped":6282,"failed":0}
------------------------------
• [SLOW TEST] [7.127 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:55:15.946
    Aug 24 10:55:15.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename resourcequota 08/24/22 10:55:15.955
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:16.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:16.024
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 08/24/22 10:55:16.029
    STEP: Creating a ResourceQuota 08/24/22 10:55:21.036
    STEP: Ensuring resource quota status is calculated 08/24/22 10:55:21.045
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 24 10:55:23.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1587" for this suite. 08/24/22 10:55:23.062
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:55:23.075
Aug 24 10:55:23.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename kubectl 08/24/22 10:55:23.079
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:23.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:23.109
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 08/24/22 10:55:23.113
Aug 24 10:55:23.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 create -f -'
Aug 24 10:55:25.043: INFO: stderr: ""
Aug 24 10:55:25.043: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:25.043
Aug 24 10:55:25.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:55:25.247: INFO: stderr: ""
Aug 24 10:55:25.248: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
Aug 24 10:55:25.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:25.386: INFO: stderr: ""
Aug 24 10:55:25.386: INFO: stdout: ""
Aug 24 10:55:25.386: INFO: update-demo-nautilus-5nn6b is created but not running
Aug 24 10:55:30.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:55:30.536: INFO: stderr: ""
Aug 24 10:55:30.536: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
Aug 24 10:55:30.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:30.679: INFO: stderr: ""
Aug 24 10:55:30.679: INFO: stdout: "true"
Aug 24 10:55:30.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:55:30.818: INFO: stderr: ""
Aug 24 10:55:30.819: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:55:30.819: INFO: validating pod update-demo-nautilus-5nn6b
Aug 24 10:55:30.832: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:55:30.832: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:55:30.832: INFO: update-demo-nautilus-5nn6b is verified up and running
Aug 24 10:55:30.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:31.027: INFO: stderr: ""
Aug 24 10:55:31.027: INFO: stdout: "true"
Aug 24 10:55:31.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:55:31.183: INFO: stderr: ""
Aug 24 10:55:31.183: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:55:31.183: INFO: validating pod update-demo-nautilus-lkrpp
Aug 24 10:55:46.545: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:55:46.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:55:46.545: INFO: update-demo-nautilus-lkrpp is verified up and running
STEP: scaling down the replication controller 08/24/22 10:55:46.545
Aug 24 10:55:46.562: INFO: scanned /root for discovery docs: <nil>
Aug 24 10:55:46.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Aug 24 10:55:47.763: INFO: stderr: ""
Aug 24 10:55:47.763: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:47.763
Aug 24 10:55:47.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:55:47.972: INFO: stderr: ""
Aug 24 10:55:47.972: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
STEP: Replicas for name=update-demo: expected=1 actual=2 08/24/22 10:55:47.972
Aug 24 10:55:52.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:55:53.157: INFO: stderr: ""
Aug 24 10:55:53.157: INFO: stdout: "update-demo-nautilus-lkrpp "
Aug 24 10:55:53.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:53.353: INFO: stderr: ""
Aug 24 10:55:53.353: INFO: stdout: "true"
Aug 24 10:55:53.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:55:53.562: INFO: stderr: ""
Aug 24 10:55:53.562: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:55:53.562: INFO: validating pod update-demo-nautilus-lkrpp
Aug 24 10:55:53.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:55:53.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:55:53.571: INFO: update-demo-nautilus-lkrpp is verified up and running
STEP: scaling up the replication controller 08/24/22 10:55:53.571
Aug 24 10:55:53.583: INFO: scanned /root for discovery docs: <nil>
Aug 24 10:55:53.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Aug 24 10:55:54.833: INFO: stderr: ""
Aug 24 10:55:54.833: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:54.833
Aug 24 10:55:54.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 10:55:55.027: INFO: stderr: ""
Aug 24 10:55:55.027: INFO: stdout: "update-demo-nautilus-lkrpp update-demo-nautilus-q95jj "
Aug 24 10:55:55.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:55.202: INFO: stderr: ""
Aug 24 10:55:55.202: INFO: stdout: "true"
Aug 24 10:55:55.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:55:55.419: INFO: stderr: ""
Aug 24 10:55:55.419: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:55:55.419: INFO: validating pod update-demo-nautilus-lkrpp
Aug 24 10:55:55.430: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:55:55.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:55:55.430: INFO: update-demo-nautilus-lkrpp is verified up and running
Aug 24 10:55:55.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-q95jj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 10:55:55.590: INFO: stderr: ""
Aug 24 10:55:55.591: INFO: stdout: "true"
Aug 24 10:55:55.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-q95jj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 10:55:55.750: INFO: stderr: ""
Aug 24 10:55:55.750: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 24 10:55:55.750: INFO: validating pod update-demo-nautilus-q95jj
Aug 24 10:55:55.769: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 10:55:55.769: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 10:55:55.769: INFO: update-demo-nautilus-q95jj is verified up and running
STEP: using delete to clean up resources 08/24/22 10:55:55.769
Aug 24 10:55:55.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 delete --grace-period=0 --force -f -'
Aug 24 10:55:55.955: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 10:55:55.955: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 24 10:55:55.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get rc,svc -l name=update-demo --no-headers'
Aug 24 10:55:56.294: INFO: stderr: "No resources found in kubectl-5212 namespace.\n"
Aug 24 10:55:56.294: INFO: stdout: ""
Aug 24 10:55:56.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 10:55:56.497: INFO: stderr: ""
Aug 24 10:55:56.497: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 24 10:55:56.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5212" for this suite. 08/24/22 10:55:56.515
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":346,"skipped":6286,"failed":0}
------------------------------
• [SLOW TEST] [33.451 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:55:23.075
    Aug 24 10:55:23.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename kubectl 08/24/22 10:55:23.079
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:23.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:23.109
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 08/24/22 10:55:23.113
    Aug 24 10:55:23.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 create -f -'
    Aug 24 10:55:25.043: INFO: stderr: ""
    Aug 24 10:55:25.043: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:25.043
    Aug 24 10:55:25.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:55:25.247: INFO: stderr: ""
    Aug 24 10:55:25.248: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
    Aug 24 10:55:25.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:25.386: INFO: stderr: ""
    Aug 24 10:55:25.386: INFO: stdout: ""
    Aug 24 10:55:25.386: INFO: update-demo-nautilus-5nn6b is created but not running
    Aug 24 10:55:30.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:55:30.536: INFO: stderr: ""
    Aug 24 10:55:30.536: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
    Aug 24 10:55:30.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:30.679: INFO: stderr: ""
    Aug 24 10:55:30.679: INFO: stdout: "true"
    Aug 24 10:55:30.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-5nn6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:55:30.818: INFO: stderr: ""
    Aug 24 10:55:30.819: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:55:30.819: INFO: validating pod update-demo-nautilus-5nn6b
    Aug 24 10:55:30.832: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:55:30.832: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:55:30.832: INFO: update-demo-nautilus-5nn6b is verified up and running
    Aug 24 10:55:30.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:31.027: INFO: stderr: ""
    Aug 24 10:55:31.027: INFO: stdout: "true"
    Aug 24 10:55:31.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:55:31.183: INFO: stderr: ""
    Aug 24 10:55:31.183: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:55:31.183: INFO: validating pod update-demo-nautilus-lkrpp
    Aug 24 10:55:46.545: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:55:46.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:55:46.545: INFO: update-demo-nautilus-lkrpp is verified up and running
    STEP: scaling down the replication controller 08/24/22 10:55:46.545
    Aug 24 10:55:46.562: INFO: scanned /root for discovery docs: <nil>
    Aug 24 10:55:46.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Aug 24 10:55:47.763: INFO: stderr: ""
    Aug 24 10:55:47.763: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:47.763
    Aug 24 10:55:47.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:55:47.972: INFO: stderr: ""
    Aug 24 10:55:47.972: INFO: stdout: "update-demo-nautilus-5nn6b update-demo-nautilus-lkrpp "
    STEP: Replicas for name=update-demo: expected=1 actual=2 08/24/22 10:55:47.972
    Aug 24 10:55:52.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:55:53.157: INFO: stderr: ""
    Aug 24 10:55:53.157: INFO: stdout: "update-demo-nautilus-lkrpp "
    Aug 24 10:55:53.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:53.353: INFO: stderr: ""
    Aug 24 10:55:53.353: INFO: stdout: "true"
    Aug 24 10:55:53.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:55:53.562: INFO: stderr: ""
    Aug 24 10:55:53.562: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:55:53.562: INFO: validating pod update-demo-nautilus-lkrpp
    Aug 24 10:55:53.571: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:55:53.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:55:53.571: INFO: update-demo-nautilus-lkrpp is verified up and running
    STEP: scaling up the replication controller 08/24/22 10:55:53.571
    Aug 24 10:55:53.583: INFO: scanned /root for discovery docs: <nil>
    Aug 24 10:55:53.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Aug 24 10:55:54.833: INFO: stderr: ""
    Aug 24 10:55:54.833: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/24/22 10:55:54.833
    Aug 24 10:55:54.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 24 10:55:55.027: INFO: stderr: ""
    Aug 24 10:55:55.027: INFO: stdout: "update-demo-nautilus-lkrpp update-demo-nautilus-q95jj "
    Aug 24 10:55:55.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:55.202: INFO: stderr: ""
    Aug 24 10:55:55.202: INFO: stdout: "true"
    Aug 24 10:55:55.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-lkrpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:55:55.419: INFO: stderr: ""
    Aug 24 10:55:55.419: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:55:55.419: INFO: validating pod update-demo-nautilus-lkrpp
    Aug 24 10:55:55.430: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:55:55.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:55:55.430: INFO: update-demo-nautilus-lkrpp is verified up and running
    Aug 24 10:55:55.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-q95jj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 24 10:55:55.590: INFO: stderr: ""
    Aug 24 10:55:55.591: INFO: stdout: "true"
    Aug 24 10:55:55.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods update-demo-nautilus-q95jj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 24 10:55:55.750: INFO: stderr: ""
    Aug 24 10:55:55.750: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 24 10:55:55.750: INFO: validating pod update-demo-nautilus-q95jj
    Aug 24 10:55:55.769: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 24 10:55:55.769: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 24 10:55:55.769: INFO: update-demo-nautilus-q95jj is verified up and running
    STEP: using delete to clean up resources 08/24/22 10:55:55.769
    Aug 24 10:55:55.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 delete --grace-period=0 --force -f -'
    Aug 24 10:55:55.955: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 24 10:55:55.955: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 24 10:55:55.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get rc,svc -l name=update-demo --no-headers'
    Aug 24 10:55:56.294: INFO: stderr: "No resources found in kubectl-5212 namespace.\n"
    Aug 24 10:55:56.294: INFO: stdout: ""
    Aug 24 10:55:56.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=kubectl-5212 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 24 10:55:56.497: INFO: stderr: ""
    Aug 24 10:55:56.497: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 24 10:55:56.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5212" for this suite. 08/24/22 10:55:56.515
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:55:56.527
Aug 24 10:55:56.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename dns 08/24/22 10:55:56.535
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:56.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:56.586
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 08/24/22 10:55:56.593
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:55:56.611
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:55:56.611
STEP: creating a pod to probe DNS 08/24/22 10:55:56.611
STEP: submitting the pod to kubernetes 08/24/22 10:55:56.611
Aug 24 10:55:56.635: INFO: Waiting up to 15m0s for pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623" in namespace "dns-3156" to be "running"
Aug 24 10:55:56.658: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 22.222171ms
Aug 24 10:55:58.674: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038575903s
Aug 24 10:56:00.665: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029066984s
Aug 24 10:56:02.673: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037685332s
Aug 24 10:56:04.668: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Running", Reason="", readiness=true. Elapsed: 8.03201241s
Aug 24 10:56:04.668: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:56:04.668
STEP: looking for the results for each expected name from probers 08/24/22 10:56:04.675
Aug 24 10:56:04.695: INFO: DNS probes using dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623 succeeded

STEP: deleting the pod 08/24/22 10:56:04.695
STEP: changing the externalName to bar.example.com 08/24/22 10:56:04.725
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:56:04.747
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:56:04.747
STEP: creating a second pod to probe DNS 08/24/22 10:56:04.748
STEP: submitting the pod to kubernetes 08/24/22 10:56:04.748
Aug 24 10:56:04.763: INFO: Waiting up to 15m0s for pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e" in namespace "dns-3156" to be "running"
Aug 24 10:56:04.776: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.681715ms
Aug 24 10:56:06.785: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022084993s
Aug 24 10:56:08.784: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Running", Reason="", readiness=true. Elapsed: 4.020342057s
Aug 24 10:56:08.784: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:56:08.784
STEP: looking for the results for each expected name from probers 08/24/22 10:56:08.793
Aug 24 10:56:08.814: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:08.824: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:08.824: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:13.834: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:13.840: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:13.840: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:18.833: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:18.839: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:18.839: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:23.832: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:23.838: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:23.838: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:28.843: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:28.853: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:28.855: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:33.836: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 10:56:33.845: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local]

Aug 24 10:56:38.851: INFO: DNS probes using dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e succeeded

STEP: deleting the pod 08/24/22 10:56:38.851
STEP: changing the service to type=ClusterIP 08/24/22 10:56:38.885
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:56:38.924
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
 08/24/22 10:56:38.925
STEP: creating a third pod to probe DNS 08/24/22 10:56:38.925
STEP: submitting the pod to kubernetes 08/24/22 10:56:38.932
Aug 24 10:56:38.950: INFO: Waiting up to 15m0s for pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d" in namespace "dns-3156" to be "running"
Aug 24 10:56:38.963: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.831104ms
Aug 24 10:56:40.972: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022672637s
Aug 24 10:56:42.971: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Running", Reason="", readiness=true. Elapsed: 4.021234596s
Aug 24 10:56:42.971: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d" satisfied condition "running"
STEP: retrieving the pod 08/24/22 10:56:42.971
STEP: looking for the results for each expected name from probers 08/24/22 10:56:42.976
Aug 24 10:56:42.993: INFO: DNS probes using dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d succeeded

STEP: deleting the pod 08/24/22 10:56:42.993
STEP: deleting the test externalName service 08/24/22 10:56:43.011
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 24 10:56:43.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3156" for this suite. 08/24/22 10:56:43.078
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":347,"skipped":6295,"failed":0}
------------------------------
• [SLOW TEST] [46.575 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:55:56.527
    Aug 24 10:55:56.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename dns 08/24/22 10:55:56.535
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:55:56.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:55:56.586
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 08/24/22 10:55:56.593
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:55:56.611
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:55:56.611
    STEP: creating a pod to probe DNS 08/24/22 10:55:56.611
    STEP: submitting the pod to kubernetes 08/24/22 10:55:56.611
    Aug 24 10:55:56.635: INFO: Waiting up to 15m0s for pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623" in namespace "dns-3156" to be "running"
    Aug 24 10:55:56.658: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 22.222171ms
    Aug 24 10:55:58.674: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038575903s
    Aug 24 10:56:00.665: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029066984s
    Aug 24 10:56:02.673: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037685332s
    Aug 24 10:56:04.668: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623": Phase="Running", Reason="", readiness=true. Elapsed: 8.03201241s
    Aug 24 10:56:04.668: INFO: Pod "dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:56:04.668
    STEP: looking for the results for each expected name from probers 08/24/22 10:56:04.675
    Aug 24 10:56:04.695: INFO: DNS probes using dns-test-9c6665c8-ae6a-47d7-9e19-5190d1fce623 succeeded

    STEP: deleting the pod 08/24/22 10:56:04.695
    STEP: changing the externalName to bar.example.com 08/24/22 10:56:04.725
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:56:04.747
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:56:04.747
    STEP: creating a second pod to probe DNS 08/24/22 10:56:04.748
    STEP: submitting the pod to kubernetes 08/24/22 10:56:04.748
    Aug 24 10:56:04.763: INFO: Waiting up to 15m0s for pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e" in namespace "dns-3156" to be "running"
    Aug 24 10:56:04.776: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.681715ms
    Aug 24 10:56:06.785: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022084993s
    Aug 24 10:56:08.784: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e": Phase="Running", Reason="", readiness=true. Elapsed: 4.020342057s
    Aug 24 10:56:08.784: INFO: Pod "dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:56:08.784
    STEP: looking for the results for each expected name from probers 08/24/22 10:56:08.793
    Aug 24 10:56:08.814: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:08.824: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:08.824: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:13.834: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:13.840: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:13.840: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:18.833: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:18.839: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:18.839: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:23.832: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:23.838: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:23.838: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:28.843: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:28.853: INFO: File jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:28.855: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:33.836: INFO: File wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local from pod  dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 24 10:56:33.845: INFO: Lookups using dns-3156/dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e failed for: [wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local]

    Aug 24 10:56:38.851: INFO: DNS probes using dns-test-bff941af-1c53-4e4d-a90a-92ce06bdcd4e succeeded

    STEP: deleting the pod 08/24/22 10:56:38.851
    STEP: changing the service to type=ClusterIP 08/24/22 10:56:38.885
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:56:38.924
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3156.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3156.svc.cluster.local; sleep 1; done
     08/24/22 10:56:38.925
    STEP: creating a third pod to probe DNS 08/24/22 10:56:38.925
    STEP: submitting the pod to kubernetes 08/24/22 10:56:38.932
    Aug 24 10:56:38.950: INFO: Waiting up to 15m0s for pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d" in namespace "dns-3156" to be "running"
    Aug 24 10:56:38.963: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.831104ms
    Aug 24 10:56:40.972: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022672637s
    Aug 24 10:56:42.971: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d": Phase="Running", Reason="", readiness=true. Elapsed: 4.021234596s
    Aug 24 10:56:42.971: INFO: Pod "dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d" satisfied condition "running"
    STEP: retrieving the pod 08/24/22 10:56:42.971
    STEP: looking for the results for each expected name from probers 08/24/22 10:56:42.976
    Aug 24 10:56:42.993: INFO: DNS probes using dns-test-63515455-f0f4-4b30-aca9-c2e6d81d976d succeeded

    STEP: deleting the pod 08/24/22 10:56:42.993
    STEP: deleting the test externalName service 08/24/22 10:56:43.011
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 24 10:56:43.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3156" for this suite. 08/24/22 10:56:43.078
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:56:43.133
Aug 24 10:56:43.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:56:43.14
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:43.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:43.187
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Aug 24 10:56:43.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:56:47.105
Aug 24 10:56:47.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 create -f -'
Aug 24 10:56:49.149: INFO: stderr: ""
Aug 24 10:56:49.149: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 24 10:56:49.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 delete e2e-test-crd-publish-openapi-4266-crds test-cr'
Aug 24 10:56:49.499: INFO: stderr: ""
Aug 24 10:56:49.499: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 24 10:56:49.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 apply -f -'
Aug 24 10:56:50.885: INFO: stderr: ""
Aug 24 10:56:50.885: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 24 10:56:50.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 delete e2e-test-crd-publish-openapi-4266-crds test-cr'
Aug 24 10:56:51.072: INFO: stderr: ""
Aug 24 10:56:51.072: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/24/22 10:56:51.072
Aug 24 10:56:51.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 explain e2e-test-crd-publish-openapi-4266-crds'
Aug 24 10:56:51.528: INFO: stderr: ""
Aug 24 10:56:51.528: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4266-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 24 10:56:55.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8606" for this suite. 08/24/22 10:56:55.248
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":348,"skipped":6312,"failed":0}
------------------------------
• [SLOW TEST] [12.127 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:56:43.133
    Aug 24 10:56:43.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename crd-publish-openapi 08/24/22 10:56:43.14
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:43.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:43.187
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Aug 24 10:56:43.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/24/22 10:56:47.105
    Aug 24 10:56:47.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 create -f -'
    Aug 24 10:56:49.149: INFO: stderr: ""
    Aug 24 10:56:49.149: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 24 10:56:49.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 delete e2e-test-crd-publish-openapi-4266-crds test-cr'
    Aug 24 10:56:49.499: INFO: stderr: ""
    Aug 24 10:56:49.499: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Aug 24 10:56:49.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 apply -f -'
    Aug 24 10:56:50.885: INFO: stderr: ""
    Aug 24 10:56:50.885: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 24 10:56:50.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 --namespace=crd-publish-openapi-8606 delete e2e-test-crd-publish-openapi-4266-crds test-cr'
    Aug 24 10:56:51.072: INFO: stderr: ""
    Aug 24 10:56:51.072: INFO: stdout: "e2e-test-crd-publish-openapi-4266-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/24/22 10:56:51.072
    Aug 24 10:56:51.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=crd-publish-openapi-8606 explain e2e-test-crd-publish-openapi-4266-crds'
    Aug 24 10:56:51.528: INFO: stderr: ""
    Aug 24 10:56:51.528: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4266-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 24 10:56:55.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8606" for this suite. 08/24/22 10:56:55.248
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:56:55.262
Aug 24 10:56:55.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename namespaces 08/24/22 10:56:55.265
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:55.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:55.307
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 08/24/22 10:56:55.312
STEP: patching the Namespace 08/24/22 10:56:55.337
STEP: get the Namespace and ensuring it has the label 08/24/22 10:56:55.346
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 24 10:56:55.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1828" for this suite. 08/24/22 10:56:55.358
STEP: Destroying namespace "nspatchtest-306af0d4-b054-4c80-8c78-55685b852c0d-2165" for this suite. 08/24/22 10:56:55.391
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":349,"skipped":6319,"failed":0}
------------------------------
• [0.171 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:56:55.262
    Aug 24 10:56:55.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename namespaces 08/24/22 10:56:55.265
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:55.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:55.307
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 08/24/22 10:56:55.312
    STEP: patching the Namespace 08/24/22 10:56:55.337
    STEP: get the Namespace and ensuring it has the label 08/24/22 10:56:55.346
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 10:56:55.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1828" for this suite. 08/24/22 10:56:55.358
    STEP: Destroying namespace "nspatchtest-306af0d4-b054-4c80-8c78-55685b852c0d-2165" for this suite. 08/24/22 10:56:55.391
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:56:55.443
Aug 24 10:56:55.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:56:55.449
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:55.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:55.497
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/24/22 10:56:55.501
Aug 24 10:56:55.516: INFO: Waiting up to 5m0s for pod "pod-6b682777-962d-41f8-b401-4e49337a9332" in namespace "emptydir-9083" to be "Succeeded or Failed"
Aug 24 10:56:55.529: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 12.212718ms
Aug 24 10:56:57.537: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020144463s
Aug 24 10:56:59.543: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026006402s
Aug 24 10:57:01.558: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041827264s
Aug 24 10:57:03.537: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020094949s
STEP: Saw pod success 08/24/22 10:57:03.537
Aug 24 10:57:03.538: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332" satisfied condition "Succeeded or Failed"
Aug 24 10:57:03.544: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-6b682777-962d-41f8-b401-4e49337a9332 container test-container: <nil>
STEP: delete the pod 08/24/22 10:57:03.572
Aug 24 10:57:03.596: INFO: Waiting for pod pod-6b682777-962d-41f8-b401-4e49337a9332 to disappear
Aug 24 10:57:03.603: INFO: Pod pod-6b682777-962d-41f8-b401-4e49337a9332 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 10:57:03.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9083" for this suite. 08/24/22 10:57:03.61
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":350,"skipped":6394,"failed":0}
------------------------------
• [SLOW TEST] [8.176 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:56:55.443
    Aug 24 10:56:55.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:56:55.449
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:56:55.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:56:55.497
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/24/22 10:56:55.501
    Aug 24 10:56:55.516: INFO: Waiting up to 5m0s for pod "pod-6b682777-962d-41f8-b401-4e49337a9332" in namespace "emptydir-9083" to be "Succeeded or Failed"
    Aug 24 10:56:55.529: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 12.212718ms
    Aug 24 10:56:57.537: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020144463s
    Aug 24 10:56:59.543: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026006402s
    Aug 24 10:57:01.558: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041827264s
    Aug 24 10:57:03.537: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020094949s
    STEP: Saw pod success 08/24/22 10:57:03.537
    Aug 24 10:57:03.538: INFO: Pod "pod-6b682777-962d-41f8-b401-4e49337a9332" satisfied condition "Succeeded or Failed"
    Aug 24 10:57:03.544: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-6b682777-962d-41f8-b401-4e49337a9332 container test-container: <nil>
    STEP: delete the pod 08/24/22 10:57:03.572
    Aug 24 10:57:03.596: INFO: Waiting for pod pod-6b682777-962d-41f8-b401-4e49337a9332 to disappear
    Aug 24 10:57:03.603: INFO: Pod pod-6b682777-962d-41f8-b401-4e49337a9332 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 10:57:03.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9083" for this suite. 08/24/22 10:57:03.61
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:03.622
Aug 24 10:57:03.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:57:03.626
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:03.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:03.661
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:57:03.673
Aug 24 10:57:03.687: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6699" to be "running and ready"
Aug 24 10:57:03.694: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.438555ms
Aug 24 10:57:03.695: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:57:05.703: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01558154s
Aug 24 10:57:05.703: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 24 10:57:05.703: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 08/24/22 10:57:05.71
Aug 24 10:57:05.721: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-6699" to be "running and ready"
Aug 24 10:57:05.729: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.955473ms
Aug 24 10:57:05.729: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:57:07.742: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020842868s
Aug 24 10:57:07.742: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:57:09.744: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023216474s
Aug 24 10:57:09.744: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Aug 24 10:57:09.744: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/24/22 10:57:09.753
Aug 24 10:57:09.772: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 24 10:57:09.784: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 24 10:57:11.785: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 24 10:57:11.793: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 08/24/22 10:57:11.793
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 24 10:57:11.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6699" for this suite. 08/24/22 10:57:11.844
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":351,"skipped":6413,"failed":0}
------------------------------
• [SLOW TEST] [8.237 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:03.622
    Aug 24 10:57:03.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/24/22 10:57:03.626
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:03.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:03.661
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/24/22 10:57:03.673
    Aug 24 10:57:03.687: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6699" to be "running and ready"
    Aug 24 10:57:03.694: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.438555ms
    Aug 24 10:57:03.695: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:57:05.703: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01558154s
    Aug 24 10:57:05.703: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 24 10:57:05.703: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 08/24/22 10:57:05.71
    Aug 24 10:57:05.721: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-6699" to be "running and ready"
    Aug 24 10:57:05.729: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.955473ms
    Aug 24 10:57:05.729: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:57:07.742: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020842868s
    Aug 24 10:57:07.742: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:57:09.744: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.023216474s
    Aug 24 10:57:09.744: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Aug 24 10:57:09.744: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/24/22 10:57:09.753
    Aug 24 10:57:09.772: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 24 10:57:09.784: INFO: Pod pod-with-prestop-exec-hook still exists
    Aug 24 10:57:11.785: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 24 10:57:11.793: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 08/24/22 10:57:11.793
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 24 10:57:11.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6699" for this suite. 08/24/22 10:57:11.844
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:11.866
Aug 24 10:57:11.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename services 08/24/22 10:57:11.87
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:11.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:11.914
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-5553 08/24/22 10:57:11.922
Aug 24 10:57:11.944: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5553" to be "running and ready"
Aug 24 10:57:11.961: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 16.827931ms
Aug 24 10:57:11.961: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:57:13.966: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.022086403s
Aug 24 10:57:13.966: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 24 10:57:13.967: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Aug 24 10:57:13.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 24 10:57:14.397: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 24 10:57:14.397: INFO: stdout: "iptables"
Aug 24 10:57:14.397: INFO: proxyMode: iptables
Aug 24 10:57:14.420: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 24 10:57:14.426: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-5553 08/24/22 10:57:14.426
STEP: creating replication controller affinity-clusterip-timeout in namespace services-5553 08/24/22 10:57:14.44
I0824 10:57:14.452567      14 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5553, replica count: 3
I0824 10:57:17.503950      14 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 10:57:17.517: INFO: Creating new exec pod
Aug 24 10:57:17.527: INFO: Waiting up to 5m0s for pod "execpod-affinity2v5bh" in namespace "services-5553" to be "running"
Aug 24 10:57:17.533: INFO: Pod "execpod-affinity2v5bh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.525895ms
Aug 24 10:57:19.542: INFO: Pod "execpod-affinity2v5bh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014962278s
Aug 24 10:57:21.543: INFO: Pod "execpod-affinity2v5bh": Phase="Running", Reason="", readiness=true. Elapsed: 4.01655505s
Aug 24 10:57:21.544: INFO: Pod "execpod-affinity2v5bh" satisfied condition "running"
Aug 24 10:57:22.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Aug 24 10:57:22.819: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Aug 24 10:57:22.819: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:57:22.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.51.252 80'
Aug 24 10:57:23.527: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.51.252 80\nConnection to 10.233.51.252 80 port [tcp/http] succeeded!\n"
Aug 24 10:57:23.527: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 10:57:23.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.51.252:80/ ; done'
Aug 24 10:57:23.965: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
Aug 24 10:57:23.965: INFO: stdout: "\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd"
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
Aug 24 10:57:23.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.51.252:80/'
Aug 24 10:57:24.310: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
Aug 24 10:57:24.310: INFO: stdout: "affinity-clusterip-timeout-rvrcd"
Aug 24 10:57:44.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.51.252:80/'
Aug 24 10:57:44.576: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
Aug 24 10:57:44.576: INFO: stdout: "affinity-clusterip-timeout-jxfml"
Aug 24 10:57:44.576: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5553, will wait for the garbage collector to delete the pods 08/24/22 10:57:44.601
Aug 24 10:57:44.672: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 13.251219ms
Aug 24 10:57:44.873: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 201.170955ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 24 10:57:47.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5553" for this suite. 08/24/22 10:57:47.314
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":352,"skipped":6462,"failed":0}
------------------------------
• [SLOW TEST] [35.460 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:11.866
    Aug 24 10:57:11.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename services 08/24/22 10:57:11.87
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:11.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:11.914
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-5553 08/24/22 10:57:11.922
    Aug 24 10:57:11.944: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5553" to be "running and ready"
    Aug 24 10:57:11.961: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 16.827931ms
    Aug 24 10:57:11.961: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:57:13.966: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.022086403s
    Aug 24 10:57:13.966: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Aug 24 10:57:13.967: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Aug 24 10:57:13.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Aug 24 10:57:14.397: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Aug 24 10:57:14.397: INFO: stdout: "iptables"
    Aug 24 10:57:14.397: INFO: proxyMode: iptables
    Aug 24 10:57:14.420: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Aug 24 10:57:14.426: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-5553 08/24/22 10:57:14.426
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-5553 08/24/22 10:57:14.44
    I0824 10:57:14.452567      14 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5553, replica count: 3
    I0824 10:57:17.503950      14 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 24 10:57:17.517: INFO: Creating new exec pod
    Aug 24 10:57:17.527: INFO: Waiting up to 5m0s for pod "execpod-affinity2v5bh" in namespace "services-5553" to be "running"
    Aug 24 10:57:17.533: INFO: Pod "execpod-affinity2v5bh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.525895ms
    Aug 24 10:57:19.542: INFO: Pod "execpod-affinity2v5bh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014962278s
    Aug 24 10:57:21.543: INFO: Pod "execpod-affinity2v5bh": Phase="Running", Reason="", readiness=true. Elapsed: 4.01655505s
    Aug 24 10:57:21.544: INFO: Pod "execpod-affinity2v5bh" satisfied condition "running"
    Aug 24 10:57:22.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Aug 24 10:57:22.819: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Aug 24 10:57:22.819: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:57:22.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.51.252 80'
    Aug 24 10:57:23.527: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.51.252 80\nConnection to 10.233.51.252 80 port [tcp/http] succeeded!\n"
    Aug 24 10:57:23.527: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 24 10:57:23.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.51.252:80/ ; done'
    Aug 24 10:57:23.965: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
    Aug 24 10:57:23.965: INFO: stdout: "\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd\naffinity-clusterip-timeout-rvrcd"
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.965: INFO: Received response from host: affinity-clusterip-timeout-rvrcd
    Aug 24 10:57:23.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.51.252:80/'
    Aug 24 10:57:24.310: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
    Aug 24 10:57:24.310: INFO: stdout: "affinity-clusterip-timeout-rvrcd"
    Aug 24 10:57:44.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3815608707 --namespace=services-5553 exec execpod-affinity2v5bh -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.51.252:80/'
    Aug 24 10:57:44.576: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.51.252:80/\n"
    Aug 24 10:57:44.576: INFO: stdout: "affinity-clusterip-timeout-jxfml"
    Aug 24 10:57:44.576: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5553, will wait for the garbage collector to delete the pods 08/24/22 10:57:44.601
    Aug 24 10:57:44.672: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 13.251219ms
    Aug 24 10:57:44.873: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 201.170955ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 24 10:57:47.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5553" for this suite. 08/24/22 10:57:47.314
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:47.342
Aug 24 10:57:47.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename configmap 08/24/22 10:57:47.349
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:47.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:47.399
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-bb344603-f1d2-4b59-8383-a66f280539c9 08/24/22 10:57:47.403
STEP: Creating a pod to test consume configMaps 08/24/22 10:57:47.425
Aug 24 10:57:47.439: INFO: Waiting up to 5m0s for pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d" in namespace "configmap-6747" to be "Succeeded or Failed"
Aug 24 10:57:47.443: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251972ms
Aug 24 10:57:49.451: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012156523s
Aug 24 10:57:51.451: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011715026s
Aug 24 10:57:53.452: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013408544s
STEP: Saw pod success 08/24/22 10:57:53.453
Aug 24 10:57:53.453: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d" satisfied condition "Succeeded or Failed"
Aug 24 10:57:53.457: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d container agnhost-container: <nil>
STEP: delete the pod 08/24/22 10:57:53.472
Aug 24 10:57:53.518: INFO: Waiting for pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d to disappear
Aug 24 10:57:53.524: INFO: Pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 24 10:57:53.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6747" for this suite. 08/24/22 10:57:53.531
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":353,"skipped":6487,"failed":0}
------------------------------
• [SLOW TEST] [6.199 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:47.342
    Aug 24 10:57:47.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename configmap 08/24/22 10:57:47.349
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:47.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:47.399
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-bb344603-f1d2-4b59-8383-a66f280539c9 08/24/22 10:57:47.403
    STEP: Creating a pod to test consume configMaps 08/24/22 10:57:47.425
    Aug 24 10:57:47.439: INFO: Waiting up to 5m0s for pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d" in namespace "configmap-6747" to be "Succeeded or Failed"
    Aug 24 10:57:47.443: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251972ms
    Aug 24 10:57:49.451: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012156523s
    Aug 24 10:57:51.451: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011715026s
    Aug 24 10:57:53.452: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013408544s
    STEP: Saw pod success 08/24/22 10:57:53.453
    Aug 24 10:57:53.453: INFO: Pod "pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d" satisfied condition "Succeeded or Failed"
    Aug 24 10:57:53.457: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d container agnhost-container: <nil>
    STEP: delete the pod 08/24/22 10:57:53.472
    Aug 24 10:57:53.518: INFO: Waiting for pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d to disappear
    Aug 24 10:57:53.524: INFO: Pod pod-configmaps-38974340-0ad6-48e9-b665-b54b26e7a46d no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 24 10:57:53.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6747" for this suite. 08/24/22 10:57:53.531
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:53.55
Aug 24 10:57:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename endpointslice 08/24/22 10:57:53.553
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:53.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:53.587
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Aug 24 10:57:53.603: INFO: Endpoints addresses: [192.168.121.119 192.168.121.214] , ports: [6443]
Aug 24 10:57:53.603: INFO: EndpointSlices addresses: [192.168.121.119 192.168.121.214] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 24 10:57:53.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4140" for this suite. 08/24/22 10:57:53.611
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":354,"skipped":6509,"failed":0}
------------------------------
• [0.069 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:53.55
    Aug 24 10:57:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename endpointslice 08/24/22 10:57:53.553
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:53.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:53.587
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Aug 24 10:57:53.603: INFO: Endpoints addresses: [192.168.121.119 192.168.121.214] , ports: [6443]
    Aug 24 10:57:53.603: INFO: EndpointSlices addresses: [192.168.121.119 192.168.121.214] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 24 10:57:53.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4140" for this suite. 08/24/22 10:57:53.611
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:53.625
Aug 24 10:57:53.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename replication-controller 08/24/22 10:57:53.627
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:53.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:53.666
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 08/24/22 10:57:53.671
STEP: When the matched label of one of its pods change 08/24/22 10:57:53.682
Aug 24 10:57:53.688: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 24 10:57:58.703: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 08/24/22 10:57:58.722
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 24 10:57:58.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5083" for this suite. 08/24/22 10:57:58.907
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":355,"skipped":6521,"failed":0}
------------------------------
• [SLOW TEST] [5.309 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:53.625
    Aug 24 10:57:53.626: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename replication-controller 08/24/22 10:57:53.627
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:53.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:53.666
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 08/24/22 10:57:53.671
    STEP: When the matched label of one of its pods change 08/24/22 10:57:53.682
    Aug 24 10:57:53.688: INFO: Pod name pod-release: Found 0 pods out of 1
    Aug 24 10:57:58.703: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/24/22 10:57:58.722
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 24 10:57:58.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5083" for this suite. 08/24/22 10:57:58.907
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:57:58.94
Aug 24 10:57:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename statefulset 08/24/22 10:57:58.944
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:59.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:59.155
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8545 08/24/22 10:57:59.159
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-8545 08/24/22 10:57:59.173
Aug 24 10:57:59.208: INFO: Found 0 stateful pods, waiting for 1
Aug 24 10:58:09.216: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 24 10:58:19.216: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 08/24/22 10:58:19.231
STEP: updating a scale subresource 08/24/22 10:58:19.237
STEP: verifying the statefulset Spec.Replicas was modified 08/24/22 10:58:19.247
STEP: Patch a scale subresource 08/24/22 10:58:19.255
STEP: verifying the statefulset Spec.Replicas was modified 08/24/22 10:58:19.274
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 24 10:58:19.286: INFO: Deleting all statefulset in ns statefulset-8545
Aug 24 10:58:19.291: INFO: Scaling statefulset ss to 0
Aug 24 10:58:29.371: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 10:58:29.378: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 24 10:58:29.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8545" for this suite. 08/24/22 10:58:29.438
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":356,"skipped":6527,"failed":0}
------------------------------
• [SLOW TEST] [30.511 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:57:58.94
    Aug 24 10:57:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename statefulset 08/24/22 10:57:58.944
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:57:59.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:57:59.155
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8545 08/24/22 10:57:59.159
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-8545 08/24/22 10:57:59.173
    Aug 24 10:57:59.208: INFO: Found 0 stateful pods, waiting for 1
    Aug 24 10:58:09.216: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Aug 24 10:58:19.216: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 08/24/22 10:58:19.231
    STEP: updating a scale subresource 08/24/22 10:58:19.237
    STEP: verifying the statefulset Spec.Replicas was modified 08/24/22 10:58:19.247
    STEP: Patch a scale subresource 08/24/22 10:58:19.255
    STEP: verifying the statefulset Spec.Replicas was modified 08/24/22 10:58:19.274
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 24 10:58:19.286: INFO: Deleting all statefulset in ns statefulset-8545
    Aug 24 10:58:19.291: INFO: Scaling statefulset ss to 0
    Aug 24 10:58:29.371: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 24 10:58:29.378: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 24 10:58:29.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8545" for this suite. 08/24/22 10:58:29.438
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:58:29.467
Aug 24 10:58:29.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename container-probe 08/24/22 10:58:29.471
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:58:29.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:58:29.508
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Aug 24 10:58:29.527: INFO: Waiting up to 5m0s for pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712" in namespace "container-probe-2588" to be "running and ready"
Aug 24 10:58:29.532: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757163ms
Aug 24 10:58:29.532: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:58:31.541: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013804903s
Aug 24 10:58:31.542: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 10:58:33.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 4.010932572s
Aug 24 10:58:33.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:35.543: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 6.015342843s
Aug 24 10:58:35.543: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:37.540: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 8.012503135s
Aug 24 10:58:37.540: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:39.541: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 10.013060101s
Aug 24 10:58:39.541: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:41.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 12.011310262s
Aug 24 10:58:41.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:43.543: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 14.015293539s
Aug 24 10:58:43.543: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:45.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 16.011485084s
Aug 24 10:58:45.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:47.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 18.011354828s
Aug 24 10:58:47.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:49.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 20.011459388s
Aug 24 10:58:49.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:51.544: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 22.015991973s
Aug 24 10:58:51.544: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:53.538: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 24.010239327s
Aug 24 10:58:53.538: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:55.552: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 26.024332135s
Aug 24 10:58:55.552: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:57.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 28.011365233s
Aug 24 10:58:57.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:58:59.553: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 30.024981373s
Aug 24 10:58:59.553: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
Aug 24 10:59:01.551: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=true. Elapsed: 32.023598203s
Aug 24 10:59:01.552: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = true)
Aug 24 10:59:01.552: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712" satisfied condition "running and ready"
Aug 24 10:59:01.558: INFO: Container started at 2022-08-24 10:58:31 +0000 UTC, pod became ready at 2022-08-24 10:59:00 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 24 10:59:01.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2588" for this suite. 08/24/22 10:59:01.569
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":357,"skipped":6567,"failed":0}
------------------------------
• [SLOW TEST] [32.121 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:58:29.467
    Aug 24 10:58:29.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename container-probe 08/24/22 10:58:29.471
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:58:29.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:58:29.508
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Aug 24 10:58:29.527: INFO: Waiting up to 5m0s for pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712" in namespace "container-probe-2588" to be "running and ready"
    Aug 24 10:58:29.532: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757163ms
    Aug 24 10:58:29.532: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:58:31.541: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013804903s
    Aug 24 10:58:31.542: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 10:58:33.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 4.010932572s
    Aug 24 10:58:33.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:35.543: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 6.015342843s
    Aug 24 10:58:35.543: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:37.540: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 8.012503135s
    Aug 24 10:58:37.540: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:39.541: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 10.013060101s
    Aug 24 10:58:39.541: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:41.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 12.011310262s
    Aug 24 10:58:41.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:43.543: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 14.015293539s
    Aug 24 10:58:43.543: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:45.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 16.011485084s
    Aug 24 10:58:45.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:47.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 18.011354828s
    Aug 24 10:58:47.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:49.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 20.011459388s
    Aug 24 10:58:49.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:51.544: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 22.015991973s
    Aug 24 10:58:51.544: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:53.538: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 24.010239327s
    Aug 24 10:58:53.538: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:55.552: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 26.024332135s
    Aug 24 10:58:55.552: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:57.539: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 28.011365233s
    Aug 24 10:58:57.539: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:58:59.553: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=false. Elapsed: 30.024981373s
    Aug 24 10:58:59.553: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = false)
    Aug 24 10:59:01.551: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712": Phase="Running", Reason="", readiness=true. Elapsed: 32.023598203s
    Aug 24 10:59:01.552: INFO: The phase of Pod test-webserver-ec5a1909-50ac-45df-945a-405dc748e712 is Running (Ready = true)
    Aug 24 10:59:01.552: INFO: Pod "test-webserver-ec5a1909-50ac-45df-945a-405dc748e712" satisfied condition "running and ready"
    Aug 24 10:59:01.558: INFO: Container started at 2022-08-24 10:58:31 +0000 UTC, pod became ready at 2022-08-24 10:59:00 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 24 10:59:01.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2588" for this suite. 08/24/22 10:59:01.569
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:59:01.619
Aug 24 10:59:01.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename aggregator 08/24/22 10:59:01.623
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:59:01.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:59:01.665
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Aug 24 10:59:01.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 08/24/22 10:59:01.672
Aug 24 10:59:02.418: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Aug 24 10:59:04.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:06.540: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:08.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:10.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:12.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:14.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:16.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:18.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:20.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:22.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:24.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:26.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:28.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:30.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:32.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:34.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:36.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:38.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:40.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:42.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:44.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:46.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:48.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:50.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:52.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:54.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:56.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 10:59:58.695: INFO: Waited 148.47375ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 08/24/22 10:59:58.812
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/24/22 10:59:58.82
STEP: List APIServices 08/24/22 10:59:58.836
Aug 24 10:59:58.863: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Aug 24 10:59:59.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1114" for this suite. 08/24/22 10:59:59.187
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":358,"skipped":6608,"failed":0}
------------------------------
• [SLOW TEST] [57.583 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:59:01.619
    Aug 24 10:59:01.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename aggregator 08/24/22 10:59:01.623
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:59:01.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:59:01.665
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Aug 24 10:59:01.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 08/24/22 10:59:01.672
    Aug 24 10:59:02.418: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
    Aug 24 10:59:04.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:06.540: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:08.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:10.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:12.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:14.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:16.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:18.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:20.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:22.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:24.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:26.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:28.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:30.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:32.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:34.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:36.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:38.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:40.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:42.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:44.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:46.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:48.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:50.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:52.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:54.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:56.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 10, 59, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 24 10:59:58.695: INFO: Waited 148.47375ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 08/24/22 10:59:58.812
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/24/22 10:59:58.82
    STEP: List APIServices 08/24/22 10:59:58.836
    Aug 24 10:59:58.863: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Aug 24 10:59:59.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-1114" for this suite. 08/24/22 10:59:59.187
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 10:59:59.241
Aug 24 10:59:59.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename emptydir 08/24/22 10:59:59.281
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:59:59.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:59:59.343
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 08/24/22 10:59:59.348
Aug 24 10:59:59.364: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924" in namespace "emptydir-8464" to be "running"
Aug 24 10:59:59.369: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 5.273959ms
Aug 24 11:00:01.387: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02299627s
Aug 24 11:00:03.376: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012349592s
Aug 24 11:00:05.375: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Running", Reason="", readiness=false. Elapsed: 6.011430113s
Aug 24 11:00:05.376: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924" satisfied condition "running"
STEP: Reading file content from the nginx-container 08/24/22 11:00:05.376
Aug 24 11:00:05.376: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8464 PodName:pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 11:00:05.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
Aug 24 11:00:05.379: INFO: ExecWithOptions: Clientset creation
Aug 24 11:00:05.379: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-8464/pods/pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Aug 24 11:00:05.581: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 24 11:00:05.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8464" for this suite. 08/24/22 11:00:05.592
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":359,"skipped":6633,"failed":0}
------------------------------
• [SLOW TEST] [6.363 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 10:59:59.241
    Aug 24 10:59:59.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename emptydir 08/24/22 10:59:59.281
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 10:59:59.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 10:59:59.343
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 08/24/22 10:59:59.348
    Aug 24 10:59:59.364: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924" in namespace "emptydir-8464" to be "running"
    Aug 24 10:59:59.369: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 5.273959ms
    Aug 24 11:00:01.387: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02299627s
    Aug 24 11:00:03.376: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012349592s
    Aug 24 11:00:05.375: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924": Phase="Running", Reason="", readiness=false. Elapsed: 6.011430113s
    Aug 24 11:00:05.376: INFO: Pod "pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924" satisfied condition "running"
    STEP: Reading file content from the nginx-container 08/24/22 11:00:05.376
    Aug 24 11:00:05.376: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8464 PodName:pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 24 11:00:05.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    Aug 24 11:00:05.379: INFO: ExecWithOptions: Clientset creation
    Aug 24 11:00:05.379: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-8464/pods/pod-sharedvolume-78e84224-a1cf-4d5e-8d14-f5defe369924/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Aug 24 11:00:05.581: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 24 11:00:05.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8464" for this suite. 08/24/22 11:00:05.592
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 11:00:05.606
Aug 24 11:00:05.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename projected 08/24/22 11:00:05.61
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:05.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:05.649
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 08/24/22 11:00:05.654
Aug 24 11:00:05.669: INFO: Waiting up to 5m0s for pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01" in namespace "projected-8150" to be "running and ready"
Aug 24 11:00:05.677: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763884ms
Aug 24 11:00:05.677: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:00:07.685: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016535256s
Aug 24 11:00:07.686: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:00:09.684: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014825957s
Aug 24 11:00:09.684: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:00:11.694: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Running", Reason="", readiness=true. Elapsed: 6.025399618s
Aug 24 11:00:11.694: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Running (Ready = true)
Aug 24 11:00:11.695: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01" satisfied condition "running and ready"
Aug 24 11:00:12.265: INFO: Successfully updated pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 24 11:00:14.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8150" for this suite. 08/24/22 11:00:14.298
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":360,"skipped":6641,"failed":0}
------------------------------
• [SLOW TEST] [8.702 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 11:00:05.606
    Aug 24 11:00:05.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename projected 08/24/22 11:00:05.61
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:05.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:05.649
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 08/24/22 11:00:05.654
    Aug 24 11:00:05.669: INFO: Waiting up to 5m0s for pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01" in namespace "projected-8150" to be "running and ready"
    Aug 24 11:00:05.677: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763884ms
    Aug 24 11:00:05.677: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 11:00:07.685: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016535256s
    Aug 24 11:00:07.686: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 11:00:09.684: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014825957s
    Aug 24 11:00:09.684: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Pending, waiting for it to be Running (with Ready = true)
    Aug 24 11:00:11.694: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01": Phase="Running", Reason="", readiness=true. Elapsed: 6.025399618s
    Aug 24 11:00:11.694: INFO: The phase of Pod labelsupdate184c8282-7557-4f70-af0f-7a927e725b01 is Running (Ready = true)
    Aug 24 11:00:11.695: INFO: Pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01" satisfied condition "running and ready"
    Aug 24 11:00:12.265: INFO: Successfully updated pod "labelsupdate184c8282-7557-4f70-af0f-7a927e725b01"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 24 11:00:14.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8150" for this suite. 08/24/22 11:00:14.298
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 11:00:14.312
Aug 24 11:00:14.313: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename subpath 08/24/22 11:00:14.315
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:14.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:14.346
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/24/22 11:00:14.351
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-lksj 08/24/22 11:00:14.365
STEP: Creating a pod to test atomic-volume-subpath 08/24/22 11:00:14.366
Aug 24 11:00:14.379: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lksj" in namespace "subpath-8373" to be "Succeeded or Failed"
Aug 24 11:00:14.386: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.856249ms
Aug 24 11:00:16.393: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014017739s
Aug 24 11:00:18.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 4.016682753s
Aug 24 11:00:20.395: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 6.015504642s
Aug 24 11:00:22.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 8.014773759s
Aug 24 11:00:24.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 10.014150157s
Aug 24 11:00:26.397: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 12.017757205s
Aug 24 11:00:28.399: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 14.019567664s
Aug 24 11:00:30.400: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 16.020333542s
Aug 24 11:00:32.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 18.014096968s
Aug 24 11:00:34.395: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 20.015732292s
Aug 24 11:00:36.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 22.016407707s
Aug 24 11:00:38.393: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=false. Elapsed: 24.013733307s
Aug 24 11:00:40.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.016587737s
STEP: Saw pod success 08/24/22 11:00:40.396
Aug 24 11:00:40.398: INFO: Pod "pod-subpath-test-downwardapi-lksj" satisfied condition "Succeeded or Failed"
Aug 24 11:00:40.408: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-downwardapi-lksj container test-container-subpath-downwardapi-lksj: <nil>
STEP: delete the pod 08/24/22 11:00:40.429
Aug 24 11:00:40.458: INFO: Waiting for pod pod-subpath-test-downwardapi-lksj to disappear
Aug 24 11:00:40.464: INFO: Pod pod-subpath-test-downwardapi-lksj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-lksj 08/24/22 11:00:40.464
Aug 24 11:00:40.464: INFO: Deleting pod "pod-subpath-test-downwardapi-lksj" in namespace "subpath-8373"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 24 11:00:40.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8373" for this suite. 08/24/22 11:00:40.483
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":361,"skipped":6644,"failed":0}
------------------------------
• [SLOW TEST] [26.185 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 11:00:14.312
    Aug 24 11:00:14.313: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename subpath 08/24/22 11:00:14.315
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:14.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:14.346
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/24/22 11:00:14.351
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-lksj 08/24/22 11:00:14.365
    STEP: Creating a pod to test atomic-volume-subpath 08/24/22 11:00:14.366
    Aug 24 11:00:14.379: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lksj" in namespace "subpath-8373" to be "Succeeded or Failed"
    Aug 24 11:00:14.386: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.856249ms
    Aug 24 11:00:16.393: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014017739s
    Aug 24 11:00:18.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 4.016682753s
    Aug 24 11:00:20.395: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 6.015504642s
    Aug 24 11:00:22.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 8.014773759s
    Aug 24 11:00:24.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 10.014150157s
    Aug 24 11:00:26.397: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 12.017757205s
    Aug 24 11:00:28.399: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 14.019567664s
    Aug 24 11:00:30.400: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 16.020333542s
    Aug 24 11:00:32.394: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 18.014096968s
    Aug 24 11:00:34.395: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 20.015732292s
    Aug 24 11:00:36.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=true. Elapsed: 22.016407707s
    Aug 24 11:00:38.393: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Running", Reason="", readiness=false. Elapsed: 24.013733307s
    Aug 24 11:00:40.396: INFO: Pod "pod-subpath-test-downwardapi-lksj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.016587737s
    STEP: Saw pod success 08/24/22 11:00:40.396
    Aug 24 11:00:40.398: INFO: Pod "pod-subpath-test-downwardapi-lksj" satisfied condition "Succeeded or Failed"
    Aug 24 11:00:40.408: INFO: Trying to get logs from node kah9uighaagh-3 pod pod-subpath-test-downwardapi-lksj container test-container-subpath-downwardapi-lksj: <nil>
    STEP: delete the pod 08/24/22 11:00:40.429
    Aug 24 11:00:40.458: INFO: Waiting for pod pod-subpath-test-downwardapi-lksj to disappear
    Aug 24 11:00:40.464: INFO: Pod pod-subpath-test-downwardapi-lksj no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-lksj 08/24/22 11:00:40.464
    Aug 24 11:00:40.464: INFO: Deleting pod "pod-subpath-test-downwardapi-lksj" in namespace "subpath-8373"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 24 11:00:40.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8373" for this suite. 08/24/22 11:00:40.483
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 11:00:40.524
Aug 24 11:00:40.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption 08/24/22 11:00:40.534
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:40.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:40.578
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 24 11:00:40.614: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 11:01:40.658: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/24/22 11:01:40.666
Aug 24 11:01:40.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
STEP: Building a namespace api object, basename sched-preemption-path 08/24/22 11:01:40.671
STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:01:40.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:01:40.707
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Aug 24 11:01:40.747: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Aug 24 11:01:40.754: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Aug 24 11:01:40.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2373" for this suite. 08/24/22 11:01:40.8
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 24 11:01:40.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-54" for this suite. 08/24/22 11:01:40.849
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":362,"skipped":6687,"failed":0}
------------------------------
• [SLOW TEST] [60.460 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 11:00:40.524
    Aug 24 11:00:40.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption 08/24/22 11:00:40.534
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:00:40.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:00:40.578
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 24 11:00:40.614: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 24 11:01:40.658: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/24/22 11:01:40.666
    Aug 24 11:01:40.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3815608707
    STEP: Building a namespace api object, basename sched-preemption-path 08/24/22 11:01:40.671
    STEP: Waiting for a default service account to be provisioned in namespace 08/24/22 11:01:40.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/24/22 11:01:40.707
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Aug 24 11:01:40.747: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Aug 24 11:01:40.754: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Aug 24 11:01:40.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-2373" for this suite. 08/24/22 11:01:40.8
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 24 11:01:40.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-54" for this suite. 08/24/22 11:01:40.849
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Aug 24 11:01:40.993: INFO: Running AfterSuite actions on all nodes
Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Aug 24 11:01:41.005: INFO: Running AfterSuite actions on node 1
Aug 24 11:01:41.005: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.012 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 24 11:01:40.993: INFO: Running AfterSuite actions on all nodes
    Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Aug 24 11:01:41.004: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Aug 24 11:01:41.005: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 24 11:01:41.005: INFO: Running AfterSuite actions on node 1
    Aug 24 11:01:41.005: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.131 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 6076.547 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h41m17.487364726s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.4[0m

