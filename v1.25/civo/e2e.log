I0213 13:33:02.339038      19 e2e.go:116] Starting e2e run "8a5a0cb0-4dbb-4dde-8847-35c08d716de3" on Ginkgo node 1
Feb 13 13:33:02.351: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1676295182 - will randomize all specs

Will run 362 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Feb 13 13:33:02.486: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
E0213 13:33:02.487145      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
E0213 13:33:02.487145      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Feb 13 13:33:02.487: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 13 13:33:02.499: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 13:33:02.532: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 13:33:02.532: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb 13 13:33:02.532: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'civo-csi-node' (0 seconds elapsed)
Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 13 13:33:02.539: INFO: e2e test version: v1.25.5
Feb 13 13:33:02.541: INFO: kube-apiserver version: v1.25.5
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Feb 13 13:33:02.542: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:33:02.547: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.062 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Feb 13 13:33:02.486: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    E0213 13:33:02.487145      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Feb 13 13:33:02.487: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Feb 13 13:33:02.499: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Feb 13 13:33:02.532: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Feb 13 13:33:02.532: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
    Feb 13 13:33:02.532: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'civo-csi-node' (0 seconds elapsed)
    Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
    Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
    Feb 13 13:33:02.539: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Feb 13 13:33:02.539: INFO: e2e test version: v1.25.5
    Feb 13 13:33:02.541: INFO: kube-apiserver version: v1.25.5
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Feb 13 13:33:02.542: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:33:02.547: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:33:02.575
Feb 13 13:33:02.575: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 13:33:02.576
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:02.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:02.596
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-a8c758c3-9c6e-468f-90f3-49cd565c535a 02/13/23 13:33:02.6
STEP: Creating a pod to test consume secrets 02/13/23 13:33:02.606
W0213 13:33:02.619856      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:33:02.620: INFO: Waiting up to 5m0s for pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7" in namespace "secrets-8869" to be "Succeeded or Failed"
Feb 13 13:33:02.628: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.679652ms
Feb 13 13:33:04.634: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013697481s
Feb 13 13:33:06.634: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Running", Reason="", readiness=true. Elapsed: 4.013944843s
Feb 13 13:33:08.637: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Running", Reason="", readiness=false. Elapsed: 6.016373366s
Feb 13 13:33:10.635: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014602092s
STEP: Saw pod success 02/13/23 13:33:10.635
Feb 13 13:33:10.635: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7" satisfied condition "Succeeded or Failed"
Feb 13 13:33:10.641: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:33:10.677
Feb 13 13:33:10.697: INFO: Waiting for pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 to disappear
Feb 13 13:33:10.701: INFO: Pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 13:33:10.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8869" for this suite. 02/13/23 13:33:10.705
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":1,"skipped":0,"failed":0}
------------------------------
• [SLOW TEST] [8.136 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:33:02.575
    Feb 13 13:33:02.575: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 13:33:02.576
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:02.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:02.596
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-a8c758c3-9c6e-468f-90f3-49cd565c535a 02/13/23 13:33:02.6
    STEP: Creating a pod to test consume secrets 02/13/23 13:33:02.606
    W0213 13:33:02.619856      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:33:02.620: INFO: Waiting up to 5m0s for pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7" in namespace "secrets-8869" to be "Succeeded or Failed"
    Feb 13 13:33:02.628: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.679652ms
    Feb 13 13:33:04.634: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013697481s
    Feb 13 13:33:06.634: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Running", Reason="", readiness=true. Elapsed: 4.013944843s
    Feb 13 13:33:08.637: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Running", Reason="", readiness=false. Elapsed: 6.016373366s
    Feb 13 13:33:10.635: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014602092s
    STEP: Saw pod success 02/13/23 13:33:10.635
    Feb 13 13:33:10.635: INFO: Pod "pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7" satisfied condition "Succeeded or Failed"
    Feb 13 13:33:10.641: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:33:10.677
    Feb 13 13:33:10.697: INFO: Waiting for pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 to disappear
    Feb 13 13:33:10.701: INFO: Pod pod-secrets-df65fdbe-0993-4290-b188-3e23e26642a7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 13:33:10.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8869" for this suite. 02/13/23 13:33:10.705
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:33:10.712
Feb 13 13:33:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename watch 02/13/23 13:33:10.715
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:10.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:10.733
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 02/13/23 13:33:10.736
STEP: creating a watch on configmaps with label B 02/13/23 13:33:10.738
STEP: creating a watch on configmaps with label A or B 02/13/23 13:33:10.74
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.742
Feb 13 13:33:10.749: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4399 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:10.750: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4399 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.75
Feb 13 13:33:10.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4400 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:10.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4400 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 02/13/23 13:33:10.759
Feb 13 13:33:10.767: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4401 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:10.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4401 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.769
Feb 13 13:33:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4402 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4402 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 02/13/23 13:33:10.776
Feb 13 13:33:10.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4403 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:10.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4403 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 02/13/23 13:33:20.784
Feb 13 13:33:20.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4436 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:33:20.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4436 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Feb 13 13:33:30.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1750" for this suite. 02/13/23 13:33:30.806
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":2,"skipped":0,"failed":0}
------------------------------
• [SLOW TEST] [20.102 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:33:10.712
    Feb 13 13:33:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename watch 02/13/23 13:33:10.715
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:10.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:10.733
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 02/13/23 13:33:10.736
    STEP: creating a watch on configmaps with label B 02/13/23 13:33:10.738
    STEP: creating a watch on configmaps with label A or B 02/13/23 13:33:10.74
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.742
    Feb 13 13:33:10.749: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4399 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:10.750: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4399 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.75
    Feb 13 13:33:10.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4400 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:10.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4400 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 02/13/23 13:33:10.759
    Feb 13 13:33:10.767: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4401 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:10.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4401 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 02/13/23 13:33:10.769
    Feb 13 13:33:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4402 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1750  f69801e5-02c8-40c6-a9e9-442b10fcc028 4402 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 02/13/23 13:33:10.776
    Feb 13 13:33:10.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4403 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:10.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4403 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 02/13/23 13:33:20.784
    Feb 13 13:33:20.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4436 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:33:20.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1750  45406ded-eb51-4d01-a329-25391b7f7cbd 4436 0 2023-02-13 13:33:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-02-13 13:33:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Feb 13 13:33:30.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1750" for this suite. 02/13/23 13:33:30.806
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:33:30.817
Feb 13 13:33:30.817: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 13:33:30.818
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:30.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:30.843
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2258 02/13/23 13:33:30.847
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 02/13/23 13:33:30.855
W0213 13:33:30.864648      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:33:30.869: INFO: Found 0 stateful pods, waiting for 3
Feb 13 13:33:40.875: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:33:40.875: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:33:40.875: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 13 13:33:50.879: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:33:50.879: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:33:50.879: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 02/13/23 13:33:50.892
W0213 13:33:50.920964      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:33:50.921: INFO: Updating stateful set ss2
STEP: Creating a new revision 02/13/23 13:33:50.921
STEP: Not applying an update when the partition is greater than the number of replicas 02/13/23 13:34:00.948
STEP: Performing a canary update 02/13/23 13:34:00.948
W0213 13:34:00.970265      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:34:00.970: INFO: Updating stateful set ss2
Feb 13 13:34:00.981: INFO: Waiting for Pod statefulset-2258/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 02/13/23 13:34:11.003
Feb 13 13:34:11.065: INFO: Found 2 stateful pods, waiting for 3
Feb 13 13:34:21.076: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:34:21.076: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:34:21.076: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 02/13/23 13:34:21.085
W0213 13:34:21.112503      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:34:21.113: INFO: Updating stateful set ss2
Feb 13 13:34:21.128: INFO: Waiting for Pod statefulset-2258/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
W0213 13:34:31.172761      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:34:31.173: INFO: Updating stateful set ss2
Feb 13 13:34:31.186: INFO: Waiting for StatefulSet statefulset-2258/ss2 to complete update
Feb 13 13:34:31.186: INFO: Waiting for Pod statefulset-2258/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 13:34:41.201: INFO: Deleting all statefulset in ns statefulset-2258
Feb 13 13:34:41.206: INFO: Scaling statefulset ss2 to 0
W0213 13:34:41.222308      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:34:51.235: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:34:51.247: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 13:34:51.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2258" for this suite. 02/13/23 13:34:51.301
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":3,"skipped":1,"failed":0}
------------------------------
• [SLOW TEST] [80.491 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:33:30.817
    Feb 13 13:33:30.817: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 13:33:30.818
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:33:30.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:33:30.843
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2258 02/13/23 13:33:30.847
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 02/13/23 13:33:30.855
    W0213 13:33:30.864648      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:33:30.869: INFO: Found 0 stateful pods, waiting for 3
    Feb 13 13:33:40.875: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:33:40.875: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:33:40.875: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
    Feb 13 13:33:50.879: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:33:50.879: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:33:50.879: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 02/13/23 13:33:50.892
    W0213 13:33:50.920964      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:33:50.921: INFO: Updating stateful set ss2
    STEP: Creating a new revision 02/13/23 13:33:50.921
    STEP: Not applying an update when the partition is greater than the number of replicas 02/13/23 13:34:00.948
    STEP: Performing a canary update 02/13/23 13:34:00.948
    W0213 13:34:00.970265      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:34:00.970: INFO: Updating stateful set ss2
    Feb 13 13:34:00.981: INFO: Waiting for Pod statefulset-2258/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 02/13/23 13:34:11.003
    Feb 13 13:34:11.065: INFO: Found 2 stateful pods, waiting for 3
    Feb 13 13:34:21.076: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:34:21.076: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 13:34:21.076: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 02/13/23 13:34:21.085
    W0213 13:34:21.112503      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:34:21.113: INFO: Updating stateful set ss2
    Feb 13 13:34:21.128: INFO: Waiting for Pod statefulset-2258/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    W0213 13:34:31.172761      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:34:31.173: INFO: Updating stateful set ss2
    Feb 13 13:34:31.186: INFO: Waiting for StatefulSet statefulset-2258/ss2 to complete update
    Feb 13 13:34:31.186: INFO: Waiting for Pod statefulset-2258/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 13:34:41.201: INFO: Deleting all statefulset in ns statefulset-2258
    Feb 13 13:34:41.206: INFO: Scaling statefulset ss2 to 0
    W0213 13:34:41.222308      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:34:51.235: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 13:34:51.247: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 13:34:51.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2258" for this suite. 02/13/23 13:34:51.301
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:34:51.311
Feb 13 13:34:51.312: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replication-controller 02/13/23 13:34:51.315
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:34:51.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:34:51.338
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 02/13/23 13:34:51.348
W0213 13:34:51.358796      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: waiting for RC to be added 02/13/23 13:34:51.359
STEP: waiting for available Replicas 02/13/23 13:34:51.361
STEP: patching ReplicationController 02/13/23 13:34:53.668
W0213 13:34:53.680255      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: waiting for RC to be modified 02/13/23 13:34:53.68
STEP: patching ReplicationController status 02/13/23 13:34:53.681
STEP: waiting for RC to be modified 02/13/23 13:34:53.693
STEP: waiting for available Replicas 02/13/23 13:34:53.695
STEP: fetching ReplicationController status 02/13/23 13:34:53.702
STEP: patching ReplicationController scale 02/13/23 13:34:53.708
STEP: waiting for RC to be modified 02/13/23 13:34:53.72
STEP: waiting for ReplicationController's scale to be the max amount 02/13/23 13:34:53.722
STEP: fetching ReplicationController; ensuring that it's patched 02/13/23 13:34:56.62
STEP: updating ReplicationController status 02/13/23 13:34:56.625
STEP: waiting for RC to be modified 02/13/23 13:34:56.632
STEP: listing all ReplicationControllers 02/13/23 13:34:56.632
STEP: checking that ReplicationController has expected values 02/13/23 13:34:56.635
STEP: deleting ReplicationControllers by collection 02/13/23 13:34:56.635
STEP: waiting for ReplicationController to have a DELETED watchEvent 02/13/23 13:34:56.644
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Feb 13 13:34:56.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1485" for this suite. 02/13/23 13:34:56.671
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":4,"skipped":2,"failed":0}
------------------------------
• [SLOW TEST] [5.364 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:34:51.311
    Feb 13 13:34:51.312: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replication-controller 02/13/23 13:34:51.315
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:34:51.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:34:51.338
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 02/13/23 13:34:51.348
    W0213 13:34:51.358796      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: waiting for RC to be added 02/13/23 13:34:51.359
    STEP: waiting for available Replicas 02/13/23 13:34:51.361
    STEP: patching ReplicationController 02/13/23 13:34:53.668
    W0213 13:34:53.680255      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: waiting for RC to be modified 02/13/23 13:34:53.68
    STEP: patching ReplicationController status 02/13/23 13:34:53.681
    STEP: waiting for RC to be modified 02/13/23 13:34:53.693
    STEP: waiting for available Replicas 02/13/23 13:34:53.695
    STEP: fetching ReplicationController status 02/13/23 13:34:53.702
    STEP: patching ReplicationController scale 02/13/23 13:34:53.708
    STEP: waiting for RC to be modified 02/13/23 13:34:53.72
    STEP: waiting for ReplicationController's scale to be the max amount 02/13/23 13:34:53.722
    STEP: fetching ReplicationController; ensuring that it's patched 02/13/23 13:34:56.62
    STEP: updating ReplicationController status 02/13/23 13:34:56.625
    STEP: waiting for RC to be modified 02/13/23 13:34:56.632
    STEP: listing all ReplicationControllers 02/13/23 13:34:56.632
    STEP: checking that ReplicationController has expected values 02/13/23 13:34:56.635
    STEP: deleting ReplicationControllers by collection 02/13/23 13:34:56.635
    STEP: waiting for ReplicationController to have a DELETED watchEvent 02/13/23 13:34:56.644
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Feb 13 13:34:56.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1485" for this suite. 02/13/23 13:34:56.671
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:34:56.682
Feb 13 13:34:56.682: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-runtime 02/13/23 13:34:56.684
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:34:56.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:34:56.713
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 02/13/23 13:34:56.718
W0213 13:34:56.730480      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: wait for the container to reach Succeeded 02/13/23 13:34:56.73
STEP: get the container status 02/13/23 13:35:00.764
STEP: the container should be terminated 02/13/23 13:35:00.774
STEP: the termination message should be set 02/13/23 13:35:00.775
Feb 13 13:35:00.775: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 02/13/23 13:35:00.775
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Feb 13 13:35:00.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5015" for this suite. 02/13/23 13:35:00.811
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":5,"skipped":33,"failed":0}
------------------------------
• [4.137 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:34:56.682
    Feb 13 13:34:56.682: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-runtime 02/13/23 13:34:56.684
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:34:56.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:34:56.713
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 02/13/23 13:34:56.718
    W0213 13:34:56.730480      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: wait for the container to reach Succeeded 02/13/23 13:34:56.73
    STEP: get the container status 02/13/23 13:35:00.764
    STEP: the container should be terminated 02/13/23 13:35:00.774
    STEP: the termination message should be set 02/13/23 13:35:00.775
    Feb 13 13:35:00.775: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 02/13/23 13:35:00.775
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Feb 13 13:35:00.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5015" for this suite. 02/13/23 13:35:00.811
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:00.82
Feb 13 13:35:00.820: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 13:35:00.822
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:00.842
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:00.848
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 02/13/23 13:35:00.853
Feb 13 13:35:00.854: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Feb 13 13:35:00.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:01.750: INFO: stderr: ""
Feb 13 13:35:01.750: INFO: stdout: "service/agnhost-replica created\n"
Feb 13 13:35:01.750: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Feb 13 13:35:01.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:02.078: INFO: stderr: ""
Feb 13 13:35:02.078: INFO: stdout: "service/agnhost-primary created\n"
Feb 13 13:35:02.078: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 13 13:35:02.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:02.399: INFO: stderr: ""
Feb 13 13:35:02.399: INFO: stdout: "service/frontend created\n"
Feb 13 13:35:02.399: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Feb 13 13:35:02.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:02.647: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"guestbook-frontend\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"guestbook-frontend\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"guestbook-frontend\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"guestbook-frontend\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:35:02.647: INFO: stdout: "deployment.apps/frontend created\n"
Feb 13 13:35:02.647: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 13 13:35:02.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:02.887: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:35:02.887: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Feb 13 13:35:02.887: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 13 13:35:02.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
Feb 13 13:35:03.179: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"replica\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"replica\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"replica\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"replica\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:35:03.179: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 02/13/23 13:35:03.179
Feb 13 13:35:03.180: INFO: Waiting for all frontend pods to be Running.
Feb 13 13:35:08.231: INFO: Waiting for frontend to serve content.
Feb 13 13:35:08.261: INFO: Trying to add a new entry to the guestbook.
Feb 13 13:35:08.285: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 02/13/23 13:35:08.311
Feb 13 13:35:08.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:08.451: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:08.451: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 02/13/23 13:35:08.451
Feb 13 13:35:08.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:08.583: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:08.583: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 02/13/23 13:35:08.583
Feb 13 13:35:08.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:08.710: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:08.710: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 02/13/23 13:35:08.711
Feb 13 13:35:08.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:08.814: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:08.814: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 02/13/23 13:35:08.815
Feb 13 13:35:08.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:08.935: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:08.935: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 02/13/23 13:35:08.935
Feb 13 13:35:08.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
Feb 13 13:35:09.064: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:35:09.064: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 13:35:09.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3394" for this suite. 02/13/23 13:35:09.07
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":6,"skipped":38,"failed":0}
------------------------------
• [SLOW TEST] [8.256 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:00.82
    Feb 13 13:35:00.820: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 13:35:00.822
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:00.842
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:00.848
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 02/13/23 13:35:00.853
    Feb 13 13:35:00.854: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Feb 13 13:35:00.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:01.750: INFO: stderr: ""
    Feb 13 13:35:01.750: INFO: stdout: "service/agnhost-replica created\n"
    Feb 13 13:35:01.750: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Feb 13 13:35:01.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:02.078: INFO: stderr: ""
    Feb 13 13:35:02.078: INFO: stdout: "service/agnhost-primary created\n"
    Feb 13 13:35:02.078: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Feb 13 13:35:02.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:02.399: INFO: stderr: ""
    Feb 13 13:35:02.399: INFO: stdout: "service/frontend created\n"
    Feb 13 13:35:02.399: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Feb 13 13:35:02.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:02.647: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"guestbook-frontend\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"guestbook-frontend\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"guestbook-frontend\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"guestbook-frontend\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:35:02.647: INFO: stdout: "deployment.apps/frontend created\n"
    Feb 13 13:35:02.647: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Feb 13 13:35:02.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:02.887: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:35:02.887: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Feb 13 13:35:02.887: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Feb 13 13:35:02.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 create -f -'
    Feb 13 13:35:03.179: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"replica\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"replica\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"replica\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"replica\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:35:03.179: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 02/13/23 13:35:03.179
    Feb 13 13:35:03.180: INFO: Waiting for all frontend pods to be Running.
    Feb 13 13:35:08.231: INFO: Waiting for frontend to serve content.
    Feb 13 13:35:08.261: INFO: Trying to add a new entry to the guestbook.
    Feb 13 13:35:08.285: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 02/13/23 13:35:08.311
    Feb 13 13:35:08.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:08.451: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:08.451: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 02/13/23 13:35:08.451
    Feb 13 13:35:08.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:08.583: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:08.583: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 02/13/23 13:35:08.583
    Feb 13 13:35:08.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:08.710: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:08.710: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 02/13/23 13:35:08.711
    Feb 13 13:35:08.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:08.814: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:08.814: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 02/13/23 13:35:08.815
    Feb 13 13:35:08.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:08.935: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:08.935: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 02/13/23 13:35:08.935
    Feb 13 13:35:08.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3394 delete --grace-period=0 --force -f -'
    Feb 13 13:35:09.064: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:35:09.064: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 13:35:09.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3394" for this suite. 02/13/23 13:35:09.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:09.082
Feb 13 13:35:09.083: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 13:35:09.084
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:09.101
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:09.11
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Feb 13 13:35:09.127: INFO: Waiting up to 5m0s for pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49" in namespace "pods-1129" to be "running and ready"
Feb 13 13:35:09.133: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49": Phase="Pending", Reason="", readiness=false. Elapsed: 5.794772ms
Feb 13 13:35:09.134: INFO: The phase of Pod server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:35:11.160: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49": Phase="Running", Reason="", readiness=true. Elapsed: 2.032309168s
Feb 13 13:35:11.160: INFO: The phase of Pod server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49 is Running (Ready = true)
Feb 13 13:35:11.160: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49" satisfied condition "running and ready"
Feb 13 13:35:11.193: INFO: Waiting up to 5m0s for pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe" in namespace "pods-1129" to be "Succeeded or Failed"
Feb 13 13:35:11.200: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.815782ms
Feb 13 13:35:13.206: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012941719s
Feb 13 13:35:15.207: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013325645s
STEP: Saw pod success 02/13/23 13:35:15.207
Feb 13 13:35:15.210: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe" satisfied condition "Succeeded or Failed"
Feb 13 13:35:15.214: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe container env3cont: <nil>
STEP: delete the pod 02/13/23 13:35:15.248
Feb 13 13:35:15.264: INFO: Waiting for pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe to disappear
Feb 13 13:35:15.269: INFO: Pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 13:35:15.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1129" for this suite. 02/13/23 13:35:15.274
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":7,"skipped":63,"failed":0}
------------------------------
• [SLOW TEST] [6.199 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:09.082
    Feb 13 13:35:09.083: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 13:35:09.084
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:09.101
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:09.11
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Feb 13 13:35:09.127: INFO: Waiting up to 5m0s for pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49" in namespace "pods-1129" to be "running and ready"
    Feb 13 13:35:09.133: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49": Phase="Pending", Reason="", readiness=false. Elapsed: 5.794772ms
    Feb 13 13:35:09.134: INFO: The phase of Pod server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:35:11.160: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49": Phase="Running", Reason="", readiness=true. Elapsed: 2.032309168s
    Feb 13 13:35:11.160: INFO: The phase of Pod server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49 is Running (Ready = true)
    Feb 13 13:35:11.160: INFO: Pod "server-envvars-0a10e39a-1e0d-49ba-a1a6-31d84bcace49" satisfied condition "running and ready"
    Feb 13 13:35:11.193: INFO: Waiting up to 5m0s for pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe" in namespace "pods-1129" to be "Succeeded or Failed"
    Feb 13 13:35:11.200: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.815782ms
    Feb 13 13:35:13.206: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012941719s
    Feb 13 13:35:15.207: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013325645s
    STEP: Saw pod success 02/13/23 13:35:15.207
    Feb 13 13:35:15.210: INFO: Pod "client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe" satisfied condition "Succeeded or Failed"
    Feb 13 13:35:15.214: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe container env3cont: <nil>
    STEP: delete the pod 02/13/23 13:35:15.248
    Feb 13 13:35:15.264: INFO: Waiting for pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe to disappear
    Feb 13 13:35:15.269: INFO: Pod client-envvars-ee3349b0-5e35-4848-96e1-82260c0cfebe no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 13:35:15.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1129" for this suite. 02/13/23 13:35:15.274
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:15.286
Feb 13 13:35:15.287: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename podtemplate 02/13/23 13:35:15.289
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.309
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.314
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
W0213 13:35:15.332134      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:35:15.343139      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Feb 13 13:35:15.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9013" for this suite. 02/13/23 13:35:15.361
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":8,"skipped":73,"failed":0}
------------------------------
• [0.079 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:15.286
    Feb 13 13:35:15.287: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename podtemplate 02/13/23 13:35:15.289
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.309
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.314
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    W0213 13:35:15.332134      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:35:15.343139      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Feb 13 13:35:15.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9013" for this suite. 02/13/23 13:35:15.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:15.371
Feb 13 13:35:15.372: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename events 02/13/23 13:35:15.373
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.402
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 02/13/23 13:35:15.407
Feb 13 13:35:15.417: INFO: created test-event-1
Feb 13 13:35:15.425: INFO: created test-event-2
Feb 13 13:35:15.434: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 02/13/23 13:35:15.434
STEP: delete collection of events 02/13/23 13:35:15.44
Feb 13 13:35:15.441: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 02/13/23 13:35:15.459
Feb 13 13:35:15.459: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Feb 13 13:35:15.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5721" for this suite. 02/13/23 13:35:15.469
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":9,"skipped":101,"failed":0}
------------------------------
• [0.108 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:15.371
    Feb 13 13:35:15.372: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename events 02/13/23 13:35:15.373
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.402
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 02/13/23 13:35:15.407
    Feb 13 13:35:15.417: INFO: created test-event-1
    Feb 13 13:35:15.425: INFO: created test-event-2
    Feb 13 13:35:15.434: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 02/13/23 13:35:15.434
    STEP: delete collection of events 02/13/23 13:35:15.44
    Feb 13 13:35:15.441: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 02/13/23 13:35:15.459
    Feb 13 13:35:15.459: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Feb 13 13:35:15.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5721" for this suite. 02/13/23 13:35:15.469
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:15.487
Feb 13 13:35:15.487: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:35:15.49
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.51
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:35:15.515
W0213 13:35:15.527726      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:35:15.528: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb" in namespace "projected-6805" to be "Succeeded or Failed"
Feb 13 13:35:15.533: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198858ms
Feb 13 13:35:17.538: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010548246s
Feb 13 13:35:19.540: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012246404s
STEP: Saw pod success 02/13/23 13:35:19.54
Feb 13 13:35:19.540: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb" satisfied condition "Succeeded or Failed"
Feb 13 13:35:19.545: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb container client-container: <nil>
STEP: delete the pod 02/13/23 13:35:19.557
Feb 13 13:35:19.575: INFO: Waiting for pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb to disappear
Feb 13 13:35:19.577: INFO: Pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 13:35:19.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6805" for this suite. 02/13/23 13:35:19.581
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":10,"skipped":101,"failed":0}
------------------------------
• [4.099 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:15.487
    Feb 13 13:35:15.487: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:35:15.49
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:15.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:15.51
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:35:15.515
    W0213 13:35:15.527726      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:35:15.528: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb" in namespace "projected-6805" to be "Succeeded or Failed"
    Feb 13 13:35:15.533: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198858ms
    Feb 13 13:35:17.538: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010548246s
    Feb 13 13:35:19.540: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012246404s
    STEP: Saw pod success 02/13/23 13:35:19.54
    Feb 13 13:35:19.540: INFO: Pod "downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb" satisfied condition "Succeeded or Failed"
    Feb 13 13:35:19.545: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb container client-container: <nil>
    STEP: delete the pod 02/13/23 13:35:19.557
    Feb 13 13:35:19.575: INFO: Waiting for pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb to disappear
    Feb 13 13:35:19.577: INFO: Pod downwardapi-volume-cb5aa6f5-c37a-4ae8-921b-514ef5001fbb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 13:35:19.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6805" for this suite. 02/13/23 13:35:19.581
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:19.595
Feb 13 13:35:19.595: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename runtimeclass 02/13/23 13:35:19.598
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:19.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:19.615
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-5502-delete-me 02/13/23 13:35:19.624
STEP: Waiting for the RuntimeClass to disappear 02/13/23 13:35:19.629
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Feb 13 13:35:19.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5502" for this suite. 02/13/23 13:35:19.637
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":11,"skipped":138,"failed":0}
------------------------------
• [0.054 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:19.595
    Feb 13 13:35:19.595: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename runtimeclass 02/13/23 13:35:19.598
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:19.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:19.615
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-5502-delete-me 02/13/23 13:35:19.624
    STEP: Waiting for the RuntimeClass to disappear 02/13/23 13:35:19.629
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Feb 13 13:35:19.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5502" for this suite. 02/13/23 13:35:19.637
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:19.657
Feb 13 13:35:19.657: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 13:35:19.659
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:19.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:19.684
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 02/13/23 13:35:19.688
STEP: Counting existing ResourceQuota 02/13/23 13:35:24.695
STEP: Creating a ResourceQuota 02/13/23 13:35:29.702
STEP: Ensuring resource quota status is calculated 02/13/23 13:35:29.714
STEP: Creating a Secret 02/13/23 13:35:31.724
STEP: Ensuring resource quota status captures secret creation 02/13/23 13:35:31.746
STEP: Deleting a secret 02/13/23 13:35:33.754
STEP: Ensuring resource quota status released usage 02/13/23 13:35:33.767
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 13:35:35.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6546" for this suite. 02/13/23 13:35:35.78
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":12,"skipped":145,"failed":0}
------------------------------
• [SLOW TEST] [16.129 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:19.657
    Feb 13 13:35:19.657: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 13:35:19.659
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:19.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:19.684
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 02/13/23 13:35:19.688
    STEP: Counting existing ResourceQuota 02/13/23 13:35:24.695
    STEP: Creating a ResourceQuota 02/13/23 13:35:29.702
    STEP: Ensuring resource quota status is calculated 02/13/23 13:35:29.714
    STEP: Creating a Secret 02/13/23 13:35:31.724
    STEP: Ensuring resource quota status captures secret creation 02/13/23 13:35:31.746
    STEP: Deleting a secret 02/13/23 13:35:33.754
    STEP: Ensuring resource quota status released usage 02/13/23 13:35:33.767
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 13:35:35.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6546" for this suite. 02/13/23 13:35:35.78
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:35.787
Feb 13 13:35:35.788: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:35:35.79
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:35.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:35.816
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Feb 13 13:35:35.823: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:35:38.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3616" for this suite. 02/13/23 13:35:38.985
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":13,"skipped":150,"failed":0}
------------------------------
• [3.207 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:35.787
    Feb 13 13:35:35.788: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:35:35.79
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:35.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:35.816
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Feb 13 13:35:35.823: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:35:38.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3616" for this suite. 02/13/23 13:35:38.985
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:38.999
Feb 13 13:35:38.999: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 13:35:39.001
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:39.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:39.022
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-b3151259-a9c3-4593-8b6c-5eec8d8d98a8 02/13/23 13:35:39.045
STEP: Creating a pod to test consume secrets 02/13/23 13:35:39.054
W0213 13:35:39.063293      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:35:39.063: INFO: Waiting up to 5m0s for pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9" in namespace "secrets-7591" to be "Succeeded or Failed"
Feb 13 13:35:39.068: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.746938ms
Feb 13 13:35:41.076: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013065607s
Feb 13 13:35:43.074: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010591348s
STEP: Saw pod success 02/13/23 13:35:43.074
Feb 13 13:35:43.074: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9" satisfied condition "Succeeded or Failed"
Feb 13 13:35:43.078: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:35:43.103
Feb 13 13:35:43.119: INFO: Waiting for pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 to disappear
Feb 13 13:35:43.137: INFO: Pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 13:35:43.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7591" for this suite. 02/13/23 13:35:43.143
STEP: Destroying namespace "secret-namespace-7492" for this suite. 02/13/23 13:35:43.151
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":14,"skipped":160,"failed":0}
------------------------------
• [4.161 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:38.999
    Feb 13 13:35:38.999: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 13:35:39.001
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:39.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:39.022
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-b3151259-a9c3-4593-8b6c-5eec8d8d98a8 02/13/23 13:35:39.045
    STEP: Creating a pod to test consume secrets 02/13/23 13:35:39.054
    W0213 13:35:39.063293      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:35:39.063: INFO: Waiting up to 5m0s for pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9" in namespace "secrets-7591" to be "Succeeded or Failed"
    Feb 13 13:35:39.068: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.746938ms
    Feb 13 13:35:41.076: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013065607s
    Feb 13 13:35:43.074: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010591348s
    STEP: Saw pod success 02/13/23 13:35:43.074
    Feb 13 13:35:43.074: INFO: Pod "pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9" satisfied condition "Succeeded or Failed"
    Feb 13 13:35:43.078: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:35:43.103
    Feb 13 13:35:43.119: INFO: Waiting for pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 to disappear
    Feb 13 13:35:43.137: INFO: Pod pod-secrets-74ca8c6a-036b-49e9-b69e-67be5b48f1f9 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 13:35:43.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7591" for this suite. 02/13/23 13:35:43.143
    STEP: Destroying namespace "secret-namespace-7492" for this suite. 02/13/23 13:35:43.151
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:43.168
Feb 13 13:35:43.168: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:35:43.17
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:43.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:43.192
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Feb 13 13:35:43.197: INFO: Creating simple deployment test-new-deployment
W0213 13:35:43.204427      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:35:43.211: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource 02/13/23 13:35:45.23
STEP: updating a scale subresource 02/13/23 13:35:45.236
STEP: verifying the deployment Spec.Replicas was modified 02/13/23 13:35:45.246
STEP: Patch a scale subresource 02/13/23 13:35:45.252
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:35:45.292: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-4625  10038d85-9161-43b0-8b7a-ec4e1be89be3 5533 3 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-02-13 13:35:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:35:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ec8e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 13:35:44 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-02-13 13:35:44 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 13:35:45.301: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4625  a06833f3-b3ea-47a4-960a-86bcbb82d843 5539 2 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 10038d85-9161-43b0-8b7a-ec4e1be89be3 0xc0039eccc0 0xc0039eccc1}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"10038d85-9161-43b0-8b7a-ec4e1be89be3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ecd48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:35:45.308: INFO: Pod "test-new-deployment-845c8977d9-488qz" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-488qz test-new-deployment-845c8977d9- deployment-4625  84f1233e-f767-4d02-9f6f-f4742b152fb1 5527 0 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a06833f3-b3ea-47a4-960a-86bcbb82d843 0xc00383ddd0 0xc00383ddd1}] [] [{kube-controller-manager Update v1 2023-02-13 13:35:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a06833f3-b3ea-47a4-960a-86bcbb82d843\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:35:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ctx8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ctx8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.15,StartTime:2023-02-13 13:35:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:35:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cf458d64eecca3616a87ec546bda989b6e0c9261062567c0ba6bf5e0dc9311ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:35:45.309: INFO: Pod "test-new-deployment-845c8977d9-7hwg7" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-7hwg7 test-new-deployment-845c8977d9- deployment-4625  0b7b6762-3f04-4fc0-b6a4-0beb9fbb2172 5538 0 2023-02-13 13:35:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a06833f3-b3ea-47a4-960a-86bcbb82d843 0xc00383dfa0 0xc00383dfa1}] [] [{kube-controller-manager Update v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a06833f3-b3ea-47a4-960a-86bcbb82d843\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgk9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgk9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:35:45.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4625" for this suite. 02/13/23 13:35:45.325
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":15,"skipped":161,"failed":0}
------------------------------
• [2.168 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:43.168
    Feb 13 13:35:43.168: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:35:43.17
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:43.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:43.192
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Feb 13 13:35:43.197: INFO: Creating simple deployment test-new-deployment
    W0213 13:35:43.204427      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:35:43.211: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
    STEP: getting scale subresource 02/13/23 13:35:45.23
    STEP: updating a scale subresource 02/13/23 13:35:45.236
    STEP: verifying the deployment Spec.Replicas was modified 02/13/23 13:35:45.246
    STEP: Patch a scale subresource 02/13/23 13:35:45.252
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:35:45.292: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-4625  10038d85-9161-43b0-8b7a-ec4e1be89be3 5533 3 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-02-13 13:35:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:35:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ec8e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 13:35:44 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-02-13 13:35:44 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Feb 13 13:35:45.301: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-4625  a06833f3-b3ea-47a4-960a-86bcbb82d843 5539 2 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 10038d85-9161-43b0-8b7a-ec4e1be89be3 0xc0039eccc0 0xc0039eccc1}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"10038d85-9161-43b0-8b7a-ec4e1be89be3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ecd48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:35:45.308: INFO: Pod "test-new-deployment-845c8977d9-488qz" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-488qz test-new-deployment-845c8977d9- deployment-4625  84f1233e-f767-4d02-9f6f-f4742b152fb1 5527 0 2023-02-13 13:35:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a06833f3-b3ea-47a4-960a-86bcbb82d843 0xc00383ddd0 0xc00383ddd1}] [] [{kube-controller-manager Update v1 2023-02-13 13:35:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a06833f3-b3ea-47a4-960a-86bcbb82d843\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:35:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ctx8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ctx8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.15,StartTime:2023-02-13 13:35:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:35:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cf458d64eecca3616a87ec546bda989b6e0c9261062567c0ba6bf5e0dc9311ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:35:45.309: INFO: Pod "test-new-deployment-845c8977d9-7hwg7" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-7hwg7 test-new-deployment-845c8977d9- deployment-4625  0b7b6762-3f04-4fc0-b6a4-0beb9fbb2172 5538 0 2023-02-13 13:35:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a06833f3-b3ea-47a4-960a-86bcbb82d843 0xc00383dfa0 0xc00383dfa1}] [] [{kube-controller-manager Update v1 2023-02-13 13:35:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a06833f3-b3ea-47a4-960a-86bcbb82d843\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgk9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgk9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:35:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:35:45.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4625" for this suite. 02/13/23 13:35:45.325
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:45.34
Feb 13 13:35:45.340: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:35:45.341
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:45.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:45.367
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-c6e820d9-da62-4269-9559-4056b9d23a3c 02/13/23 13:35:45.371
STEP: Creating a pod to test consume secrets 02/13/23 13:35:45.375
W0213 13:35:45.386801      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:35:45.387: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131" in namespace "projected-9675" to be "Succeeded or Failed"
Feb 13 13:35:45.394: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Pending", Reason="", readiness=false. Elapsed: 7.247959ms
Feb 13 13:35:47.400: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013482536s
Feb 13 13:35:49.401: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014208721s
STEP: Saw pod success 02/13/23 13:35:49.401
Feb 13 13:35:49.401: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131" satisfied condition "Succeeded or Failed"
Feb 13 13:35:49.406: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 container projected-secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:35:49.421
Feb 13 13:35:49.440: INFO: Waiting for pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 to disappear
Feb 13 13:35:49.443: INFO: Pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 13:35:49.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9675" for this suite. 02/13/23 13:35:49.448
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":16,"skipped":162,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:45.34
    Feb 13 13:35:45.340: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:35:45.341
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:45.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:45.367
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-c6e820d9-da62-4269-9559-4056b9d23a3c 02/13/23 13:35:45.371
    STEP: Creating a pod to test consume secrets 02/13/23 13:35:45.375
    W0213 13:35:45.386801      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:35:45.387: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131" in namespace "projected-9675" to be "Succeeded or Failed"
    Feb 13 13:35:45.394: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Pending", Reason="", readiness=false. Elapsed: 7.247959ms
    Feb 13 13:35:47.400: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013482536s
    Feb 13 13:35:49.401: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014208721s
    STEP: Saw pod success 02/13/23 13:35:49.401
    Feb 13 13:35:49.401: INFO: Pod "pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131" satisfied condition "Succeeded or Failed"
    Feb 13 13:35:49.406: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 container projected-secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:35:49.421
    Feb 13 13:35:49.440: INFO: Waiting for pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 to disappear
    Feb 13 13:35:49.443: INFO: Pod pod-projected-secrets-18d3ade0-41b9-49ba-8466-a1aec39e6131 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 13:35:49.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9675" for this suite. 02/13/23 13:35:49.448
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:49.47
Feb 13 13:35:49.471: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 13:35:49.472
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:49.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:49.497
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 02/13/23 13:35:49.516
W0213 13:35:49.524504      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:35:49.524
Feb 13 13:35:49.535: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:35:49.535: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:35:50.544: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:35:50.544: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:35:51.548: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 13:35:51.548: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 02/13/23 13:35:51.552
STEP: DeleteCollection of the DaemonSets 02/13/23 13:35:51.559
STEP: Verify that ReplicaSets have been deleted 02/13/23 13:35:51.568
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Feb 13 13:35:51.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5666"},"items":null}

Feb 13 13:35:51.594: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5667"},"items":[{"metadata":{"name":"daemon-set-bnjtk","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"30501a68-6306-47f1-8832-fb2e26278e36","resourceVersion":"5665","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vn66f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vn66f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-vfwrl","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-vfwrl"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.10","podIP":"10.244.2.11","podIPs":[{"ip":"10.244.2.11"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://2f22e063fc9e254ff59620ce415f36803ec4353b7b2d285f551a2d542abb3ef4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-gc44w","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"f400faf7-5c76-43f2-9847-0b64fe3fc911","resourceVersion":"5664","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bb2rb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bb2rb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-myudo","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-myudo"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.12","podIP":"10.244.1.10","podIPs":[{"ip":"10.244.1.10"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://dc4aa5d495e29936dd0cc5d0062414ddd539a0e743fdc5c7b37ba2a3affb7bb9","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-x4ct9","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"d4e6fe69-bc87-4e3b-958e-a5d24c8fcd37","resourceVersion":"5663","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rpv74","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rpv74","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-o7jrw","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-o7jrw"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.11","podIP":"10.244.0.17","podIPs":[{"ip":"10.244.0.17"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9930a1a81d046e843c96ac2db4ae4d41996c478124c31cab7c7c33bf17d90219","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:35:51.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4633" for this suite. 02/13/23 13:35:51.609
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":17,"skipped":218,"failed":0}
------------------------------
• [2.143 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:49.47
    Feb 13 13:35:49.471: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 13:35:49.472
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:49.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:49.497
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 02/13/23 13:35:49.516
    W0213 13:35:49.524504      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:35:49.524
    Feb 13 13:35:49.535: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:35:49.535: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:35:50.544: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:35:50.544: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:35:51.548: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 13:35:51.548: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 02/13/23 13:35:51.552
    STEP: DeleteCollection of the DaemonSets 02/13/23 13:35:51.559
    STEP: Verify that ReplicaSets have been deleted 02/13/23 13:35:51.568
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Feb 13 13:35:51.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5666"},"items":null}

    Feb 13 13:35:51.594: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5667"},"items":[{"metadata":{"name":"daemon-set-bnjtk","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"30501a68-6306-47f1-8832-fb2e26278e36","resourceVersion":"5665","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vn66f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vn66f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-vfwrl","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-vfwrl"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.10","podIP":"10.244.2.11","podIPs":[{"ip":"10.244.2.11"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://2f22e063fc9e254ff59620ce415f36803ec4353b7b2d285f551a2d542abb3ef4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-gc44w","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"f400faf7-5c76-43f2-9847-0b64fe3fc911","resourceVersion":"5664","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bb2rb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bb2rb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-myudo","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-myudo"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.12","podIP":"10.244.1.10","podIPs":[{"ip":"10.244.1.10"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://dc4aa5d495e29936dd0cc5d0062414ddd539a0e743fdc5c7b37ba2a3affb7bb9","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-x4ct9","generateName":"daemon-set-","namespace":"daemonsets-4633","uid":"d4e6fe69-bc87-4e3b-958e-a5d24c8fcd37","resourceVersion":"5663","creationTimestamp":"2023-02-13T13:35:49Z","deletionTimestamp":"2023-02-13T13:36:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"84241533-5d6d-4ca7-a33e-6995e8be4adc","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84241533-5d6d-4ca7-a33e-6995e8be4adc\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-02-13T13:35:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rpv74","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rpv74","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"conformance-5500-0ccfa5-pool-bf9f-o7jrw","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["conformance-5500-0ccfa5-pool-bf9f-o7jrw"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-02-13T13:35:49Z"}],"hostIP":"192.168.1.11","podIP":"10.244.0.17","podIPs":[{"ip":"10.244.0.17"}],"startTime":"2023-02-13T13:35:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-02-13T13:35:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9930a1a81d046e843c96ac2db4ae4d41996c478124c31cab7c7c33bf17d90219","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:35:51.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4633" for this suite. 02/13/23 13:35:51.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:51.621
Feb 13 13:35:51.621: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 13:35:51.622
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:51.637
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:51.641
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 02/13/23 13:35:51.66
W0213 13:35:51.668432      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:35:51.668
Feb 13 13:35:51.681: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:35:51.682: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:35:52.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:35:52.696: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:35:53.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 13:35:53.694: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 02/13/23 13:35:53.7
Feb 13 13:35:53.728: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 13:35:53.728: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
Feb 13 13:35:54.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 13:35:54.741: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
Feb 13 13:35:55.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 13:35:55.740: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 02/13/23 13:35:55.74
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 13:35:55.75
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3536, will wait for the garbage collector to delete the pods 02/13/23 13:35:55.75
Feb 13 13:35:55.817: INFO: Deleting DaemonSet.extensions daemon-set took: 11.514744ms
Feb 13 13:35:55.918: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.503386ms
Feb 13 13:35:58.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:35:58.022: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 13:35:58.027: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5792"},"items":null}

Feb 13 13:35:58.032: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5792"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:35:58.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3536" for this suite. 02/13/23 13:35:58.049
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":18,"skipped":250,"failed":0}
------------------------------
• [SLOW TEST] [6.433 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:51.621
    Feb 13 13:35:51.621: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 13:35:51.622
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:51.637
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:51.641
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 02/13/23 13:35:51.66
    W0213 13:35:51.668432      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:35:51.668
    Feb 13 13:35:51.681: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:35:51.682: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:35:52.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:35:52.696: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:35:53.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 13:35:53.694: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 02/13/23 13:35:53.7
    Feb 13 13:35:53.728: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 13:35:53.728: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
    Feb 13 13:35:54.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 13:35:54.741: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
    Feb 13 13:35:55.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 13:35:55.740: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 02/13/23 13:35:55.74
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 13:35:55.75
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3536, will wait for the garbage collector to delete the pods 02/13/23 13:35:55.75
    Feb 13 13:35:55.817: INFO: Deleting DaemonSet.extensions daemon-set took: 11.514744ms
    Feb 13 13:35:55.918: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.503386ms
    Feb 13 13:35:58.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:35:58.022: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 13:35:58.027: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5792"},"items":null}

    Feb 13 13:35:58.032: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5792"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:35:58.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3536" for this suite. 02/13/23 13:35:58.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:35:58.073
Feb 13 13:35:58.073: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:35:58.075
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:58.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:58.102
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 02/13/23 13:35:58.105
W0213 13:35:58.111832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:35:58.112: INFO: Waiting up to 5m0s for pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a" in namespace "downward-api-733" to be "Succeeded or Failed"
Feb 13 13:35:58.114: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363848ms
Feb 13 13:36:00.122: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01074277s
Feb 13 13:36:02.119: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007488888s
STEP: Saw pod success 02/13/23 13:36:02.119
Feb 13 13:36:02.120: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a" satisfied condition "Succeeded or Failed"
Feb 13 13:36:02.123: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a container dapi-container: <nil>
STEP: delete the pod 02/13/23 13:36:02.136
Feb 13 13:36:02.150: INFO: Waiting for pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a to disappear
Feb 13 13:36:02.153: INFO: Pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Feb 13 13:36:02.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-733" for this suite. 02/13/23 13:36:02.157
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":19,"skipped":281,"failed":0}
------------------------------
• [4.091 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:35:58.073
    Feb 13 13:35:58.073: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:35:58.075
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:35:58.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:35:58.102
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 02/13/23 13:35:58.105
    W0213 13:35:58.111832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:35:58.112: INFO: Waiting up to 5m0s for pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a" in namespace "downward-api-733" to be "Succeeded or Failed"
    Feb 13 13:35:58.114: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363848ms
    Feb 13 13:36:00.122: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01074277s
    Feb 13 13:36:02.119: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007488888s
    STEP: Saw pod success 02/13/23 13:36:02.119
    Feb 13 13:36:02.120: INFO: Pod "downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a" satisfied condition "Succeeded or Failed"
    Feb 13 13:36:02.123: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a container dapi-container: <nil>
    STEP: delete the pod 02/13/23 13:36:02.136
    Feb 13 13:36:02.150: INFO: Waiting for pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a to disappear
    Feb 13 13:36:02.153: INFO: Pod downward-api-ebd6452f-fa76-45fa-96e3-1202f3bee02a no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Feb 13 13:36:02.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-733" for this suite. 02/13/23 13:36:02.157
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:02.165
Feb 13 13:36:02.165: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context-test 02/13/23 13:36:02.166
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:02.179
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:02.182
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
W0213 13:36:02.194528      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:02.194: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" in namespace "security-context-test-2032" to be "Succeeded or Failed"
Feb 13 13:36:02.197: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.076727ms
Feb 13 13:36:04.203: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009163822s
Feb 13 13:36:06.205: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011302401s
Feb 13 13:36:06.206: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 13:36:06.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2032" for this suite. 02/13/23 13:36:06.212
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":20,"skipped":285,"failed":0}
------------------------------
• [4.057 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:02.165
    Feb 13 13:36:02.165: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context-test 02/13/23 13:36:02.166
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:02.179
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:02.182
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    W0213 13:36:02.194528      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:02.194: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" in namespace "security-context-test-2032" to be "Succeeded or Failed"
    Feb 13 13:36:02.197: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.076727ms
    Feb 13 13:36:04.203: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009163822s
    Feb 13 13:36:06.205: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011302401s
    Feb 13 13:36:06.206: INFO: Pod "busybox-readonly-false-1c2440db-9260-4528-b243-66b5e2dbe6b6" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 13:36:06.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2032" for this suite. 02/13/23 13:36:06.212
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:06.224
Feb 13 13:36:06.224: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 13:36:06.226
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:06.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:06.255
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 02/13/23 13:36:06.261
Feb 13 13:36:06.271: INFO: Waiting up to 5m0s for pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21" in namespace "pods-3477" to be "running and ready"
Feb 13 13:36:06.274: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21": Phase="Pending", Reason="", readiness=false. Elapsed: 3.735949ms
Feb 13 13:36:06.274: INFO: The phase of Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:36:08.282: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21": Phase="Running", Reason="", readiness=true. Elapsed: 2.010897539s
Feb 13 13:36:08.282: INFO: The phase of Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 is Running (Ready = true)
Feb 13 13:36:08.282: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21" satisfied condition "running and ready"
Feb 13 13:36:08.292: INFO: Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 has hostIP: 192.168.1.11
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 13:36:08.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3477" for this suite. 02/13/23 13:36:08.3
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":21,"skipped":294,"failed":0}
------------------------------
• [2.085 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:06.224
    Feb 13 13:36:06.224: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 13:36:06.226
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:06.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:06.255
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 02/13/23 13:36:06.261
    Feb 13 13:36:06.271: INFO: Waiting up to 5m0s for pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21" in namespace "pods-3477" to be "running and ready"
    Feb 13 13:36:06.274: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21": Phase="Pending", Reason="", readiness=false. Elapsed: 3.735949ms
    Feb 13 13:36:06.274: INFO: The phase of Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:36:08.282: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21": Phase="Running", Reason="", readiness=true. Elapsed: 2.010897539s
    Feb 13 13:36:08.282: INFO: The phase of Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 is Running (Ready = true)
    Feb 13 13:36:08.282: INFO: Pod "pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21" satisfied condition "running and ready"
    Feb 13 13:36:08.292: INFO: Pod pod-hostip-ce1717ed-2930-482c-8767-5ca615506d21 has hostIP: 192.168.1.11
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 13:36:08.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3477" for this suite. 02/13/23 13:36:08.3
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:08.32
Feb 13 13:36:08.320: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 13:36:08.322
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:08.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:08.345
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-405/configmap-test-7c3b9d73-f884-4b40-9359-9e1a0b125434 02/13/23 13:36:08.349
STEP: Creating a pod to test consume configMaps 02/13/23 13:36:08.354
W0213 13:36:08.362662      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:08.363: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521" in namespace "configmap-405" to be "Succeeded or Failed"
Feb 13 13:36:08.368: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178884ms
Feb 13 13:36:10.378: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014676097s
Feb 13 13:36:12.374: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011379093s
STEP: Saw pod success 02/13/23 13:36:12.375
Feb 13 13:36:12.375: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521" satisfied condition "Succeeded or Failed"
Feb 13 13:36:12.380: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 container env-test: <nil>
STEP: delete the pod 02/13/23 13:36:12.392
Feb 13 13:36:12.409: INFO: Waiting for pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 to disappear
Feb 13 13:36:12.413: INFO: Pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 13:36:12.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-405" for this suite. 02/13/23 13:36:12.424
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":22,"skipped":336,"failed":0}
------------------------------
• [4.122 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:08.32
    Feb 13 13:36:08.320: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 13:36:08.322
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:08.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:08.345
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-405/configmap-test-7c3b9d73-f884-4b40-9359-9e1a0b125434 02/13/23 13:36:08.349
    STEP: Creating a pod to test consume configMaps 02/13/23 13:36:08.354
    W0213 13:36:08.362662      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:08.363: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521" in namespace "configmap-405" to be "Succeeded or Failed"
    Feb 13 13:36:08.368: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178884ms
    Feb 13 13:36:10.378: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014676097s
    Feb 13 13:36:12.374: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011379093s
    STEP: Saw pod success 02/13/23 13:36:12.375
    Feb 13 13:36:12.375: INFO: Pod "pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521" satisfied condition "Succeeded or Failed"
    Feb 13 13:36:12.380: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 container env-test: <nil>
    STEP: delete the pod 02/13/23 13:36:12.392
    Feb 13 13:36:12.409: INFO: Waiting for pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 to disappear
    Feb 13 13:36:12.413: INFO: Pod pod-configmaps-6ff9e899-61aa-4023-b528-6ae4203c2521 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 13:36:12.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-405" for this suite. 02/13/23 13:36:12.424
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:12.445
Feb 13 13:36:12.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:36:12.446
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:12.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:12.462
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Feb 13 13:36:12.468: INFO: Got root ca configmap in namespace "svcaccounts-8490"
Feb 13 13:36:12.474: INFO: Deleted root ca configmap in namespace "svcaccounts-8490"
STEP: waiting for a new root ca configmap created 02/13/23 13:36:12.975
Feb 13 13:36:12.980: INFO: Recreated root ca configmap in namespace "svcaccounts-8490"
Feb 13 13:36:12.985: INFO: Updated root ca configmap in namespace "svcaccounts-8490"
STEP: waiting for the root ca configmap reconciled 02/13/23 13:36:13.486
Feb 13 13:36:13.492: INFO: Reconciled root ca configmap in namespace "svcaccounts-8490"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 13:36:13.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8490" for this suite. 02/13/23 13:36:13.5
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":23,"skipped":359,"failed":0}
------------------------------
• [1.066 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:12.445
    Feb 13 13:36:12.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:36:12.446
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:12.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:12.462
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Feb 13 13:36:12.468: INFO: Got root ca configmap in namespace "svcaccounts-8490"
    Feb 13 13:36:12.474: INFO: Deleted root ca configmap in namespace "svcaccounts-8490"
    STEP: waiting for a new root ca configmap created 02/13/23 13:36:12.975
    Feb 13 13:36:12.980: INFO: Recreated root ca configmap in namespace "svcaccounts-8490"
    Feb 13 13:36:12.985: INFO: Updated root ca configmap in namespace "svcaccounts-8490"
    STEP: waiting for the root ca configmap reconciled 02/13/23 13:36:13.486
    Feb 13 13:36:13.492: INFO: Reconciled root ca configmap in namespace "svcaccounts-8490"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 13:36:13.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8490" for this suite. 02/13/23 13:36:13.5
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:13.514
Feb 13 13:36:13.515: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption 02/13/23 13:36:13.517
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:13.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:13.545
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 02/13/23 13:36:13.555
W0213 13:36:15.580064      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:36:15.592934      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:36:15.604691      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for all pods to be running 02/13/23 13:36:15.605
Feb 13 13:36:15.612: INFO: running pods: 0 < 3
Feb 13 13:36:17.621: INFO: running pods: 2 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Feb 13 13:36:19.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4208" for this suite. 02/13/23 13:36:19.636
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":24,"skipped":361,"failed":0}
------------------------------
• [SLOW TEST] [6.129 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:13.514
    Feb 13 13:36:13.515: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption 02/13/23 13:36:13.517
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:13.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:13.545
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 02/13/23 13:36:13.555
    W0213 13:36:15.580064      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:36:15.592934      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:36:15.604691      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for all pods to be running 02/13/23 13:36:15.605
    Feb 13 13:36:15.612: INFO: running pods: 0 < 3
    Feb 13 13:36:17.621: INFO: running pods: 2 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Feb 13 13:36:19.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4208" for this suite. 02/13/23 13:36:19.636
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:19.649
Feb 13 13:36:19.649: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename conformance-tests 02/13/23 13:36:19.652
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.675
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 02/13/23 13:36:19.68
Feb 13 13:36:19.680: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Feb 13 13:36:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1738" for this suite. 02/13/23 13:36:19.693
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":25,"skipped":363,"failed":0}
------------------------------
• [0.052 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:19.649
    Feb 13 13:36:19.649: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename conformance-tests 02/13/23 13:36:19.652
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.675
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 02/13/23 13:36:19.68
    Feb 13 13:36:19.680: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Feb 13 13:36:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1738" for this suite. 02/13/23 13:36:19.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:19.703
Feb 13 13:36:19.703: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:36:19.705
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.722
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 02/13/23 13:36:19.726
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 02/13/23 13:36:19.728
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 02/13/23 13:36:19.729
STEP: fetching the /apis/apiextensions.k8s.io discovery document 02/13/23 13:36:19.729
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 02/13/23 13:36:19.731
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 02/13/23 13:36:19.731
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 02/13/23 13:36:19.733
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:36:19.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1440" for this suite. 02/13/23 13:36:19.737
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":26,"skipped":371,"failed":0}
------------------------------
• [0.039 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:19.703
    Feb 13 13:36:19.703: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:36:19.705
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.722
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 02/13/23 13:36:19.726
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 02/13/23 13:36:19.728
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 02/13/23 13:36:19.729
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 02/13/23 13:36:19.729
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 02/13/23 13:36:19.731
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 02/13/23 13:36:19.731
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 02/13/23 13:36:19.733
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:36:19.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1440" for this suite. 02/13/23 13:36:19.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:19.743
Feb 13 13:36:19.744: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:36:19.745
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.759
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.764
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:36:19.773
W0213 13:36:19.786175      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:19.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824" in namespace "downward-api-9920" to be "Succeeded or Failed"
Feb 13 13:36:19.792: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095678ms
Feb 13 13:36:21.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012272691s
Feb 13 13:36:23.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012211183s
STEP: Saw pod success 02/13/23 13:36:23.799
Feb 13 13:36:23.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824" satisfied condition "Succeeded or Failed"
Feb 13 13:36:23.803: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 container client-container: <nil>
STEP: delete the pod 02/13/23 13:36:23.816
Feb 13 13:36:23.829: INFO: Waiting for pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 to disappear
Feb 13 13:36:23.833: INFO: Pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:36:23.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9920" for this suite. 02/13/23 13:36:23.837
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":27,"skipped":390,"failed":0}
------------------------------
• [4.100 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:19.743
    Feb 13 13:36:19.744: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:36:19.745
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:19.759
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:19.764
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:36:19.773
    W0213 13:36:19.786175      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:19.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824" in namespace "downward-api-9920" to be "Succeeded or Failed"
    Feb 13 13:36:19.792: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095678ms
    Feb 13 13:36:21.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012272691s
    Feb 13 13:36:23.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012211183s
    STEP: Saw pod success 02/13/23 13:36:23.799
    Feb 13 13:36:23.799: INFO: Pod "downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824" satisfied condition "Succeeded or Failed"
    Feb 13 13:36:23.803: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:36:23.816
    Feb 13 13:36:23.829: INFO: Waiting for pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 to disappear
    Feb 13 13:36:23.833: INFO: Pod downwardapi-volume-b126892b-c49a-4a57-814c-99c1ac0a4824 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:36:23.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9920" for this suite. 02/13/23 13:36:23.837
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:23.854
Feb 13 13:36:23.854: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 13:36:23.856
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:23.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:23.886
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 13:36:23.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8111" for this suite. 02/13/23 13:36:23.946
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":28,"skipped":394,"failed":0}
------------------------------
• [0.099 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:23.854
    Feb 13 13:36:23.854: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 13:36:23.856
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:23.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:23.886
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 13:36:23.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8111" for this suite. 02/13/23 13:36:23.946
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:23.961
Feb 13 13:36:23.962: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:36:23.964
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:23.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:23.994
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:36:23.999
W0213 13:36:24.014151      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:24.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563" in namespace "projected-8594" to be "Succeeded or Failed"
Feb 13 13:36:24.018: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78412ms
Feb 13 13:36:26.025: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011316063s
Feb 13 13:36:28.026: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011766499s
STEP: Saw pod success 02/13/23 13:36:28.026
Feb 13 13:36:28.026: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563" satisfied condition "Succeeded or Failed"
Feb 13 13:36:28.032: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 container client-container: <nil>
STEP: delete the pod 02/13/23 13:36:28.044
Feb 13 13:36:28.061: INFO: Waiting for pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 to disappear
Feb 13 13:36:28.065: INFO: Pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 13:36:28.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8594" for this suite. 02/13/23 13:36:28.072
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":29,"skipped":403,"failed":0}
------------------------------
• [4.122 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:23.961
    Feb 13 13:36:23.962: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:36:23.964
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:23.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:23.994
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:36:23.999
    W0213 13:36:24.014151      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:24.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563" in namespace "projected-8594" to be "Succeeded or Failed"
    Feb 13 13:36:24.018: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78412ms
    Feb 13 13:36:26.025: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011316063s
    Feb 13 13:36:28.026: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011766499s
    STEP: Saw pod success 02/13/23 13:36:28.026
    Feb 13 13:36:28.026: INFO: Pod "downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563" satisfied condition "Succeeded or Failed"
    Feb 13 13:36:28.032: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:36:28.044
    Feb 13 13:36:28.061: INFO: Waiting for pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 to disappear
    Feb 13 13:36:28.065: INFO: Pod downwardapi-volume-b4639739-f148-4167-b4f5-339f4c352563 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 13:36:28.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8594" for this suite. 02/13/23 13:36:28.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:28.1
Feb 13 13:36:28.101: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename proxy 02/13/23 13:36:28.102
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:28.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:28.127
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Feb 13 13:36:28.132: INFO: Creating pod...
W0213 13:36:28.142173      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:28.142: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9018" to be "running"
Feb 13 13:36:28.147: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.949665ms
Feb 13 13:36:30.155: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.0125196s
Feb 13 13:36:30.155: INFO: Pod "agnhost" satisfied condition "running"
Feb 13 13:36:30.155: INFO: Creating service...
Feb 13 13:36:30.186: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=DELETE
Feb 13 13:36:30.201: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Feb 13 13:36:30.201: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=OPTIONS
Feb 13 13:36:30.207: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Feb 13 13:36:30.208: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=PATCH
Feb 13 13:36:30.214: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Feb 13 13:36:30.214: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=POST
Feb 13 13:36:30.219: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Feb 13 13:36:30.220: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=PUT
Feb 13 13:36:30.227: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Feb 13 13:36:30.227: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=DELETE
Feb 13 13:36:30.237: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Feb 13 13:36:30.237: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=OPTIONS
Feb 13 13:36:30.248: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Feb 13 13:36:30.248: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=PATCH
Feb 13 13:36:30.258: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Feb 13 13:36:30.258: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=POST
Feb 13 13:36:30.268: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Feb 13 13:36:30.268: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=PUT
Feb 13 13:36:30.277: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Feb 13 13:36:30.277: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=GET
Feb 13 13:36:30.281: INFO: http.Client request:GET StatusCode:301
Feb 13 13:36:30.281: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=GET
Feb 13 13:36:30.286: INFO: http.Client request:GET StatusCode:301
Feb 13 13:36:30.286: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=HEAD
Feb 13 13:36:30.290: INFO: http.Client request:HEAD StatusCode:301
Feb 13 13:36:30.290: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=HEAD
Feb 13 13:36:30.294: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Feb 13 13:36:30.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9018" for this suite. 02/13/23 13:36:30.298
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":30,"skipped":428,"failed":0}
------------------------------
• [2.204 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:28.1
    Feb 13 13:36:28.101: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename proxy 02/13/23 13:36:28.102
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:28.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:28.127
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Feb 13 13:36:28.132: INFO: Creating pod...
    W0213 13:36:28.142173      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:28.142: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9018" to be "running"
    Feb 13 13:36:28.147: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.949665ms
    Feb 13 13:36:30.155: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.0125196s
    Feb 13 13:36:30.155: INFO: Pod "agnhost" satisfied condition "running"
    Feb 13 13:36:30.155: INFO: Creating service...
    Feb 13 13:36:30.186: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=DELETE
    Feb 13 13:36:30.201: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Feb 13 13:36:30.201: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=OPTIONS
    Feb 13 13:36:30.207: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Feb 13 13:36:30.208: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=PATCH
    Feb 13 13:36:30.214: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Feb 13 13:36:30.214: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=POST
    Feb 13 13:36:30.219: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Feb 13 13:36:30.220: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=PUT
    Feb 13 13:36:30.227: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Feb 13 13:36:30.227: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=DELETE
    Feb 13 13:36:30.237: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Feb 13 13:36:30.237: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Feb 13 13:36:30.248: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Feb 13 13:36:30.248: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=PATCH
    Feb 13 13:36:30.258: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Feb 13 13:36:30.258: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=POST
    Feb 13 13:36:30.268: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Feb 13 13:36:30.268: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=PUT
    Feb 13 13:36:30.277: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Feb 13 13:36:30.277: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=GET
    Feb 13 13:36:30.281: INFO: http.Client request:GET StatusCode:301
    Feb 13 13:36:30.281: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=GET
    Feb 13 13:36:30.286: INFO: http.Client request:GET StatusCode:301
    Feb 13 13:36:30.286: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/pods/agnhost/proxy?method=HEAD
    Feb 13 13:36:30.290: INFO: http.Client request:HEAD StatusCode:301
    Feb 13 13:36:30.290: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-9018/services/e2e-proxy-test-service/proxy?method=HEAD
    Feb 13 13:36:30.294: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Feb 13 13:36:30.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9018" for this suite. 02/13/23 13:36:30.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:36:30.305
Feb 13 13:36:30.306: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir-wrapper 02/13/23 13:36:30.307
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:30.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:30.326
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 02/13/23 13:36:30.33
STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:36:30.597
W0213 13:36:30.623824      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:30.671: INFO: Pod name wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a: Found 3 pods out of 5
Feb 13 13:36:35.684: INFO: Pod name wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a: Found 5 pods out of 5
STEP: Ensuring each pod is running 02/13/23 13:36:35.684
Feb 13 13:36:35.684: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:35.689: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 5.136689ms
Feb 13 13:36:37.696: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011954826s
Feb 13 13:36:39.701: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017319474s
Feb 13 13:36:41.701: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017366008s
Feb 13 13:36:43.700: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015705919s
Feb 13 13:36:45.699: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Running", Reason="", readiness=true. Elapsed: 10.014402323s
Feb 13 13:36:45.699: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w" satisfied condition "running"
Feb 13 13:36:45.699: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:45.708: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65": Phase="Running", Reason="", readiness=true. Elapsed: 8.757056ms
Feb 13 13:36:45.708: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65" satisfied condition "running"
Feb 13 13:36:45.708: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:45.715: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf": Phase="Running", Reason="", readiness=true. Elapsed: 6.775248ms
Feb 13 13:36:45.715: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf" satisfied condition "running"
Feb 13 13:36:45.715: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:45.721: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps": Phase="Running", Reason="", readiness=true. Elapsed: 6.053857ms
Feb 13 13:36:45.721: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps" satisfied condition "running"
Feb 13 13:36:45.721: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:45.726: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb": Phase="Running", Reason="", readiness=true. Elapsed: 4.67558ms
Feb 13 13:36:45.726: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:36:45.726
Feb 13 13:36:45.794: INFO: Deleting ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a took: 11.110188ms
Feb 13 13:36:45.895: INFO: Terminating ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a pods took: 100.780741ms
STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:36:49.203
W0213 13:36:49.227390      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:36:49.234: INFO: Pod name wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273: Found 0 pods out of 5
Feb 13 13:36:54.245: INFO: Pod name wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273: Found 5 pods out of 5
STEP: Ensuring each pod is running 02/13/23 13:36:54.245
Feb 13 13:36:54.246: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:36:54.252: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.296306ms
Feb 13 13:36:56.260: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014807395s
Feb 13 13:36:58.256: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010777878s
Feb 13 13:37:00.261: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015465106s
Feb 13 13:37:02.262: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016320715s
Feb 13 13:37:04.273: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Running", Reason="", readiness=true. Elapsed: 10.027874024s
Feb 13 13:37:04.274: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7" satisfied condition "running"
Feb 13 13:37:04.274: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:04.279: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr": Phase="Running", Reason="", readiness=true. Elapsed: 5.727943ms
Feb 13 13:37:04.279: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr" satisfied condition "running"
Feb 13 13:37:04.279: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:04.284: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8": Phase="Running", Reason="", readiness=true. Elapsed: 4.351081ms
Feb 13 13:37:04.284: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8" satisfied condition "running"
Feb 13 13:37:04.284: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:04.291: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5": Phase="Running", Reason="", readiness=true. Elapsed: 7.13108ms
Feb 13 13:37:04.291: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5" satisfied condition "running"
Feb 13 13:37:04.291: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:04.295: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl": Phase="Running", Reason="", readiness=true. Elapsed: 4.052562ms
Feb 13 13:37:04.295: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:37:04.295
Feb 13 13:37:04.358: INFO: Deleting ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 took: 5.826541ms
Feb 13 13:37:04.458: INFO: Terminating ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 pods took: 100.395298ms
STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:37:06.967
W0213 13:37:06.989358      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:37:06.994: INFO: Pod name wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982: Found 0 pods out of 5
Feb 13 13:37:12.005: INFO: Pod name wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982: Found 5 pods out of 5
STEP: Ensuring each pod is running 02/13/23 13:37:12.005
Feb 13 13:37:12.005: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:12.010: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.265945ms
Feb 13 13:37:14.019: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013815902s
Feb 13 13:37:16.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012383227s
Feb 13 13:37:18.017: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011292051s
Feb 13 13:37:20.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012380621s
Feb 13 13:37:22.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Running", Reason="", readiness=true. Elapsed: 10.012606561s
Feb 13 13:37:22.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d" satisfied condition "running"
Feb 13 13:37:22.018: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:22.024: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4": Phase="Running", Reason="", readiness=true. Elapsed: 5.529335ms
Feb 13 13:37:22.024: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4" satisfied condition "running"
Feb 13 13:37:22.024: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:22.029: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8": Phase="Running", Reason="", readiness=true. Elapsed: 5.48669ms
Feb 13 13:37:22.030: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8" satisfied condition "running"
Feb 13 13:37:22.030: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:22.035: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.172342ms
Feb 13 13:37:22.035: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq" satisfied condition "running"
Feb 13 13:37:22.035: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm" in namespace "emptydir-wrapper-4065" to be "running"
Feb 13 13:37:22.038: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm": Phase="Running", Reason="", readiness=true. Elapsed: 3.684133ms
Feb 13 13:37:22.038: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:37:22.038
Feb 13 13:37:22.108: INFO: Deleting ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 took: 14.964702ms
Feb 13 13:37:22.209: INFO: Terminating ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 pods took: 100.71375ms
STEP: Cleaning up the configMaps 02/13/23 13:37:25.31
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Feb 13 13:37:25.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4065" for this suite. 02/13/23 13:37:25.646
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":31,"skipped":445,"failed":0}
------------------------------
• [SLOW TEST] [55.347 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:36:30.305
    Feb 13 13:36:30.306: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir-wrapper 02/13/23 13:36:30.307
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:36:30.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:36:30.326
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 02/13/23 13:36:30.33
    STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:36:30.597
    W0213 13:36:30.623824      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:30.671: INFO: Pod name wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a: Found 3 pods out of 5
    Feb 13 13:36:35.684: INFO: Pod name wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a: Found 5 pods out of 5
    STEP: Ensuring each pod is running 02/13/23 13:36:35.684
    Feb 13 13:36:35.684: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:35.689: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 5.136689ms
    Feb 13 13:36:37.696: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011954826s
    Feb 13 13:36:39.701: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017319474s
    Feb 13 13:36:41.701: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017366008s
    Feb 13 13:36:43.700: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015705919s
    Feb 13 13:36:45.699: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w": Phase="Running", Reason="", readiness=true. Elapsed: 10.014402323s
    Feb 13 13:36:45.699: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-2v86w" satisfied condition "running"
    Feb 13 13:36:45.699: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:45.708: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65": Phase="Running", Reason="", readiness=true. Elapsed: 8.757056ms
    Feb 13 13:36:45.708: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-77n65" satisfied condition "running"
    Feb 13 13:36:45.708: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:45.715: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf": Phase="Running", Reason="", readiness=true. Elapsed: 6.775248ms
    Feb 13 13:36:45.715: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-jxvnf" satisfied condition "running"
    Feb 13 13:36:45.715: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:45.721: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps": Phase="Running", Reason="", readiness=true. Elapsed: 6.053857ms
    Feb 13 13:36:45.721: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-scpps" satisfied condition "running"
    Feb 13 13:36:45.721: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:45.726: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb": Phase="Running", Reason="", readiness=true. Elapsed: 4.67558ms
    Feb 13 13:36:45.726: INFO: Pod "wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a-tmzdb" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:36:45.726
    Feb 13 13:36:45.794: INFO: Deleting ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a took: 11.110188ms
    Feb 13 13:36:45.895: INFO: Terminating ReplicationController wrapped-volume-race-486146aa-ad69-46bf-b427-3c78a38f3f3a pods took: 100.780741ms
    STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:36:49.203
    W0213 13:36:49.227390      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:36:49.234: INFO: Pod name wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273: Found 0 pods out of 5
    Feb 13 13:36:54.245: INFO: Pod name wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273: Found 5 pods out of 5
    STEP: Ensuring each pod is running 02/13/23 13:36:54.245
    Feb 13 13:36:54.246: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:36:54.252: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.296306ms
    Feb 13 13:36:56.260: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014807395s
    Feb 13 13:36:58.256: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010777878s
    Feb 13 13:37:00.261: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015465106s
    Feb 13 13:37:02.262: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016320715s
    Feb 13 13:37:04.273: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7": Phase="Running", Reason="", readiness=true. Elapsed: 10.027874024s
    Feb 13 13:37:04.274: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-7g7n7" satisfied condition "running"
    Feb 13 13:37:04.274: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:04.279: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr": Phase="Running", Reason="", readiness=true. Elapsed: 5.727943ms
    Feb 13 13:37:04.279: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-fw2wr" satisfied condition "running"
    Feb 13 13:37:04.279: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:04.284: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8": Phase="Running", Reason="", readiness=true. Elapsed: 4.351081ms
    Feb 13 13:37:04.284: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-gj4f8" satisfied condition "running"
    Feb 13 13:37:04.284: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:04.291: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5": Phase="Running", Reason="", readiness=true. Elapsed: 7.13108ms
    Feb 13 13:37:04.291: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-hdnf5" satisfied condition "running"
    Feb 13 13:37:04.291: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:04.295: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl": Phase="Running", Reason="", readiness=true. Elapsed: 4.052562ms
    Feb 13 13:37:04.295: INFO: Pod "wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273-x99gl" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:37:04.295
    Feb 13 13:37:04.358: INFO: Deleting ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 took: 5.826541ms
    Feb 13 13:37:04.458: INFO: Terminating ReplicationController wrapped-volume-race-da028a7a-f5f8-481f-b2e4-0e2da4f87273 pods took: 100.395298ms
    STEP: Creating RC which spawns configmap-volume pods 02/13/23 13:37:06.967
    W0213 13:37:06.989358      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:37:06.994: INFO: Pod name wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982: Found 0 pods out of 5
    Feb 13 13:37:12.005: INFO: Pod name wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982: Found 5 pods out of 5
    STEP: Ensuring each pod is running 02/13/23 13:37:12.005
    Feb 13 13:37:12.005: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:12.010: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.265945ms
    Feb 13 13:37:14.019: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013815902s
    Feb 13 13:37:16.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012383227s
    Feb 13 13:37:18.017: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011292051s
    Feb 13 13:37:20.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012380621s
    Feb 13 13:37:22.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d": Phase="Running", Reason="", readiness=true. Elapsed: 10.012606561s
    Feb 13 13:37:22.018: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4c65d" satisfied condition "running"
    Feb 13 13:37:22.018: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:22.024: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4": Phase="Running", Reason="", readiness=true. Elapsed: 5.529335ms
    Feb 13 13:37:22.024: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-4fcd4" satisfied condition "running"
    Feb 13 13:37:22.024: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:22.029: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8": Phase="Running", Reason="", readiness=true. Elapsed: 5.48669ms
    Feb 13 13:37:22.030: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-89jr8" satisfied condition "running"
    Feb 13 13:37:22.030: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:22.035: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.172342ms
    Feb 13 13:37:22.035: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-cksqq" satisfied condition "running"
    Feb 13 13:37:22.035: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm" in namespace "emptydir-wrapper-4065" to be "running"
    Feb 13 13:37:22.038: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm": Phase="Running", Reason="", readiness=true. Elapsed: 3.684133ms
    Feb 13 13:37:22.038: INFO: Pod "wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982-tkjmm" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 in namespace emptydir-wrapper-4065, will wait for the garbage collector to delete the pods 02/13/23 13:37:22.038
    Feb 13 13:37:22.108: INFO: Deleting ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 took: 14.964702ms
    Feb 13 13:37:22.209: INFO: Terminating ReplicationController wrapped-volume-race-152b1508-0688-453c-bc18-897ec5d80982 pods took: 100.71375ms
    STEP: Cleaning up the configMaps 02/13/23 13:37:25.31
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:37:25.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4065" for this suite. 02/13/23 13:37:25.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:25.652
Feb 13 13:37:25.652: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:37:25.655
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:25.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:25.673
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1529 02/13/23 13:37:25.677
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 02/13/23 13:37:25.694
STEP: creating service externalsvc in namespace services-1529 02/13/23 13:37:25.694
STEP: creating replication controller externalsvc in namespace services-1529 02/13/23 13:37:25.709
W0213 13:37:25.714832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 13:37:25.715116      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1529, replica count: 2
I0213 13:37:28.767365      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 02/13/23 13:37:28.771
Feb 13 13:37:28.789: INFO: Creating new exec pod
W0213 13:37:28.799637      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:37:28.800: INFO: Waiting up to 5m0s for pod "execpod2q9jv" in namespace "services-1529" to be "running"
Feb 13 13:37:28.806: INFO: Pod "execpod2q9jv": Phase="Pending", Reason="", readiness=false. Elapsed: 5.699346ms
Feb 13 13:37:30.809: INFO: Pod "execpod2q9jv": Phase="Running", Reason="", readiness=true. Elapsed: 2.009327735s
Feb 13 13:37:30.809: INFO: Pod "execpod2q9jv" satisfied condition "running"
Feb 13 13:37:30.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1529 exec execpod2q9jv -- /bin/sh -x -c nslookup clusterip-service.services-1529.svc.cluster.local'
Feb 13 13:37:31.129: INFO: stderr: "+ nslookup clusterip-service.services-1529.svc.cluster.local\n"
Feb 13 13:37:31.129: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-1529.svc.cluster.local\tcanonical name = externalsvc.services-1529.svc.cluster.local.\nName:\texternalsvc.services-1529.svc.cluster.local\nAddress: 10.96.109.223\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1529, will wait for the garbage collector to delete the pods 02/13/23 13:37:31.129
Feb 13 13:37:31.197: INFO: Deleting ReplicationController externalsvc took: 12.601684ms
Feb 13 13:37:31.297: INFO: Terminating ReplicationController externalsvc pods took: 100.619335ms
Feb 13 13:37:33.547: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:37:33.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1529" for this suite. 02/13/23 13:37:33.566
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":32,"skipped":454,"failed":0}
------------------------------
• [SLOW TEST] [7.928 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:25.652
    Feb 13 13:37:25.652: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:37:25.655
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:25.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:25.673
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1529 02/13/23 13:37:25.677
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 02/13/23 13:37:25.694
    STEP: creating service externalsvc in namespace services-1529 02/13/23 13:37:25.694
    STEP: creating replication controller externalsvc in namespace services-1529 02/13/23 13:37:25.709
    W0213 13:37:25.714832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 13:37:25.715116      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1529, replica count: 2
    I0213 13:37:28.767365      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 02/13/23 13:37:28.771
    Feb 13 13:37:28.789: INFO: Creating new exec pod
    W0213 13:37:28.799637      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:37:28.800: INFO: Waiting up to 5m0s for pod "execpod2q9jv" in namespace "services-1529" to be "running"
    Feb 13 13:37:28.806: INFO: Pod "execpod2q9jv": Phase="Pending", Reason="", readiness=false. Elapsed: 5.699346ms
    Feb 13 13:37:30.809: INFO: Pod "execpod2q9jv": Phase="Running", Reason="", readiness=true. Elapsed: 2.009327735s
    Feb 13 13:37:30.809: INFO: Pod "execpod2q9jv" satisfied condition "running"
    Feb 13 13:37:30.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1529 exec execpod2q9jv -- /bin/sh -x -c nslookup clusterip-service.services-1529.svc.cluster.local'
    Feb 13 13:37:31.129: INFO: stderr: "+ nslookup clusterip-service.services-1529.svc.cluster.local\n"
    Feb 13 13:37:31.129: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-1529.svc.cluster.local\tcanonical name = externalsvc.services-1529.svc.cluster.local.\nName:\texternalsvc.services-1529.svc.cluster.local\nAddress: 10.96.109.223\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1529, will wait for the garbage collector to delete the pods 02/13/23 13:37:31.129
    Feb 13 13:37:31.197: INFO: Deleting ReplicationController externalsvc took: 12.601684ms
    Feb 13 13:37:31.297: INFO: Terminating ReplicationController externalsvc pods took: 100.619335ms
    Feb 13 13:37:33.547: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:37:33.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1529" for this suite. 02/13/23 13:37:33.566
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:33.592
Feb 13 13:37:33.593: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:37:33.596
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:33.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:33.615
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 02/13/23 13:37:33.618
W0213 13:37:33.626898      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:37:33.627: INFO: Waiting up to 5m0s for pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3" in namespace "emptydir-6842" to be "Succeeded or Failed"
Feb 13 13:37:33.633: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.779601ms
Feb 13 13:37:35.640: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013792494s
Feb 13 13:37:37.642: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015486144s
STEP: Saw pod success 02/13/23 13:37:37.642
Feb 13 13:37:37.642: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3" satisfied condition "Succeeded or Failed"
Feb 13 13:37:37.648: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 container test-container: <nil>
STEP: delete the pod 02/13/23 13:37:37.668
Feb 13 13:37:37.687: INFO: Waiting for pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 to disappear
Feb 13 13:37:37.692: INFO: Pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:37:37.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6842" for this suite. 02/13/23 13:37:37.7
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":33,"skipped":463,"failed":0}
------------------------------
• [4.115 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:33.592
    Feb 13 13:37:33.593: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:37:33.596
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:33.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:33.615
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 02/13/23 13:37:33.618
    W0213 13:37:33.626898      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:37:33.627: INFO: Waiting up to 5m0s for pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3" in namespace "emptydir-6842" to be "Succeeded or Failed"
    Feb 13 13:37:33.633: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.779601ms
    Feb 13 13:37:35.640: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013792494s
    Feb 13 13:37:37.642: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015486144s
    STEP: Saw pod success 02/13/23 13:37:37.642
    Feb 13 13:37:37.642: INFO: Pod "pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3" satisfied condition "Succeeded or Failed"
    Feb 13 13:37:37.648: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 container test-container: <nil>
    STEP: delete the pod 02/13/23 13:37:37.668
    Feb 13 13:37:37.687: INFO: Waiting for pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 to disappear
    Feb 13 13:37:37.692: INFO: Pod pod-4b33f8f5-37d2-4020-a1bb-c1f8bb5dacd3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:37:37.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6842" for this suite. 02/13/23 13:37:37.7
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:37.718
Feb 13 13:37:37.719: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:37:37.721
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:37.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:37.75
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-7033 02/13/23 13:37:37.755
STEP: creating service affinity-clusterip-transition in namespace services-7033 02/13/23 13:37:37.755
STEP: creating replication controller affinity-clusterip-transition in namespace services-7033 02/13/23 13:37:37.773
W0213 13:37:37.782068      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 13:37:37.782541      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-7033, replica count: 3
I0213 13:37:40.834631      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 13:37:40.844: INFO: Creating new exec pod
W0213 13:37:40.857132      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:37:40.857: INFO: Waiting up to 5m0s for pod "execpod-affinityw59kx" in namespace "services-7033" to be "running"
Feb 13 13:37:40.865: INFO: Pod "execpod-affinityw59kx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.885173ms
Feb 13 13:37:42.871: INFO: Pod "execpod-affinityw59kx": Phase="Running", Reason="", readiness=true. Elapsed: 2.01302388s
Feb 13 13:37:42.871: INFO: Pod "execpod-affinityw59kx" satisfied condition "running"
Feb 13 13:37:43.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Feb 13 13:37:44.183: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Feb 13 13:37:44.183: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:37:44.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.121.128 80'
Feb 13 13:37:44.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.121.128 80\nConnection to 10.104.121.128 80 port [tcp/http] succeeded!\n"
Feb 13 13:37:44.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:37:44.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.104.121.128:80/ ; done'
Feb 13 13:37:44.801: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n"
Feb 13 13:37:44.801: INFO: stdout: "\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k"
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
Feb 13 13:37:44.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.104.121.128:80/ ; done'
Feb 13 13:37:45.187: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n"
Feb 13 13:37:45.187: INFO: stdout: "\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4"
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
Feb 13 13:37:45.187: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-7033, will wait for the garbage collector to delete the pods 02/13/23 13:37:45.21
Feb 13 13:37:45.278: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.70026ms
Feb 13 13:37:45.379: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.167695ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:37:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7033" for this suite. 02/13/23 13:37:47.611
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":34,"skipped":480,"failed":0}
------------------------------
• [SLOW TEST] [9.900 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:37.718
    Feb 13 13:37:37.719: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:37:37.721
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:37.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:37.75
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-7033 02/13/23 13:37:37.755
    STEP: creating service affinity-clusterip-transition in namespace services-7033 02/13/23 13:37:37.755
    STEP: creating replication controller affinity-clusterip-transition in namespace services-7033 02/13/23 13:37:37.773
    W0213 13:37:37.782068      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 13:37:37.782541      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-7033, replica count: 3
    I0213 13:37:40.834631      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 13:37:40.844: INFO: Creating new exec pod
    W0213 13:37:40.857132      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:37:40.857: INFO: Waiting up to 5m0s for pod "execpod-affinityw59kx" in namespace "services-7033" to be "running"
    Feb 13 13:37:40.865: INFO: Pod "execpod-affinityw59kx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.885173ms
    Feb 13 13:37:42.871: INFO: Pod "execpod-affinityw59kx": Phase="Running", Reason="", readiness=true. Elapsed: 2.01302388s
    Feb 13 13:37:42.871: INFO: Pod "execpod-affinityw59kx" satisfied condition "running"
    Feb 13 13:37:43.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Feb 13 13:37:44.183: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Feb 13 13:37:44.183: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:37:44.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.121.128 80'
    Feb 13 13:37:44.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.121.128 80\nConnection to 10.104.121.128 80 port [tcp/http] succeeded!\n"
    Feb 13 13:37:44.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:37:44.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.104.121.128:80/ ; done'
    Feb 13 13:37:44.801: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n"
    Feb 13 13:37:44.801: INFO: stdout: "\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-x2hlq\naffinity-clusterip-transition-mdt6k"
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-x2hlq
    Feb 13 13:37:44.801: INFO: Received response from host: affinity-clusterip-transition-mdt6k
    Feb 13 13:37:44.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7033 exec execpod-affinityw59kx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.104.121.128:80/ ; done'
    Feb 13 13:37:45.187: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.121.128:80/\n"
    Feb 13 13:37:45.187: INFO: stdout: "\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4\naffinity-clusterip-transition-hmdm4"
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Received response from host: affinity-clusterip-transition-hmdm4
    Feb 13 13:37:45.187: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-7033, will wait for the garbage collector to delete the pods 02/13/23 13:37:45.21
    Feb 13 13:37:45.278: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.70026ms
    Feb 13 13:37:45.379: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.167695ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:37:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7033" for this suite. 02/13/23 13:37:47.611
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:47.623
Feb 13 13:37:47.623: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 13:37:47.624
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:47.636
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:47.64
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 02/13/23 13:37:47.647
W0213 13:37:47.662118      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Patching the Job 02/13/23 13:37:47.662
W0213 13:37:47.674782      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Watching for Job to be patched 02/13/23 13:37:47.674
Feb 13 13:37:47.679: INFO: Event ADDED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw] and annotations: map[batch.kubernetes.io/job-tracking:]
Feb 13 13:37:47.679: INFO: Event MODIFIED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 02/13/23 13:37:47.679
W0213 13:37:47.700571      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Watching for Job to be updated 02/13/23 13:37:47.7
Feb 13 13:37:47.702: INFO: Event MODIFIED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:47.702: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 02/13/23 13:37:47.703
Feb 13 13:37:47.706: INFO: Job: e2e-lwstw as labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched]
STEP: Waiting for job to complete 02/13/23 13:37:47.707
STEP: Delete a job collection with a labelselector 02/13/23 13:37:55.713
STEP: Watching for Job to be deleted 02/13/23 13:37:55.728
Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:55.732: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Feb 13 13:37:55.732: INFO: Event DELETED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 02/13/23 13:37:55.732
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 13:37:55.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5760" for this suite. 02/13/23 13:37:55.75
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":35,"skipped":542,"failed":0}
------------------------------
• [SLOW TEST] [8.146 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:47.623
    Feb 13 13:37:47.623: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 13:37:47.624
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:47.636
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:47.64
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 02/13/23 13:37:47.647
    W0213 13:37:47.662118      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Patching the Job 02/13/23 13:37:47.662
    W0213 13:37:47.674782      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Watching for Job to be patched 02/13/23 13:37:47.674
    Feb 13 13:37:47.679: INFO: Event ADDED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw] and annotations: map[batch.kubernetes.io/job-tracking:]
    Feb 13 13:37:47.679: INFO: Event MODIFIED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 02/13/23 13:37:47.679
    W0213 13:37:47.700571      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Watching for Job to be updated 02/13/23 13:37:47.7
    Feb 13 13:37:47.702: INFO: Event MODIFIED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:47.702: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 02/13/23 13:37:47.703
    Feb 13 13:37:47.706: INFO: Job: e2e-lwstw as labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched]
    STEP: Waiting for job to complete 02/13/23 13:37:47.707
    STEP: Delete a job collection with a labelselector 02/13/23 13:37:55.713
    STEP: Watching for Job to be deleted 02/13/23 13:37:55.728
    Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:55.731: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:55.732: INFO: Event MODIFIED observed for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Feb 13 13:37:55.732: INFO: Event DELETED found for Job e2e-lwstw in namespace job-5760 with labels: map[e2e-job-label:e2e-lwstw e2e-lwstw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 02/13/23 13:37:55.732
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 13:37:55.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5760" for this suite. 02/13/23 13:37:55.75
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:55.773
Feb 13 13:37:55.774: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-runtime 02/13/23 13:37:55.776
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:55.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:55.794
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 02/13/23 13:37:55.799
W0213 13:37:55.807221      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: wait for the container to reach Succeeded 02/13/23 13:37:55.807
STEP: get the container status 02/13/23 13:37:58.834
STEP: the container should be terminated 02/13/23 13:37:58.838
STEP: the termination message should be set 02/13/23 13:37:58.838
Feb 13 13:37:58.839: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 02/13/23 13:37:58.839
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Feb 13 13:37:58.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7696" for this suite. 02/13/23 13:37:58.864
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":36,"skipped":546,"failed":0}
------------------------------
• [3.099 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:55.773
    Feb 13 13:37:55.774: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-runtime 02/13/23 13:37:55.776
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:55.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:55.794
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 02/13/23 13:37:55.799
    W0213 13:37:55.807221      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: wait for the container to reach Succeeded 02/13/23 13:37:55.807
    STEP: get the container status 02/13/23 13:37:58.834
    STEP: the container should be terminated 02/13/23 13:37:58.838
    STEP: the termination message should be set 02/13/23 13:37:58.838
    Feb 13 13:37:58.839: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 02/13/23 13:37:58.839
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Feb 13 13:37:58.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7696" for this suite. 02/13/23 13:37:58.864
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:37:58.874
Feb 13 13:37:58.874: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename controllerrevisions 02/13/23 13:37:58.878
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:58.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:58.905
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-x9ts9-daemon-set" 02/13/23 13:37:58.941
W0213 13:37:58.950697      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:37:58.951
Feb 13 13:37:58.961: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
Feb 13 13:37:58.961: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:37:59.976: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
Feb 13 13:37:59.977: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:38:00.970: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 3
Feb 13 13:38:00.970: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-x9ts9-daemon-set
STEP: Confirm DaemonSet "e2e-x9ts9-daemon-set" successfully created with "daemonset-name=e2e-x9ts9-daemon-set" label 02/13/23 13:38:00.972
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-x9ts9-daemon-set" 02/13/23 13:38:00.977
Feb 13 13:38:00.981: INFO: Located ControllerRevision: "e2e-x9ts9-daemon-set-6b8f69d58"
STEP: Patching ControllerRevision "e2e-x9ts9-daemon-set-6b8f69d58" 02/13/23 13:38:00.984
Feb 13 13:38:00.990: INFO: e2e-x9ts9-daemon-set-6b8f69d58 has been patched
STEP: Create a new ControllerRevision 02/13/23 13:38:00.99
Feb 13 13:38:00.998: INFO: Created ControllerRevision: e2e-x9ts9-daemon-set-64686c6d64
STEP: Confirm that there are two ControllerRevisions 02/13/23 13:38:00.998
Feb 13 13:38:00.999: INFO: Requesting list of ControllerRevisions to confirm quantity
Feb 13 13:38:01.003: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-x9ts9-daemon-set-6b8f69d58" 02/13/23 13:38:01.003
STEP: Confirm that there is only one ControllerRevision 02/13/23 13:38:01.009
Feb 13 13:38:01.010: INFO: Requesting list of ControllerRevisions to confirm quantity
Feb 13 13:38:01.013: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-x9ts9-daemon-set-64686c6d64" 02/13/23 13:38:01.017
Feb 13 13:38:01.026: INFO: e2e-x9ts9-daemon-set-64686c6d64 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 02/13/23 13:38:01.026
W0213 13:38:01.038692      19 warnings.go:70] unknown field "updateStrategy"
W0213 13:38:01.038737      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Confirm that there are two ControllerRevisions 02/13/23 13:38:01.039
Feb 13 13:38:01.039: INFO: Requesting list of ControllerRevisions to confirm quantity
Feb 13 13:38:02.044: INFO: Requesting list of ControllerRevisions to confirm quantity
Feb 13 13:38:02.050: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-x9ts9-daemon-set-64686c6d64=updated" 02/13/23 13:38:02.051
STEP: Confirm that there is only one ControllerRevision 02/13/23 13:38:02.064
Feb 13 13:38:02.065: INFO: Requesting list of ControllerRevisions to confirm quantity
Feb 13 13:38:02.070: INFO: Found 1 ControllerRevisions
Feb 13 13:38:02.075: INFO: ControllerRevision "e2e-x9ts9-daemon-set-85ddcc5bbf" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-x9ts9-daemon-set" 02/13/23 13:38:02.081
STEP: deleting DaemonSet.extensions e2e-x9ts9-daemon-set in namespace controllerrevisions-7476, will wait for the garbage collector to delete the pods 02/13/23 13:38:02.082
Feb 13 13:38:02.146: INFO: Deleting DaemonSet.extensions e2e-x9ts9-daemon-set took: 8.035157ms
Feb 13 13:38:02.247: INFO: Terminating DaemonSet.extensions e2e-x9ts9-daemon-set pods took: 100.811103ms
Feb 13 13:38:03.754: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
Feb 13 13:38:03.754: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-x9ts9-daemon-set
Feb 13 13:38:03.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7618"},"items":null}

Feb 13 13:38:03.763: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7618"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:38:03.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-7476" for this suite. 02/13/23 13:38:03.787
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":37,"skipped":566,"failed":0}
------------------------------
• [4.920 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:37:58.874
    Feb 13 13:37:58.874: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename controllerrevisions 02/13/23 13:37:58.878
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:37:58.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:37:58.905
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-x9ts9-daemon-set" 02/13/23 13:37:58.941
    W0213 13:37:58.950697      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:37:58.951
    Feb 13 13:37:58.961: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
    Feb 13 13:37:58.961: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:37:59.976: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
    Feb 13 13:37:59.977: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:38:00.970: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 3
    Feb 13 13:38:00.970: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-x9ts9-daemon-set
    STEP: Confirm DaemonSet "e2e-x9ts9-daemon-set" successfully created with "daemonset-name=e2e-x9ts9-daemon-set" label 02/13/23 13:38:00.972
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-x9ts9-daemon-set" 02/13/23 13:38:00.977
    Feb 13 13:38:00.981: INFO: Located ControllerRevision: "e2e-x9ts9-daemon-set-6b8f69d58"
    STEP: Patching ControllerRevision "e2e-x9ts9-daemon-set-6b8f69d58" 02/13/23 13:38:00.984
    Feb 13 13:38:00.990: INFO: e2e-x9ts9-daemon-set-6b8f69d58 has been patched
    STEP: Create a new ControllerRevision 02/13/23 13:38:00.99
    Feb 13 13:38:00.998: INFO: Created ControllerRevision: e2e-x9ts9-daemon-set-64686c6d64
    STEP: Confirm that there are two ControllerRevisions 02/13/23 13:38:00.998
    Feb 13 13:38:00.999: INFO: Requesting list of ControllerRevisions to confirm quantity
    Feb 13 13:38:01.003: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-x9ts9-daemon-set-6b8f69d58" 02/13/23 13:38:01.003
    STEP: Confirm that there is only one ControllerRevision 02/13/23 13:38:01.009
    Feb 13 13:38:01.010: INFO: Requesting list of ControllerRevisions to confirm quantity
    Feb 13 13:38:01.013: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-x9ts9-daemon-set-64686c6d64" 02/13/23 13:38:01.017
    Feb 13 13:38:01.026: INFO: e2e-x9ts9-daemon-set-64686c6d64 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 02/13/23 13:38:01.026
    W0213 13:38:01.038692      19 warnings.go:70] unknown field "updateStrategy"
    W0213 13:38:01.038737      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Confirm that there are two ControllerRevisions 02/13/23 13:38:01.039
    Feb 13 13:38:01.039: INFO: Requesting list of ControllerRevisions to confirm quantity
    Feb 13 13:38:02.044: INFO: Requesting list of ControllerRevisions to confirm quantity
    Feb 13 13:38:02.050: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-x9ts9-daemon-set-64686c6d64=updated" 02/13/23 13:38:02.051
    STEP: Confirm that there is only one ControllerRevision 02/13/23 13:38:02.064
    Feb 13 13:38:02.065: INFO: Requesting list of ControllerRevisions to confirm quantity
    Feb 13 13:38:02.070: INFO: Found 1 ControllerRevisions
    Feb 13 13:38:02.075: INFO: ControllerRevision "e2e-x9ts9-daemon-set-85ddcc5bbf" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-x9ts9-daemon-set" 02/13/23 13:38:02.081
    STEP: deleting DaemonSet.extensions e2e-x9ts9-daemon-set in namespace controllerrevisions-7476, will wait for the garbage collector to delete the pods 02/13/23 13:38:02.082
    Feb 13 13:38:02.146: INFO: Deleting DaemonSet.extensions e2e-x9ts9-daemon-set took: 8.035157ms
    Feb 13 13:38:02.247: INFO: Terminating DaemonSet.extensions e2e-x9ts9-daemon-set pods took: 100.811103ms
    Feb 13 13:38:03.754: INFO: Number of nodes with available pods controlled by daemonset e2e-x9ts9-daemon-set: 0
    Feb 13 13:38:03.754: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-x9ts9-daemon-set
    Feb 13 13:38:03.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7618"},"items":null}

    Feb 13 13:38:03.763: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7618"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:38:03.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-7476" for this suite. 02/13/23 13:38:03.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:38:03.797
Feb 13 13:38:03.797: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 13:38:03.799
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:38:03.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:38:03.82
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-145 02/13/23 13:38:03.825
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 02/13/23 13:38:03.831
STEP: Creating pod with conflicting port in namespace statefulset-145 02/13/23 13:38:03.837
W0213 13:38:03.848141      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting until pod test-pod will start running in namespace statefulset-145 02/13/23 13:38:03.848
Feb 13 13:38:03.848: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-145" to be "running"
Feb 13 13:38:03.850: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.577243ms
Feb 13 13:38:05.860: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011731321s
Feb 13 13:38:05.860: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-145 02/13/23 13:38:05.86
W0213 13:38:05.870633      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-145 02/13/23 13:38:05.87
Feb 13 13:38:05.896: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Pending. Waiting for statefulset controller to delete.
Feb 13 13:38:05.915: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 13:38:05.924: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 13:38:05.928: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-145
STEP: Removing pod with conflicting port in namespace statefulset-145 02/13/23 13:38:05.928
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-145 and will be in running state 02/13/23 13:38:05.943
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 13:38:07.955: INFO: Deleting all statefulset in ns statefulset-145
Feb 13 13:38:07.959: INFO: Scaling statefulset ss to 0
W0213 13:38:07.970633      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:38:17.992: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:38:17.998: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 13:38:18.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-145" for this suite. 02/13/23 13:38:18.023
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":38,"skipped":585,"failed":0}
------------------------------
• [SLOW TEST] [14.235 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:38:03.797
    Feb 13 13:38:03.797: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 13:38:03.799
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:38:03.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:38:03.82
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-145 02/13/23 13:38:03.825
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 02/13/23 13:38:03.831
    STEP: Creating pod with conflicting port in namespace statefulset-145 02/13/23 13:38:03.837
    W0213 13:38:03.848141      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting until pod test-pod will start running in namespace statefulset-145 02/13/23 13:38:03.848
    Feb 13 13:38:03.848: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-145" to be "running"
    Feb 13 13:38:03.850: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.577243ms
    Feb 13 13:38:05.860: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011731321s
    Feb 13 13:38:05.860: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-145 02/13/23 13:38:05.86
    W0213 13:38:05.870633      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-145 02/13/23 13:38:05.87
    Feb 13 13:38:05.896: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Pending. Waiting for statefulset controller to delete.
    Feb 13 13:38:05.915: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Failed. Waiting for statefulset controller to delete.
    Feb 13 13:38:05.924: INFO: Observed stateful pod in namespace: statefulset-145, name: ss-0, uid: 76ca61d8-fbdc-488a-91b7-15c75f0a628b, status phase: Failed. Waiting for statefulset controller to delete.
    Feb 13 13:38:05.928: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-145
    STEP: Removing pod with conflicting port in namespace statefulset-145 02/13/23 13:38:05.928
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-145 and will be in running state 02/13/23 13:38:05.943
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 13:38:07.955: INFO: Deleting all statefulset in ns statefulset-145
    Feb 13 13:38:07.959: INFO: Scaling statefulset ss to 0
    W0213 13:38:07.970633      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:38:17.992: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 13:38:17.998: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 13:38:18.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-145" for this suite. 02/13/23 13:38:18.023
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:38:18.035
Feb 13 13:38:18.035: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 13:38:18.037
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:38:18.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:38:18.055
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 02/13/23 13:38:18.062
W0213 13:38:18.067050      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: delete the rc 02/13/23 13:38:23.071
STEP: wait for the rc to be deleted 02/13/23 13:38:23.086
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 02/13/23 13:38:28.095
STEP: Gathering metrics 02/13/23 13:38:58.12
W0213 13:38:58.131736      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 13:38:58.131: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Feb 13 13:38:58.131: INFO: Deleting pod "simpletest.rc-2qd52" in namespace "gc-3124"
Feb 13 13:38:58.148: INFO: Deleting pod "simpletest.rc-2vzhc" in namespace "gc-3124"
Feb 13 13:38:58.165: INFO: Deleting pod "simpletest.rc-44bxt" in namespace "gc-3124"
Feb 13 13:38:58.179: INFO: Deleting pod "simpletest.rc-45qmb" in namespace "gc-3124"
Feb 13 13:38:58.190: INFO: Deleting pod "simpletest.rc-4bglg" in namespace "gc-3124"
Feb 13 13:38:58.200: INFO: Deleting pod "simpletest.rc-4gqxq" in namespace "gc-3124"
Feb 13 13:38:58.212: INFO: Deleting pod "simpletest.rc-4rmk9" in namespace "gc-3124"
Feb 13 13:38:58.223: INFO: Deleting pod "simpletest.rc-5tp64" in namespace "gc-3124"
Feb 13 13:38:58.234: INFO: Deleting pod "simpletest.rc-627zs" in namespace "gc-3124"
Feb 13 13:38:58.243: INFO: Deleting pod "simpletest.rc-65xps" in namespace "gc-3124"
Feb 13 13:38:58.253: INFO: Deleting pod "simpletest.rc-6bcp9" in namespace "gc-3124"
Feb 13 13:38:58.262: INFO: Deleting pod "simpletest.rc-6dgfd" in namespace "gc-3124"
Feb 13 13:38:58.270: INFO: Deleting pod "simpletest.rc-6fq6n" in namespace "gc-3124"
Feb 13 13:38:58.281: INFO: Deleting pod "simpletest.rc-6j5dn" in namespace "gc-3124"
Feb 13 13:38:58.293: INFO: Deleting pod "simpletest.rc-6mmdh" in namespace "gc-3124"
Feb 13 13:38:58.301: INFO: Deleting pod "simpletest.rc-6mtxw" in namespace "gc-3124"
Feb 13 13:38:58.312: INFO: Deleting pod "simpletest.rc-7kznw" in namespace "gc-3124"
Feb 13 13:38:58.324: INFO: Deleting pod "simpletest.rc-7p9gq" in namespace "gc-3124"
Feb 13 13:38:58.333: INFO: Deleting pod "simpletest.rc-7qxn6" in namespace "gc-3124"
Feb 13 13:38:58.342: INFO: Deleting pod "simpletest.rc-7wlbm" in namespace "gc-3124"
Feb 13 13:38:58.359: INFO: Deleting pod "simpletest.rc-882mh" in namespace "gc-3124"
Feb 13 13:38:58.373: INFO: Deleting pod "simpletest.rc-8dszv" in namespace "gc-3124"
Feb 13 13:38:58.384: INFO: Deleting pod "simpletest.rc-8hvm7" in namespace "gc-3124"
Feb 13 13:38:58.396: INFO: Deleting pod "simpletest.rc-8krm7" in namespace "gc-3124"
Feb 13 13:38:58.407: INFO: Deleting pod "simpletest.rc-97gcn" in namespace "gc-3124"
Feb 13 13:38:58.419: INFO: Deleting pod "simpletest.rc-9bvmc" in namespace "gc-3124"
Feb 13 13:38:58.429: INFO: Deleting pod "simpletest.rc-bdh7n" in namespace "gc-3124"
Feb 13 13:38:58.442: INFO: Deleting pod "simpletest.rc-bh425" in namespace "gc-3124"
Feb 13 13:38:58.452: INFO: Deleting pod "simpletest.rc-btgpf" in namespace "gc-3124"
Feb 13 13:38:58.470: INFO: Deleting pod "simpletest.rc-c2vvq" in namespace "gc-3124"
Feb 13 13:38:58.489: INFO: Deleting pod "simpletest.rc-cgghp" in namespace "gc-3124"
Feb 13 13:38:58.502: INFO: Deleting pod "simpletest.rc-cgzck" in namespace "gc-3124"
Feb 13 13:38:58.514: INFO: Deleting pod "simpletest.rc-cpsxf" in namespace "gc-3124"
Feb 13 13:38:58.526: INFO: Deleting pod "simpletest.rc-cqlh7" in namespace "gc-3124"
Feb 13 13:38:58.535: INFO: Deleting pod "simpletest.rc-d2p9r" in namespace "gc-3124"
Feb 13 13:38:58.550: INFO: Deleting pod "simpletest.rc-d75m5" in namespace "gc-3124"
Feb 13 13:38:58.567: INFO: Deleting pod "simpletest.rc-d76j7" in namespace "gc-3124"
Feb 13 13:38:58.578: INFO: Deleting pod "simpletest.rc-dg2md" in namespace "gc-3124"
Feb 13 13:38:58.597: INFO: Deleting pod "simpletest.rc-f57r6" in namespace "gc-3124"
Feb 13 13:38:58.609: INFO: Deleting pod "simpletest.rc-f9pb4" in namespace "gc-3124"
Feb 13 13:38:58.618: INFO: Deleting pod "simpletest.rc-fp8dm" in namespace "gc-3124"
Feb 13 13:38:58.630: INFO: Deleting pod "simpletest.rc-fw9kf" in namespace "gc-3124"
Feb 13 13:38:58.640: INFO: Deleting pod "simpletest.rc-g76bd" in namespace "gc-3124"
Feb 13 13:38:58.647: INFO: Deleting pod "simpletest.rc-g98nr" in namespace "gc-3124"
Feb 13 13:38:58.659: INFO: Deleting pod "simpletest.rc-gtxvd" in namespace "gc-3124"
Feb 13 13:38:58.672: INFO: Deleting pod "simpletest.rc-gzbr8" in namespace "gc-3124"
Feb 13 13:38:58.686: INFO: Deleting pod "simpletest.rc-hh9zt" in namespace "gc-3124"
Feb 13 13:38:58.708: INFO: Deleting pod "simpletest.rc-hv8zg" in namespace "gc-3124"
Feb 13 13:38:58.720: INFO: Deleting pod "simpletest.rc-jv578" in namespace "gc-3124"
Feb 13 13:38:58.731: INFO: Deleting pod "simpletest.rc-k4rjd" in namespace "gc-3124"
Feb 13 13:38:58.739: INFO: Deleting pod "simpletest.rc-k5qzt" in namespace "gc-3124"
Feb 13 13:38:58.747: INFO: Deleting pod "simpletest.rc-kfgv4" in namespace "gc-3124"
Feb 13 13:38:58.765: INFO: Deleting pod "simpletest.rc-kj9tf" in namespace "gc-3124"
Feb 13 13:38:58.772: INFO: Deleting pod "simpletest.rc-krbrz" in namespace "gc-3124"
Feb 13 13:38:58.779: INFO: Deleting pod "simpletest.rc-lgqk5" in namespace "gc-3124"
Feb 13 13:38:58.788: INFO: Deleting pod "simpletest.rc-lks7j" in namespace "gc-3124"
Feb 13 13:38:58.796: INFO: Deleting pod "simpletest.rc-lpmsq" in namespace "gc-3124"
Feb 13 13:38:58.804: INFO: Deleting pod "simpletest.rc-m42xd" in namespace "gc-3124"
Feb 13 13:38:58.815: INFO: Deleting pod "simpletest.rc-mgcnk" in namespace "gc-3124"
Feb 13 13:38:58.823: INFO: Deleting pod "simpletest.rc-mllm2" in namespace "gc-3124"
Feb 13 13:38:58.834: INFO: Deleting pod "simpletest.rc-mp5dh" in namespace "gc-3124"
Feb 13 13:38:58.848: INFO: Deleting pod "simpletest.rc-mz7rl" in namespace "gc-3124"
Feb 13 13:38:58.862: INFO: Deleting pod "simpletest.rc-n7g64" in namespace "gc-3124"
Feb 13 13:38:58.873: INFO: Deleting pod "simpletest.rc-n9rnz" in namespace "gc-3124"
Feb 13 13:38:58.909: INFO: Deleting pod "simpletest.rc-nlbmz" in namespace "gc-3124"
Feb 13 13:38:58.965: INFO: Deleting pod "simpletest.rc-pdz4s" in namespace "gc-3124"
Feb 13 13:38:59.013: INFO: Deleting pod "simpletest.rc-pj6t9" in namespace "gc-3124"
Feb 13 13:38:59.062: INFO: Deleting pod "simpletest.rc-pn8b6" in namespace "gc-3124"
Feb 13 13:38:59.114: INFO: Deleting pod "simpletest.rc-pv5rj" in namespace "gc-3124"
Feb 13 13:38:59.166: INFO: Deleting pod "simpletest.rc-q6sfl" in namespace "gc-3124"
Feb 13 13:38:59.215: INFO: Deleting pod "simpletest.rc-q7gzh" in namespace "gc-3124"
Feb 13 13:38:59.264: INFO: Deleting pod "simpletest.rc-q866g" in namespace "gc-3124"
Feb 13 13:38:59.310: INFO: Deleting pod "simpletest.rc-r4f7k" in namespace "gc-3124"
Feb 13 13:38:59.367: INFO: Deleting pod "simpletest.rc-r8ffq" in namespace "gc-3124"
Feb 13 13:38:59.412: INFO: Deleting pod "simpletest.rc-rbk2q" in namespace "gc-3124"
Feb 13 13:38:59.463: INFO: Deleting pod "simpletest.rc-rkdhs" in namespace "gc-3124"
Feb 13 13:38:59.514: INFO: Deleting pod "simpletest.rc-s9wkc" in namespace "gc-3124"
Feb 13 13:38:59.568: INFO: Deleting pod "simpletest.rc-sbq2z" in namespace "gc-3124"
Feb 13 13:38:59.609: INFO: Deleting pod "simpletest.rc-sbrfn" in namespace "gc-3124"
Feb 13 13:38:59.669: INFO: Deleting pod "simpletest.rc-sclqm" in namespace "gc-3124"
Feb 13 13:38:59.714: INFO: Deleting pod "simpletest.rc-t9f8s" in namespace "gc-3124"
Feb 13 13:38:59.772: INFO: Deleting pod "simpletest.rc-tm884" in namespace "gc-3124"
Feb 13 13:38:59.819: INFO: Deleting pod "simpletest.rc-tpfhv" in namespace "gc-3124"
Feb 13 13:38:59.866: INFO: Deleting pod "simpletest.rc-v6ktj" in namespace "gc-3124"
Feb 13 13:38:59.915: INFO: Deleting pod "simpletest.rc-vllg4" in namespace "gc-3124"
Feb 13 13:38:59.972: INFO: Deleting pod "simpletest.rc-vntdn" in namespace "gc-3124"
Feb 13 13:39:00.012: INFO: Deleting pod "simpletest.rc-vrzxs" in namespace "gc-3124"
Feb 13 13:39:00.070: INFO: Deleting pod "simpletest.rc-w2k79" in namespace "gc-3124"
Feb 13 13:39:00.116: INFO: Deleting pod "simpletest.rc-wq9v7" in namespace "gc-3124"
Feb 13 13:39:00.169: INFO: Deleting pod "simpletest.rc-wxgbb" in namespace "gc-3124"
Feb 13 13:39:00.214: INFO: Deleting pod "simpletest.rc-x5njb" in namespace "gc-3124"
Feb 13 13:39:00.262: INFO: Deleting pod "simpletest.rc-xjsc9" in namespace "gc-3124"
Feb 13 13:39:00.313: INFO: Deleting pod "simpletest.rc-xl56m" in namespace "gc-3124"
Feb 13 13:39:00.365: INFO: Deleting pod "simpletest.rc-xwqlx" in namespace "gc-3124"
Feb 13 13:39:00.416: INFO: Deleting pod "simpletest.rc-zdcfj" in namespace "gc-3124"
Feb 13 13:39:00.466: INFO: Deleting pod "simpletest.rc-zdpc7" in namespace "gc-3124"
Feb 13 13:39:00.512: INFO: Deleting pod "simpletest.rc-zkfl8" in namespace "gc-3124"
Feb 13 13:39:00.571: INFO: Deleting pod "simpletest.rc-zmqb6" in namespace "gc-3124"
Feb 13 13:39:00.617: INFO: Deleting pod "simpletest.rc-zsrbz" in namespace "gc-3124"
Feb 13 13:39:00.667: INFO: Deleting pod "simpletest.rc-zzktq" in namespace "gc-3124"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 13:39:00.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3124" for this suite. 02/13/23 13:39:00.755
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":39,"skipped":589,"failed":0}
------------------------------
• [SLOW TEST] [42.768 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:38:18.035
    Feb 13 13:38:18.035: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 13:38:18.037
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:38:18.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:38:18.055
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 02/13/23 13:38:18.062
    W0213 13:38:18.067050      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: delete the rc 02/13/23 13:38:23.071
    STEP: wait for the rc to be deleted 02/13/23 13:38:23.086
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 02/13/23 13:38:28.095
    STEP: Gathering metrics 02/13/23 13:38:58.12
    W0213 13:38:58.131736      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 13:38:58.131: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Feb 13 13:38:58.131: INFO: Deleting pod "simpletest.rc-2qd52" in namespace "gc-3124"
    Feb 13 13:38:58.148: INFO: Deleting pod "simpletest.rc-2vzhc" in namespace "gc-3124"
    Feb 13 13:38:58.165: INFO: Deleting pod "simpletest.rc-44bxt" in namespace "gc-3124"
    Feb 13 13:38:58.179: INFO: Deleting pod "simpletest.rc-45qmb" in namespace "gc-3124"
    Feb 13 13:38:58.190: INFO: Deleting pod "simpletest.rc-4bglg" in namespace "gc-3124"
    Feb 13 13:38:58.200: INFO: Deleting pod "simpletest.rc-4gqxq" in namespace "gc-3124"
    Feb 13 13:38:58.212: INFO: Deleting pod "simpletest.rc-4rmk9" in namespace "gc-3124"
    Feb 13 13:38:58.223: INFO: Deleting pod "simpletest.rc-5tp64" in namespace "gc-3124"
    Feb 13 13:38:58.234: INFO: Deleting pod "simpletest.rc-627zs" in namespace "gc-3124"
    Feb 13 13:38:58.243: INFO: Deleting pod "simpletest.rc-65xps" in namespace "gc-3124"
    Feb 13 13:38:58.253: INFO: Deleting pod "simpletest.rc-6bcp9" in namespace "gc-3124"
    Feb 13 13:38:58.262: INFO: Deleting pod "simpletest.rc-6dgfd" in namespace "gc-3124"
    Feb 13 13:38:58.270: INFO: Deleting pod "simpletest.rc-6fq6n" in namespace "gc-3124"
    Feb 13 13:38:58.281: INFO: Deleting pod "simpletest.rc-6j5dn" in namespace "gc-3124"
    Feb 13 13:38:58.293: INFO: Deleting pod "simpletest.rc-6mmdh" in namespace "gc-3124"
    Feb 13 13:38:58.301: INFO: Deleting pod "simpletest.rc-6mtxw" in namespace "gc-3124"
    Feb 13 13:38:58.312: INFO: Deleting pod "simpletest.rc-7kznw" in namespace "gc-3124"
    Feb 13 13:38:58.324: INFO: Deleting pod "simpletest.rc-7p9gq" in namespace "gc-3124"
    Feb 13 13:38:58.333: INFO: Deleting pod "simpletest.rc-7qxn6" in namespace "gc-3124"
    Feb 13 13:38:58.342: INFO: Deleting pod "simpletest.rc-7wlbm" in namespace "gc-3124"
    Feb 13 13:38:58.359: INFO: Deleting pod "simpletest.rc-882mh" in namespace "gc-3124"
    Feb 13 13:38:58.373: INFO: Deleting pod "simpletest.rc-8dszv" in namespace "gc-3124"
    Feb 13 13:38:58.384: INFO: Deleting pod "simpletest.rc-8hvm7" in namespace "gc-3124"
    Feb 13 13:38:58.396: INFO: Deleting pod "simpletest.rc-8krm7" in namespace "gc-3124"
    Feb 13 13:38:58.407: INFO: Deleting pod "simpletest.rc-97gcn" in namespace "gc-3124"
    Feb 13 13:38:58.419: INFO: Deleting pod "simpletest.rc-9bvmc" in namespace "gc-3124"
    Feb 13 13:38:58.429: INFO: Deleting pod "simpletest.rc-bdh7n" in namespace "gc-3124"
    Feb 13 13:38:58.442: INFO: Deleting pod "simpletest.rc-bh425" in namespace "gc-3124"
    Feb 13 13:38:58.452: INFO: Deleting pod "simpletest.rc-btgpf" in namespace "gc-3124"
    Feb 13 13:38:58.470: INFO: Deleting pod "simpletest.rc-c2vvq" in namespace "gc-3124"
    Feb 13 13:38:58.489: INFO: Deleting pod "simpletest.rc-cgghp" in namespace "gc-3124"
    Feb 13 13:38:58.502: INFO: Deleting pod "simpletest.rc-cgzck" in namespace "gc-3124"
    Feb 13 13:38:58.514: INFO: Deleting pod "simpletest.rc-cpsxf" in namespace "gc-3124"
    Feb 13 13:38:58.526: INFO: Deleting pod "simpletest.rc-cqlh7" in namespace "gc-3124"
    Feb 13 13:38:58.535: INFO: Deleting pod "simpletest.rc-d2p9r" in namespace "gc-3124"
    Feb 13 13:38:58.550: INFO: Deleting pod "simpletest.rc-d75m5" in namespace "gc-3124"
    Feb 13 13:38:58.567: INFO: Deleting pod "simpletest.rc-d76j7" in namespace "gc-3124"
    Feb 13 13:38:58.578: INFO: Deleting pod "simpletest.rc-dg2md" in namespace "gc-3124"
    Feb 13 13:38:58.597: INFO: Deleting pod "simpletest.rc-f57r6" in namespace "gc-3124"
    Feb 13 13:38:58.609: INFO: Deleting pod "simpletest.rc-f9pb4" in namespace "gc-3124"
    Feb 13 13:38:58.618: INFO: Deleting pod "simpletest.rc-fp8dm" in namespace "gc-3124"
    Feb 13 13:38:58.630: INFO: Deleting pod "simpletest.rc-fw9kf" in namespace "gc-3124"
    Feb 13 13:38:58.640: INFO: Deleting pod "simpletest.rc-g76bd" in namespace "gc-3124"
    Feb 13 13:38:58.647: INFO: Deleting pod "simpletest.rc-g98nr" in namespace "gc-3124"
    Feb 13 13:38:58.659: INFO: Deleting pod "simpletest.rc-gtxvd" in namespace "gc-3124"
    Feb 13 13:38:58.672: INFO: Deleting pod "simpletest.rc-gzbr8" in namespace "gc-3124"
    Feb 13 13:38:58.686: INFO: Deleting pod "simpletest.rc-hh9zt" in namespace "gc-3124"
    Feb 13 13:38:58.708: INFO: Deleting pod "simpletest.rc-hv8zg" in namespace "gc-3124"
    Feb 13 13:38:58.720: INFO: Deleting pod "simpletest.rc-jv578" in namespace "gc-3124"
    Feb 13 13:38:58.731: INFO: Deleting pod "simpletest.rc-k4rjd" in namespace "gc-3124"
    Feb 13 13:38:58.739: INFO: Deleting pod "simpletest.rc-k5qzt" in namespace "gc-3124"
    Feb 13 13:38:58.747: INFO: Deleting pod "simpletest.rc-kfgv4" in namespace "gc-3124"
    Feb 13 13:38:58.765: INFO: Deleting pod "simpletest.rc-kj9tf" in namespace "gc-3124"
    Feb 13 13:38:58.772: INFO: Deleting pod "simpletest.rc-krbrz" in namespace "gc-3124"
    Feb 13 13:38:58.779: INFO: Deleting pod "simpletest.rc-lgqk5" in namespace "gc-3124"
    Feb 13 13:38:58.788: INFO: Deleting pod "simpletest.rc-lks7j" in namespace "gc-3124"
    Feb 13 13:38:58.796: INFO: Deleting pod "simpletest.rc-lpmsq" in namespace "gc-3124"
    Feb 13 13:38:58.804: INFO: Deleting pod "simpletest.rc-m42xd" in namespace "gc-3124"
    Feb 13 13:38:58.815: INFO: Deleting pod "simpletest.rc-mgcnk" in namespace "gc-3124"
    Feb 13 13:38:58.823: INFO: Deleting pod "simpletest.rc-mllm2" in namespace "gc-3124"
    Feb 13 13:38:58.834: INFO: Deleting pod "simpletest.rc-mp5dh" in namespace "gc-3124"
    Feb 13 13:38:58.848: INFO: Deleting pod "simpletest.rc-mz7rl" in namespace "gc-3124"
    Feb 13 13:38:58.862: INFO: Deleting pod "simpletest.rc-n7g64" in namespace "gc-3124"
    Feb 13 13:38:58.873: INFO: Deleting pod "simpletest.rc-n9rnz" in namespace "gc-3124"
    Feb 13 13:38:58.909: INFO: Deleting pod "simpletest.rc-nlbmz" in namespace "gc-3124"
    Feb 13 13:38:58.965: INFO: Deleting pod "simpletest.rc-pdz4s" in namespace "gc-3124"
    Feb 13 13:38:59.013: INFO: Deleting pod "simpletest.rc-pj6t9" in namespace "gc-3124"
    Feb 13 13:38:59.062: INFO: Deleting pod "simpletest.rc-pn8b6" in namespace "gc-3124"
    Feb 13 13:38:59.114: INFO: Deleting pod "simpletest.rc-pv5rj" in namespace "gc-3124"
    Feb 13 13:38:59.166: INFO: Deleting pod "simpletest.rc-q6sfl" in namespace "gc-3124"
    Feb 13 13:38:59.215: INFO: Deleting pod "simpletest.rc-q7gzh" in namespace "gc-3124"
    Feb 13 13:38:59.264: INFO: Deleting pod "simpletest.rc-q866g" in namespace "gc-3124"
    Feb 13 13:38:59.310: INFO: Deleting pod "simpletest.rc-r4f7k" in namespace "gc-3124"
    Feb 13 13:38:59.367: INFO: Deleting pod "simpletest.rc-r8ffq" in namespace "gc-3124"
    Feb 13 13:38:59.412: INFO: Deleting pod "simpletest.rc-rbk2q" in namespace "gc-3124"
    Feb 13 13:38:59.463: INFO: Deleting pod "simpletest.rc-rkdhs" in namespace "gc-3124"
    Feb 13 13:38:59.514: INFO: Deleting pod "simpletest.rc-s9wkc" in namespace "gc-3124"
    Feb 13 13:38:59.568: INFO: Deleting pod "simpletest.rc-sbq2z" in namespace "gc-3124"
    Feb 13 13:38:59.609: INFO: Deleting pod "simpletest.rc-sbrfn" in namespace "gc-3124"
    Feb 13 13:38:59.669: INFO: Deleting pod "simpletest.rc-sclqm" in namespace "gc-3124"
    Feb 13 13:38:59.714: INFO: Deleting pod "simpletest.rc-t9f8s" in namespace "gc-3124"
    Feb 13 13:38:59.772: INFO: Deleting pod "simpletest.rc-tm884" in namespace "gc-3124"
    Feb 13 13:38:59.819: INFO: Deleting pod "simpletest.rc-tpfhv" in namespace "gc-3124"
    Feb 13 13:38:59.866: INFO: Deleting pod "simpletest.rc-v6ktj" in namespace "gc-3124"
    Feb 13 13:38:59.915: INFO: Deleting pod "simpletest.rc-vllg4" in namespace "gc-3124"
    Feb 13 13:38:59.972: INFO: Deleting pod "simpletest.rc-vntdn" in namespace "gc-3124"
    Feb 13 13:39:00.012: INFO: Deleting pod "simpletest.rc-vrzxs" in namespace "gc-3124"
    Feb 13 13:39:00.070: INFO: Deleting pod "simpletest.rc-w2k79" in namespace "gc-3124"
    Feb 13 13:39:00.116: INFO: Deleting pod "simpletest.rc-wq9v7" in namespace "gc-3124"
    Feb 13 13:39:00.169: INFO: Deleting pod "simpletest.rc-wxgbb" in namespace "gc-3124"
    Feb 13 13:39:00.214: INFO: Deleting pod "simpletest.rc-x5njb" in namespace "gc-3124"
    Feb 13 13:39:00.262: INFO: Deleting pod "simpletest.rc-xjsc9" in namespace "gc-3124"
    Feb 13 13:39:00.313: INFO: Deleting pod "simpletest.rc-xl56m" in namespace "gc-3124"
    Feb 13 13:39:00.365: INFO: Deleting pod "simpletest.rc-xwqlx" in namespace "gc-3124"
    Feb 13 13:39:00.416: INFO: Deleting pod "simpletest.rc-zdcfj" in namespace "gc-3124"
    Feb 13 13:39:00.466: INFO: Deleting pod "simpletest.rc-zdpc7" in namespace "gc-3124"
    Feb 13 13:39:00.512: INFO: Deleting pod "simpletest.rc-zkfl8" in namespace "gc-3124"
    Feb 13 13:39:00.571: INFO: Deleting pod "simpletest.rc-zmqb6" in namespace "gc-3124"
    Feb 13 13:39:00.617: INFO: Deleting pod "simpletest.rc-zsrbz" in namespace "gc-3124"
    Feb 13 13:39:00.667: INFO: Deleting pod "simpletest.rc-zzktq" in namespace "gc-3124"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 13:39:00.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3124" for this suite. 02/13/23 13:39:00.755
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:00.804
Feb 13 13:39:00.805: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:39:00.806
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:00.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:00.829
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 02/13/23 13:39:00.832
W0213 13:39:00.837832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:39:00.838: INFO: Waiting up to 5m0s for pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c" in namespace "emptydir-7606" to be "Succeeded or Failed"
Feb 13 13:39:00.840: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.308136ms
Feb 13 13:39:02.847: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00931819s
Feb 13 13:39:04.846: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00859066s
STEP: Saw pod success 02/13/23 13:39:04.846
Feb 13 13:39:04.847: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c" satisfied condition "Succeeded or Failed"
Feb 13 13:39:04.852: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-82878255-5ad1-4658-b798-b406e26bdf4c container test-container: <nil>
STEP: delete the pod 02/13/23 13:39:04.889
Feb 13 13:39:04.909: INFO: Waiting for pod pod-82878255-5ad1-4658-b798-b406e26bdf4c to disappear
Feb 13 13:39:04.916: INFO: Pod pod-82878255-5ad1-4658-b798-b406e26bdf4c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:39:04.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7606" for this suite. 02/13/23 13:39:04.922
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":40,"skipped":591,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:00.804
    Feb 13 13:39:00.805: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:39:00.806
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:00.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:00.829
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 02/13/23 13:39:00.832
    W0213 13:39:00.837832      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:39:00.838: INFO: Waiting up to 5m0s for pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c" in namespace "emptydir-7606" to be "Succeeded or Failed"
    Feb 13 13:39:00.840: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.308136ms
    Feb 13 13:39:02.847: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00931819s
    Feb 13 13:39:04.846: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00859066s
    STEP: Saw pod success 02/13/23 13:39:04.846
    Feb 13 13:39:04.847: INFO: Pod "pod-82878255-5ad1-4658-b798-b406e26bdf4c" satisfied condition "Succeeded or Failed"
    Feb 13 13:39:04.852: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-82878255-5ad1-4658-b798-b406e26bdf4c container test-container: <nil>
    STEP: delete the pod 02/13/23 13:39:04.889
    Feb 13 13:39:04.909: INFO: Waiting for pod pod-82878255-5ad1-4658-b798-b406e26bdf4c to disappear
    Feb 13 13:39:04.916: INFO: Pod pod-82878255-5ad1-4658-b798-b406e26bdf4c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:39:04.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7606" for this suite. 02/13/23 13:39:04.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:04.933
Feb 13 13:39:04.934: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:39:04.934
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:04.952
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:04.956
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-c971c1e6-002d-4476-85c5-0e12db54e05b 02/13/23 13:39:04.96
STEP: Creating a pod to test consume secrets 02/13/23 13:39:04.966
W0213 13:39:04.973912      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:39:04.974: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab" in namespace "projected-5960" to be "Succeeded or Failed"
Feb 13 13:39:04.980: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.288902ms
Feb 13 13:39:06.985: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010954495s
Feb 13 13:39:08.987: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012790966s
STEP: Saw pod success 02/13/23 13:39:08.987
Feb 13 13:39:08.987: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab" satisfied condition "Succeeded or Failed"
Feb 13 13:39:08.991: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab container projected-secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:39:09.001
Feb 13 13:39:09.028: INFO: Waiting for pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab to disappear
Feb 13 13:39:09.033: INFO: Pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 13:39:09.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5960" for this suite. 02/13/23 13:39:09.038
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":41,"skipped":611,"failed":0}
------------------------------
• [4.111 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:04.933
    Feb 13 13:39:04.934: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:39:04.934
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:04.952
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:04.956
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-c971c1e6-002d-4476-85c5-0e12db54e05b 02/13/23 13:39:04.96
    STEP: Creating a pod to test consume secrets 02/13/23 13:39:04.966
    W0213 13:39:04.973912      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:39:04.974: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab" in namespace "projected-5960" to be "Succeeded or Failed"
    Feb 13 13:39:04.980: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.288902ms
    Feb 13 13:39:06.985: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010954495s
    Feb 13 13:39:08.987: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012790966s
    STEP: Saw pod success 02/13/23 13:39:08.987
    Feb 13 13:39:08.987: INFO: Pod "pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab" satisfied condition "Succeeded or Failed"
    Feb 13 13:39:08.991: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab container projected-secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:39:09.001
    Feb 13 13:39:09.028: INFO: Waiting for pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab to disappear
    Feb 13 13:39:09.033: INFO: Pod pod-projected-secrets-1f975932-f461-49c4-b630-e6eee29395ab no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 13:39:09.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5960" for this suite. 02/13/23 13:39:09.038
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:09.048
Feb 13 13:39:09.049: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:39:09.051
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:09.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:09.074
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 02/13/23 13:39:09.079
W0213 13:39:09.091736      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:39:09.091: INFO: Waiting up to 5m0s for pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc" in namespace "emptydir-376" to be "Succeeded or Failed"
Feb 13 13:39:09.096: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246817ms
Feb 13 13:39:11.104: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012324606s
Feb 13 13:39:13.105: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013212462s
STEP: Saw pod success 02/13/23 13:39:13.105
Feb 13 13:39:13.105: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc" satisfied condition "Succeeded or Failed"
Feb 13 13:39:13.111: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc container test-container: <nil>
STEP: delete the pod 02/13/23 13:39:13.133
Feb 13 13:39:13.150: INFO: Waiting for pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc to disappear
Feb 13 13:39:13.155: INFO: Pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:39:13.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-376" for this suite. 02/13/23 13:39:13.162
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":42,"skipped":612,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:09.048
    Feb 13 13:39:09.049: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:39:09.051
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:09.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:09.074
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 02/13/23 13:39:09.079
    W0213 13:39:09.091736      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:39:09.091: INFO: Waiting up to 5m0s for pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc" in namespace "emptydir-376" to be "Succeeded or Failed"
    Feb 13 13:39:09.096: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246817ms
    Feb 13 13:39:11.104: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012324606s
    Feb 13 13:39:13.105: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013212462s
    STEP: Saw pod success 02/13/23 13:39:13.105
    Feb 13 13:39:13.105: INFO: Pod "pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc" satisfied condition "Succeeded or Failed"
    Feb 13 13:39:13.111: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc container test-container: <nil>
    STEP: delete the pod 02/13/23 13:39:13.133
    Feb 13 13:39:13.150: INFO: Waiting for pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc to disappear
    Feb 13 13:39:13.155: INFO: Pod pod-b6740b1b-232f-41fc-b8ed-4ba5261f70fc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:39:13.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-376" for this suite. 02/13/23 13:39:13.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:13.181
Feb 13 13:39:13.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption 02/13/23 13:39:13.183
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:13.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:13.211
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 02/13/23 13:39:13.214
STEP: Waiting for the pdb to be processed 02/13/23 13:39:13.22
W0213 13:39:13.236425      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: First trying to evict a pod which shouldn't be evictable 02/13/23 13:39:13.236
STEP: Waiting for all pods to be running 02/13/23 13:39:13.236
Feb 13 13:39:13.239: INFO: pods: 0 < 3
STEP: locating a running pod 02/13/23 13:39:15.249
STEP: Updating the pdb to allow a pod to be evicted 02/13/23 13:39:15.266
STEP: Waiting for the pdb to be processed 02/13/23 13:39:15.275
STEP: Trying to evict the same pod we tried earlier which should now be evictable 02/13/23 13:39:15.277
STEP: Waiting for all pods to be running 02/13/23 13:39:15.278
STEP: Waiting for the pdb to observed all healthy pods 02/13/23 13:39:15.281
STEP: Patching the pdb to disallow a pod to be evicted 02/13/23 13:39:15.295
STEP: Waiting for the pdb to be processed 02/13/23 13:39:15.312
STEP: Waiting for all pods to be running 02/13/23 13:39:17.328
STEP: locating a running pod 02/13/23 13:39:17.335
STEP: Deleting the pdb to allow a pod to be evicted 02/13/23 13:39:17.347
STEP: Waiting for the pdb to be deleted 02/13/23 13:39:17.353
STEP: Trying to evict the same pod we tried earlier which should now be evictable 02/13/23 13:39:17.357
STEP: Waiting for all pods to be running 02/13/23 13:39:17.357
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Feb 13 13:39:17.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6064" for this suite. 02/13/23 13:39:17.381
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":43,"skipped":652,"failed":0}
------------------------------
• [4.209 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:13.181
    Feb 13 13:39:13.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption 02/13/23 13:39:13.183
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:13.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:13.211
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 02/13/23 13:39:13.214
    STEP: Waiting for the pdb to be processed 02/13/23 13:39:13.22
    W0213 13:39:13.236425      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: First trying to evict a pod which shouldn't be evictable 02/13/23 13:39:13.236
    STEP: Waiting for all pods to be running 02/13/23 13:39:13.236
    Feb 13 13:39:13.239: INFO: pods: 0 < 3
    STEP: locating a running pod 02/13/23 13:39:15.249
    STEP: Updating the pdb to allow a pod to be evicted 02/13/23 13:39:15.266
    STEP: Waiting for the pdb to be processed 02/13/23 13:39:15.275
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 02/13/23 13:39:15.277
    STEP: Waiting for all pods to be running 02/13/23 13:39:15.278
    STEP: Waiting for the pdb to observed all healthy pods 02/13/23 13:39:15.281
    STEP: Patching the pdb to disallow a pod to be evicted 02/13/23 13:39:15.295
    STEP: Waiting for the pdb to be processed 02/13/23 13:39:15.312
    STEP: Waiting for all pods to be running 02/13/23 13:39:17.328
    STEP: locating a running pod 02/13/23 13:39:17.335
    STEP: Deleting the pdb to allow a pod to be evicted 02/13/23 13:39:17.347
    STEP: Waiting for the pdb to be deleted 02/13/23 13:39:17.353
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 02/13/23 13:39:17.357
    STEP: Waiting for all pods to be running 02/13/23 13:39:17.357
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Feb 13 13:39:17.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6064" for this suite. 02/13/23 13:39:17.381
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:17.39
Feb 13 13:39:17.390: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 13:39:17.391
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:17.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:17.414
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 13:39:17.429
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:17.72
STEP: Deploying the webhook pod 02/13/23 13:39:17.729
W0213 13:39:17.748363      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 13:39:17.748
Feb 13 13:39:17.761: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 13:39:19.78
STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:19.797
Feb 13 13:39:20.798: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 02/13/23 13:39:20.805
STEP: create a pod that should be updated by the webhook 02/13/23 13:39:20.855
W0213 13:39:20.904494      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webhook-added-init-container", "example" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webhook-added-init-container", "example" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webhook-added-init-container", "example" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webhook-added-init-container", "example" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:39:20.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6176" for this suite. 02/13/23 13:39:20.928
STEP: Destroying namespace "webhook-6176-markers" for this suite. 02/13/23 13:39:20.944
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":44,"skipped":656,"failed":0}
------------------------------
• [3.606 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:17.39
    Feb 13 13:39:17.390: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 13:39:17.391
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:17.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:17.414
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 13:39:17.429
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:17.72
    STEP: Deploying the webhook pod 02/13/23 13:39:17.729
    W0213 13:39:17.748363      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 13:39:17.748
    Feb 13 13:39:17.761: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 13:39:19.78
    STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:19.797
    Feb 13 13:39:20.798: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 02/13/23 13:39:20.805
    STEP: create a pod that should be updated by the webhook 02/13/23 13:39:20.855
    W0213 13:39:20.904494      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webhook-added-init-container", "example" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webhook-added-init-container", "example" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webhook-added-init-container", "example" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webhook-added-init-container", "example" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:39:20.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6176" for this suite. 02/13/23 13:39:20.928
    STEP: Destroying namespace "webhook-6176-markers" for this suite. 02/13/23 13:39:20.944
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:21.009
Feb 13 13:39:21.009: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sysctl 02/13/23 13:39:21.009
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:21.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:21.025
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 02/13/23 13:39:21.027
W0213 13:39:21.035313      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Watching for error events or started pod 02/13/23 13:39:21.035
STEP: Waiting for pod completion 02/13/23 13:39:23.043
Feb 13 13:39:23.044: INFO: Waiting up to 3m0s for pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96" in namespace "sysctl-8563" to be "completed"
Feb 13 13:39:23.049: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96": Phase="Pending", Reason="", readiness=false. Elapsed: 5.666826ms
Feb 13 13:39:25.057: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013041028s
Feb 13 13:39:25.057: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96" satisfied condition "completed"
STEP: Checking that the pod succeeded 02/13/23 13:39:25.061
STEP: Getting logs from the pod 02/13/23 13:39:25.063
STEP: Checking that the sysctl is actually updated 02/13/23 13:39:25.102
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 13:39:25.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8563" for this suite. 02/13/23 13:39:25.107
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":45,"skipped":692,"failed":0}
------------------------------
• [4.106 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:21.009
    Feb 13 13:39:21.009: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sysctl 02/13/23 13:39:21.009
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:21.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:21.025
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 02/13/23 13:39:21.027
    W0213 13:39:21.035313      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Watching for error events or started pod 02/13/23 13:39:21.035
    STEP: Waiting for pod completion 02/13/23 13:39:23.043
    Feb 13 13:39:23.044: INFO: Waiting up to 3m0s for pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96" in namespace "sysctl-8563" to be "completed"
    Feb 13 13:39:23.049: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96": Phase="Pending", Reason="", readiness=false. Elapsed: 5.666826ms
    Feb 13 13:39:25.057: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013041028s
    Feb 13 13:39:25.057: INFO: Pod "sysctl-ea05a722-75e7-4785-a0cf-7954c037fe96" satisfied condition "completed"
    STEP: Checking that the pod succeeded 02/13/23 13:39:25.061
    STEP: Getting logs from the pod 02/13/23 13:39:25.063
    STEP: Checking that the sysctl is actually updated 02/13/23 13:39:25.102
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 13:39:25.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-8563" for this suite. 02/13/23 13:39:25.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:25.118
Feb 13 13:39:25.118: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 13:39:25.12
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:25.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:25.153
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 13:39:25.17
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:25.591
STEP: Deploying the webhook pod 02/13/23 13:39:25.6
W0213 13:39:25.620029      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 13:39:25.62
Feb 13 13:39:25.629: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 13:39:27.649
STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:27.702
Feb 13 13:39:28.702: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 02/13/23 13:39:28.707
STEP: create a namespace for the webhook 02/13/23 13:39:28.744
STEP: create a configmap should be unconditionally rejected by the webhook 02/13/23 13:39:28.756
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:39:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9092" for this suite. 02/13/23 13:39:28.816
STEP: Destroying namespace "webhook-9092-markers" for this suite. 02/13/23 13:39:28.825
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":46,"skipped":701,"failed":0}
------------------------------
• [3.753 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:25.118
    Feb 13 13:39:25.118: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 13:39:25.12
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:25.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:25.153
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 13:39:25.17
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:25.591
    STEP: Deploying the webhook pod 02/13/23 13:39:25.6
    W0213 13:39:25.620029      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 13:39:25.62
    Feb 13 13:39:25.629: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 13:39:27.649
    STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:27.702
    Feb 13 13:39:28.702: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 02/13/23 13:39:28.707
    STEP: create a namespace for the webhook 02/13/23 13:39:28.744
    STEP: create a configmap should be unconditionally rejected by the webhook 02/13/23 13:39:28.756
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:39:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9092" for this suite. 02/13/23 13:39:28.816
    STEP: Destroying namespace "webhook-9092-markers" for this suite. 02/13/23 13:39:28.825
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:28.883
Feb 13 13:39:28.883: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 13:39:28.884
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:28.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:28.905
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 02/13/23 13:39:28.908
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 02/13/23 13:39:28.908
STEP: creating a pod to probe DNS 02/13/23 13:39:28.908
STEP: submitting the pod to kubernetes 02/13/23 13:39:28.908
W0213 13:39:28.916589      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:39:28.917: INFO: Waiting up to 15m0s for pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30" in namespace "dns-2445" to be "running"
Feb 13 13:39:28.924: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 7.340465ms
Feb 13 13:39:30.931: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013758834s
Feb 13 13:39:32.933: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016104222s
Feb 13 13:39:34.934: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01729946s
Feb 13 13:39:36.932: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Running", Reason="", readiness=true. Elapsed: 8.015222658s
Feb 13 13:39:36.932: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30" satisfied condition "running"
STEP: retrieving the pod 02/13/23 13:39:36.932
STEP: looking for the results for each expected name from probers 02/13/23 13:39:36.938
Feb 13 13:39:36.982: INFO: DNS probes using dns-2445/dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30 succeeded

STEP: deleting the pod 02/13/23 13:39:36.982
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 13:39:36.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2445" for this suite. 02/13/23 13:39:37.002
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":47,"skipped":714,"failed":0}
------------------------------
• [SLOW TEST] [8.127 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:28.883
    Feb 13 13:39:28.883: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 13:39:28.884
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:28.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:28.905
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     02/13/23 13:39:28.908
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     02/13/23 13:39:28.908
    STEP: creating a pod to probe DNS 02/13/23 13:39:28.908
    STEP: submitting the pod to kubernetes 02/13/23 13:39:28.908
    W0213 13:39:28.916589      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:39:28.917: INFO: Waiting up to 15m0s for pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30" in namespace "dns-2445" to be "running"
    Feb 13 13:39:28.924: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 7.340465ms
    Feb 13 13:39:30.931: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013758834s
    Feb 13 13:39:32.933: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016104222s
    Feb 13 13:39:34.934: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01729946s
    Feb 13 13:39:36.932: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30": Phase="Running", Reason="", readiness=true. Elapsed: 8.015222658s
    Feb 13 13:39:36.932: INFO: Pod "dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 13:39:36.932
    STEP: looking for the results for each expected name from probers 02/13/23 13:39:36.938
    Feb 13 13:39:36.982: INFO: DNS probes using dns-2445/dns-test-e62cb4e5-3a18-43f4-9868-cadc3c721d30 succeeded

    STEP: deleting the pod 02/13/23 13:39:36.982
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 13:39:36.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2445" for this suite. 02/13/23 13:39:37.002
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:37.016
Feb 13 13:39:37.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:39:37.019
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:37.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:37.04
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1112 02/13/23 13:39:37.044
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 02/13/23 13:39:37.067
STEP: creating service externalsvc in namespace services-1112 02/13/23 13:39:37.068
STEP: creating replication controller externalsvc in namespace services-1112 02/13/23 13:39:37.088
W0213 13:39:37.100142      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 13:39:37.100301      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1112, replica count: 2
I0213 13:39:40.151142      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 02/13/23 13:39:40.161
Feb 13 13:39:40.189: INFO: Creating new exec pod
W0213 13:39:40.199280      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:39:40.200: INFO: Waiting up to 5m0s for pod "execpodm6nln" in namespace "services-1112" to be "running"
Feb 13 13:39:40.205: INFO: Pod "execpodm6nln": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934416ms
Feb 13 13:39:42.209: INFO: Pod "execpodm6nln": Phase="Running", Reason="", readiness=true. Elapsed: 2.008940164s
Feb 13 13:39:42.209: INFO: Pod "execpodm6nln" satisfied condition "running"
Feb 13 13:39:42.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1112 exec execpodm6nln -- /bin/sh -x -c nslookup nodeport-service.services-1112.svc.cluster.local'
Feb 13 13:39:42.503: INFO: stderr: "+ nslookup nodeport-service.services-1112.svc.cluster.local\n"
Feb 13 13:39:42.503: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-1112.svc.cluster.local\tcanonical name = externalsvc.services-1112.svc.cluster.local.\nName:\texternalsvc.services-1112.svc.cluster.local\nAddress: 10.103.93.252\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1112, will wait for the garbage collector to delete the pods 02/13/23 13:39:42.503
Feb 13 13:39:42.571: INFO: Deleting ReplicationController externalsvc took: 10.333811ms
Feb 13 13:39:42.672: INFO: Terminating ReplicationController externalsvc pods took: 100.987488ms
Feb 13 13:39:44.499: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:39:44.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1112" for this suite. 02/13/23 13:39:44.522
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":48,"skipped":728,"failed":0}
------------------------------
• [SLOW TEST] [7.515 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:37.016
    Feb 13 13:39:37.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:39:37.019
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:37.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:37.04
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-1112 02/13/23 13:39:37.044
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 02/13/23 13:39:37.067
    STEP: creating service externalsvc in namespace services-1112 02/13/23 13:39:37.068
    STEP: creating replication controller externalsvc in namespace services-1112 02/13/23 13:39:37.088
    W0213 13:39:37.100142      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 13:39:37.100301      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1112, replica count: 2
    I0213 13:39:40.151142      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 02/13/23 13:39:40.161
    Feb 13 13:39:40.189: INFO: Creating new exec pod
    W0213 13:39:40.199280      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:39:40.200: INFO: Waiting up to 5m0s for pod "execpodm6nln" in namespace "services-1112" to be "running"
    Feb 13 13:39:40.205: INFO: Pod "execpodm6nln": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934416ms
    Feb 13 13:39:42.209: INFO: Pod "execpodm6nln": Phase="Running", Reason="", readiness=true. Elapsed: 2.008940164s
    Feb 13 13:39:42.209: INFO: Pod "execpodm6nln" satisfied condition "running"
    Feb 13 13:39:42.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1112 exec execpodm6nln -- /bin/sh -x -c nslookup nodeport-service.services-1112.svc.cluster.local'
    Feb 13 13:39:42.503: INFO: stderr: "+ nslookup nodeport-service.services-1112.svc.cluster.local\n"
    Feb 13 13:39:42.503: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-1112.svc.cluster.local\tcanonical name = externalsvc.services-1112.svc.cluster.local.\nName:\texternalsvc.services-1112.svc.cluster.local\nAddress: 10.103.93.252\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1112, will wait for the garbage collector to delete the pods 02/13/23 13:39:42.503
    Feb 13 13:39:42.571: INFO: Deleting ReplicationController externalsvc took: 10.333811ms
    Feb 13 13:39:42.672: INFO: Terminating ReplicationController externalsvc pods took: 100.987488ms
    Feb 13 13:39:44.499: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:39:44.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1112" for this suite. 02/13/23 13:39:44.522
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:44.534
Feb 13 13:39:44.534: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 13:39:44.535
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:44.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:44.561
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 13:39:44.579
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:45.22
STEP: Deploying the webhook pod 02/13/23 13:39:45.226
W0213 13:39:45.243420      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 13:39:45.243
Feb 13 13:39:45.253: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 13:39:47.265
STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:47.28
Feb 13 13:39:48.281: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 02/13/23 13:39:48.288
STEP: create a pod that should be denied by the webhook 02/13/23 13:39:48.331
W0213 13:39:48.369221      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webhook-disallow" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webhook-disallow" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webhook-disallow" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webhook-disallow" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: create a pod that causes the webhook to hang 02/13/23 13:39:48.369
W0213 13:39:58.381548      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "wait-forever" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "wait-forever" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "wait-forever" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "wait-forever" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: create a configmap that should be denied by the webhook 02/13/23 13:39:58.386
STEP: create a configmap that should be admitted by the webhook 02/13/23 13:39:58.419
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 02/13/23 13:39:58.444
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 02/13/23 13:39:58.456
STEP: create a namespace that bypass the webhook 02/13/23 13:39:58.466
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 02/13/23 13:39:58.473
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:39:58.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3524" for this suite. 02/13/23 13:39:58.51
STEP: Destroying namespace "webhook-3524-markers" for this suite. 02/13/23 13:39:58.514
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":49,"skipped":730,"failed":0}
------------------------------
• [SLOW TEST] [14.029 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:44.534
    Feb 13 13:39:44.534: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 13:39:44.535
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:44.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:44.561
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 13:39:44.579
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:45.22
    STEP: Deploying the webhook pod 02/13/23 13:39:45.226
    W0213 13:39:45.243420      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 13:39:45.243
    Feb 13 13:39:45.253: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 13:39:47.265
    STEP: Verifying the service has paired with the endpoint 02/13/23 13:39:47.28
    Feb 13 13:39:48.281: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 02/13/23 13:39:48.288
    STEP: create a pod that should be denied by the webhook 02/13/23 13:39:48.331
    W0213 13:39:48.369221      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webhook-disallow" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webhook-disallow" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webhook-disallow" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webhook-disallow" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: create a pod that causes the webhook to hang 02/13/23 13:39:48.369
    W0213 13:39:58.381548      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "wait-forever" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "wait-forever" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "wait-forever" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "wait-forever" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: create a configmap that should be denied by the webhook 02/13/23 13:39:58.386
    STEP: create a configmap that should be admitted by the webhook 02/13/23 13:39:58.419
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 02/13/23 13:39:58.444
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 02/13/23 13:39:58.456
    STEP: create a namespace that bypass the webhook 02/13/23 13:39:58.466
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 02/13/23 13:39:58.473
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:39:58.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3524" for this suite. 02/13/23 13:39:58.51
    STEP: Destroying namespace "webhook-3524-markers" for this suite. 02/13/23 13:39:58.514
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:39:58.565
Feb 13 13:39:58.566: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 13:39:58.567
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:58.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:58.586
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 13:39:58.604
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:58.978
STEP: Deploying the webhook pod 02/13/23 13:39:58.992
W0213 13:39:59.011608      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 13:39:59.011
Feb 13 13:39:59.023: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 13:40:01.046
STEP: Verifying the service has paired with the endpoint 02/13/23 13:40:01.064
Feb 13 13:40:02.067: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 02/13/23 13:40:02.073
STEP: Creating a custom resource definition that should be denied by the webhook 02/13/23 13:40:02.107
Feb 13 13:40:02.108: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:40:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2024" for this suite. 02/13/23 13:40:02.147
STEP: Destroying namespace "webhook-2024-markers" for this suite. 02/13/23 13:40:02.154
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":50,"skipped":774,"failed":0}
------------------------------
• [3.631 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:39:58.565
    Feb 13 13:39:58.566: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 13:39:58.567
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:39:58.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:39:58.586
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 13:39:58.604
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:39:58.978
    STEP: Deploying the webhook pod 02/13/23 13:39:58.992
    W0213 13:39:59.011608      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 13:39:59.011
    Feb 13 13:39:59.023: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 13:40:01.046
    STEP: Verifying the service has paired with the endpoint 02/13/23 13:40:01.064
    Feb 13 13:40:02.067: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 02/13/23 13:40:02.073
    STEP: Creating a custom resource definition that should be denied by the webhook 02/13/23 13:40:02.107
    Feb 13 13:40:02.108: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:40:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2024" for this suite. 02/13/23 13:40:02.147
    STEP: Destroying namespace "webhook-2024-markers" for this suite. 02/13/23 13:40:02.154
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:40:02.198
Feb 13 13:40:02.198: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:40:02.2
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:02.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:02.223
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-5d2cfd86-0e2e-44ee-b0cd-806714c86a6d 02/13/23 13:40:02.23
STEP: Creating a pod to test consume configMaps 02/13/23 13:40:02.234
W0213 13:40:02.246403      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:40:02.246: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121" in namespace "projected-6468" to be "Succeeded or Failed"
Feb 13 13:40:02.252: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447946ms
Feb 13 13:40:04.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012574802s
Feb 13 13:40:06.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01257148s
STEP: Saw pod success 02/13/23 13:40:06.259
Feb 13 13:40:06.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121" satisfied condition "Succeeded or Failed"
Feb 13 13:40:06.266: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:40:06.28
Feb 13 13:40:06.299: INFO: Waiting for pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 to disappear
Feb 13 13:40:06.304: INFO: Pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 13:40:06.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6468" for this suite. 02/13/23 13:40:06.309
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":51,"skipped":806,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:40:02.198
    Feb 13 13:40:02.198: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:40:02.2
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:02.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:02.223
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-5d2cfd86-0e2e-44ee-b0cd-806714c86a6d 02/13/23 13:40:02.23
    STEP: Creating a pod to test consume configMaps 02/13/23 13:40:02.234
    W0213 13:40:02.246403      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:40:02.246: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121" in namespace "projected-6468" to be "Succeeded or Failed"
    Feb 13 13:40:02.252: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447946ms
    Feb 13 13:40:04.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012574802s
    Feb 13 13:40:06.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01257148s
    STEP: Saw pod success 02/13/23 13:40:06.259
    Feb 13 13:40:06.259: INFO: Pod "pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121" satisfied condition "Succeeded or Failed"
    Feb 13 13:40:06.266: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:40:06.28
    Feb 13 13:40:06.299: INFO: Waiting for pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 to disappear
    Feb 13 13:40:06.304: INFO: Pod pod-projected-configmaps-cbf6d431-1b64-40e4-93dd-e4f32f643121 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 13:40:06.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6468" for this suite. 02/13/23 13:40:06.309
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:40:06.322
Feb 13 13:40:06.322: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 13:40:06.324
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:06.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:06.354
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 02/13/23 13:40:06.36
W0213 13:40:06.371612      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:40:06.372: INFO: Waiting up to 5m0s for pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705" in namespace "var-expansion-1904" to be "Succeeded or Failed"
Feb 13 13:40:06.376: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203984ms
Feb 13 13:40:08.384: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012013046s
Feb 13 13:40:10.383: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011289061s
STEP: Saw pod success 02/13/23 13:40:10.383
Feb 13 13:40:10.384: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705" satisfied condition "Succeeded or Failed"
Feb 13 13:40:10.389: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 container dapi-container: <nil>
STEP: delete the pod 02/13/23 13:40:10.401
Feb 13 13:40:10.421: INFO: Waiting for pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 to disappear
Feb 13 13:40:10.426: INFO: Pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 13:40:10.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1904" for this suite. 02/13/23 13:40:10.432
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":52,"skipped":818,"failed":0}
------------------------------
• [4.117 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:40:06.322
    Feb 13 13:40:06.322: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 13:40:06.324
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:06.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:06.354
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 02/13/23 13:40:06.36
    W0213 13:40:06.371612      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:40:06.372: INFO: Waiting up to 5m0s for pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705" in namespace "var-expansion-1904" to be "Succeeded or Failed"
    Feb 13 13:40:06.376: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203984ms
    Feb 13 13:40:08.384: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012013046s
    Feb 13 13:40:10.383: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011289061s
    STEP: Saw pod success 02/13/23 13:40:10.383
    Feb 13 13:40:10.384: INFO: Pod "var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705" satisfied condition "Succeeded or Failed"
    Feb 13 13:40:10.389: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 container dapi-container: <nil>
    STEP: delete the pod 02/13/23 13:40:10.401
    Feb 13 13:40:10.421: INFO: Waiting for pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 to disappear
    Feb 13 13:40:10.426: INFO: Pod var-expansion-987adec6-5788-4fb9-9bfb-04d34ebc1705 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 13:40:10.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1904" for this suite. 02/13/23 13:40:10.432
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:40:10.443
Feb 13 13:40:10.444: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 13:40:10.446
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:10.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:10.467
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 02/13/23 13:40:10.473
W0213 13:40:10.489969      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:40:10.490: INFO: Waiting up to 2m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218" to be "running"
Feb 13 13:40:10.495: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.219322ms
Feb 13 13:40:12.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0132291s
Feb 13 13:40:14.505: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015251614s
Feb 13 13:40:16.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012577942s
Feb 13 13:40:18.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011884127s
Feb 13 13:40:20.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011927262s
Feb 13 13:40:22.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 12.012296698s
Feb 13 13:40:24.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01316545s
Feb 13 13:40:26.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013480702s
Feb 13 13:40:28.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013279767s
Feb 13 13:40:30.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 20.01230075s
Feb 13 13:40:32.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 22.011357112s
Feb 13 13:40:34.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 24.015893753s
Feb 13 13:40:36.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 26.01141741s
Feb 13 13:40:38.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 28.011055386s
Feb 13 13:40:40.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 30.010323642s
Feb 13 13:40:42.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 32.012259869s
Feb 13 13:40:44.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013858866s
Feb 13 13:40:46.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 36.011988308s
Feb 13 13:40:48.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011067023s
Feb 13 13:40:50.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012651793s
Feb 13 13:40:52.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011651787s
Feb 13 13:40:54.499: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 44.009773893s
Feb 13 13:40:56.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011258342s
Feb 13 13:40:58.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 48.012110537s
Feb 13 13:41:00.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 50.012883311s
Feb 13 13:41:02.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 52.011503125s
Feb 13 13:41:04.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013551493s
Feb 13 13:41:06.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013217957s
Feb 13 13:41:08.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 58.012028181s
Feb 13 13:41:10.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013257003s
Feb 13 13:41:12.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.012596521s
Feb 13 13:41:14.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.011701783s
Feb 13 13:41:16.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014323213s
Feb 13 13:41:18.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.012383519s
Feb 13 13:41:20.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014241675s
Feb 13 13:41:22.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015984438s
Feb 13 13:41:24.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.012088625s
Feb 13 13:41:26.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01079756s
Feb 13 13:41:28.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013774535s
Feb 13 13:41:30.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.012607589s
Feb 13 13:41:32.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.01263823s
Feb 13 13:41:34.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012032407s
Feb 13 13:41:36.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.011402593s
Feb 13 13:41:38.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010466204s
Feb 13 13:41:40.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013900921s
Feb 13 13:41:42.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.01152095s
Feb 13 13:41:44.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014745182s
Feb 13 13:41:46.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.011594487s
Feb 13 13:41:48.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012218611s
Feb 13 13:41:50.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.016276624s
Feb 13 13:41:52.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011558433s
Feb 13 13:41:54.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.012589259s
Feb 13 13:41:56.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013292079s
Feb 13 13:41:58.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014676779s
Feb 13 13:42:00.499: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.009127311s
Feb 13 13:42:02.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.011028837s
Feb 13 13:42:04.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011504107s
Feb 13 13:42:06.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.012997976s
Feb 13 13:42:08.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.011635259s
Feb 13 13:42:10.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013387869s
Feb 13 13:42:10.510: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020114426s
STEP: updating the pod 02/13/23 13:42:10.51
Feb 13 13:42:11.033: INFO: Successfully updated pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674"
STEP: waiting for pod running 02/13/23 13:42:11.033
Feb 13 13:42:11.034: INFO: Waiting up to 2m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218" to be "running"
Feb 13 13:42:11.038: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721075ms
Feb 13 13:42:13.044: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Running", Reason="", readiness=true. Elapsed: 2.010493558s
Feb 13 13:42:13.044: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" satisfied condition "running"
STEP: deleting the pod gracefully 02/13/23 13:42:13.044
Feb 13 13:42:13.045: INFO: Deleting pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218"
Feb 13 13:42:13.055: INFO: Wait up to 5m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 13:42:45.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8218" for this suite. 02/13/23 13:42:45.075
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":53,"skipped":824,"failed":0}
------------------------------
• [SLOW TEST] [154.641 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:40:10.443
    Feb 13 13:40:10.444: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 13:40:10.446
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:40:10.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:40:10.467
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 02/13/23 13:40:10.473
    W0213 13:40:10.489969      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:40:10.490: INFO: Waiting up to 2m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218" to be "running"
    Feb 13 13:40:10.495: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.219322ms
    Feb 13 13:40:12.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0132291s
    Feb 13 13:40:14.505: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015251614s
    Feb 13 13:40:16.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012577942s
    Feb 13 13:40:18.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011884127s
    Feb 13 13:40:20.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011927262s
    Feb 13 13:40:22.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 12.012296698s
    Feb 13 13:40:24.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01316545s
    Feb 13 13:40:26.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013480702s
    Feb 13 13:40:28.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013279767s
    Feb 13 13:40:30.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 20.01230075s
    Feb 13 13:40:32.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 22.011357112s
    Feb 13 13:40:34.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 24.015893753s
    Feb 13 13:40:36.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 26.01141741s
    Feb 13 13:40:38.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 28.011055386s
    Feb 13 13:40:40.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 30.010323642s
    Feb 13 13:40:42.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 32.012259869s
    Feb 13 13:40:44.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013858866s
    Feb 13 13:40:46.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 36.011988308s
    Feb 13 13:40:48.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011067023s
    Feb 13 13:40:50.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012651793s
    Feb 13 13:40:52.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011651787s
    Feb 13 13:40:54.499: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 44.009773893s
    Feb 13 13:40:56.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011258342s
    Feb 13 13:40:58.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 48.012110537s
    Feb 13 13:41:00.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 50.012883311s
    Feb 13 13:41:02.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 52.011503125s
    Feb 13 13:41:04.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013551493s
    Feb 13 13:41:06.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013217957s
    Feb 13 13:41:08.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 58.012028181s
    Feb 13 13:41:10.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013257003s
    Feb 13 13:41:12.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.012596521s
    Feb 13 13:41:14.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.011701783s
    Feb 13 13:41:16.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014323213s
    Feb 13 13:41:18.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.012383519s
    Feb 13 13:41:20.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014241675s
    Feb 13 13:41:22.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015984438s
    Feb 13 13:41:24.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.012088625s
    Feb 13 13:41:26.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01079756s
    Feb 13 13:41:28.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013774535s
    Feb 13 13:41:30.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.012607589s
    Feb 13 13:41:32.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.01263823s
    Feb 13 13:41:34.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012032407s
    Feb 13 13:41:36.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.011402593s
    Feb 13 13:41:38.500: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010466204s
    Feb 13 13:41:40.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013900921s
    Feb 13 13:41:42.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.01152095s
    Feb 13 13:41:44.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014745182s
    Feb 13 13:41:46.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.011594487s
    Feb 13 13:41:48.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012218611s
    Feb 13 13:41:50.506: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.016276624s
    Feb 13 13:41:52.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011558433s
    Feb 13 13:41:54.502: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.012589259s
    Feb 13 13:41:56.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013292079s
    Feb 13 13:41:58.504: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014676779s
    Feb 13 13:42:00.499: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.009127311s
    Feb 13 13:42:02.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.011028837s
    Feb 13 13:42:04.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011504107s
    Feb 13 13:42:06.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.012997976s
    Feb 13 13:42:08.501: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.011635259s
    Feb 13 13:42:10.503: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013387869s
    Feb 13 13:42:10.510: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020114426s
    STEP: updating the pod 02/13/23 13:42:10.51
    Feb 13 13:42:11.033: INFO: Successfully updated pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674"
    STEP: waiting for pod running 02/13/23 13:42:11.033
    Feb 13 13:42:11.034: INFO: Waiting up to 2m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218" to be "running"
    Feb 13 13:42:11.038: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721075ms
    Feb 13 13:42:13.044: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674": Phase="Running", Reason="", readiness=true. Elapsed: 2.010493558s
    Feb 13 13:42:13.044: INFO: Pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" satisfied condition "running"
    STEP: deleting the pod gracefully 02/13/23 13:42:13.044
    Feb 13 13:42:13.045: INFO: Deleting pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" in namespace "var-expansion-8218"
    Feb 13 13:42:13.055: INFO: Wait up to 5m0s for pod "var-expansion-96c36f4d-2169-41bc-9bd2-557dc0140674" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 13:42:45.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8218" for this suite. 02/13/23 13:42:45.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:42:45.091
Feb 13 13:42:45.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 13:42:45.095
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:45.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:45.123
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-4f555864-4811-496f-9cc6-7e0364dd9f90 02/13/23 13:42:45.131
STEP: Creating the pod 02/13/23 13:42:45.139
W0213 13:42:45.149076      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:42:45.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820" in namespace "configmap-7261" to be "running"
Feb 13 13:42:45.156: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820": Phase="Pending", Reason="", readiness=false. Elapsed: 6.930663ms
Feb 13 13:42:47.172: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820": Phase="Running", Reason="", readiness=false. Elapsed: 2.023201674s
Feb 13 13:42:47.172: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820" satisfied condition "running"
STEP: Waiting for pod with text data 02/13/23 13:42:47.172
STEP: Waiting for pod with binary data 02/13/23 13:42:47.215
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 13:42:47.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7261" for this suite. 02/13/23 13:42:47.23
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":54,"skipped":851,"failed":0}
------------------------------
• [2.146 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:42:45.091
    Feb 13 13:42:45.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 13:42:45.095
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:45.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:45.123
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-4f555864-4811-496f-9cc6-7e0364dd9f90 02/13/23 13:42:45.131
    STEP: Creating the pod 02/13/23 13:42:45.139
    W0213 13:42:45.149076      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:42:45.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820" in namespace "configmap-7261" to be "running"
    Feb 13 13:42:45.156: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820": Phase="Pending", Reason="", readiness=false. Elapsed: 6.930663ms
    Feb 13 13:42:47.172: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820": Phase="Running", Reason="", readiness=false. Elapsed: 2.023201674s
    Feb 13 13:42:47.172: INFO: Pod "pod-configmaps-3f23f982-c723-4bcf-86ac-b58c51866820" satisfied condition "running"
    STEP: Waiting for pod with text data 02/13/23 13:42:47.172
    STEP: Waiting for pod with binary data 02/13/23 13:42:47.215
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 13:42:47.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7261" for this suite. 02/13/23 13:42:47.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:42:47.239
Feb 13 13:42:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename prestop 02/13/23 13:42:47.24
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:47.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:47.263
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-2248 02/13/23 13:42:47.268
W0213 13:42:47.279185      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for pods to come up. 02/13/23 13:42:47.279
Feb 13 13:42:47.279: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2248" to be "running"
Feb 13 13:42:47.283: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222767ms
Feb 13 13:42:49.291: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.01152686s
Feb 13 13:42:49.291: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-2248 02/13/23 13:42:49.296
W0213 13:42:49.307822      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "tester" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "tester" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "tester" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "tester" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:42:49.307: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2248" to be "running"
Feb 13 13:42:49.318: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 10.855398ms
Feb 13 13:42:51.327: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.019040086s
Feb 13 13:42:51.327: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 02/13/23 13:42:51.327
Feb 13 13:42:56.355: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 02/13/23 13:42:56.355
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Feb 13 13:42:56.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2248" for this suite. 02/13/23 13:42:56.381
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":55,"skipped":859,"failed":0}
------------------------------
• [SLOW TEST] [9.150 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:42:47.239
    Feb 13 13:42:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename prestop 02/13/23 13:42:47.24
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:47.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:47.263
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-2248 02/13/23 13:42:47.268
    W0213 13:42:47.279185      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for pods to come up. 02/13/23 13:42:47.279
    Feb 13 13:42:47.279: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-2248" to be "running"
    Feb 13 13:42:47.283: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222767ms
    Feb 13 13:42:49.291: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.01152686s
    Feb 13 13:42:49.291: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-2248 02/13/23 13:42:49.296
    W0213 13:42:49.307822      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "tester" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "tester" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "tester" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "tester" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:42:49.307: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-2248" to be "running"
    Feb 13 13:42:49.318: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 10.855398ms
    Feb 13 13:42:51.327: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.019040086s
    Feb 13 13:42:51.327: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 02/13/23 13:42:51.327
    Feb 13 13:42:56.355: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 02/13/23 13:42:56.355
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Feb 13 13:42:56.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-2248" for this suite. 02/13/23 13:42:56.381
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:42:56.393
Feb 13 13:42:56.393: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replication-controller 02/13/23 13:42:56.395
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:56.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:56.418
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d 02/13/23 13:42:56.42
W0213 13:42:56.427540      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:42:56.432: INFO: Pod name my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Found 0 pods out of 1
Feb 13 13:43:01.438: INFO: Pod name my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Found 1 pods out of 1
Feb 13 13:43:01.438: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" are running
Feb 13 13:43:01.438: INFO: Waiting up to 5m0s for pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" in namespace "replication-controller-6440" to be "running"
Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp": Phase="Running", Reason="", readiness=true. Elapsed: 3.402628ms
Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" satisfied condition "running"
Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:56 +0000 UTC Reason: Message:}])
Feb 13 13:43:01.442: INFO: Trying to dial the pod
Feb 13 13:43:06.481: INFO: Controller my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Got expected result from replica 1 [my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp]: "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Feb 13 13:43:06.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6440" for this suite. 02/13/23 13:43:06.487
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":56,"skipped":878,"failed":0}
------------------------------
• [SLOW TEST] [10.105 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:42:56.393
    Feb 13 13:42:56.393: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replication-controller 02/13/23 13:42:56.395
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:42:56.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:42:56.418
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d 02/13/23 13:42:56.42
    W0213 13:42:56.427540      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:42:56.432: INFO: Pod name my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Found 0 pods out of 1
    Feb 13 13:43:01.438: INFO: Pod name my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Found 1 pods out of 1
    Feb 13 13:43:01.438: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d" are running
    Feb 13 13:43:01.438: INFO: Waiting up to 5m0s for pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" in namespace "replication-controller-6440" to be "running"
    Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp": Phase="Running", Reason="", readiness=true. Elapsed: 3.402628ms
    Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" satisfied condition "running"
    Feb 13 13:43:01.442: INFO: Pod "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:42:56 +0000 UTC Reason: Message:}])
    Feb 13 13:43:01.442: INFO: Trying to dial the pod
    Feb 13 13:43:06.481: INFO: Controller my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d: Got expected result from replica 1 [my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp]: "my-hostname-basic-83351c9a-59b9-4886-aaad-bf5bc8c01c6d-gl4fp", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Feb 13 13:43:06.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-6440" for this suite. 02/13/23 13:43:06.487
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:43:06.51
Feb 13 13:43:06.510: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:43:06.512
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:43:06.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:43:06.538
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Feb 13 13:43:06.568: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 13:44:06.610: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:06.614
Feb 13 13:44:06.615: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption-path 02/13/23 13:44:06.617
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:06.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:06.643
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 02/13/23 13:44:06.646
STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 13:44:06.647
Feb 13 13:44:06.656: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8228" to be "running"
Feb 13 13:44:06.659: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.775486ms
Feb 13 13:44:08.667: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011519275s
Feb 13 13:44:08.667: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 13:44:08.673
Feb 13 13:44:08.689: INFO: found a healthy node: conformance-5500-0ccfa5-pool-bf9f-o7jrw
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Feb 13 13:44:22.794: INFO: pods created so far: [1 1 1]
Feb 13 13:44:22.794: INFO: length of pods created so far: 3
Feb 13 13:44:24.812: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Feb 13 13:44:31.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8228" for this suite. 02/13/23 13:44:31.825
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:44:31.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5858" for this suite. 02/13/23 13:44:31.894
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":57,"skipped":915,"failed":0}
------------------------------
• [SLOW TEST] [85.437 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:43:06.51
    Feb 13 13:43:06.510: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:43:06.512
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:43:06.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:43:06.538
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Feb 13 13:43:06.568: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 13:44:06.610: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:06.614
    Feb 13 13:44:06.615: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption-path 02/13/23 13:44:06.617
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:06.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:06.643
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 02/13/23 13:44:06.646
    STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 13:44:06.647
    Feb 13 13:44:06.656: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8228" to be "running"
    Feb 13 13:44:06.659: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.775486ms
    Feb 13 13:44:08.667: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011519275s
    Feb 13 13:44:08.667: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 13:44:08.673
    Feb 13 13:44:08.689: INFO: found a healthy node: conformance-5500-0ccfa5-pool-bf9f-o7jrw
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Feb 13 13:44:22.794: INFO: pods created so far: [1 1 1]
    Feb 13 13:44:22.794: INFO: length of pods created so far: 3
    Feb 13 13:44:24.812: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Feb 13 13:44:31.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8228" for this suite. 02/13/23 13:44:31.825
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:44:31.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5858" for this suite. 02/13/23 13:44:31.894
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:31.951
Feb 13 13:44:31.951: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:44:31.953
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:31.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:31.97
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-bb8c13b8-11ea-4313-9699-7e10821d2ee5 02/13/23 13:44:31.973
STEP: Creating a pod to test consume configMaps 02/13/23 13:44:31.977
W0213 13:44:31.985029      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:44:31.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3" in namespace "projected-3241" to be "Succeeded or Failed"
Feb 13 13:44:31.989: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413317ms
Feb 13 13:44:33.995: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01011996s
Feb 13 13:44:35.994: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008727405s
STEP: Saw pod success 02/13/23 13:44:35.994
Feb 13 13:44:35.995: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3" satisfied condition "Succeeded or Failed"
Feb 13 13:44:35.999: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:44:36.037
Feb 13 13:44:36.057: INFO: Waiting for pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 to disappear
Feb 13 13:44:36.061: INFO: Pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 13:44:36.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3241" for this suite. 02/13/23 13:44:36.067
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":58,"skipped":935,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:31.951
    Feb 13 13:44:31.951: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:44:31.953
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:31.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:31.97
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-bb8c13b8-11ea-4313-9699-7e10821d2ee5 02/13/23 13:44:31.973
    STEP: Creating a pod to test consume configMaps 02/13/23 13:44:31.977
    W0213 13:44:31.985029      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:44:31.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3" in namespace "projected-3241" to be "Succeeded or Failed"
    Feb 13 13:44:31.989: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413317ms
    Feb 13 13:44:33.995: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01011996s
    Feb 13 13:44:35.994: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008727405s
    STEP: Saw pod success 02/13/23 13:44:35.994
    Feb 13 13:44:35.995: INFO: Pod "pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3" satisfied condition "Succeeded or Failed"
    Feb 13 13:44:35.999: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:44:36.037
    Feb 13 13:44:36.057: INFO: Waiting for pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 to disappear
    Feb 13 13:44:36.061: INFO: Pod pod-projected-configmaps-9fcf88a5-cbf4-4f49-b2c4-e77e239936f3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 13:44:36.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3241" for this suite. 02/13/23 13:44:36.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:36.075
Feb 13 13:44:36.075: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename csistoragecapacity 02/13/23 13:44:36.077
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:36.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:36.094
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 02/13/23 13:44:36.099
STEP: getting /apis/storage.k8s.io 02/13/23 13:44:36.102
STEP: getting /apis/storage.k8s.io/v1 02/13/23 13:44:36.103
STEP: creating 02/13/23 13:44:36.105
STEP: watching 02/13/23 13:44:36.123
Feb 13 13:44:36.123: INFO: starting watch
STEP: getting 02/13/23 13:44:36.134
STEP: listing in namespace 02/13/23 13:44:36.137
STEP: listing across namespaces 02/13/23 13:44:36.141
STEP: patching 02/13/23 13:44:36.144
STEP: updating 02/13/23 13:44:36.152
Feb 13 13:44:36.159: INFO: waiting for watch events with expected annotations in namespace
Feb 13 13:44:36.160: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 02/13/23 13:44:36.16
STEP: deleting a collection 02/13/23 13:44:36.177
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Feb 13 13:44:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-2375" for this suite. 02/13/23 13:44:36.198
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":59,"skipped":945,"failed":0}
------------------------------
• [0.131 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:36.075
    Feb 13 13:44:36.075: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename csistoragecapacity 02/13/23 13:44:36.077
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:36.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:36.094
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 02/13/23 13:44:36.099
    STEP: getting /apis/storage.k8s.io 02/13/23 13:44:36.102
    STEP: getting /apis/storage.k8s.io/v1 02/13/23 13:44:36.103
    STEP: creating 02/13/23 13:44:36.105
    STEP: watching 02/13/23 13:44:36.123
    Feb 13 13:44:36.123: INFO: starting watch
    STEP: getting 02/13/23 13:44:36.134
    STEP: listing in namespace 02/13/23 13:44:36.137
    STEP: listing across namespaces 02/13/23 13:44:36.141
    STEP: patching 02/13/23 13:44:36.144
    STEP: updating 02/13/23 13:44:36.152
    Feb 13 13:44:36.159: INFO: waiting for watch events with expected annotations in namespace
    Feb 13 13:44:36.160: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 02/13/23 13:44:36.16
    STEP: deleting a collection 02/13/23 13:44:36.177
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Feb 13 13:44:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-2375" for this suite. 02/13/23 13:44:36.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:36.215
Feb 13 13:44:36.215: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replication-controller 02/13/23 13:44:36.217
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:36.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:36.237
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 02/13/23 13:44:36.24
W0213 13:44:36.245678      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: When the matched label of one of its pods change 02/13/23 13:44:36.245
Feb 13 13:44:36.249: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 13 13:44:41.259: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 02/13/23 13:44:41.274
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Feb 13 13:44:41.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3107" for this suite. 02/13/23 13:44:41.293
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":60,"skipped":990,"failed":0}
------------------------------
• [SLOW TEST] [5.092 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:36.215
    Feb 13 13:44:36.215: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replication-controller 02/13/23 13:44:36.217
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:36.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:36.237
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 02/13/23 13:44:36.24
    W0213 13:44:36.245678      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: When the matched label of one of its pods change 02/13/23 13:44:36.245
    Feb 13 13:44:36.249: INFO: Pod name pod-release: Found 0 pods out of 1
    Feb 13 13:44:41.259: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 02/13/23 13:44:41.274
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Feb 13 13:44:41.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3107" for this suite. 02/13/23 13:44:41.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:41.315
Feb 13 13:44:41.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption 02/13/23 13:44:41.318
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:41.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:41.347
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 02/13/23 13:44:41.363
STEP: Updating PodDisruptionBudget status 02/13/23 13:44:41.369
W0213 13:44:41.385488      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for all pods to be running 02/13/23 13:44:41.385
Feb 13 13:44:41.396: INFO: running pods: 0 < 1
STEP: locating a running pod 02/13/23 13:44:43.404
STEP: Waiting for the pdb to be processed 02/13/23 13:44:43.42
STEP: Patching PodDisruptionBudget status 02/13/23 13:44:43.428
STEP: Waiting for the pdb to be processed 02/13/23 13:44:43.44
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Feb 13 13:44:43.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8888" for this suite. 02/13/23 13:44:43.446
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":61,"skipped":1048,"failed":0}
------------------------------
• [2.135 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:41.315
    Feb 13 13:44:41.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption 02/13/23 13:44:41.318
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:41.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:41.347
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 02/13/23 13:44:41.363
    STEP: Updating PodDisruptionBudget status 02/13/23 13:44:41.369
    W0213 13:44:41.385488      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for all pods to be running 02/13/23 13:44:41.385
    Feb 13 13:44:41.396: INFO: running pods: 0 < 1
    STEP: locating a running pod 02/13/23 13:44:43.404
    STEP: Waiting for the pdb to be processed 02/13/23 13:44:43.42
    STEP: Patching PodDisruptionBudget status 02/13/23 13:44:43.428
    STEP: Waiting for the pdb to be processed 02/13/23 13:44:43.44
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Feb 13 13:44:43.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8888" for this suite. 02/13/23 13:44:43.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:43.456
Feb 13 13:44:43.456: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 13:44:43.457
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:43.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:43.481
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 13:44:43.484
Feb 13 13:44:43.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Feb 13 13:44:43.615: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:44:43.615: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 02/13/23 13:44:43.615
Feb 13 13:44:43.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Feb 13 13:44:44.477: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:44:44.477: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 13:44:44.477
Feb 13 13:44:44.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 delete pods e2e-test-httpd-pod'
Feb 13 13:44:46.130: INFO: stderr: ""
Feb 13 13:44:46.130: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 13:44:46.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2591" for this suite. 02/13/23 13:44:46.136
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":62,"skipped":1084,"failed":0}
------------------------------
• [2.686 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:43.456
    Feb 13 13:44:43.456: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 13:44:43.457
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:43.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:43.481
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 13:44:43.484
    Feb 13 13:44:43.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Feb 13 13:44:43.615: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:44:43.615: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 02/13/23 13:44:43.615
    Feb 13 13:44:43.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Feb 13 13:44:44.477: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:44:44.477: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 13:44:44.477
    Feb 13 13:44:44.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2591 delete pods e2e-test-httpd-pod'
    Feb 13 13:44:46.130: INFO: stderr: ""
    Feb 13 13:44:46.130: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 13:44:46.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2591" for this suite. 02/13/23 13:44:46.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:46.151
Feb 13 13:44:46.151: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 13:44:46.153
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:46.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:46.176
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 02/13/23 13:44:46.182
STEP: Creating a ResourceQuota 02/13/23 13:44:51.186
STEP: Ensuring resource quota status is calculated 02/13/23 13:44:51.191
STEP: Creating a ReplicationController 02/13/23 13:44:53.201
W0213 13:44:53.223902      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota status captures replication controller creation 02/13/23 13:44:53.224
STEP: Deleting a ReplicationController 02/13/23 13:44:55.231
STEP: Ensuring resource quota status released usage 02/13/23 13:44:55.24
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 13:44:57.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3900" for this suite. 02/13/23 13:44:57.25
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":63,"skipped":1130,"failed":0}
------------------------------
• [SLOW TEST] [11.106 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:46.151
    Feb 13 13:44:46.151: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 13:44:46.153
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:46.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:46.176
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 02/13/23 13:44:46.182
    STEP: Creating a ResourceQuota 02/13/23 13:44:51.186
    STEP: Ensuring resource quota status is calculated 02/13/23 13:44:51.191
    STEP: Creating a ReplicationController 02/13/23 13:44:53.201
    W0213 13:44:53.223902      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota status captures replication controller creation 02/13/23 13:44:53.224
    STEP: Deleting a ReplicationController 02/13/23 13:44:55.231
    STEP: Ensuring resource quota status released usage 02/13/23 13:44:55.24
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 13:44:57.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3900" for this suite. 02/13/23 13:44:57.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:44:57.258
Feb 13 13:44:57.258: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename endpointslice 02/13/23 13:44:57.259
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:57.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:57.279
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
W0213 13:44:57.295186      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:44:57.303586      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: referencing a single matching pod 02/13/23 13:45:02.368
STEP: referencing matching pods with named port 02/13/23 13:45:07.38
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 02/13/23 13:45:12.393
STEP: recreating EndpointSlices after they've been deleted 02/13/23 13:45:17.405
Feb 13 13:45:17.430: INFO: EndpointSlice for Service endpointslice-5112/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Feb 13 13:45:27.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5112" for this suite. 02/13/23 13:45:27.452
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":64,"skipped":1135,"failed":0}
------------------------------
• [SLOW TEST] [30.203 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:44:57.258
    Feb 13 13:44:57.258: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename endpointslice 02/13/23 13:44:57.259
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:44:57.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:44:57.279
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    W0213 13:44:57.295186      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:44:57.303586      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: referencing a single matching pod 02/13/23 13:45:02.368
    STEP: referencing matching pods with named port 02/13/23 13:45:07.38
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 02/13/23 13:45:12.393
    STEP: recreating EndpointSlices after they've been deleted 02/13/23 13:45:17.405
    Feb 13 13:45:17.430: INFO: EndpointSlice for Service endpointslice-5112/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Feb 13 13:45:27.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5112" for this suite. 02/13/23 13:45:27.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:27.467
Feb 13 13:45:27.467: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:45:27.47
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:27.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:27.497
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
W0213 13:45:27.514168      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:45:27.521: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 13 13:45:32.526: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 13:45:32.526
Feb 13 13:45:32.527: INFO: Creating deployment test-cleanup-deployment
W0213 13:45:32.545604      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 02/13/23 13:45:32.546
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:45:32.561: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9500  1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057 11515 1 2023-02-13 13:45:32 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-02-13 13:45:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4a8d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb 13 13:45:32.566: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Feb 13 13:45:32.566: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 13 13:45:32.566: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9500  0aa65a05-f4f5-4c36-84ef-bd9ac2597c86 11519 1 2023-02-13 13:45:27 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057 0xc001e4ac27 0xc001e4ac28}] [] [{e2e.test Update apps/v1 2023-02-13 13:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:45:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-02-13 13:45:32 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001e4ace8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:45:32.573: INFO: Pod "test-cleanup-controller-vh5b4" is available:
&Pod{ObjectMeta:{test-cleanup-controller-vh5b4 test-cleanup-controller- deployment-9500  d8c3c796-eb81-4bb0-9a6d-09110bba3819 11491 0 2023-02-13 13:45:27 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 0aa65a05-f4f5-4c36-84ef-bd9ac2597c86 0xc001e4afb7 0xc001e4afb8}] [] [{kube-controller-manager Update v1 2023-02-13 13:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0aa65a05-f4f5-4c36-84ef-bd9ac2597c86\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9jp6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9jp6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.64,StartTime:2023-02-13 13:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b4aeb17b8200c97e05215372ccd3b09ef764ed5bd5a8815942653093dbe43cdf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:45:32.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9500" for this suite. 02/13/23 13:45:32.58
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":65,"skipped":1161,"failed":0}
------------------------------
• [SLOW TEST] [5.138 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:27.467
    Feb 13 13:45:27.467: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:45:27.47
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:27.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:27.497
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    W0213 13:45:27.514168      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:45:27.521: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Feb 13 13:45:32.526: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 13:45:32.526
    Feb 13 13:45:32.527: INFO: Creating deployment test-cleanup-deployment
    W0213 13:45:32.545604      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 02/13/23 13:45:32.546
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:45:32.561: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9500  1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057 11515 1 2023-02-13 13:45:32 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-02-13 13:45:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4a8d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Feb 13 13:45:32.566: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Feb 13 13:45:32.566: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Feb 13 13:45:32.566: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9500  0aa65a05-f4f5-4c36-84ef-bd9ac2597c86 11519 1 2023-02-13 13:45:27 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057 0xc001e4ac27 0xc001e4ac28}] [] [{e2e.test Update apps/v1 2023-02-13 13:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:45:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-02-13 13:45:32 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"1f85ebd9-c4a3-49d1-9d12-0b4aa0e63057\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001e4ace8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:45:32.573: INFO: Pod "test-cleanup-controller-vh5b4" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-vh5b4 test-cleanup-controller- deployment-9500  d8c3c796-eb81-4bb0-9a6d-09110bba3819 11491 0 2023-02-13 13:45:27 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 0aa65a05-f4f5-4c36-84ef-bd9ac2597c86 0xc001e4afb7 0xc001e4afb8}] [] [{kube-controller-manager Update v1 2023-02-13 13:45:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0aa65a05-f4f5-4c36-84ef-bd9ac2597c86\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:45:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9jp6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9jp6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:45:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.64,StartTime:2023-02-13 13:45:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:45:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b4aeb17b8200c97e05215372ccd3b09ef764ed5bd5a8815942653093dbe43cdf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:45:32.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9500" for this suite. 02/13/23 13:45:32.58
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:32.609
Feb 13 13:45:32.609: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:45:32.61
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:32.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:32.664
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 02/13/23 13:45:32.668
W0213 13:45:32.682855      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:45:32.683: INFO: Waiting up to 5m0s for pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b" in namespace "emptydir-8572" to be "Succeeded or Failed"
Feb 13 13:45:32.688: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.206386ms
Feb 13 13:45:34.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010132349s
Feb 13 13:45:36.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010009397s
STEP: Saw pod success 02/13/23 13:45:36.693
Feb 13 13:45:36.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b" satisfied condition "Succeeded or Failed"
Feb 13 13:45:36.697: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b container test-container: <nil>
STEP: delete the pod 02/13/23 13:45:36.708
Feb 13 13:45:36.727: INFO: Waiting for pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b to disappear
Feb 13 13:45:36.730: INFO: Pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:45:36.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8572" for this suite. 02/13/23 13:45:36.734
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":66,"skipped":1178,"failed":0}
------------------------------
• [4.133 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:32.609
    Feb 13 13:45:32.609: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:45:32.61
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:32.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:32.664
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 02/13/23 13:45:32.668
    W0213 13:45:32.682855      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:45:32.683: INFO: Waiting up to 5m0s for pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b" in namespace "emptydir-8572" to be "Succeeded or Failed"
    Feb 13 13:45:32.688: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.206386ms
    Feb 13 13:45:34.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010132349s
    Feb 13 13:45:36.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010009397s
    STEP: Saw pod success 02/13/23 13:45:36.693
    Feb 13 13:45:36.693: INFO: Pod "pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b" satisfied condition "Succeeded or Failed"
    Feb 13 13:45:36.697: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b container test-container: <nil>
    STEP: delete the pod 02/13/23 13:45:36.708
    Feb 13 13:45:36.727: INFO: Waiting for pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b to disappear
    Feb 13 13:45:36.730: INFO: Pod pod-a4a10ebe-7fb5-44a9-99ed-2b484e84cc8b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:45:36.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8572" for this suite. 02/13/23 13:45:36.734
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:36.753
Feb 13 13:45:36.753: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename tables 02/13/23 13:45:36.755
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:36.777
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:36.781
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Feb 13 13:45:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5821" for this suite. 02/13/23 13:45:36.794
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":67,"skipped":1278,"failed":0}
------------------------------
• [0.046 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:36.753
    Feb 13 13:45:36.753: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename tables 02/13/23 13:45:36.755
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:36.777
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:36.781
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Feb 13 13:45:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-5821" for this suite. 02/13/23 13:45:36.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:36.801
Feb 13 13:45:36.802: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 13:45:36.803
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:36.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:36.838
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 02/13/23 13:45:36.842
W0213 13:45:36.849965      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensure pods equal to paralellism count is attached to the job 02/13/23 13:45:36.85
STEP: patching /status 02/13/23 13:45:38.859
STEP: updating /status 02/13/23 13:45:38.874
STEP: get /status 02/13/23 13:45:38.914
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 13:45:38.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5458" for this suite. 02/13/23 13:45:38.925
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":68,"skipped":1290,"failed":0}
------------------------------
• [2.130 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:36.801
    Feb 13 13:45:36.802: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 13:45:36.803
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:36.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:36.838
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 02/13/23 13:45:36.842
    W0213 13:45:36.849965      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensure pods equal to paralellism count is attached to the job 02/13/23 13:45:36.85
    STEP: patching /status 02/13/23 13:45:38.859
    STEP: updating /status 02/13/23 13:45:38.874
    STEP: get /status 02/13/23 13:45:38.914
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 13:45:38.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5458" for this suite. 02/13/23 13:45:38.925
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:38.935
Feb 13 13:45:38.936: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename certificates 02/13/23 13:45:38.937
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:38.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:38.959
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 02/13/23 13:45:39.49
STEP: getting /apis/certificates.k8s.io 02/13/23 13:45:39.497
STEP: getting /apis/certificates.k8s.io/v1 02/13/23 13:45:39.499
STEP: creating 02/13/23 13:45:39.501
STEP: getting 02/13/23 13:45:39.524
STEP: listing 02/13/23 13:45:39.529
STEP: watching 02/13/23 13:45:39.533
Feb 13 13:45:39.534: INFO: starting watch
STEP: patching 02/13/23 13:45:39.536
STEP: updating 02/13/23 13:45:39.545
Feb 13 13:45:39.551: INFO: waiting for watch events with expected annotations
Feb 13 13:45:39.552: INFO: saw patched and updated annotations
STEP: getting /approval 02/13/23 13:45:39.552
STEP: patching /approval 02/13/23 13:45:39.557
STEP: updating /approval 02/13/23 13:45:39.566
STEP: getting /status 02/13/23 13:45:39.576
STEP: patching /status 02/13/23 13:45:39.581
STEP: updating /status 02/13/23 13:45:39.591
STEP: deleting 02/13/23 13:45:39.601
STEP: deleting a collection 02/13/23 13:45:39.615
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:45:39.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-1679" for this suite. 02/13/23 13:45:39.63
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":69,"skipped":1298,"failed":0}
------------------------------
• [0.701 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:38.935
    Feb 13 13:45:38.936: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename certificates 02/13/23 13:45:38.937
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:38.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:38.959
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 02/13/23 13:45:39.49
    STEP: getting /apis/certificates.k8s.io 02/13/23 13:45:39.497
    STEP: getting /apis/certificates.k8s.io/v1 02/13/23 13:45:39.499
    STEP: creating 02/13/23 13:45:39.501
    STEP: getting 02/13/23 13:45:39.524
    STEP: listing 02/13/23 13:45:39.529
    STEP: watching 02/13/23 13:45:39.533
    Feb 13 13:45:39.534: INFO: starting watch
    STEP: patching 02/13/23 13:45:39.536
    STEP: updating 02/13/23 13:45:39.545
    Feb 13 13:45:39.551: INFO: waiting for watch events with expected annotations
    Feb 13 13:45:39.552: INFO: saw patched and updated annotations
    STEP: getting /approval 02/13/23 13:45:39.552
    STEP: patching /approval 02/13/23 13:45:39.557
    STEP: updating /approval 02/13/23 13:45:39.566
    STEP: getting /status 02/13/23 13:45:39.576
    STEP: patching /status 02/13/23 13:45:39.581
    STEP: updating /status 02/13/23 13:45:39.591
    STEP: deleting 02/13/23 13:45:39.601
    STEP: deleting a collection 02/13/23 13:45:39.615
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:45:39.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-1679" for this suite. 02/13/23 13:45:39.63
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:39.656
Feb 13 13:45:39.656: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:45:39.657
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:39.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:39.677
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 02/13/23 13:45:39.681
W0213 13:45:39.690117      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-main-container", "busybox-sub-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-main-container", "busybox-sub-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:45:39.690: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6" in namespace "emptydir-9348" to be "running"
Feb 13 13:45:39.694: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.244621ms
Feb 13 13:45:41.701: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6": Phase="Running", Reason="", readiness=false. Elapsed: 2.010916915s
Feb 13 13:45:41.701: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6" satisfied condition "running"
STEP: Reading file content from the nginx-container 02/13/23 13:45:41.701
Feb 13 13:45:41.701: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9348 PodName:pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:45:41.701: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:45:41.702: INFO: ExecWithOptions: Clientset creation
Feb 13 13:45:41.703: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-9348/pods/pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Feb 13 13:45:41.885: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:45:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9348" for this suite. 02/13/23 13:45:41.891
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":70,"skipped":1391,"failed":0}
------------------------------
• [2.244 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:39.656
    Feb 13 13:45:39.656: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:45:39.657
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:39.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:39.677
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 02/13/23 13:45:39.681
    W0213 13:45:39.690117      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-main-container", "busybox-sub-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-main-container", "busybox-sub-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:45:39.690: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6" in namespace "emptydir-9348" to be "running"
    Feb 13 13:45:39.694: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.244621ms
    Feb 13 13:45:41.701: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6": Phase="Running", Reason="", readiness=false. Elapsed: 2.010916915s
    Feb 13 13:45:41.701: INFO: Pod "pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6" satisfied condition "running"
    STEP: Reading file content from the nginx-container 02/13/23 13:45:41.701
    Feb 13 13:45:41.701: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9348 PodName:pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:45:41.701: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:45:41.702: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:45:41.703: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-9348/pods/pod-sharedvolume-b22b3211-85f4-4d14-a0c1-041684e53dd6/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Feb 13 13:45:41.885: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:45:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9348" for this suite. 02/13/23 13:45:41.891
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:45:41.903
Feb 13 13:45:41.903: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename taint-single-pod 02/13/23 13:45:41.905
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:41.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:41.933
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Feb 13 13:45:41.937: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 13:46:41.973: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Feb 13 13:46:41.980: INFO: Starting informer...
STEP: Starting pod... 02/13/23 13:46:41.98
W0213 13:46:42.000678      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:46:42.208: INFO: Pod is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
STEP: Trying to apply a taint on the Node 02/13/23 13:46:42.208
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 13:46:42.228
STEP: Waiting short time to make sure Pod is queued for deletion 02/13/23 13:46:42.232
Feb 13 13:46:42.232: INFO: Pod wasn't evicted. Proceeding
Feb 13 13:46:42.232: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 13:46:42.253
STEP: Waiting some time to make sure that toleration time passed. 02/13/23 13:46:42.258
Feb 13 13:47:57.259: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:47:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8714" for this suite. 02/13/23 13:47:57.267
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":71,"skipped":1395,"failed":0}
------------------------------
• [SLOW TEST] [135.374 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:45:41.903
    Feb 13 13:45:41.903: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename taint-single-pod 02/13/23 13:45:41.905
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:45:41.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:45:41.933
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Feb 13 13:45:41.937: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 13:46:41.973: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Feb 13 13:46:41.980: INFO: Starting informer...
    STEP: Starting pod... 02/13/23 13:46:41.98
    W0213 13:46:42.000678      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:46:42.208: INFO: Pod is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
    STEP: Trying to apply a taint on the Node 02/13/23 13:46:42.208
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 13:46:42.228
    STEP: Waiting short time to make sure Pod is queued for deletion 02/13/23 13:46:42.232
    Feb 13 13:46:42.232: INFO: Pod wasn't evicted. Proceeding
    Feb 13 13:46:42.232: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 13:46:42.253
    STEP: Waiting some time to make sure that toleration time passed. 02/13/23 13:46:42.258
    Feb 13 13:47:57.259: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:47:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-8714" for this suite. 02/13/23 13:47:57.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:47:57.283
Feb 13 13:47:57.283: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubelet-test 02/13/23 13:47:57.286
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:47:57.309
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:47:57.314
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
W0213 13:47:57.327253      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Feb 13 13:48:01.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4925" for this suite. 02/13/23 13:48:01.349
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":72,"skipped":1407,"failed":0}
------------------------------
• [4.075 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:47:57.283
    Feb 13 13:47:57.283: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubelet-test 02/13/23 13:47:57.286
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:47:57.309
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:47:57.314
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    W0213 13:47:57.327253      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-false01949019-1a37-4849-bb67-2c5070313868" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Feb 13 13:48:01.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4925" for this suite. 02/13/23 13:48:01.349
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:01.361
Feb 13 13:48:01.361: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename containers 02/13/23 13:48:01.362
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:01.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:01.387
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 02/13/23 13:48:01.391
W0213 13:48:01.400929      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:01.401: INFO: Waiting up to 5m0s for pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955" in namespace "containers-3384" to be "Succeeded or Failed"
Feb 13 13:48:01.405: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039401ms
Feb 13 13:48:03.411: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009590393s
Feb 13 13:48:05.412: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011175833s
STEP: Saw pod success 02/13/23 13:48:05.412
Feb 13 13:48:05.412: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955" satisfied condition "Succeeded or Failed"
Feb 13 13:48:05.419: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:48:05.454
Feb 13 13:48:05.470: INFO: Waiting for pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 to disappear
Feb 13 13:48:05.474: INFO: Pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Feb 13 13:48:05.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3384" for this suite. 02/13/23 13:48:05.481
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":73,"skipped":1417,"failed":0}
------------------------------
• [4.130 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:01.361
    Feb 13 13:48:01.361: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename containers 02/13/23 13:48:01.362
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:01.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:01.387
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 02/13/23 13:48:01.391
    W0213 13:48:01.400929      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:01.401: INFO: Waiting up to 5m0s for pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955" in namespace "containers-3384" to be "Succeeded or Failed"
    Feb 13 13:48:01.405: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039401ms
    Feb 13 13:48:03.411: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009590393s
    Feb 13 13:48:05.412: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011175833s
    STEP: Saw pod success 02/13/23 13:48:05.412
    Feb 13 13:48:05.412: INFO: Pod "client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:05.419: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:48:05.454
    Feb 13 13:48:05.470: INFO: Waiting for pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 to disappear
    Feb 13 13:48:05.474: INFO: Pod client-containers-43ea9f4d-ccc2-4afc-86ca-de9d26a14955 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Feb 13 13:48:05.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3384" for this suite. 02/13/23 13:48:05.481
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:05.496
Feb 13 13:48:05.496: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:48:05.499
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:05.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:05.523
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 02/13/23 13:48:05.528
W0213 13:48:05.539250      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:05.540: INFO: Waiting up to 5m0s for pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5" in namespace "emptydir-7211" to be "Succeeded or Failed"
Feb 13 13:48:05.546: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.268263ms
Feb 13 13:48:07.551: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011441593s
Feb 13 13:48:09.554: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014198159s
STEP: Saw pod success 02/13/23 13:48:09.554
Feb 13 13:48:09.554: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5" satisfied condition "Succeeded or Failed"
Feb 13 13:48:09.560: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 container test-container: <nil>
STEP: delete the pod 02/13/23 13:48:09.575
Feb 13 13:48:09.607: INFO: Waiting for pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 to disappear
Feb 13 13:48:09.612: INFO: Pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:48:09.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7211" for this suite. 02/13/23 13:48:09.617
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":74,"skipped":1417,"failed":0}
------------------------------
• [4.128 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:05.496
    Feb 13 13:48:05.496: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:48:05.499
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:05.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:05.523
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 02/13/23 13:48:05.528
    W0213 13:48:05.539250      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:05.540: INFO: Waiting up to 5m0s for pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5" in namespace "emptydir-7211" to be "Succeeded or Failed"
    Feb 13 13:48:05.546: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.268263ms
    Feb 13 13:48:07.551: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011441593s
    Feb 13 13:48:09.554: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014198159s
    STEP: Saw pod success 02/13/23 13:48:09.554
    Feb 13 13:48:09.554: INFO: Pod "pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:09.560: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 container test-container: <nil>
    STEP: delete the pod 02/13/23 13:48:09.575
    Feb 13 13:48:09.607: INFO: Waiting for pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 to disappear
    Feb 13 13:48:09.612: INFO: Pod pod-8ae8e4c4-c03b-4f32-b9d3-70b965c6e1c5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:48:09.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7211" for this suite. 02/13/23 13:48:09.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:09.63
Feb 13 13:48:09.630: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:48:09.632
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:09.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:09.66
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Feb 13 13:48:09.665: INFO: Creating deployment "test-recreate-deployment"
W0213 13:48:09.671941      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:09.672: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 13 13:48:09.679: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 13 13:48:11.691: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 13 13:48:11.696: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
W0213 13:48:11.711868      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:11.712: INFO: Updating deployment test-recreate-deployment
Feb 13 13:48:11.712: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:48:11.814: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1158  c8c97607-f769-445f-b329-fc5d349411b8 12192 2 2023-02-13 13:48:09 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001ddd2f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-02-13 13:48:11 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-02-13 13:48:11 +0000 UTC,LastTransitionTime:2023-02-13 13:48:09 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 13 13:48:11.818: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1158  6587acc9-5194-41a8-a69b-4ae26664090f 12191 1 2023-02-13 13:48:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment c8c97607-f769-445f-b329-fc5d349411b8 0xc003ca3d00 0xc003ca3d01}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8c97607-f769-445f-b329-fc5d349411b8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca3d98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:48:11.818: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 13 13:48:11.819: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1158  5434b96d-f11d-4c97-85fe-460616b4df85 12179 2 2023-02-13 13:48:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment c8c97607-f769-445f-b329-fc5d349411b8 0xc003ca3be7 0xc003ca3be8}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8c97607-f769-445f-b329-fc5d349411b8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca3c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:48:11.823: INFO: Pod "test-recreate-deployment-9d58999df-gdllg" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-gdllg test-recreate-deployment-9d58999df- deployment-1158  5725ea38-3dda-4217-b5ab-3944048eeb15 12190 0 2023-02-13 13:48:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6587acc9-5194-41a8-a69b-4ae26664090f 0xc0037fbff0 0xc0037fbff1}] [] [{kube-controller-manager Update v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6587acc9-5194-41a8-a69b-4ae26664090f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2pctr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2pctr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:48:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:48:11.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1158" for this suite. 02/13/23 13:48:11.83
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":75,"skipped":1448,"failed":0}
------------------------------
• [2.211 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:09.63
    Feb 13 13:48:09.630: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:48:09.632
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:09.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:09.66
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Feb 13 13:48:09.665: INFO: Creating deployment "test-recreate-deployment"
    W0213 13:48:09.671941      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:09.672: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Feb 13 13:48:09.679: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Feb 13 13:48:11.691: INFO: Waiting deployment "test-recreate-deployment" to complete
    Feb 13 13:48:11.696: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    W0213 13:48:11.711868      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:11.712: INFO: Updating deployment test-recreate-deployment
    Feb 13 13:48:11.712: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:48:11.814: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-1158  c8c97607-f769-445f-b329-fc5d349411b8 12192 2 2023-02-13 13:48:09 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001ddd2f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-02-13 13:48:11 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-02-13 13:48:11 +0000 UTC,LastTransitionTime:2023-02-13 13:48:09 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Feb 13 13:48:11.818: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1158  6587acc9-5194-41a8-a69b-4ae26664090f 12191 1 2023-02-13 13:48:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment c8c97607-f769-445f-b329-fc5d349411b8 0xc003ca3d00 0xc003ca3d01}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8c97607-f769-445f-b329-fc5d349411b8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca3d98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:48:11.818: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Feb 13 13:48:11.819: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1158  5434b96d-f11d-4c97-85fe-460616b4df85 12179 2 2023-02-13 13:48:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment c8c97607-f769-445f-b329-fc5d349411b8 0xc003ca3be7 0xc003ca3be8}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8c97607-f769-445f-b329-fc5d349411b8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca3c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:48:11.823: INFO: Pod "test-recreate-deployment-9d58999df-gdllg" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-gdllg test-recreate-deployment-9d58999df- deployment-1158  5725ea38-3dda-4217-b5ab-3944048eeb15 12190 0 2023-02-13 13:48:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6587acc9-5194-41a8-a69b-4ae26664090f 0xc0037fbff0 0xc0037fbff1}] [] [{kube-controller-manager Update v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6587acc9-5194-41a8-a69b-4ae26664090f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:48:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2pctr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2pctr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:48:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:48:11.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1158" for this suite. 02/13/23 13:48:11.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:11.85
Feb 13 13:48:11.850: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:48:11.852
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:11.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:11.878
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-4414 02/13/23 13:48:11.886
STEP: creating replication controller nodeport-test in namespace services-4414 02/13/23 13:48:11.905
W0213 13:48:11.916233      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nodeport-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nodeport-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nodeport-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nodeport-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 13:48:11.917038      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4414, replica count: 2
I0213 13:48:14.968518      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 13:48:14.968: INFO: Creating new exec pod
W0213 13:48:14.979902      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:14.980: INFO: Waiting up to 5m0s for pod "execpodzvnfg" in namespace "services-4414" to be "running"
Feb 13 13:48:14.986: INFO: Pod "execpodzvnfg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253144ms
Feb 13 13:48:16.992: INFO: Pod "execpodzvnfg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142246s
Feb 13 13:48:16.992: INFO: Pod "execpodzvnfg" satisfied condition "running"
Feb 13 13:48:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Feb 13 13:48:18.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb 13 13:48:18.297: INFO: stdout: "nodeport-test-g7zrd"
Feb 13 13:48:18.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.161.37 80'
Feb 13 13:48:18.570: INFO: stderr: "+ nc -v -t -w 2 10.104.161.37 80\n+ echo hostName\nConnection to 10.104.161.37 80 port [tcp/http] succeeded!\n"
Feb 13 13:48:18.570: INFO: stdout: "nodeport-test-c8zcc"
Feb 13 13:48:18.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 30628'
Feb 13 13:48:18.890: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 30628\nConnection to 192.168.1.12 30628 port [tcp/*] succeeded!\n"
Feb 13 13:48:18.890: INFO: stdout: "nodeport-test-g7zrd"
Feb 13 13:48:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 30628'
Feb 13 13:48:19.145: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 30628\nConnection to 192.168.1.10 30628 port [tcp/*] succeeded!\n"
Feb 13 13:48:19.145: INFO: stdout: "nodeport-test-g7zrd"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:48:19.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4414" for this suite. 02/13/23 13:48:19.152
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":76,"skipped":1468,"failed":0}
------------------------------
• [SLOW TEST] [7.311 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:11.85
    Feb 13 13:48:11.850: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:48:11.852
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:11.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:11.878
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-4414 02/13/23 13:48:11.886
    STEP: creating replication controller nodeport-test in namespace services-4414 02/13/23 13:48:11.905
    W0213 13:48:11.916233      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nodeport-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nodeport-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nodeport-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nodeport-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 13:48:11.917038      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4414, replica count: 2
    I0213 13:48:14.968518      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 13:48:14.968: INFO: Creating new exec pod
    W0213 13:48:14.979902      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:14.980: INFO: Waiting up to 5m0s for pod "execpodzvnfg" in namespace "services-4414" to be "running"
    Feb 13 13:48:14.986: INFO: Pod "execpodzvnfg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253144ms
    Feb 13 13:48:16.992: INFO: Pod "execpodzvnfg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142246s
    Feb 13 13:48:16.992: INFO: Pod "execpodzvnfg" satisfied condition "running"
    Feb 13 13:48:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Feb 13 13:48:18.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Feb 13 13:48:18.297: INFO: stdout: "nodeport-test-g7zrd"
    Feb 13 13:48:18.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.161.37 80'
    Feb 13 13:48:18.570: INFO: stderr: "+ nc -v -t -w 2 10.104.161.37 80\n+ echo hostName\nConnection to 10.104.161.37 80 port [tcp/http] succeeded!\n"
    Feb 13 13:48:18.570: INFO: stdout: "nodeport-test-c8zcc"
    Feb 13 13:48:18.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 30628'
    Feb 13 13:48:18.890: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 30628\nConnection to 192.168.1.12 30628 port [tcp/*] succeeded!\n"
    Feb 13 13:48:18.890: INFO: stdout: "nodeport-test-g7zrd"
    Feb 13 13:48:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4414 exec execpodzvnfg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 30628'
    Feb 13 13:48:19.145: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 30628\nConnection to 192.168.1.10 30628 port [tcp/*] succeeded!\n"
    Feb 13 13:48:19.145: INFO: stdout: "nodeport-test-g7zrd"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:48:19.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4414" for this suite. 02/13/23 13:48:19.152
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:19.162
Feb 13 13:48:19.162: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename proxy 02/13/23 13:48:19.166
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:19.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:19.191
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Feb 13 13:48:19.195: INFO: Creating pod...
W0213 13:48:19.205305      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:19.205: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3032" to be "running"
Feb 13 13:48:19.214: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.718341ms
Feb 13 13:48:21.219: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.012390213s
Feb 13 13:48:21.220: INFO: Pod "agnhost" satisfied condition "running"
Feb 13 13:48:21.220: INFO: Creating service...
Feb 13 13:48:21.240: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/DELETE
Feb 13 13:48:21.259: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Feb 13 13:48:21.260: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/GET
Feb 13 13:48:21.267: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Feb 13 13:48:21.267: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/HEAD
Feb 13 13:48:21.274: INFO: http.Client request:HEAD | StatusCode:200
Feb 13 13:48:21.274: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/OPTIONS
Feb 13 13:48:21.278: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Feb 13 13:48:21.278: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/PATCH
Feb 13 13:48:21.284: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Feb 13 13:48:21.284: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/POST
Feb 13 13:48:21.291: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Feb 13 13:48:21.291: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/PUT
Feb 13 13:48:21.296: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Feb 13 13:48:21.296: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/DELETE
Feb 13 13:48:21.301: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Feb 13 13:48:21.301: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/GET
Feb 13 13:48:21.306: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Feb 13 13:48:21.306: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/HEAD
Feb 13 13:48:21.312: INFO: http.Client request:HEAD | StatusCode:200
Feb 13 13:48:21.312: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/OPTIONS
Feb 13 13:48:21.319: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Feb 13 13:48:21.319: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/PATCH
Feb 13 13:48:21.325: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Feb 13 13:48:21.325: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/POST
Feb 13 13:48:21.331: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Feb 13 13:48:21.332: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/PUT
Feb 13 13:48:21.337: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Feb 13 13:48:21.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3032" for this suite. 02/13/23 13:48:21.342
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":77,"skipped":1468,"failed":0}
------------------------------
• [2.186 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:19.162
    Feb 13 13:48:19.162: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename proxy 02/13/23 13:48:19.166
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:19.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:19.191
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Feb 13 13:48:19.195: INFO: Creating pod...
    W0213 13:48:19.205305      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:19.205: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3032" to be "running"
    Feb 13 13:48:19.214: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.718341ms
    Feb 13 13:48:21.219: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.012390213s
    Feb 13 13:48:21.220: INFO: Pod "agnhost" satisfied condition "running"
    Feb 13 13:48:21.220: INFO: Creating service...
    Feb 13 13:48:21.240: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/DELETE
    Feb 13 13:48:21.259: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Feb 13 13:48:21.260: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/GET
    Feb 13 13:48:21.267: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Feb 13 13:48:21.267: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/HEAD
    Feb 13 13:48:21.274: INFO: http.Client request:HEAD | StatusCode:200
    Feb 13 13:48:21.274: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/OPTIONS
    Feb 13 13:48:21.278: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Feb 13 13:48:21.278: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/PATCH
    Feb 13 13:48:21.284: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Feb 13 13:48:21.284: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/POST
    Feb 13 13:48:21.291: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Feb 13 13:48:21.291: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/pods/agnhost/proxy/some/path/with/PUT
    Feb 13 13:48:21.296: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Feb 13 13:48:21.296: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/DELETE
    Feb 13 13:48:21.301: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Feb 13 13:48:21.301: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/GET
    Feb 13 13:48:21.306: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Feb 13 13:48:21.306: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/HEAD
    Feb 13 13:48:21.312: INFO: http.Client request:HEAD | StatusCode:200
    Feb 13 13:48:21.312: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/OPTIONS
    Feb 13 13:48:21.319: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Feb 13 13:48:21.319: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/PATCH
    Feb 13 13:48:21.325: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Feb 13 13:48:21.325: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/POST
    Feb 13 13:48:21.331: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Feb 13 13:48:21.332: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-3032/services/test-service/proxy/some/path/with/PUT
    Feb 13 13:48:21.337: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Feb 13 13:48:21.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3032" for this suite. 02/13/23 13:48:21.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:21.358
Feb 13 13:48:21.358: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 13:48:21.358
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.38
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 02/13/23 13:48:21.383
STEP: Getting a ResourceQuota 02/13/23 13:48:21.389
STEP: Updating a ResourceQuota 02/13/23 13:48:21.393
STEP: Verifying a ResourceQuota was modified 02/13/23 13:48:21.399
STEP: Deleting a ResourceQuota 02/13/23 13:48:21.404
STEP: Verifying the deleted ResourceQuota 02/13/23 13:48:21.411
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 13:48:21.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3936" for this suite. 02/13/23 13:48:21.422
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":78,"skipped":1509,"failed":0}
------------------------------
• [0.070 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:21.358
    Feb 13 13:48:21.358: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 13:48:21.358
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.38
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 02/13/23 13:48:21.383
    STEP: Getting a ResourceQuota 02/13/23 13:48:21.389
    STEP: Updating a ResourceQuota 02/13/23 13:48:21.393
    STEP: Verifying a ResourceQuota was modified 02/13/23 13:48:21.399
    STEP: Deleting a ResourceQuota 02/13/23 13:48:21.404
    STEP: Verifying the deleted ResourceQuota 02/13/23 13:48:21.411
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 13:48:21.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3936" for this suite. 02/13/23 13:48:21.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:21.434
Feb 13 13:48:21.434: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 13:48:21.436
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.458
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 02/13/23 13:48:21.461
Feb 13 13:48:21.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-6466 api-versions'
Feb 13 13:48:21.559: INFO: stderr: ""
Feb 13 13:48:21.559: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 13:48:21.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6466" for this suite. 02/13/23 13:48:21.567
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":79,"skipped":1520,"failed":0}
------------------------------
• [0.141 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:21.434
    Feb 13 13:48:21.434: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 13:48:21.436
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.458
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 02/13/23 13:48:21.461
    Feb 13 13:48:21.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-6466 api-versions'
    Feb 13 13:48:21.559: INFO: stderr: ""
    Feb 13 13:48:21.559: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 13:48:21.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6466" for this suite. 02/13/23 13:48:21.567
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:21.577
Feb 13 13:48:21.577: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 13:48:21.578
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.606
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Feb 13 13:48:21.610: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: creating the pod 02/13/23 13:48:21.612
STEP: submitting the pod to kubernetes 02/13/23 13:48:21.613
Feb 13 13:48:21.622: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae" in namespace "pods-5248" to be "running and ready"
Feb 13 13:48:21.631: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae": Phase="Pending", Reason="", readiness=false. Elapsed: 8.53558ms
Feb 13 13:48:21.631: INFO: The phase of Pod pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:48:23.637: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae": Phase="Running", Reason="", readiness=true. Elapsed: 2.01439828s
Feb 13 13:48:23.637: INFO: The phase of Pod pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae is Running (Ready = true)
Feb 13 13:48:23.637: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 13:48:23.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5248" for this suite. 02/13/23 13:48:23.665
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":80,"skipped":1533,"failed":0}
------------------------------
• [2.096 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:21.577
    Feb 13 13:48:21.577: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 13:48:21.578
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:21.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:21.606
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Feb 13 13:48:21.610: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: creating the pod 02/13/23 13:48:21.612
    STEP: submitting the pod to kubernetes 02/13/23 13:48:21.613
    Feb 13 13:48:21.622: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae" in namespace "pods-5248" to be "running and ready"
    Feb 13 13:48:21.631: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae": Phase="Pending", Reason="", readiness=false. Elapsed: 8.53558ms
    Feb 13 13:48:21.631: INFO: The phase of Pod pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:48:23.637: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae": Phase="Running", Reason="", readiness=true. Elapsed: 2.01439828s
    Feb 13 13:48:23.637: INFO: The phase of Pod pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae is Running (Ready = true)
    Feb 13 13:48:23.637: INFO: Pod "pod-logs-websocket-04516e66-4dc4-4ccc-bade-29426983aaae" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 13:48:23.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5248" for this suite. 02/13/23 13:48:23.665
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:23.677
Feb 13 13:48:23.677: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 13:48:23.678
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:23.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:23.702
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-ba70f8d8-baf6-41f0-b4f9-8b7cea9c7b02 02/13/23 13:48:23.706
STEP: Creating a pod to test consume secrets 02/13/23 13:48:23.713
W0213 13:48:23.724311      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:23.724: INFO: Waiting up to 5m0s for pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe" in namespace "secrets-9473" to be "Succeeded or Failed"
Feb 13 13:48:23.728: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.274837ms
Feb 13 13:48:25.736: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011598437s
Feb 13 13:48:27.736: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011569644s
STEP: Saw pod success 02/13/23 13:48:27.736
Feb 13 13:48:27.737: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe" satisfied condition "Succeeded or Failed"
Feb 13 13:48:27.743: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:48:27.774
Feb 13 13:48:27.792: INFO: Waiting for pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe to disappear
Feb 13 13:48:27.796: INFO: Pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 13:48:27.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9473" for this suite. 02/13/23 13:48:27.802
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":81,"skipped":1535,"failed":0}
------------------------------
• [4.135 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:23.677
    Feb 13 13:48:23.677: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 13:48:23.678
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:23.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:23.702
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-ba70f8d8-baf6-41f0-b4f9-8b7cea9c7b02 02/13/23 13:48:23.706
    STEP: Creating a pod to test consume secrets 02/13/23 13:48:23.713
    W0213 13:48:23.724311      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:23.724: INFO: Waiting up to 5m0s for pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe" in namespace "secrets-9473" to be "Succeeded or Failed"
    Feb 13 13:48:23.728: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.274837ms
    Feb 13 13:48:25.736: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011598437s
    Feb 13 13:48:27.736: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011569644s
    STEP: Saw pod success 02/13/23 13:48:27.736
    Feb 13 13:48:27.737: INFO: Pod "pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:27.743: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:48:27.774
    Feb 13 13:48:27.792: INFO: Waiting for pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe to disappear
    Feb 13 13:48:27.796: INFO: Pod pod-secrets-b0352fd7-3124-4a9b-89de-210a395603fe no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 13:48:27.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9473" for this suite. 02/13/23 13:48:27.802
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:27.814
Feb 13 13:48:27.814: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:48:27.818
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:27.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:27.842
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 02/13/23 13:48:27.846
Feb 13 13:48:27.846: INFO: Creating e2e-svc-a-zwv8m
Feb 13 13:48:27.874: INFO: Creating e2e-svc-b-7g857
Feb 13 13:48:27.893: INFO: Creating e2e-svc-c-xjfvx
STEP: deleting service collection 02/13/23 13:48:27.913
Feb 13 13:48:27.953: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:48:27.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9555" for this suite. 02/13/23 13:48:27.959
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":82,"skipped":1547,"failed":0}
------------------------------
• [0.152 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:27.814
    Feb 13 13:48:27.814: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:48:27.818
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:27.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:27.842
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 02/13/23 13:48:27.846
    Feb 13 13:48:27.846: INFO: Creating e2e-svc-a-zwv8m
    Feb 13 13:48:27.874: INFO: Creating e2e-svc-b-7g857
    Feb 13 13:48:27.893: INFO: Creating e2e-svc-c-xjfvx
    STEP: deleting service collection 02/13/23 13:48:27.913
    Feb 13 13:48:27.953: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:48:27.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9555" for this suite. 02/13/23 13:48:27.959
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:27.974
Feb 13 13:48:27.974: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:48:27.976
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:27.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:28.001
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:48:28.008
W0213 13:48:28.019288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:28.020: INFO: Waiting up to 5m0s for pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325" in namespace "projected-3596" to be "Succeeded or Failed"
Feb 13 13:48:28.028: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017062ms
Feb 13 13:48:30.036: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016184071s
Feb 13 13:48:32.035: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015748728s
STEP: Saw pod success 02/13/23 13:48:32.036
Feb 13 13:48:32.037: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325" satisfied condition "Succeeded or Failed"
Feb 13 13:48:32.042: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 container client-container: <nil>
STEP: delete the pod 02/13/23 13:48:32.056
Feb 13 13:48:32.071: INFO: Waiting for pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 to disappear
Feb 13 13:48:32.074: INFO: Pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 13:48:32.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3596" for this suite. 02/13/23 13:48:32.081
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":83,"skipped":1574,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:27.974
    Feb 13 13:48:27.974: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:48:27.976
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:27.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:28.001
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:48:28.008
    W0213 13:48:28.019288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:28.020: INFO: Waiting up to 5m0s for pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325" in namespace "projected-3596" to be "Succeeded or Failed"
    Feb 13 13:48:28.028: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017062ms
    Feb 13 13:48:30.036: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016184071s
    Feb 13 13:48:32.035: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015748728s
    STEP: Saw pod success 02/13/23 13:48:32.036
    Feb 13 13:48:32.037: INFO: Pod "downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:32.042: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:48:32.056
    Feb 13 13:48:32.071: INFO: Waiting for pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 to disappear
    Feb 13 13:48:32.074: INFO: Pod downwardapi-volume-061afb25-ecda-4dc6-956b-5f24825d5325 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 13:48:32.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3596" for this suite. 02/13/23 13:48:32.081
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:32.098
Feb 13 13:48:32.099: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename watch 02/13/23 13:48:32.101
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.128
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 02/13/23 13:48:32.134
STEP: modifying the configmap once 02/13/23 13:48:32.143
STEP: modifying the configmap a second time 02/13/23 13:48:32.152
STEP: deleting the configmap 02/13/23 13:48:32.163
STEP: creating a watch on configmaps from the resource version returned by the first update 02/13/23 13:48:32.169
STEP: Expecting to observe notifications for all changes to the configmap after the first update 02/13/23 13:48:32.172
Feb 13 13:48:32.172: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-65  ec6228f3-9554-4e80-8e03-714db2defe19 12471 0 2023-02-13 13:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-02-13 13:48:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 13:48:32.173: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-65  ec6228f3-9554-4e80-8e03-714db2defe19 12472 0 2023-02-13 13:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-02-13 13:48:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Feb 13 13:48:32.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-65" for this suite. 02/13/23 13:48:32.179
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":84,"skipped":1602,"failed":0}
------------------------------
• [0.090 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:32.098
    Feb 13 13:48:32.099: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename watch 02/13/23 13:48:32.101
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.128
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 02/13/23 13:48:32.134
    STEP: modifying the configmap once 02/13/23 13:48:32.143
    STEP: modifying the configmap a second time 02/13/23 13:48:32.152
    STEP: deleting the configmap 02/13/23 13:48:32.163
    STEP: creating a watch on configmaps from the resource version returned by the first update 02/13/23 13:48:32.169
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 02/13/23 13:48:32.172
    Feb 13 13:48:32.172: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-65  ec6228f3-9554-4e80-8e03-714db2defe19 12471 0 2023-02-13 13:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-02-13 13:48:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 13:48:32.173: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-65  ec6228f3-9554-4e80-8e03-714db2defe19 12472 0 2023-02-13 13:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-02-13 13:48:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Feb 13 13:48:32.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-65" for this suite. 02/13/23 13:48:32.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:32.192
Feb 13 13:48:32.193: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 13:48:32.195
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.217
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 02/13/23 13:48:32.222
STEP: listing secrets in all namespaces to ensure that there are more than zero 02/13/23 13:48:32.228
STEP: patching the secret 02/13/23 13:48:32.234
STEP: deleting the secret using a LabelSelector 02/13/23 13:48:32.248
STEP: listing secrets in all namespaces, searching for label name and value in patch 02/13/23 13:48:32.256
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Feb 13 13:48:32.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2186" for this suite. 02/13/23 13:48:32.266
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":85,"skipped":1615,"failed":0}
------------------------------
• [0.080 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:32.192
    Feb 13 13:48:32.193: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 13:48:32.195
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.217
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 02/13/23 13:48:32.222
    STEP: listing secrets in all namespaces to ensure that there are more than zero 02/13/23 13:48:32.228
    STEP: patching the secret 02/13/23 13:48:32.234
    STEP: deleting the secret using a LabelSelector 02/13/23 13:48:32.248
    STEP: listing secrets in all namespaces, searching for label name and value in patch 02/13/23 13:48:32.256
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 13:48:32.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2186" for this suite. 02/13/23 13:48:32.266
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:32.278
Feb 13 13:48:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 13:48:32.281
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.348
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.357
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 02/13/23 13:48:32.392
W0213 13:48:32.399849      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:48:32.4
Feb 13 13:48:32.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:48:32.408: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:48:33.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 13:48:33.424: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 13:48:34.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 13:48:34.427: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 02/13/23 13:48:34.433
Feb 13 13:48:34.439: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 02/13/23 13:48:34.439
Feb 13 13:48:34.452: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 02/13/23 13:48:34.452
Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: ADDED
Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.456: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.456: INFO: Found daemon set daemon-set in namespace daemonsets-4455 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Feb 13 13:48:34.456: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 02/13/23 13:48:34.456
STEP: watching for the daemon set status to be patched 02/13/23 13:48:34.465
Feb 13 13:48:34.467: INFO: Observed &DaemonSet event: ADDED
Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.469: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.469: INFO: Observed daemon set daemon-set in namespace daemonsets-4455 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Feb 13 13:48:34.469: INFO: Observed &DaemonSet event: MODIFIED
Feb 13 13:48:34.469: INFO: Found daemon set daemon-set in namespace daemonsets-4455 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Feb 13 13:48:34.469: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 13:48:34.472
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4455, will wait for the garbage collector to delete the pods 02/13/23 13:48:34.472
Feb 13 13:48:34.537: INFO: Deleting DaemonSet.extensions daemon-set took: 12.028924ms
Feb 13 13:48:34.638: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.982374ms
Feb 13 13:48:36.545: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 13:48:36.545: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 13:48:36.552: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12562"},"items":null}

Feb 13 13:48:36.558: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12562"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:48:36.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4455" for this suite. 02/13/23 13:48:36.58
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":86,"skipped":1615,"failed":0}
------------------------------
• [4.308 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:32.278
    Feb 13 13:48:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 13:48:32.281
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:32.348
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:32.357
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 02/13/23 13:48:32.392
    W0213 13:48:32.399849      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 13:48:32.4
    Feb 13 13:48:32.408: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:48:32.408: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:48:33.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 13:48:33.424: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 13:48:34.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 13:48:34.427: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 02/13/23 13:48:34.433
    Feb 13 13:48:34.439: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 02/13/23 13:48:34.439
    Feb 13 13:48:34.452: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 02/13/23 13:48:34.452
    Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: ADDED
    Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.455: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.456: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.456: INFO: Found daemon set daemon-set in namespace daemonsets-4455 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Feb 13 13:48:34.456: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 02/13/23 13:48:34.456
    STEP: watching for the daemon set status to be patched 02/13/23 13:48:34.465
    Feb 13 13:48:34.467: INFO: Observed &DaemonSet event: ADDED
    Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.468: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.469: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.469: INFO: Observed daemon set daemon-set in namespace daemonsets-4455 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Feb 13 13:48:34.469: INFO: Observed &DaemonSet event: MODIFIED
    Feb 13 13:48:34.469: INFO: Found daemon set daemon-set in namespace daemonsets-4455 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Feb 13 13:48:34.469: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 13:48:34.472
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4455, will wait for the garbage collector to delete the pods 02/13/23 13:48:34.472
    Feb 13 13:48:34.537: INFO: Deleting DaemonSet.extensions daemon-set took: 12.028924ms
    Feb 13 13:48:34.638: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.982374ms
    Feb 13 13:48:36.545: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 13:48:36.545: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 13:48:36.552: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12562"},"items":null}

    Feb 13 13:48:36.558: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12562"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:48:36.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4455" for this suite. 02/13/23 13:48:36.58
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:36.592
Feb 13 13:48:36.593: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:48:36.594
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:36.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:36.612
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:48:36.616
W0213 13:48:36.625121      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:36.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3" in namespace "projected-4453" to be "Succeeded or Failed"
Feb 13 13:48:36.636: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.911979ms
Feb 13 13:48:38.643: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017490086s
Feb 13 13:48:40.649: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024363346s
STEP: Saw pod success 02/13/23 13:48:40.65
Feb 13 13:48:40.651: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3" satisfied condition "Succeeded or Failed"
Feb 13 13:48:40.658: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 container client-container: <nil>
STEP: delete the pod 02/13/23 13:48:40.676
Feb 13 13:48:40.694: INFO: Waiting for pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 to disappear
Feb 13 13:48:40.698: INFO: Pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 13:48:40.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4453" for this suite. 02/13/23 13:48:40.704
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":87,"skipped":1625,"failed":0}
------------------------------
• [4.119 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:36.592
    Feb 13 13:48:36.593: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:48:36.594
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:36.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:36.612
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:48:36.616
    W0213 13:48:36.625121      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:36.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3" in namespace "projected-4453" to be "Succeeded or Failed"
    Feb 13 13:48:36.636: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.911979ms
    Feb 13 13:48:38.643: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017490086s
    Feb 13 13:48:40.649: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024363346s
    STEP: Saw pod success 02/13/23 13:48:40.65
    Feb 13 13:48:40.651: INFO: Pod "downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:40.658: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:48:40.676
    Feb 13 13:48:40.694: INFO: Waiting for pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 to disappear
    Feb 13 13:48:40.698: INFO: Pod downwardapi-volume-46801818-bdab-446f-9349-91e651a2e7d3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 13:48:40.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4453" for this suite. 02/13/23 13:48:40.704
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:40.716
Feb 13 13:48:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubelet-test 02/13/23 13:48:40.719
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:40.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:40.745
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
W0213 13:48:40.758762      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:40.759: INFO: Waiting up to 5m0s for pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" in namespace "kubelet-test-4804" to be "running and ready"
Feb 13 13:48:40.768: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807724ms
Feb 13 13:48:40.768: INFO: The phase of Pod busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:48:42.775: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71": Phase="Running", Reason="", readiness=true. Elapsed: 2.015945557s
Feb 13 13:48:42.775: INFO: The phase of Pod busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71 is Running (Ready = true)
Feb 13 13:48:42.775: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Feb 13 13:48:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4804" for this suite. 02/13/23 13:48:42.796
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":88,"skipped":1626,"failed":0}
------------------------------
• [2.086 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:40.716
    Feb 13 13:48:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubelet-test 02/13/23 13:48:40.719
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:40.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:40.745
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    W0213 13:48:40.758762      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:40.759: INFO: Waiting up to 5m0s for pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" in namespace "kubelet-test-4804" to be "running and ready"
    Feb 13 13:48:40.768: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807724ms
    Feb 13 13:48:40.768: INFO: The phase of Pod busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:48:42.775: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71": Phase="Running", Reason="", readiness=true. Elapsed: 2.015945557s
    Feb 13 13:48:42.775: INFO: The phase of Pod busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71 is Running (Ready = true)
    Feb 13 13:48:42.775: INFO: Pod "busybox-scheduling-219876ae-9f06-449d-8d32-0593e411af71" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Feb 13 13:48:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4804" for this suite. 02/13/23 13:48:42.796
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:42.804
Feb 13 13:48:42.804: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 13:48:42.805
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:42.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:42.826
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
W0213 13:48:42.841349      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:42.846: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 13 13:48:47.850: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 13:48:47.85
STEP: Scaling up "test-rs" replicaset  02/13/23 13:48:47.85
W0213 13:48:47.861124      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:47.861: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 02/13/23 13:48:47.861
W0213 13:48:47.870039      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
W0213 13:48:47.870091      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-rs", "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-rs", "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-rs", "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-rs", "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:47.872: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
Feb 13 13:48:47.890: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
Feb 13 13:48:47.905: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
Feb 13 13:48:47.930: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
Feb 13 13:48:49.148: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 2, AvailableReplicas 2
Feb 13 13:48:49.532: INFO: observed Replicaset test-rs in namespace replicaset-6797 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 13:48:49.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6797" for this suite. 02/13/23 13:48:49.537
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":89,"skipped":1628,"failed":0}
------------------------------
• [SLOW TEST] [6.741 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:42.804
    Feb 13 13:48:42.804: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 13:48:42.805
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:42.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:42.826
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    W0213 13:48:42.841349      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:42.846: INFO: Pod name sample-pod: Found 0 pods out of 1
    Feb 13 13:48:47.850: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 13:48:47.85
    STEP: Scaling up "test-rs" replicaset  02/13/23 13:48:47.85
    W0213 13:48:47.861124      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:47.861: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 02/13/23 13:48:47.861
    W0213 13:48:47.870039      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    W0213 13:48:47.870091      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-rs", "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-rs", "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-rs", "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-rs", "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:47.872: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
    Feb 13 13:48:47.890: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
    Feb 13 13:48:47.905: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
    Feb 13 13:48:47.930: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 1, AvailableReplicas 1
    Feb 13 13:48:49.148: INFO: observed ReplicaSet test-rs in namespace replicaset-6797 with ReadyReplicas 2, AvailableReplicas 2
    Feb 13 13:48:49.532: INFO: observed Replicaset test-rs in namespace replicaset-6797 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 13:48:49.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6797" for this suite. 02/13/23 13:48:49.537
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:49.548
Feb 13 13:48:49.548: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context 02/13/23 13:48:49.549
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:49.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:49.581
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 02/13/23 13:48:49.584
W0213 13:48:49.592138      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:49.592: INFO: Waiting up to 5m0s for pod "security-context-564353ca-d42f-4836-a05d-891918b9d718" in namespace "security-context-6605" to be "Succeeded or Failed"
Feb 13 13:48:49.595: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Pending", Reason="", readiness=false. Elapsed: 3.093977ms
Feb 13 13:48:51.599: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007326985s
Feb 13 13:48:53.602: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010031867s
STEP: Saw pod success 02/13/23 13:48:53.602
Feb 13 13:48:53.603: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718" satisfied condition "Succeeded or Failed"
Feb 13 13:48:53.610: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod security-context-564353ca-d42f-4836-a05d-891918b9d718 container test-container: <nil>
STEP: delete the pod 02/13/23 13:48:53.625
Feb 13 13:48:53.642: INFO: Waiting for pod security-context-564353ca-d42f-4836-a05d-891918b9d718 to disappear
Feb 13 13:48:53.646: INFO: Pod security-context-564353ca-d42f-4836-a05d-891918b9d718 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 13:48:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-6605" for this suite. 02/13/23 13:48:53.651
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":90,"skipped":1628,"failed":0}
------------------------------
• [4.110 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:49.548
    Feb 13 13:48:49.548: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context 02/13/23 13:48:49.549
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:49.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:49.581
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 02/13/23 13:48:49.584
    W0213 13:48:49.592138      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:49.592: INFO: Waiting up to 5m0s for pod "security-context-564353ca-d42f-4836-a05d-891918b9d718" in namespace "security-context-6605" to be "Succeeded or Failed"
    Feb 13 13:48:49.595: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Pending", Reason="", readiness=false. Elapsed: 3.093977ms
    Feb 13 13:48:51.599: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007326985s
    Feb 13 13:48:53.602: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010031867s
    STEP: Saw pod success 02/13/23 13:48:53.602
    Feb 13 13:48:53.603: INFO: Pod "security-context-564353ca-d42f-4836-a05d-891918b9d718" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:53.610: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod security-context-564353ca-d42f-4836-a05d-891918b9d718 container test-container: <nil>
    STEP: delete the pod 02/13/23 13:48:53.625
    Feb 13 13:48:53.642: INFO: Waiting for pod security-context-564353ca-d42f-4836-a05d-891918b9d718 to disappear
    Feb 13 13:48:53.646: INFO: Pod security-context-564353ca-d42f-4836-a05d-891918b9d718 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 13:48:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-6605" for this suite. 02/13/23 13:48:53.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:53.67
Feb 13 13:48:53.670: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:48:53.672
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:53.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:53.698
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 02/13/23 13:48:53.703
W0213 13:48:53.711882      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:53.712: INFO: Waiting up to 5m0s for pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c" in namespace "emptydir-4018" to be "Succeeded or Failed"
Feb 13 13:48:53.715: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.041505ms
Feb 13 13:48:55.724: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Running", Reason="", readiness=false. Elapsed: 2.012234958s
Feb 13 13:48:57.721: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009270255s
STEP: Saw pod success 02/13/23 13:48:57.721
Feb 13 13:48:57.722: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c" satisfied condition "Succeeded or Failed"
Feb 13 13:48:57.728: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c container test-container: <nil>
STEP: delete the pod 02/13/23 13:48:57.745
Feb 13 13:48:57.764: INFO: Waiting for pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c to disappear
Feb 13 13:48:57.768: INFO: Pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:48:57.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4018" for this suite. 02/13/23 13:48:57.773
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":91,"skipped":1658,"failed":0}
------------------------------
• [4.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:53.67
    Feb 13 13:48:53.670: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:48:53.672
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:53.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:53.698
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 02/13/23 13:48:53.703
    W0213 13:48:53.711882      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:53.712: INFO: Waiting up to 5m0s for pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c" in namespace "emptydir-4018" to be "Succeeded or Failed"
    Feb 13 13:48:53.715: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.041505ms
    Feb 13 13:48:55.724: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Running", Reason="", readiness=false. Elapsed: 2.012234958s
    Feb 13 13:48:57.721: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009270255s
    STEP: Saw pod success 02/13/23 13:48:57.721
    Feb 13 13:48:57.722: INFO: Pod "pod-097b9a12-9476-4937-8cfe-2f4129c5577c" satisfied condition "Succeeded or Failed"
    Feb 13 13:48:57.728: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c container test-container: <nil>
    STEP: delete the pod 02/13/23 13:48:57.745
    Feb 13 13:48:57.764: INFO: Waiting for pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c to disappear
    Feb 13 13:48:57.768: INFO: Pod pod-097b9a12-9476-4937-8cfe-2f4129c5577c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:48:57.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4018" for this suite. 02/13/23 13:48:57.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:48:57.786
Feb 13 13:48:57.786: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:48:57.787
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:57.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:57.814
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Feb 13 13:48:57.817: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
W0213 13:48:57.824735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:57.832: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 13:48:57.832
Feb 13 13:48:57.833: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-vd58b" in namespace "deployment-6807" to be "running"
Feb 13 13:48:57.840: INFO: Pod "test-rolling-update-controller-vd58b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.615131ms
Feb 13 13:48:59.849: INFO: Pod "test-rolling-update-controller-vd58b": Phase="Running", Reason="", readiness=true. Elapsed: 2.0168707s
Feb 13 13:48:59.850: INFO: Pod "test-rolling-update-controller-vd58b" satisfied condition "running"
Feb 13 13:48:59.850: INFO: Creating deployment "test-rolling-update-deployment"
W0213 13:48:59.861520      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:48:59.861: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 13 13:48:59.874: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 13 13:49:01.885: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 13 13:49:01.889: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:49:01.900: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6807  997ce6fc-c0b7-4a2a-b192-51044e6728ec 12853 1 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4a5b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 13:48:59 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-02-13 13:49:01 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 13:49:01.905: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-6807  09f41f7f-5458-4b47-813e-6557348ba810 12844 1 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 997ce6fc-c0b7-4a2a-b192-51044e6728ec 0xc001e4aab7 0xc001e4aab8}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"997ce6fc-c0b7-4a2a-b192-51044e6728ec\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4ab68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:49:01.905: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 13 13:49:01.905: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6807  5cfc6a25-cbb1-4dd6-af39-3cd143a21175 12852 2 2023-02-13 13:48:57 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 997ce6fc-c0b7-4a2a-b192-51044e6728ec 0xc001e4a987 0xc001e4a988}] [] [{e2e.test Update apps/v1 2023-02-13 13:48:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"997ce6fc-c0b7-4a2a-b192-51044e6728ec\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001e4aa48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:49:01.909: INFO: Pod "test-rolling-update-deployment-78f575d8ff-kq78z" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-kq78z test-rolling-update-deployment-78f575d8ff- deployment-6807  ed25bef2-c827-49eb-acaa-bc831a9796a3 12843 0 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 09f41f7f-5458-4b47-813e-6557348ba810 0xc001e4afd7 0xc001e4afd8}] [] [{kube-controller-manager Update v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"09f41f7f-5458-4b47-813e-6557348ba810\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47nkg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47nkg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.115,StartTime:2023-02-13 13:48:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:49:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca003494d14c30d4ed6b043fd2431f11acc385eb7b052ed329b53b9fb9b1d041,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:49:01.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6807" for this suite. 02/13/23 13:49:01.916
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":92,"skipped":1667,"failed":0}
------------------------------
• [4.140 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:48:57.786
    Feb 13 13:48:57.786: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:48:57.787
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:48:57.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:48:57.814
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Feb 13 13:48:57.817: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    W0213 13:48:57.824735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:57.832: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 13:48:57.832
    Feb 13 13:48:57.833: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-vd58b" in namespace "deployment-6807" to be "running"
    Feb 13 13:48:57.840: INFO: Pod "test-rolling-update-controller-vd58b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.615131ms
    Feb 13 13:48:59.849: INFO: Pod "test-rolling-update-controller-vd58b": Phase="Running", Reason="", readiness=true. Elapsed: 2.0168707s
    Feb 13 13:48:59.850: INFO: Pod "test-rolling-update-controller-vd58b" satisfied condition "running"
    Feb 13 13:48:59.850: INFO: Creating deployment "test-rolling-update-deployment"
    W0213 13:48:59.861520      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:48:59.861: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Feb 13 13:48:59.874: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Feb 13 13:49:01.885: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Feb 13 13:49:01.889: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:49:01.900: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6807  997ce6fc-c0b7-4a2a-b192-51044e6728ec 12853 1 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4a5b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 13:48:59 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-02-13 13:49:01 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Feb 13 13:49:01.905: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-6807  09f41f7f-5458-4b47-813e-6557348ba810 12844 1 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 997ce6fc-c0b7-4a2a-b192-51044e6728ec 0xc001e4aab7 0xc001e4aab8}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"997ce6fc-c0b7-4a2a-b192-51044e6728ec\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4ab68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:49:01.905: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Feb 13 13:49:01.905: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6807  5cfc6a25-cbb1-4dd6-af39-3cd143a21175 12852 2 2023-02-13 13:48:57 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 997ce6fc-c0b7-4a2a-b192-51044e6728ec 0xc001e4a987 0xc001e4a988}] [] [{e2e.test Update apps/v1 2023-02-13 13:48:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"997ce6fc-c0b7-4a2a-b192-51044e6728ec\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001e4aa48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:49:01.909: INFO: Pod "test-rolling-update-deployment-78f575d8ff-kq78z" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-kq78z test-rolling-update-deployment-78f575d8ff- deployment-6807  ed25bef2-c827-49eb-acaa-bc831a9796a3 12843 0 2023-02-13 13:48:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 09f41f7f-5458-4b47-813e-6557348ba810 0xc001e4afd7 0xc001e4afd8}] [] [{kube-controller-manager Update v1 2023-02-13 13:48:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"09f41f7f-5458-4b47-813e-6557348ba810\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:49:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47nkg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47nkg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:48:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.115,StartTime:2023-02-13 13:48:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:49:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca003494d14c30d4ed6b043fd2431f11acc385eb7b052ed329b53b9fb9b1d041,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:49:01.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6807" for this suite. 02/13/23 13:49:01.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:49:01.932
Feb 13 13:49:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 13:49:01.936
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:01.952
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:01.956
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 02/13/23 13:49:01.959
W0213 13:49:01.967828      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring job reaches completions 02/13/23 13:49:01.968
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 13:49:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4255" for this suite. 02/13/23 13:49:11.983
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":93,"skipped":1686,"failed":0}
------------------------------
• [SLOW TEST] [10.059 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:49:01.932
    Feb 13 13:49:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 13:49:01.936
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:01.952
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:01.956
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 02/13/23 13:49:01.959
    W0213 13:49:01.967828      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring job reaches completions 02/13/23 13:49:01.968
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 13:49:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4255" for this suite. 02/13/23 13:49:11.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:49:11.995
Feb 13 13:49:11.995: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 13:49:11.998
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:12.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:12.027
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Feb 13 13:49:12.032: INFO: Creating ReplicaSet my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e
W0213 13:49:12.038925      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:49:12.042: INFO: Pod name my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Found 0 pods out of 1
Feb 13 13:49:17.048: INFO: Pod name my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Found 1 pods out of 1
Feb 13 13:49:17.049: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" is running
Feb 13 13:49:17.049: INFO: Waiting up to 5m0s for pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" in namespace "replicaset-4422" to be "running"
Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9": Phase="Running", Reason="", readiness=true. Elapsed: 3.419563ms
Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" satisfied condition "running"
Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:12 +0000 UTC Reason: Message:}])
Feb 13 13:49:17.052: INFO: Trying to dial the pod
Feb 13 13:49:22.074: INFO: Controller my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Got expected result from replica 1 [my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9]: "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 13:49:22.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4422" for this suite. 02/13/23 13:49:22.082
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":94,"skipped":1693,"failed":0}
------------------------------
• [SLOW TEST] [10.098 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:49:11.995
    Feb 13 13:49:11.995: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 13:49:11.998
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:12.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:12.027
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Feb 13 13:49:12.032: INFO: Creating ReplicaSet my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e
    W0213 13:49:12.038925      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:49:12.042: INFO: Pod name my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Found 0 pods out of 1
    Feb 13 13:49:17.048: INFO: Pod name my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Found 1 pods out of 1
    Feb 13 13:49:17.049: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e" is running
    Feb 13 13:49:17.049: INFO: Waiting up to 5m0s for pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" in namespace "replicaset-4422" to be "running"
    Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9": Phase="Running", Reason="", readiness=true. Elapsed: 3.419563ms
    Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" satisfied condition "running"
    Feb 13 13:49:17.052: INFO: Pod "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-02-13 13:49:12 +0000 UTC Reason: Message:}])
    Feb 13 13:49:17.052: INFO: Trying to dial the pod
    Feb 13 13:49:22.074: INFO: Controller my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e: Got expected result from replica 1 [my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9]: "my-hostname-basic-fd630f52-b25d-409a-88fa-10ab6f31798e-fpvm9", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 13:49:22.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4422" for this suite. 02/13/23 13:49:22.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:49:22.1
Feb 13 13:49:22.100: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context-test 02/13/23 13:49:22.103
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:22.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:22.125
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
W0213 13:49:22.141828      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:49:22.142: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" in namespace "security-context-test-2430" to be "Succeeded or Failed"
Feb 13 13:49:22.147: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.532699ms
Feb 13 13:49:24.155: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01322665s
Feb 13 13:49:26.154: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012277425s
Feb 13 13:49:26.154: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 13:49:26.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2430" for this suite. 02/13/23 13:49:26.161
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":95,"skipped":1700,"failed":0}
------------------------------
• [4.070 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:49:22.1
    Feb 13 13:49:22.100: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context-test 02/13/23 13:49:22.103
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:22.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:22.125
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    W0213 13:49:22.141828      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:49:22.142: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" in namespace "security-context-test-2430" to be "Succeeded or Failed"
    Feb 13 13:49:22.147: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.532699ms
    Feb 13 13:49:24.155: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01322665s
    Feb 13 13:49:26.154: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012277425s
    Feb 13 13:49:26.154: INFO: Pod "busybox-user-65534-a96c8260-c61b-4e03-9c3c-d17ff3d744f7" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 13:49:26.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2430" for this suite. 02/13/23 13:49:26.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:49:26.175
Feb 13 13:49:26.175: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 13:49:26.176
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:26.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:26.2
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 in namespace container-probe-7496 02/13/23 13:49:26.204
W0213 13:49:26.214687      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:49:26.214: INFO: Waiting up to 5m0s for pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728" in namespace "container-probe-7496" to be "not pending"
Feb 13 13:49:26.218: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728": Phase="Pending", Reason="", readiness=false. Elapsed: 3.941703ms
Feb 13 13:49:28.226: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728": Phase="Running", Reason="", readiness=true. Elapsed: 2.011713184s
Feb 13 13:49:28.226: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728" satisfied condition "not pending"
Feb 13 13:49:28.226: INFO: Started pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 in namespace container-probe-7496
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 13:49:28.226
Feb 13 13:49:28.231: INFO: Initial restart count of pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is 0
Feb 13 13:49:48.308: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 1 (20.077268012s elapsed)
Feb 13 13:50:08.385: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 2 (40.154006258s elapsed)
Feb 13 13:50:28.454: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 3 (1m0.223220086s elapsed)
Feb 13 13:50:48.523: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 4 (1m20.292193325s elapsed)
Feb 13 13:52:00.773: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 5 (2m32.542240031s elapsed)
STEP: deleting the pod 02/13/23 13:52:00.773
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 13:52:00.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7496" for this suite. 02/13/23 13:52:00.796
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":96,"skipped":1723,"failed":0}
------------------------------
• [SLOW TEST] [154.636 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:49:26.175
    Feb 13 13:49:26.175: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 13:49:26.176
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:49:26.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:49:26.2
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 in namespace container-probe-7496 02/13/23 13:49:26.204
    W0213 13:49:26.214687      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:49:26.214: INFO: Waiting up to 5m0s for pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728" in namespace "container-probe-7496" to be "not pending"
    Feb 13 13:49:26.218: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728": Phase="Pending", Reason="", readiness=false. Elapsed: 3.941703ms
    Feb 13 13:49:28.226: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728": Phase="Running", Reason="", readiness=true. Elapsed: 2.011713184s
    Feb 13 13:49:28.226: INFO: Pod "liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728" satisfied condition "not pending"
    Feb 13 13:49:28.226: INFO: Started pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 in namespace container-probe-7496
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 13:49:28.226
    Feb 13 13:49:28.231: INFO: Initial restart count of pod liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is 0
    Feb 13 13:49:48.308: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 1 (20.077268012s elapsed)
    Feb 13 13:50:08.385: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 2 (40.154006258s elapsed)
    Feb 13 13:50:28.454: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 3 (1m0.223220086s elapsed)
    Feb 13 13:50:48.523: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 4 (1m20.292193325s elapsed)
    Feb 13 13:52:00.773: INFO: Restart count of pod container-probe-7496/liveness-4cf11bdc-45f6-4fdf-85b6-8c677f506728 is now 5 (2m32.542240031s elapsed)
    STEP: deleting the pod 02/13/23 13:52:00.773
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 13:52:00.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7496" for this suite. 02/13/23 13:52:00.796
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:00.812
Feb 13 13:52:00.812: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:52:00.816
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:00.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:00.836
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 02/13/23 13:52:00.841
W0213 13:52:00.849233      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:00.849: INFO: Waiting up to 5m0s for pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef" in namespace "downward-api-3973" to be "running and ready"
Feb 13 13:52:00.856: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef": Phase="Pending", Reason="", readiness=false. Elapsed: 7.089957ms
Feb 13 13:52:00.856: INFO: The phase of Pod labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:52:02.863: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef": Phase="Running", Reason="", readiness=true. Elapsed: 2.014217361s
Feb 13 13:52:02.863: INFO: The phase of Pod labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef is Running (Ready = true)
Feb 13 13:52:02.863: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef" satisfied condition "running and ready"
Feb 13 13:52:03.426: INFO: Successfully updated pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:52:07.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3973" for this suite. 02/13/23 13:52:07.484
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":97,"skipped":1723,"failed":0}
------------------------------
• [SLOW TEST] [6.678 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:00.812
    Feb 13 13:52:00.812: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:52:00.816
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:00.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:00.836
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 02/13/23 13:52:00.841
    W0213 13:52:00.849233      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:00.849: INFO: Waiting up to 5m0s for pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef" in namespace "downward-api-3973" to be "running and ready"
    Feb 13 13:52:00.856: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef": Phase="Pending", Reason="", readiness=false. Elapsed: 7.089957ms
    Feb 13 13:52:00.856: INFO: The phase of Pod labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:52:02.863: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef": Phase="Running", Reason="", readiness=true. Elapsed: 2.014217361s
    Feb 13 13:52:02.863: INFO: The phase of Pod labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef is Running (Ready = true)
    Feb 13 13:52:02.863: INFO: Pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef" satisfied condition "running and ready"
    Feb 13 13:52:03.426: INFO: Successfully updated pod "labelsupdate884e5527-6fbc-4529-88eb-0e775caefaef"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:52:07.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3973" for this suite. 02/13/23 13:52:07.484
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:07.49
Feb 13 13:52:07.490: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename subpath 02/13/23 13:52:07.491
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:07.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:07.511
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 02/13/23 13:52:07.516
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-skn2 02/13/23 13:52:07.528
STEP: Creating a pod to test atomic-volume-subpath 02/13/23 13:52:07.528
W0213 13:52:07.538545      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-downwardapi-skn2" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-downwardapi-skn2" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-downwardapi-skn2" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-downwardapi-skn2" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:07.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-skn2" in namespace "subpath-2449" to be "Succeeded or Failed"
Feb 13 13:52:07.548: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.718751ms
Feb 13 13:52:09.556: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 2.0176749s
Feb 13 13:52:11.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014637661s
Feb 13 13:52:13.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 6.014728715s
Feb 13 13:52:15.557: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 8.018479723s
Feb 13 13:52:17.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 10.014949516s
Feb 13 13:52:19.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 12.016908895s
Feb 13 13:52:21.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 14.017189976s
Feb 13 13:52:23.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 16.015180657s
Feb 13 13:52:25.558: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 18.019371778s
Feb 13 13:52:27.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 20.016737096s
Feb 13 13:52:29.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=false. Elapsed: 22.016807584s
Feb 13 13:52:31.557: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018354282s
STEP: Saw pod success 02/13/23 13:52:31.557
Feb 13 13:52:31.557: INFO: Pod "pod-subpath-test-downwardapi-skn2" satisfied condition "Succeeded or Failed"
Feb 13 13:52:31.562: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-subpath-test-downwardapi-skn2 container test-container-subpath-downwardapi-skn2: <nil>
STEP: delete the pod 02/13/23 13:52:31.601
Feb 13 13:52:31.618: INFO: Waiting for pod pod-subpath-test-downwardapi-skn2 to disappear
Feb 13 13:52:31.621: INFO: Pod pod-subpath-test-downwardapi-skn2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-skn2 02/13/23 13:52:31.621
Feb 13 13:52:31.621: INFO: Deleting pod "pod-subpath-test-downwardapi-skn2" in namespace "subpath-2449"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Feb 13 13:52:31.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2449" for this suite. 02/13/23 13:52:31.628
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":98,"skipped":1727,"failed":0}
------------------------------
• [SLOW TEST] [24.145 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:07.49
    Feb 13 13:52:07.490: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename subpath 02/13/23 13:52:07.491
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:07.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:07.511
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 02/13/23 13:52:07.516
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-skn2 02/13/23 13:52:07.528
    STEP: Creating a pod to test atomic-volume-subpath 02/13/23 13:52:07.528
    W0213 13:52:07.538545      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-downwardapi-skn2" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-downwardapi-skn2" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-downwardapi-skn2" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-downwardapi-skn2" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:07.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-skn2" in namespace "subpath-2449" to be "Succeeded or Failed"
    Feb 13 13:52:07.548: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.718751ms
    Feb 13 13:52:09.556: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 2.0176749s
    Feb 13 13:52:11.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014637661s
    Feb 13 13:52:13.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 6.014728715s
    Feb 13 13:52:15.557: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 8.018479723s
    Feb 13 13:52:17.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 10.014949516s
    Feb 13 13:52:19.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 12.016908895s
    Feb 13 13:52:21.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 14.017189976s
    Feb 13 13:52:23.553: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 16.015180657s
    Feb 13 13:52:25.558: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 18.019371778s
    Feb 13 13:52:27.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=true. Elapsed: 20.016737096s
    Feb 13 13:52:29.555: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Running", Reason="", readiness=false. Elapsed: 22.016807584s
    Feb 13 13:52:31.557: INFO: Pod "pod-subpath-test-downwardapi-skn2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018354282s
    STEP: Saw pod success 02/13/23 13:52:31.557
    Feb 13 13:52:31.557: INFO: Pod "pod-subpath-test-downwardapi-skn2" satisfied condition "Succeeded or Failed"
    Feb 13 13:52:31.562: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-subpath-test-downwardapi-skn2 container test-container-subpath-downwardapi-skn2: <nil>
    STEP: delete the pod 02/13/23 13:52:31.601
    Feb 13 13:52:31.618: INFO: Waiting for pod pod-subpath-test-downwardapi-skn2 to disappear
    Feb 13 13:52:31.621: INFO: Pod pod-subpath-test-downwardapi-skn2 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-skn2 02/13/23 13:52:31.621
    Feb 13 13:52:31.621: INFO: Deleting pod "pod-subpath-test-downwardapi-skn2" in namespace "subpath-2449"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Feb 13 13:52:31.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2449" for this suite. 02/13/23 13:52:31.628
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:31.636
Feb 13 13:52:31.636: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename ephemeral-containers-test 02/13/23 13:52:31.637
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:31.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:31.656
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 02/13/23 13:52:31.659
W0213 13:52:31.667515      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:31.667: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2326" to be "running and ready"
Feb 13 13:52:31.671: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.57201ms
Feb 13 13:52:31.671: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:52:33.677: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009290685s
Feb 13 13:52:33.677: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Feb 13 13:52:33.677: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 02/13/23 13:52:33.681
W0213 13:52:33.707591      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-container-1", "debugger" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-container-1", "debugger" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-container-1", "debugger" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-container-1", "debugger" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:33.707: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2326" to be "container debugger running"
Feb 13 13:52:33.713: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.871041ms
Feb 13 13:52:35.721: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013568905s
Feb 13 13:52:37.721: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.013206939s
Feb 13 13:52:37.721: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 02/13/23 13:52:37.721
Feb 13 13:52:37.721: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2326 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:52:37.721: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:52:37.722: INFO: ExecWithOptions: Clientset creation
Feb 13 13:52:37.722: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-2326/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Feb 13 13:52:37.879: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 13:52:37.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-2326" for this suite. 02/13/23 13:52:37.894
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":99,"skipped":1731,"failed":0}
------------------------------
• [SLOW TEST] [6.264 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:31.636
    Feb 13 13:52:31.636: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename ephemeral-containers-test 02/13/23 13:52:31.637
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:31.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:31.656
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 02/13/23 13:52:31.659
    W0213 13:52:31.667515      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:31.667: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2326" to be "running and ready"
    Feb 13 13:52:31.671: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.57201ms
    Feb 13 13:52:31.671: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:52:33.677: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009290685s
    Feb 13 13:52:33.677: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Feb 13 13:52:33.677: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 02/13/23 13:52:33.681
    W0213 13:52:33.707591      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-container-1", "debugger" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-container-1", "debugger" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-container-1", "debugger" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-container-1", "debugger" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:33.707: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2326" to be "container debugger running"
    Feb 13 13:52:33.713: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.871041ms
    Feb 13 13:52:35.721: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013568905s
    Feb 13 13:52:37.721: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.013206939s
    Feb 13 13:52:37.721: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 02/13/23 13:52:37.721
    Feb 13 13:52:37.721: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2326 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:52:37.721: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:52:37.722: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:52:37.722: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-2326/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Feb 13 13:52:37.879: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 13:52:37.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-2326" for this suite. 02/13/23 13:52:37.894
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:37.907
Feb 13 13:52:37.907: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:52:37.909
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:37.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:37.928
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-c1ef4ec7-204e-48fa-bf22-566fdab4b509 02/13/23 13:52:37.932
STEP: Creating a pod to test consume secrets 02/13/23 13:52:37.94
W0213 13:52:37.949523      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:37.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad" in namespace "projected-9146" to be "Succeeded or Failed"
Feb 13 13:52:37.952: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981377ms
Feb 13 13:52:39.959: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01017668s
Feb 13 13:52:41.958: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008567158s
STEP: Saw pod success 02/13/23 13:52:41.958
Feb 13 13:52:41.958: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad" satisfied condition "Succeeded or Failed"
Feb 13 13:52:41.962: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:52:41.974
Feb 13 13:52:41.993: INFO: Waiting for pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad to disappear
Feb 13 13:52:41.997: INFO: Pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 13:52:41.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9146" for this suite. 02/13/23 13:52:42.002
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":100,"skipped":1747,"failed":0}
------------------------------
• [4.102 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:37.907
    Feb 13 13:52:37.907: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:52:37.909
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:37.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:37.928
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-c1ef4ec7-204e-48fa-bf22-566fdab4b509 02/13/23 13:52:37.932
    STEP: Creating a pod to test consume secrets 02/13/23 13:52:37.94
    W0213 13:52:37.949523      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:37.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad" in namespace "projected-9146" to be "Succeeded or Failed"
    Feb 13 13:52:37.952: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981377ms
    Feb 13 13:52:39.959: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01017668s
    Feb 13 13:52:41.958: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008567158s
    STEP: Saw pod success 02/13/23 13:52:41.958
    Feb 13 13:52:41.958: INFO: Pod "pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad" satisfied condition "Succeeded or Failed"
    Feb 13 13:52:41.962: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:52:41.974
    Feb 13 13:52:41.993: INFO: Waiting for pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad to disappear
    Feb 13 13:52:41.997: INFO: Pod pod-projected-secrets-44fbadd5-ad26-4260-91d9-a90301622cad no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 13:52:41.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9146" for this suite. 02/13/23 13:52:42.002
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:42.016
Feb 13 13:52:42.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 13:52:42.018
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:42.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:42.047
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 02/13/23 13:52:42.052
Feb 13 13:52:42.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 create -f -'
Feb 13 13:52:42.312: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 13:52:42.312: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:42.312
Feb 13 13:52:42.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 13:52:42.412: INFO: stderr: ""
Feb 13 13:52:42.412: INFO: stdout: "update-demo-nautilus-6tfpd update-demo-nautilus-rfl5h "
Feb 13 13:52:42.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:42.499: INFO: stderr: ""
Feb 13 13:52:42.499: INFO: stdout: ""
Feb 13 13:52:42.499: INFO: update-demo-nautilus-6tfpd is created but not running
Feb 13 13:52:47.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 13:52:47.646: INFO: stderr: ""
Feb 13 13:52:47.646: INFO: stdout: "update-demo-nautilus-6tfpd update-demo-nautilus-rfl5h "
Feb 13 13:52:47.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:47.739: INFO: stderr: ""
Feb 13 13:52:47.739: INFO: stdout: "true"
Feb 13 13:52:47.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 13:52:47.827: INFO: stderr: ""
Feb 13 13:52:47.827: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 13:52:47.827: INFO: validating pod update-demo-nautilus-6tfpd
Feb 13 13:52:47.848: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:52:47.848: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:52:47.848: INFO: update-demo-nautilus-6tfpd is verified up and running
Feb 13 13:52:47.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:47.934: INFO: stderr: ""
Feb 13 13:52:47.934: INFO: stdout: "true"
Feb 13 13:52:47.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 13:52:48.049: INFO: stderr: ""
Feb 13 13:52:48.049: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 13:52:48.049: INFO: validating pod update-demo-nautilus-rfl5h
Feb 13 13:52:48.067: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:52:48.067: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:52:48.067: INFO: update-demo-nautilus-rfl5h is verified up and running
STEP: scaling down the replication controller 02/13/23 13:52:48.067
Feb 13 13:52:48.070: INFO: scanned /root for discovery docs: <nil>
Feb 13 13:52:48.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Feb 13 13:52:49.272: INFO: stderr: ""
Feb 13 13:52:49.272: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:49.272
Feb 13 13:52:49.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 13:52:49.360: INFO: stderr: ""
Feb 13 13:52:49.360: INFO: stdout: "update-demo-nautilus-rfl5h "
Feb 13 13:52:49.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:49.476: INFO: stderr: ""
Feb 13 13:52:49.476: INFO: stdout: "true"
Feb 13 13:52:49.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 13:52:49.576: INFO: stderr: ""
Feb 13 13:52:49.576: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 13:52:49.576: INFO: validating pod update-demo-nautilus-rfl5h
Feb 13 13:52:49.587: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:52:49.587: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:52:49.587: INFO: update-demo-nautilus-rfl5h is verified up and running
STEP: scaling up the replication controller 02/13/23 13:52:49.587
Feb 13 13:52:49.590: INFO: scanned /root for discovery docs: <nil>
Feb 13 13:52:49.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Feb 13 13:52:50.733: INFO: stderr: ""
Feb 13 13:52:50.733: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:50.733
Feb 13 13:52:50.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 13:52:50.844: INFO: stderr: ""
Feb 13 13:52:50.844: INFO: stdout: "update-demo-nautilus-9sgc9 update-demo-nautilus-rfl5h "
Feb 13 13:52:50.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:50.941: INFO: stderr: ""
Feb 13 13:52:50.941: INFO: stdout: ""
Feb 13 13:52:50.941: INFO: update-demo-nautilus-9sgc9 is created but not running
Feb 13 13:52:55.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 13:52:56.039: INFO: stderr: ""
Feb 13 13:52:56.039: INFO: stdout: "update-demo-nautilus-9sgc9 update-demo-nautilus-rfl5h "
Feb 13 13:52:56.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:56.115: INFO: stderr: ""
Feb 13 13:52:56.115: INFO: stdout: "true"
Feb 13 13:52:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 13:52:56.198: INFO: stderr: ""
Feb 13 13:52:56.198: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 13:52:56.198: INFO: validating pod update-demo-nautilus-9sgc9
Feb 13 13:52:56.214: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:52:56.214: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:52:56.214: INFO: update-demo-nautilus-9sgc9 is verified up and running
Feb 13 13:52:56.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 13:52:56.329: INFO: stderr: ""
Feb 13 13:52:56.329: INFO: stdout: "true"
Feb 13 13:52:56.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 13:52:56.429: INFO: stderr: ""
Feb 13 13:52:56.429: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 13:52:56.429: INFO: validating pod update-demo-nautilus-rfl5h
Feb 13 13:52:56.438: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:52:56.438: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:52:56.438: INFO: update-demo-nautilus-rfl5h is verified up and running
STEP: using delete to clean up resources 02/13/23 13:52:56.438
Feb 13 13:52:56.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 delete --grace-period=0 --force -f -'
Feb 13 13:52:56.550: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:52:56.550: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 13:52:56.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get rc,svc -l name=update-demo --no-headers'
Feb 13 13:52:56.679: INFO: stderr: "No resources found in kubectl-2110 namespace.\n"
Feb 13 13:52:56.679: INFO: stdout: ""
Feb 13 13:52:56.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 13:52:56.790: INFO: stderr: ""
Feb 13 13:52:56.790: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 13:52:56.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2110" for this suite. 02/13/23 13:52:56.796
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":101,"skipped":1770,"failed":0}
------------------------------
• [SLOW TEST] [14.789 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:42.016
    Feb 13 13:52:42.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 13:52:42.018
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:42.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:42.047
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 02/13/23 13:52:42.052
    Feb 13 13:52:42.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 create -f -'
    Feb 13 13:52:42.312: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 13:52:42.312: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:42.312
    Feb 13 13:52:42.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 13:52:42.412: INFO: stderr: ""
    Feb 13 13:52:42.412: INFO: stdout: "update-demo-nautilus-6tfpd update-demo-nautilus-rfl5h "
    Feb 13 13:52:42.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:42.499: INFO: stderr: ""
    Feb 13 13:52:42.499: INFO: stdout: ""
    Feb 13 13:52:42.499: INFO: update-demo-nautilus-6tfpd is created but not running
    Feb 13 13:52:47.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 13:52:47.646: INFO: stderr: ""
    Feb 13 13:52:47.646: INFO: stdout: "update-demo-nautilus-6tfpd update-demo-nautilus-rfl5h "
    Feb 13 13:52:47.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:47.739: INFO: stderr: ""
    Feb 13 13:52:47.739: INFO: stdout: "true"
    Feb 13 13:52:47.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-6tfpd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 13:52:47.827: INFO: stderr: ""
    Feb 13 13:52:47.827: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 13:52:47.827: INFO: validating pod update-demo-nautilus-6tfpd
    Feb 13 13:52:47.848: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 13:52:47.848: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 13:52:47.848: INFO: update-demo-nautilus-6tfpd is verified up and running
    Feb 13 13:52:47.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:47.934: INFO: stderr: ""
    Feb 13 13:52:47.934: INFO: stdout: "true"
    Feb 13 13:52:47.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 13:52:48.049: INFO: stderr: ""
    Feb 13 13:52:48.049: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 13:52:48.049: INFO: validating pod update-demo-nautilus-rfl5h
    Feb 13 13:52:48.067: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 13:52:48.067: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 13:52:48.067: INFO: update-demo-nautilus-rfl5h is verified up and running
    STEP: scaling down the replication controller 02/13/23 13:52:48.067
    Feb 13 13:52:48.070: INFO: scanned /root for discovery docs: <nil>
    Feb 13 13:52:48.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Feb 13 13:52:49.272: INFO: stderr: ""
    Feb 13 13:52:49.272: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:49.272
    Feb 13 13:52:49.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 13:52:49.360: INFO: stderr: ""
    Feb 13 13:52:49.360: INFO: stdout: "update-demo-nautilus-rfl5h "
    Feb 13 13:52:49.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:49.476: INFO: stderr: ""
    Feb 13 13:52:49.476: INFO: stdout: "true"
    Feb 13 13:52:49.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 13:52:49.576: INFO: stderr: ""
    Feb 13 13:52:49.576: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 13:52:49.576: INFO: validating pod update-demo-nautilus-rfl5h
    Feb 13 13:52:49.587: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 13:52:49.587: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 13:52:49.587: INFO: update-demo-nautilus-rfl5h is verified up and running
    STEP: scaling up the replication controller 02/13/23 13:52:49.587
    Feb 13 13:52:49.590: INFO: scanned /root for discovery docs: <nil>
    Feb 13 13:52:49.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Feb 13 13:52:50.733: INFO: stderr: ""
    Feb 13 13:52:50.733: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 13:52:50.733
    Feb 13 13:52:50.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 13:52:50.844: INFO: stderr: ""
    Feb 13 13:52:50.844: INFO: stdout: "update-demo-nautilus-9sgc9 update-demo-nautilus-rfl5h "
    Feb 13 13:52:50.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:50.941: INFO: stderr: ""
    Feb 13 13:52:50.941: INFO: stdout: ""
    Feb 13 13:52:50.941: INFO: update-demo-nautilus-9sgc9 is created but not running
    Feb 13 13:52:55.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 13:52:56.039: INFO: stderr: ""
    Feb 13 13:52:56.039: INFO: stdout: "update-demo-nautilus-9sgc9 update-demo-nautilus-rfl5h "
    Feb 13 13:52:56.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:56.115: INFO: stderr: ""
    Feb 13 13:52:56.115: INFO: stdout: "true"
    Feb 13 13:52:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-9sgc9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 13:52:56.198: INFO: stderr: ""
    Feb 13 13:52:56.198: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 13:52:56.198: INFO: validating pod update-demo-nautilus-9sgc9
    Feb 13 13:52:56.214: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 13:52:56.214: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 13:52:56.214: INFO: update-demo-nautilus-9sgc9 is verified up and running
    Feb 13 13:52:56.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 13:52:56.329: INFO: stderr: ""
    Feb 13 13:52:56.329: INFO: stdout: "true"
    Feb 13 13:52:56.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods update-demo-nautilus-rfl5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 13:52:56.429: INFO: stderr: ""
    Feb 13 13:52:56.429: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 13:52:56.429: INFO: validating pod update-demo-nautilus-rfl5h
    Feb 13 13:52:56.438: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 13:52:56.438: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 13:52:56.438: INFO: update-demo-nautilus-rfl5h is verified up and running
    STEP: using delete to clean up resources 02/13/23 13:52:56.438
    Feb 13 13:52:56.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 delete --grace-period=0 --force -f -'
    Feb 13 13:52:56.550: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 13:52:56.550: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Feb 13 13:52:56.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get rc,svc -l name=update-demo --no-headers'
    Feb 13 13:52:56.679: INFO: stderr: "No resources found in kubectl-2110 namespace.\n"
    Feb 13 13:52:56.679: INFO: stdout: ""
    Feb 13 13:52:56.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2110 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Feb 13 13:52:56.790: INFO: stderr: ""
    Feb 13 13:52:56.790: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 13:52:56.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2110" for this suite. 02/13/23 13:52:56.796
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:52:56.807
Feb 13 13:52:56.807: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 13:52:56.808
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:56.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:56.837
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 02/13/23 13:52:56.842
W0213 13:52:56.853042      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:52:56.853: INFO: Waiting up to 5m0s for pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3" in namespace "var-expansion-3559" to be "Succeeded or Failed"
Feb 13 13:52:56.863: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.2343ms
Feb 13 13:52:58.872: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018977052s
Feb 13 13:53:00.869: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016284255s
STEP: Saw pod success 02/13/23 13:53:00.87
Feb 13 13:53:00.870: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3" satisfied condition "Succeeded or Failed"
Feb 13 13:53:00.874: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 container dapi-container: <nil>
STEP: delete the pod 02/13/23 13:53:00.885
Feb 13 13:53:00.900: INFO: Waiting for pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 to disappear
Feb 13 13:53:00.904: INFO: Pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 13:53:00.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3559" for this suite. 02/13/23 13:53:00.91
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":102,"skipped":1801,"failed":0}
------------------------------
• [4.112 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:52:56.807
    Feb 13 13:52:56.807: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 13:52:56.808
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:52:56.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:52:56.837
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 02/13/23 13:52:56.842
    W0213 13:52:56.853042      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:52:56.853: INFO: Waiting up to 5m0s for pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3" in namespace "var-expansion-3559" to be "Succeeded or Failed"
    Feb 13 13:52:56.863: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.2343ms
    Feb 13 13:52:58.872: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018977052s
    Feb 13 13:53:00.869: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016284255s
    STEP: Saw pod success 02/13/23 13:53:00.87
    Feb 13 13:53:00.870: INFO: Pod "var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3" satisfied condition "Succeeded or Failed"
    Feb 13 13:53:00.874: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 container dapi-container: <nil>
    STEP: delete the pod 02/13/23 13:53:00.885
    Feb 13 13:53:00.900: INFO: Waiting for pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 to disappear
    Feb 13 13:53:00.904: INFO: Pod var-expansion-ca9175f0-3991-4cb6-9b31-c02e656405b3 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 13:53:00.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3559" for this suite. 02/13/23 13:53:00.91
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:00.922
Feb 13 13:53:00.922: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:53:00.926
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:00.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:00.95
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:53:00.957
W0213 13:53:00.970380      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:00.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760" in namespace "downward-api-373" to be "Succeeded or Failed"
Feb 13 13:53:00.978: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Pending", Reason="", readiness=false. Elapsed: 7.223235ms
Feb 13 13:53:02.984: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013182804s
Feb 13 13:53:04.986: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015123231s
STEP: Saw pod success 02/13/23 13:53:04.986
Feb 13 13:53:04.986: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760" satisfied condition "Succeeded or Failed"
Feb 13 13:53:04.993: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 container client-container: <nil>
STEP: delete the pod 02/13/23 13:53:05.006
Feb 13 13:53:05.026: INFO: Waiting for pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 to disappear
Feb 13 13:53:05.031: INFO: Pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:53:05.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-373" for this suite. 02/13/23 13:53:05.038
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":1803,"failed":0}
------------------------------
• [4.125 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:00.922
    Feb 13 13:53:00.922: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:53:00.926
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:00.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:00.95
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:53:00.957
    W0213 13:53:00.970380      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:00.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760" in namespace "downward-api-373" to be "Succeeded or Failed"
    Feb 13 13:53:00.978: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Pending", Reason="", readiness=false. Elapsed: 7.223235ms
    Feb 13 13:53:02.984: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013182804s
    Feb 13 13:53:04.986: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015123231s
    STEP: Saw pod success 02/13/23 13:53:04.986
    Feb 13 13:53:04.986: INFO: Pod "downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760" satisfied condition "Succeeded or Failed"
    Feb 13 13:53:04.993: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:53:05.006
    Feb 13 13:53:05.026: INFO: Waiting for pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 to disappear
    Feb 13 13:53:05.031: INFO: Pod downwardapi-volume-6cde46c6-bad3-4cc7-b5d0-fc649e65b760 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:53:05.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-373" for this suite. 02/13/23 13:53:05.038
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:05.048
Feb 13 13:53:05.049: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:53:05.051
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:05.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:05.074
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
W0213 13:53:05.091045      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:05.091: INFO: Waiting up to 5m0s for pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f" in namespace "svcaccounts-2233" to be "running"
Feb 13 13:53:05.096: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.196293ms
Feb 13 13:53:07.102: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f": Phase="Running", Reason="", readiness=true. Elapsed: 2.011314436s
Feb 13 13:53:07.102: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f" satisfied condition "running"
STEP: reading a file in the container 02/13/23 13:53:07.102
Feb 13 13:53:07.103: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 02/13/23 13:53:07.344
Feb 13 13:53:07.345: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 02/13/23 13:53:07.604
Feb 13 13:53:07.605: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Feb 13 13:53:07.870: INFO: Got root ca configmap in namespace "svcaccounts-2233"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 13:53:07.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2233" for this suite. 02/13/23 13:53:07.88
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":104,"skipped":1818,"failed":0}
------------------------------
• [2.841 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:05.048
    Feb 13 13:53:05.049: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:53:05.051
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:05.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:05.074
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    W0213 13:53:05.091045      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:05.091: INFO: Waiting up to 5m0s for pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f" in namespace "svcaccounts-2233" to be "running"
    Feb 13 13:53:05.096: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.196293ms
    Feb 13 13:53:07.102: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f": Phase="Running", Reason="", readiness=true. Elapsed: 2.011314436s
    Feb 13 13:53:07.102: INFO: Pod "pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f" satisfied condition "running"
    STEP: reading a file in the container 02/13/23 13:53:07.102
    Feb 13 13:53:07.103: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 02/13/23 13:53:07.344
    Feb 13 13:53:07.345: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 02/13/23 13:53:07.604
    Feb 13 13:53:07.605: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2233 pod-service-account-ff2a958b-0255-4fcf-a9ad-bfa912cee54f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Feb 13 13:53:07.870: INFO: Got root ca configmap in namespace "svcaccounts-2233"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 13:53:07.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2233" for this suite. 02/13/23 13:53:07.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:07.899
Feb 13 13:53:07.900: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 13:53:07.902
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:07.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:07.923
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 02/13/23 13:53:07.929
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_tcp@PTR;sleep 1; done
 02/13/23 13:53:07.956
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_tcp@PTR;sleep 1; done
 02/13/23 13:53:07.956
STEP: creating a pod to probe DNS 02/13/23 13:53:07.957
STEP: submitting the pod to kubernetes 02/13/23 13:53:07.957
W0213 13:53:07.984992      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:07.985: INFO: Waiting up to 15m0s for pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef" in namespace "dns-3761" to be "running"
Feb 13 13:53:07.989: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.18766ms
Feb 13 13:53:09.997: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011623984s
Feb 13 13:53:11.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012494898s
Feb 13 13:53:13.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012328078s
Feb 13 13:53:15.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Running", Reason="", readiness=true. Elapsed: 8.012374842s
Feb 13 13:53:15.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef" satisfied condition "running"
STEP: retrieving the pod 02/13/23 13:53:15.998
STEP: looking for the results for each expected name from probers 02/13/23 13:53:16.005
Feb 13 13:53:16.020: INFO: Unable to read wheezy_udp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.029: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.038: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.046: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.085: INFO: Unable to read jessie_udp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.095: INFO: Unable to read jessie_tcp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.104: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.113: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
Feb 13 13:53:16.147: INFO: Lookups using dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef failed for: [wheezy_udp@dns-test-service.dns-3761.svc.cluster.local wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local jessie_udp@dns-test-service.dns-3761.svc.cluster.local jessie_tcp@dns-test-service.dns-3761.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local]

Feb 13 13:53:21.279: INFO: DNS probes using dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef succeeded

STEP: deleting the pod 02/13/23 13:53:21.279
STEP: deleting the test service 02/13/23 13:53:21.304
STEP: deleting the test headless service 02/13/23 13:53:21.335
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 13:53:21.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3761" for this suite. 02/13/23 13:53:21.359
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":105,"skipped":1870,"failed":0}
------------------------------
• [SLOW TEST] [13.465 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:07.899
    Feb 13 13:53:07.900: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 13:53:07.902
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:07.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:07.923
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 02/13/23 13:53:07.929
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_tcp@PTR;sleep 1; done
     02/13/23 13:53:07.956
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.123.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.123.6_tcp@PTR;sleep 1; done
     02/13/23 13:53:07.956
    STEP: creating a pod to probe DNS 02/13/23 13:53:07.957
    STEP: submitting the pod to kubernetes 02/13/23 13:53:07.957
    W0213 13:53:07.984992      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:07.985: INFO: Waiting up to 15m0s for pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef" in namespace "dns-3761" to be "running"
    Feb 13 13:53:07.989: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.18766ms
    Feb 13 13:53:09.997: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011623984s
    Feb 13 13:53:11.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012494898s
    Feb 13 13:53:13.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012328078s
    Feb 13 13:53:15.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef": Phase="Running", Reason="", readiness=true. Elapsed: 8.012374842s
    Feb 13 13:53:15.998: INFO: Pod "dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 13:53:15.998
    STEP: looking for the results for each expected name from probers 02/13/23 13:53:16.005
    Feb 13 13:53:16.020: INFO: Unable to read wheezy_udp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.029: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.038: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.046: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.085: INFO: Unable to read jessie_udp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.095: INFO: Unable to read jessie_tcp@dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.104: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.113: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local from pod dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef: the server could not find the requested resource (get pods dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef)
    Feb 13 13:53:16.147: INFO: Lookups using dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef failed for: [wheezy_udp@dns-test-service.dns-3761.svc.cluster.local wheezy_tcp@dns-test-service.dns-3761.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local jessie_udp@dns-test-service.dns-3761.svc.cluster.local jessie_tcp@dns-test-service.dns-3761.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3761.svc.cluster.local]

    Feb 13 13:53:21.279: INFO: DNS probes using dns-3761/dns-test-d989a711-b572-4012-a5b0-fd5c115dfaef succeeded

    STEP: deleting the pod 02/13/23 13:53:21.279
    STEP: deleting the test service 02/13/23 13:53:21.304
    STEP: deleting the test headless service 02/13/23 13:53:21.335
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 13:53:21.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3761" for this suite. 02/13/23 13:53:21.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:21.378
Feb 13 13:53:21.378: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:53:21.38
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:21.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:21.404
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Feb 13 13:53:21.410: INFO: Creating deployment "webserver-deployment"
W0213 13:53:21.417846      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:21.418: INFO: Waiting for observed generation 1
Feb 13 13:53:23.431: INFO: Waiting for all required pods to come up
Feb 13 13:53:23.436: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 02/13/23 13:53:23.436
Feb 13 13:53:23.436: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wvvjz" in namespace "deployment-2416" to be "running"
Feb 13 13:53:23.439: INFO: Pod "webserver-deployment-845c8977d9-wvvjz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.958047ms
Feb 13 13:53:25.446: INFO: Pod "webserver-deployment-845c8977d9-wvvjz": Phase="Running", Reason="", readiness=true. Elapsed: 2.010363735s
Feb 13 13:53:25.447: INFO: Pod "webserver-deployment-845c8977d9-wvvjz" satisfied condition "running"
Feb 13 13:53:25.447: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 13 13:53:25.456: INFO: Updating deployment "webserver-deployment" with a non-existent image
W0213 13:53:25.470160      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:25.470: INFO: Updating deployment webserver-deployment
Feb 13 13:53:25.470: INFO: Waiting for observed generation 2
Feb 13 13:53:27.478: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 13 13:53:27.482: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 13 13:53:27.486: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 13 13:53:27.497: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 13 13:53:27.497: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 13 13:53:27.501: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 13 13:53:27.508: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 13 13:53:27.508: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
W0213 13:53:27.517203      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:27.517: INFO: Updating deployment webserver-deployment
Feb 13 13:53:27.517: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 13 13:53:27.536: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 13 13:53:29.554: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:53:29.564: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2416  eea32030-1c88-4aae-92ae-6b5b5cf3741f 14250 3 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4bd38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-02-13 13:53:27 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-02-13 13:53:27 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb 13 13:53:29.568: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2416  cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 14249 3 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment eea32030-1c88-4aae-92ae-6b5b5cf3741f 0xc00378c177 0xc00378c178}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eea32030-1c88-4aae-92ae-6b5b5cf3741f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00378c218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:53:29.568: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 13 13:53:29.568: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2416  89449047-641c-41eb-bd5c-b6703020f6fc 14236 3 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment eea32030-1c88-4aae-92ae-6b5b5cf3741f 0xc00378c277 0xc00378c278}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eea32030-1c88-4aae-92ae-6b5b5cf3741f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00378c308 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:53:29.581: INFO: Pod "webserver-deployment-69b7448995-6755m" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6755m webserver-deployment-69b7448995- deployment-2416  1f9e22f6-118d-4ae6-a23f-dfba142c1e00 14254 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378c7b7 0xc00378c7b8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jj8s2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jj8s2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.581: INFO: Pod "webserver-deployment-69b7448995-6tpc2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6tpc2 webserver-deployment-69b7448995- deployment-2416  98cfaea0-5d2a-4c83-ae14-e2d564510487 14230 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378c9a7 0xc00378c9a8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t829z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t829z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-fx44r" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fx44r webserver-deployment-69b7448995- deployment-2416  7040ab5b-9acc-42b4-ad46-b22a3c313bea 14224 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378cb20 0xc00378cb21}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gsd8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gsd8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-fzvdm" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fzvdm webserver-deployment-69b7448995- deployment-2416  a845ce25-fa84-4179-8abe-4d8015521dfc 14247 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378cc80 0xc00378cc81}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5t48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5t48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-jghcf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jghcf webserver-deployment-69b7448995- deployment-2416  9267c643-d8e3-416f-8743-7a682d2f7f0b 14194 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378ce57 0xc00378ce58}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lr9ht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lr9ht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-kffwh" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-kffwh webserver-deployment-69b7448995- deployment-2416  a4ecef4c-a376-47f3-bee9-60544d6da83c 14226 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d037 0xc00378d038}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-krptb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-krptb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-m2x62" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-m2x62 webserver-deployment-69b7448995- deployment-2416  48d442a7-6252-4b2f-a915-e38795b9ccdc 14196 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d1a0 0xc00378d1a1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m8sfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m8sfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-p85xt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-p85xt webserver-deployment-69b7448995- deployment-2416  d163ddb0-1f1e-4157-8a87-19983551b4fc 14155 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d300 0xc00378d301}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj5mg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj5mg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.87,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-ppzhz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ppzhz webserver-deployment-69b7448995- deployment-2416  445a6369-f635-4f44-affb-e90a08f8fe55 14233 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d500 0xc00378d501}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tqdg2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tqdg2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-rh5bd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-rh5bd webserver-deployment-69b7448995- deployment-2416  e74d1971-776c-4c27-8dc7-9f011757920b 14160 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d6d7 0xc00378d6d8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7gzrt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7gzrt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.62,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-s8lhc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-s8lhc webserver-deployment-69b7448995- deployment-2416  6f17c619-95c2-4912-811c-1d5f27d61c1e 14149 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d8f0 0xc00378d8f1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.132\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k6jq9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k6jq9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.132,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.132,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-sq9mv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sq9mv webserver-deployment-69b7448995- deployment-2416  916ae49b-e194-4e35-a3ca-f95b043e1533 14162 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378db17 0xc00378db18}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-msxdc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-msxdc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.88,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-tdpmn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-tdpmn webserver-deployment-69b7448995- deployment-2416  630bb9d7-a092-452d-be0d-176229611b40 14153 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378dd30 0xc00378dd31}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbd9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbd9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.131,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-25p2n" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-25p2n webserver-deployment-845c8977d9- deployment-2416  7be63d71-3297-4c3a-9cc8-df875b7b6e6f 14304 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc00378df67 0xc00378df68}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rx87m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rx87m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-4sdxz" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4sdxz webserver-deployment-845c8977d9- deployment-2416  c6373cbf-ff19-4f42-bdfc-b78b6945a687 14253 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a3f7 0xc001b3a3f8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8s7l4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8s7l4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-542c5" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-542c5 webserver-deployment-845c8977d9- deployment-2416  21c2125a-18fd-46b7-b7ef-3efdd71e3156 14024 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a697 0xc001b3a698}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkt7p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkt7p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.59,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f31013a82683dd71537aa1ef8b38ffb77e3ff58d74ee75475065a04f8b714e86,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-7ps9c" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7ps9c webserver-deployment-845c8977d9- deployment-2416  4972dacd-aae0-4059-887e-eabd18d9f7d9 14237 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a870 0xc001b3a871}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xgzsk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xgzsk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-9jkp2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9jkp2 webserver-deployment-845c8977d9- deployment-2416  8044267e-c890-484a-8145-1435c873be6d 14041 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3aa27 0xc001b3aa28}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.129\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6d2rb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6d2rb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.129,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ec69d7ef95950fdb8472fcc15928bb6c8602a7e63c9cae22c4b03f03fa7b98f0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cd687" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cd687 webserver-deployment-845c8977d9- deployment-2416  fec7b96b-513c-44ad-97c3-ef919074e925 14227 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3ac17 0xc001b3ac18}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4dznn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4dznn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cg8sl" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cg8sl webserver-deployment-845c8977d9- deployment-2416  0a61a0e6-bcdd-4f95-89ad-e1db85991bc1 14248 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3ad80 0xc001b3ad81}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k62gz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k62gz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cs4c8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cs4c8 webserver-deployment-845c8977d9- deployment-2416  77d2bb3b-5b04-4eb5-8e7e-2095af1dcbf7 14220 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3af37 0xc001b3af38}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xcnt8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xcnt8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-g89km" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-g89km webserver-deployment-845c8977d9- deployment-2416  c5583bdf-a39f-4749-958c-2673ca3f3b89 14046 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b290 0xc001b3b291}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59kz6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59kz6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.84,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e12a520256e2a7a81863da6f67e23ca8d1232235899e77f0a8354aba03ff794b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-h9nrd" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-h9nrd webserver-deployment-845c8977d9- deployment-2416  c94feb12-f40a-42f8-9ce4-17eca2a44b62 14050 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b460 0xc001b3b461}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sjmfm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sjmfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.86,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c4a080d916dbb4f0fe7008e1544cf8a4580e58d4279112a78cbb78053e14013,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-jq65s" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jq65s webserver-deployment-845c8977d9- deployment-2416  fd5110a4-dd94-4d41-8bf4-258805bfa5d7 14188 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b630 0xc001b3b631}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7mh62,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7mh62,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-kf5pr" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kf5pr webserver-deployment-845c8977d9- deployment-2416  c53fb865-e998-43b0-9d1f-7da900445b03 14015 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b780 0xc001b3b781}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wptcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wptcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.61,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://41ca733ed9915ae3352a80120b5dfdb0a669a476b963ef232bef11d4d80d83db,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-l946l" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-l946l webserver-deployment-845c8977d9- deployment-2416  f91f96ba-f81e-40f0-af56-fef0d813c616 14019 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b950 0xc001b3b951}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.128\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27fp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27fp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.128,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6d7c7305db63e66b9534babbbac26833c8288e56e6888e5cb4c06025660d4737,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.128,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-lfzwc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lfzwc webserver-deployment-845c8977d9- deployment-2416  114753c8-9192-4a0e-bd79-e3bbe3805aad 14044 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bb27 0xc001b3bb28}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9dw29,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9dw29,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.85,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3d7210f59fb57910f6756117fe387628bf042a2e88e383e42ce39b6b09a4fcd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-nnjtp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nnjtp webserver-deployment-845c8977d9- deployment-2416  2904b903-daeb-4b9c-994c-e9aa5e768255 14306 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bd00 0xc001b3bd01}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f4k8x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f4k8x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-ppkrw" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ppkrw webserver-deployment-845c8977d9- deployment-2416  4fd91489-6861-44f9-b163-87858eefbb77 14229 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bf57 0xc001b3bf58}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpgjv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpgjv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-pwdtc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-pwdtc webserver-deployment-845c8977d9- deployment-2416  046db13d-9f93-4050-b59a-39eba1535482 14204 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc0037fb147 0xc0037fb148}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zlvc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zlvc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-xjb6x" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xjb6x webserver-deployment-845c8977d9- deployment-2416  98a86c7e-0bfd-4492-b3ee-900ec2e1e109 14251 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca2247 0xc003ca2248}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nkx4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nkx4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-xrjs8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xrjs8 webserver-deployment-845c8977d9- deployment-2416  00b1f51f-47de-41f3-8fdb-3db1243842bb 14010 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca2407 0xc003ca2408}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpwng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpwng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.60,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1c9986f454da7dd5694891c5dcd0ce32583d310dc4560b43f9db1460546de02c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-zgzbx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zgzbx webserver-deployment-845c8977d9- deployment-2416  091ca94e-28c4-456f-934a-d049074e0ea6 14183 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca25e0 0xc003ca25e1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgwp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgwp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:53:29.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2416" for this suite. 02/13/23 13:53:29.596
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":106,"skipped":1902,"failed":0}
------------------------------
• [SLOW TEST] [8.228 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:21.378
    Feb 13 13:53:21.378: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:53:21.38
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:21.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:21.404
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Feb 13 13:53:21.410: INFO: Creating deployment "webserver-deployment"
    W0213 13:53:21.417846      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:21.418: INFO: Waiting for observed generation 1
    Feb 13 13:53:23.431: INFO: Waiting for all required pods to come up
    Feb 13 13:53:23.436: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 02/13/23 13:53:23.436
    Feb 13 13:53:23.436: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wvvjz" in namespace "deployment-2416" to be "running"
    Feb 13 13:53:23.439: INFO: Pod "webserver-deployment-845c8977d9-wvvjz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.958047ms
    Feb 13 13:53:25.446: INFO: Pod "webserver-deployment-845c8977d9-wvvjz": Phase="Running", Reason="", readiness=true. Elapsed: 2.010363735s
    Feb 13 13:53:25.447: INFO: Pod "webserver-deployment-845c8977d9-wvvjz" satisfied condition "running"
    Feb 13 13:53:25.447: INFO: Waiting for deployment "webserver-deployment" to complete
    Feb 13 13:53:25.456: INFO: Updating deployment "webserver-deployment" with a non-existent image
    W0213 13:53:25.470160      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:25.470: INFO: Updating deployment webserver-deployment
    Feb 13 13:53:25.470: INFO: Waiting for observed generation 2
    Feb 13 13:53:27.478: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Feb 13 13:53:27.482: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Feb 13 13:53:27.486: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Feb 13 13:53:27.497: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Feb 13 13:53:27.497: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Feb 13 13:53:27.501: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Feb 13 13:53:27.508: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Feb 13 13:53:27.508: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    W0213 13:53:27.517203      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:27.517: INFO: Updating deployment webserver-deployment
    Feb 13 13:53:27.517: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Feb 13 13:53:27.536: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Feb 13 13:53:29.554: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:53:29.564: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-2416  eea32030-1c88-4aae-92ae-6b5b5cf3741f 14250 3 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001e4bd38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-02-13 13:53:27 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-02-13 13:53:27 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Feb 13 13:53:29.568: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2416  cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 14249 3 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment eea32030-1c88-4aae-92ae-6b5b5cf3741f 0xc00378c177 0xc00378c178}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eea32030-1c88-4aae-92ae-6b5b5cf3741f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00378c218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:53:29.568: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Feb 13 13:53:29.568: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2416  89449047-641c-41eb-bd5c-b6703020f6fc 14236 3 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment eea32030-1c88-4aae-92ae-6b5b5cf3741f 0xc00378c277 0xc00378c278}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eea32030-1c88-4aae-92ae-6b5b5cf3741f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00378c308 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:53:29.581: INFO: Pod "webserver-deployment-69b7448995-6755m" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6755m webserver-deployment-69b7448995- deployment-2416  1f9e22f6-118d-4ae6-a23f-dfba142c1e00 14254 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378c7b7 0xc00378c7b8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jj8s2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jj8s2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.581: INFO: Pod "webserver-deployment-69b7448995-6tpc2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6tpc2 webserver-deployment-69b7448995- deployment-2416  98cfaea0-5d2a-4c83-ae14-e2d564510487 14230 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378c9a7 0xc00378c9a8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t829z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t829z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-fx44r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fx44r webserver-deployment-69b7448995- deployment-2416  7040ab5b-9acc-42b4-ad46-b22a3c313bea 14224 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378cb20 0xc00378cb21}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gsd8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gsd8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-fzvdm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fzvdm webserver-deployment-69b7448995- deployment-2416  a845ce25-fa84-4179-8abe-4d8015521dfc 14247 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378cc80 0xc00378cc81}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5t48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5t48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-jghcf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jghcf webserver-deployment-69b7448995- deployment-2416  9267c643-d8e3-416f-8743-7a682d2f7f0b 14194 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378ce57 0xc00378ce58}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lr9ht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lr9ht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-kffwh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-kffwh webserver-deployment-69b7448995- deployment-2416  a4ecef4c-a376-47f3-bee9-60544d6da83c 14226 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d037 0xc00378d038}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-krptb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-krptb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-m2x62" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-m2x62 webserver-deployment-69b7448995- deployment-2416  48d442a7-6252-4b2f-a915-e38795b9ccdc 14196 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d1a0 0xc00378d1a1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m8sfk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m8sfk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.582: INFO: Pod "webserver-deployment-69b7448995-p85xt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-p85xt webserver-deployment-69b7448995- deployment-2416  d163ddb0-1f1e-4157-8a87-19983551b4fc 14155 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d300 0xc00378d301}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj5mg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj5mg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.87,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-ppzhz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ppzhz webserver-deployment-69b7448995- deployment-2416  445a6369-f635-4f44-affb-e90a08f8fe55 14233 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d500 0xc00378d501}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tqdg2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tqdg2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-rh5bd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-rh5bd webserver-deployment-69b7448995- deployment-2416  e74d1971-776c-4c27-8dc7-9f011757920b 14160 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d6d7 0xc00378d6d8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7gzrt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7gzrt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.62,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-s8lhc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-s8lhc webserver-deployment-69b7448995- deployment-2416  6f17c619-95c2-4912-811c-1d5f27d61c1e 14149 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378d8f0 0xc00378d8f1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.132\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k6jq9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k6jq9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.132,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.132,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-sq9mv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sq9mv webserver-deployment-69b7448995- deployment-2416  916ae49b-e194-4e35-a3ca-f95b043e1533 14162 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378db17 0xc00378db18}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-msxdc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-msxdc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.88,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.583: INFO: Pod "webserver-deployment-69b7448995-tdpmn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-tdpmn webserver-deployment-69b7448995- deployment-2416  630bb9d7-a092-452d-be0d-176229611b40 14153 0 2023-02-13 13:53:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 cc50a8c7-6694-40ca-8fe6-ed0af9bb1979 0xc00378dd30 0xc00378dd31}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc50a8c7-6694-40ca-8fe6-ed0af9bb1979\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbd9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbd9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.131,StartTime:2023-02-13 13:53:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-25p2n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-25p2n webserver-deployment-845c8977d9- deployment-2416  7be63d71-3297-4c3a-9cc8-df875b7b6e6f 14304 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc00378df67 0xc00378df68}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rx87m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rx87m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-4sdxz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4sdxz webserver-deployment-845c8977d9- deployment-2416  c6373cbf-ff19-4f42-bdfc-b78b6945a687 14253 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a3f7 0xc001b3a3f8}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8s7l4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8s7l4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-542c5" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-542c5 webserver-deployment-845c8977d9- deployment-2416  21c2125a-18fd-46b7-b7ef-3efdd71e3156 14024 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a697 0xc001b3a698}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkt7p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkt7p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.59,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f31013a82683dd71537aa1ef8b38ffb77e3ff58d74ee75475065a04f8b714e86,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-7ps9c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7ps9c webserver-deployment-845c8977d9- deployment-2416  4972dacd-aae0-4059-887e-eabd18d9f7d9 14237 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3a870 0xc001b3a871}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xgzsk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xgzsk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.584: INFO: Pod "webserver-deployment-845c8977d9-9jkp2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9jkp2 webserver-deployment-845c8977d9- deployment-2416  8044267e-c890-484a-8145-1435c873be6d 14041 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3aa27 0xc001b3aa28}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.129\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6d2rb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6d2rb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.129,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ec69d7ef95950fdb8472fcc15928bb6c8602a7e63c9cae22c4b03f03fa7b98f0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cd687" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cd687 webserver-deployment-845c8977d9- deployment-2416  fec7b96b-513c-44ad-97c3-ef919074e925 14227 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3ac17 0xc001b3ac18}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4dznn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4dznn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cg8sl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cg8sl webserver-deployment-845c8977d9- deployment-2416  0a61a0e6-bcdd-4f95-89ad-e1db85991bc1 14248 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3ad80 0xc001b3ad81}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k62gz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k62gz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.585: INFO: Pod "webserver-deployment-845c8977d9-cs4c8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cs4c8 webserver-deployment-845c8977d9- deployment-2416  77d2bb3b-5b04-4eb5-8e7e-2095af1dcbf7 14220 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3af37 0xc001b3af38}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xcnt8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xcnt8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-g89km" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-g89km webserver-deployment-845c8977d9- deployment-2416  c5583bdf-a39f-4749-958c-2673ca3f3b89 14046 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b290 0xc001b3b291}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59kz6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59kz6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.84,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e12a520256e2a7a81863da6f67e23ca8d1232235899e77f0a8354aba03ff794b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-h9nrd" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-h9nrd webserver-deployment-845c8977d9- deployment-2416  c94feb12-f40a-42f8-9ce4-17eca2a44b62 14050 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b460 0xc001b3b461}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sjmfm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sjmfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.86,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c4a080d916dbb4f0fe7008e1544cf8a4580e58d4279112a78cbb78053e14013,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-jq65s" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jq65s webserver-deployment-845c8977d9- deployment-2416  fd5110a4-dd94-4d41-8bf4-258805bfa5d7 14188 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b630 0xc001b3b631}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7mh62,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7mh62,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.587: INFO: Pod "webserver-deployment-845c8977d9-kf5pr" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kf5pr webserver-deployment-845c8977d9- deployment-2416  c53fb865-e998-43b0-9d1f-7da900445b03 14015 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b780 0xc001b3b781}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wptcx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wptcx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.61,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://41ca733ed9915ae3352a80120b5dfdb0a669a476b963ef232bef11d4d80d83db,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-l946l" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-l946l webserver-deployment-845c8977d9- deployment-2416  f91f96ba-f81e-40f0-af56-fef0d813c616 14019 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3b950 0xc001b3b951}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.128\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27fp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27fp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.128,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6d7c7305db63e66b9534babbbac26833c8288e56e6888e5cb4c06025660d4737,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.128,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-lfzwc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lfzwc webserver-deployment-845c8977d9- deployment-2416  114753c8-9192-4a0e-bd79-e3bbe3805aad 14044 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bb27 0xc001b3bb28}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9dw29,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9dw29,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.85,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3d7210f59fb57910f6756117fe387628bf042a2e88e383e42ce39b6b09a4fcd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-nnjtp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nnjtp webserver-deployment-845c8977d9- deployment-2416  2904b903-daeb-4b9c-994c-e9aa5e768255 14306 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bd00 0xc001b3bd01}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f4k8x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f4k8x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-ppkrw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ppkrw webserver-deployment-845c8977d9- deployment-2416  4fd91489-6861-44f9-b163-87858eefbb77 14229 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc001b3bf57 0xc001b3bf58}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpgjv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpgjv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.588: INFO: Pod "webserver-deployment-845c8977d9-pwdtc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-pwdtc webserver-deployment-845c8977d9- deployment-2416  046db13d-9f93-4050-b59a-39eba1535482 14204 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc0037fb147 0xc0037fb148}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zlvc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zlvc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-xjb6x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xjb6x webserver-deployment-845c8977d9- deployment-2416  98a86c7e-0bfd-4492-b3ee-900ec2e1e109 14251 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca2247 0xc003ca2248}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nkx4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nkx4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-xrjs8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xrjs8 webserver-deployment-845c8977d9- deployment-2416  00b1f51f-47de-41f3-8fdb-3db1243842bb 14010 0 2023-02-13 13:53:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca2407 0xc003ca2408}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpwng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpwng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-myudo,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.12,PodIP:10.244.1.60,StartTime:2023-02-13 13:53:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:53:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1c9986f454da7dd5694891c5dcd0ce32583d310dc4560b43f9db1460546de02c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 13:53:29.589: INFO: Pod "webserver-deployment-845c8977d9-zgzbx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zgzbx webserver-deployment-845c8977d9- deployment-2416  091ca94e-28c4-456f-934a-d049074e0ea6 14183 0 2023-02-13 13:53:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 89449047-641c-41eb-bd5c-b6703020f6fc 0xc003ca25e0 0xc003ca25e1}] [] [{kube-controller-manager Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"89449047-641c-41eb-bd5c-b6703020f6fc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:53:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgwp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgwp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:53:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2023-02-13 13:53:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:53:29.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2416" for this suite. 02/13/23 13:53:29.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:29.612
Feb 13 13:53:29.612: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 13:53:29.614
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:29.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:29.635
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Feb 13 13:53:29.639: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 13:53:31.805
Feb 13 13:53:31.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 create -f -'
Feb 13 13:53:32.497: INFO: stderr: ""
Feb 13 13:53:32.497: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 13 13:53:32.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 delete e2e-test-crd-publish-openapi-2548-crds test-cr'
Feb 13 13:53:32.607: INFO: stderr: ""
Feb 13 13:53:32.607: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 13 13:53:32.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 apply -f -'
Feb 13 13:53:32.846: INFO: stderr: ""
Feb 13 13:53:32.846: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 13 13:53:32.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 delete e2e-test-crd-publish-openapi-2548-crds test-cr'
Feb 13 13:53:32.933: INFO: stderr: ""
Feb 13 13:53:32.933: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 02/13/23 13:53:32.933
Feb 13 13:53:32.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 explain e2e-test-crd-publish-openapi-2548-crds'
Feb 13 13:53:33.173: INFO: stderr: ""
Feb 13 13:53:33.173: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2548-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:53:35.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6098" for this suite. 02/13/23 13:53:35.544
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":107,"skipped":1912,"failed":0}
------------------------------
• [SLOW TEST] [5.949 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:29.612
    Feb 13 13:53:29.612: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 13:53:29.614
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:29.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:29.635
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Feb 13 13:53:29.639: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 13:53:31.805
    Feb 13 13:53:31.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 create -f -'
    Feb 13 13:53:32.497: INFO: stderr: ""
    Feb 13 13:53:32.497: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Feb 13 13:53:32.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 delete e2e-test-crd-publish-openapi-2548-crds test-cr'
    Feb 13 13:53:32.607: INFO: stderr: ""
    Feb 13 13:53:32.607: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Feb 13 13:53:32.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 apply -f -'
    Feb 13 13:53:32.846: INFO: stderr: ""
    Feb 13 13:53:32.846: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Feb 13 13:53:32.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 --namespace=crd-publish-openapi-6098 delete e2e-test-crd-publish-openapi-2548-crds test-cr'
    Feb 13 13:53:32.933: INFO: stderr: ""
    Feb 13 13:53:32.933: INFO: stdout: "e2e-test-crd-publish-openapi-2548-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 02/13/23 13:53:32.933
    Feb 13 13:53:32.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-6098 explain e2e-test-crd-publish-openapi-2548-crds'
    Feb 13 13:53:33.173: INFO: stderr: ""
    Feb 13 13:53:33.173: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2548-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:53:35.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6098" for this suite. 02/13/23 13:53:35.544
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:35.563
Feb 13 13:53:35.563: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:53:35.564
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:35.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:35.585
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-e7bbcb07-994a-4cc4-82a7-c472d6776f48 02/13/23 13:53:35.589
STEP: Creating a pod to test consume configMaps 02/13/23 13:53:35.594
W0213 13:53:35.608497      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:35.608: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf" in namespace "projected-658" to be "Succeeded or Failed"
Feb 13 13:53:35.613: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198538ms
Feb 13 13:53:37.620: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011953074s
Feb 13 13:53:39.619: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010863011s
Feb 13 13:53:41.619: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011086385s
STEP: Saw pod success 02/13/23 13:53:41.619
Feb 13 13:53:41.620: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf" satisfied condition "Succeeded or Failed"
Feb 13 13:53:41.625: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:53:41.642
Feb 13 13:53:41.659: INFO: Waiting for pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf to disappear
Feb 13 13:53:41.664: INFO: Pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 13:53:41.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-658" for this suite. 02/13/23 13:53:41.669
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":108,"skipped":1987,"failed":0}
------------------------------
• [SLOW TEST] [6.112 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:35.563
    Feb 13 13:53:35.563: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:53:35.564
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:35.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:35.585
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-e7bbcb07-994a-4cc4-82a7-c472d6776f48 02/13/23 13:53:35.589
    STEP: Creating a pod to test consume configMaps 02/13/23 13:53:35.594
    W0213 13:53:35.608497      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:35.608: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf" in namespace "projected-658" to be "Succeeded or Failed"
    Feb 13 13:53:35.613: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198538ms
    Feb 13 13:53:37.620: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011953074s
    Feb 13 13:53:39.619: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010863011s
    Feb 13 13:53:41.619: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011086385s
    STEP: Saw pod success 02/13/23 13:53:41.619
    Feb 13 13:53:41.620: INFO: Pod "pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf" satisfied condition "Succeeded or Failed"
    Feb 13 13:53:41.625: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:53:41.642
    Feb 13 13:53:41.659: INFO: Waiting for pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf to disappear
    Feb 13 13:53:41.664: INFO: Pod pod-projected-configmaps-2b80188a-6ac3-40e2-ba68-e8d02f56c1cf no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 13:53:41.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-658" for this suite. 02/13/23 13:53:41.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:41.677
Feb 13 13:53:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:53:41.679
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:41.696
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:41.701
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Feb 13 13:53:41.707: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:53:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9485" for this suite. 02/13/23 13:53:42.75
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":109,"skipped":1992,"failed":0}
------------------------------
• [1.083 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:41.677
    Feb 13 13:53:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 13:53:41.679
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:41.696
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:41.701
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Feb 13 13:53:41.707: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:53:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9485" for this suite. 02/13/23 13:53:42.75
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:42.76
Feb 13 13:53:42.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:53:42.762
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:42.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:42.779
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5245 02/13/23 13:53:42.785
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[] 02/13/23 13:53:42.8
Feb 13 13:53:42.808: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5245 02/13/23 13:53:42.809
W0213 13:53:42.818260      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:42.819: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5245" to be "running and ready"
Feb 13 13:53:42.823: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.243311ms
Feb 13 13:53:42.823: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:53:44.832: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012957102s
Feb 13 13:53:44.832: INFO: The phase of Pod pod1 is Running (Ready = true)
Feb 13 13:53:44.832: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod1:[100]] 02/13/23 13:53:44.837
Feb 13 13:53:44.858: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5245 02/13/23 13:53:44.858
W0213 13:53:44.870781      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:44.871: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5245" to be "running and ready"
Feb 13 13:53:44.878: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.966667ms
Feb 13 13:53:44.879: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:53:46.887: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015504666s
Feb 13 13:53:46.887: INFO: The phase of Pod pod2 is Running (Ready = true)
Feb 13 13:53:46.887: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod1:[100] pod2:[101]] 02/13/23 13:53:46.893
Feb 13 13:53:46.916: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 02/13/23 13:53:46.916
Feb 13 13:53:46.917: INFO: Creating new exec pod
W0213 13:53:46.932931      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:46.933: INFO: Waiting up to 5m0s for pod "execpod7xf4z" in namespace "services-5245" to be "running"
Feb 13 13:53:46.938: INFO: Pod "execpod7xf4z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464346ms
Feb 13 13:53:48.945: INFO: Pod "execpod7xf4z": Phase="Running", Reason="", readiness=true. Elapsed: 2.011948895s
Feb 13 13:53:48.945: INFO: Pod "execpod7xf4z" satisfied condition "running"
Feb 13 13:53:49.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Feb 13 13:53:50.247: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Feb 13 13:53:50.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:53:50.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.199.181 80'
Feb 13 13:53:50.517: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.107.199.181 80\nConnection to 10.107.199.181 80 port [tcp/http] succeeded!\n"
Feb 13 13:53:50.517: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:53:50.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Feb 13 13:53:50.797: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Feb 13 13:53:50.797: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:53:50.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.199.181 81'
Feb 13 13:53:51.066: INFO: stderr: "+ nc -v -t -w 2 10.107.199.181 81\n+ echo hostName\nConnection to 10.107.199.181 81 port [tcp/*] succeeded!\n"
Feb 13 13:53:51.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5245 02/13/23 13:53:51.066
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod2:[101]] 02/13/23 13:53:51.098
Feb 13 13:53:51.113: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5245 02/13/23 13:53:51.113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[] 02/13/23 13:53:51.124
Feb 13 13:53:52.153: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:53:52.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5245" for this suite. 02/13/23 13:53:52.185
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":110,"skipped":1993,"failed":0}
------------------------------
• [SLOW TEST] [9.433 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:42.76
    Feb 13 13:53:42.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:53:42.762
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:42.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:42.779
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5245 02/13/23 13:53:42.785
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[] 02/13/23 13:53:42.8
    Feb 13 13:53:42.808: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5245 02/13/23 13:53:42.809
    W0213 13:53:42.818260      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:42.819: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5245" to be "running and ready"
    Feb 13 13:53:42.823: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.243311ms
    Feb 13 13:53:42.823: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:53:44.832: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012957102s
    Feb 13 13:53:44.832: INFO: The phase of Pod pod1 is Running (Ready = true)
    Feb 13 13:53:44.832: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod1:[100]] 02/13/23 13:53:44.837
    Feb 13 13:53:44.858: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5245 02/13/23 13:53:44.858
    W0213 13:53:44.870781      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:44.871: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5245" to be "running and ready"
    Feb 13 13:53:44.878: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.966667ms
    Feb 13 13:53:44.879: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:53:46.887: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015504666s
    Feb 13 13:53:46.887: INFO: The phase of Pod pod2 is Running (Ready = true)
    Feb 13 13:53:46.887: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod1:[100] pod2:[101]] 02/13/23 13:53:46.893
    Feb 13 13:53:46.916: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 02/13/23 13:53:46.916
    Feb 13 13:53:46.917: INFO: Creating new exec pod
    W0213 13:53:46.932931      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:46.933: INFO: Waiting up to 5m0s for pod "execpod7xf4z" in namespace "services-5245" to be "running"
    Feb 13 13:53:46.938: INFO: Pod "execpod7xf4z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464346ms
    Feb 13 13:53:48.945: INFO: Pod "execpod7xf4z": Phase="Running", Reason="", readiness=true. Elapsed: 2.011948895s
    Feb 13 13:53:48.945: INFO: Pod "execpod7xf4z" satisfied condition "running"
    Feb 13 13:53:49.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Feb 13 13:53:50.247: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Feb 13 13:53:50.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:53:50.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.199.181 80'
    Feb 13 13:53:50.517: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.107.199.181 80\nConnection to 10.107.199.181 80 port [tcp/http] succeeded!\n"
    Feb 13 13:53:50.517: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:53:50.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Feb 13 13:53:50.797: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Feb 13 13:53:50.797: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:53:50.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5245 exec execpod7xf4z -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.199.181 81'
    Feb 13 13:53:51.066: INFO: stderr: "+ nc -v -t -w 2 10.107.199.181 81\n+ echo hostName\nConnection to 10.107.199.181 81 port [tcp/*] succeeded!\n"
    Feb 13 13:53:51.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5245 02/13/23 13:53:51.066
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[pod2:[101]] 02/13/23 13:53:51.098
    Feb 13 13:53:51.113: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5245 02/13/23 13:53:51.113
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5245 to expose endpoints map[] 02/13/23 13:53:51.124
    Feb 13 13:53:52.153: INFO: successfully validated that service multi-endpoint-test in namespace services-5245 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:53:52.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5245" for this suite. 02/13/23 13:53:52.185
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:52.199
Feb 13 13:53:52.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:53:52.201
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:52.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:52.218
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 02/13/23 13:53:52.226
STEP: waiting for available Endpoint 02/13/23 13:53:52.23
STEP: listing all Endpoints 02/13/23 13:53:52.233
STEP: updating the Endpoint 02/13/23 13:53:52.236
STEP: fetching the Endpoint 02/13/23 13:53:52.244
STEP: patching the Endpoint 02/13/23 13:53:52.246
STEP: fetching the Endpoint 02/13/23 13:53:52.255
STEP: deleting the Endpoint by Collection 02/13/23 13:53:52.258
STEP: waiting for Endpoint deletion 02/13/23 13:53:52.263
STEP: fetching the Endpoint 02/13/23 13:53:52.266
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:53:52.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3549" for this suite. 02/13/23 13:53:52.273
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":111,"skipped":2011,"failed":0}
------------------------------
• [0.080 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:52.199
    Feb 13 13:53:52.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:53:52.201
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:52.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:52.218
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 02/13/23 13:53:52.226
    STEP: waiting for available Endpoint 02/13/23 13:53:52.23
    STEP: listing all Endpoints 02/13/23 13:53:52.233
    STEP: updating the Endpoint 02/13/23 13:53:52.236
    STEP: fetching the Endpoint 02/13/23 13:53:52.244
    STEP: patching the Endpoint 02/13/23 13:53:52.246
    STEP: fetching the Endpoint 02/13/23 13:53:52.255
    STEP: deleting the Endpoint by Collection 02/13/23 13:53:52.258
    STEP: waiting for Endpoint deletion 02/13/23 13:53:52.263
    STEP: fetching the Endpoint 02/13/23 13:53:52.266
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:53:52.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3549" for this suite. 02/13/23 13:53:52.273
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:52.287
Feb 13 13:53:52.287: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 13:53:52.289
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:52.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:52.309
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 02/13/23 13:53:52.313
W0213 13:53:52.322785      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:52.323: INFO: Waiting up to 5m0s for pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2" in namespace "emptydir-3252" to be "Succeeded or Failed"
Feb 13 13:53:52.330: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.420719ms
Feb 13 13:53:54.335: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012352349s
Feb 13 13:53:56.336: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013469067s
STEP: Saw pod success 02/13/23 13:53:56.337
Feb 13 13:53:56.337: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2" satisfied condition "Succeeded or Failed"
Feb 13 13:53:56.343: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 container test-container: <nil>
STEP: delete the pod 02/13/23 13:53:56.356
Feb 13 13:53:56.373: INFO: Waiting for pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 to disappear
Feb 13 13:53:56.377: INFO: Pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 13:53:56.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3252" for this suite. 02/13/23 13:53:56.383
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":112,"skipped":2048,"failed":0}
------------------------------
• [4.103 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:52.287
    Feb 13 13:53:52.287: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 13:53:52.289
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:52.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:52.309
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 02/13/23 13:53:52.313
    W0213 13:53:52.322785      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:52.323: INFO: Waiting up to 5m0s for pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2" in namespace "emptydir-3252" to be "Succeeded or Failed"
    Feb 13 13:53:52.330: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.420719ms
    Feb 13 13:53:54.335: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012352349s
    Feb 13 13:53:56.336: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013469067s
    STEP: Saw pod success 02/13/23 13:53:56.337
    Feb 13 13:53:56.337: INFO: Pod "pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2" satisfied condition "Succeeded or Failed"
    Feb 13 13:53:56.343: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 container test-container: <nil>
    STEP: delete the pod 02/13/23 13:53:56.356
    Feb 13 13:53:56.373: INFO: Waiting for pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 to disappear
    Feb 13 13:53:56.377: INFO: Pod pod-096722b1-efa2-4769-aa60-0dd4ab43c9c2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 13:53:56.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3252" for this suite. 02/13/23 13:53:56.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:53:56.404
Feb 13 13:53:56.404: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 13:53:56.406
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:56.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:56.43
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-56691014-3c51-43b6-aae2-53fd6c04207a 02/13/23 13:53:56.435
STEP: Creating a pod to test consume configMaps 02/13/23 13:53:56.44
W0213 13:53:56.449413      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:53:56.449: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943" in namespace "configmap-9801" to be "Succeeded or Failed"
Feb 13 13:53:56.455: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Pending", Reason="", readiness=false. Elapsed: 6.225499ms
Feb 13 13:53:58.463: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013880685s
Feb 13 13:54:00.463: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013717845s
STEP: Saw pod success 02/13/23 13:54:00.463
Feb 13 13:54:00.464: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943" satisfied condition "Succeeded or Failed"
Feb 13 13:54:00.470: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:54:00.482
Feb 13 13:54:00.496: INFO: Waiting for pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 to disappear
Feb 13 13:54:00.499: INFO: Pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 13:54:00.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9801" for this suite. 02/13/23 13:54:00.504
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":113,"skipped":2085,"failed":0}
------------------------------
• [4.107 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:53:56.404
    Feb 13 13:53:56.404: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 13:53:56.406
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:53:56.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:53:56.43
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-56691014-3c51-43b6-aae2-53fd6c04207a 02/13/23 13:53:56.435
    STEP: Creating a pod to test consume configMaps 02/13/23 13:53:56.44
    W0213 13:53:56.449413      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:53:56.449: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943" in namespace "configmap-9801" to be "Succeeded or Failed"
    Feb 13 13:53:56.455: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Pending", Reason="", readiness=false. Elapsed: 6.225499ms
    Feb 13 13:53:58.463: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013880685s
    Feb 13 13:54:00.463: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013717845s
    STEP: Saw pod success 02/13/23 13:54:00.463
    Feb 13 13:54:00.464: INFO: Pod "pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943" satisfied condition "Succeeded or Failed"
    Feb 13 13:54:00.470: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:54:00.482
    Feb 13 13:54:00.496: INFO: Waiting for pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 to disappear
    Feb 13 13:54:00.499: INFO: Pod pod-configmaps-ff1b47c3-785a-4e48-aa4b-0562a5eb9943 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 13:54:00.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9801" for this suite. 02/13/23 13:54:00.504
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:00.522
Feb 13 13:54:00.522: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename ingressclass 02/13/23 13:54:00.524
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.547
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 02/13/23 13:54:00.553
STEP: getting /apis/networking.k8s.io 02/13/23 13:54:00.557
STEP: getting /apis/networking.k8s.iov1 02/13/23 13:54:00.559
STEP: creating 02/13/23 13:54:00.562
STEP: getting 02/13/23 13:54:00.584
STEP: listing 02/13/23 13:54:00.588
STEP: watching 02/13/23 13:54:00.592
Feb 13 13:54:00.592: INFO: starting watch
STEP: patching 02/13/23 13:54:00.595
STEP: updating 02/13/23 13:54:00.601
Feb 13 13:54:00.608: INFO: waiting for watch events with expected annotations
Feb 13 13:54:00.608: INFO: saw patched and updated annotations
STEP: deleting 02/13/23 13:54:00.608
STEP: deleting a collection 02/13/23 13:54:00.618
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Feb 13 13:54:00.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-9773" for this suite. 02/13/23 13:54:00.632
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":114,"skipped":2104,"failed":0}
------------------------------
• [0.115 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:00.522
    Feb 13 13:54:00.522: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename ingressclass 02/13/23 13:54:00.524
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.547
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 02/13/23 13:54:00.553
    STEP: getting /apis/networking.k8s.io 02/13/23 13:54:00.557
    STEP: getting /apis/networking.k8s.iov1 02/13/23 13:54:00.559
    STEP: creating 02/13/23 13:54:00.562
    STEP: getting 02/13/23 13:54:00.584
    STEP: listing 02/13/23 13:54:00.588
    STEP: watching 02/13/23 13:54:00.592
    Feb 13 13:54:00.592: INFO: starting watch
    STEP: patching 02/13/23 13:54:00.595
    STEP: updating 02/13/23 13:54:00.601
    Feb 13 13:54:00.608: INFO: waiting for watch events with expected annotations
    Feb 13 13:54:00.608: INFO: saw patched and updated annotations
    STEP: deleting 02/13/23 13:54:00.608
    STEP: deleting a collection 02/13/23 13:54:00.618
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Feb 13 13:54:00.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-9773" for this suite. 02/13/23 13:54:00.632
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:00.648
Feb 13 13:54:00.648: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 13:54:00.65
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.668
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 02/13/23 13:54:00.672
STEP: submitting the pod to kubernetes 02/13/23 13:54:00.672
W0213 13:54:00.683386      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: verifying QOS class is set on the pod 02/13/23 13:54:00.683
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Feb 13 13:54:00.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7900" for this suite. 02/13/23 13:54:00.692
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":115,"skipped":2124,"failed":0}
------------------------------
• [0.055 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:00.648
    Feb 13 13:54:00.648: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 13:54:00.65
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.668
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 02/13/23 13:54:00.672
    STEP: submitting the pod to kubernetes 02/13/23 13:54:00.672
    W0213 13:54:00.683386      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: verifying QOS class is set on the pod 02/13/23 13:54:00.683
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Feb 13 13:54:00.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7900" for this suite. 02/13/23 13:54:00.692
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:00.706
Feb 13 13:54:00.707: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 13:54:00.711
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.731
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Feb 13 13:54:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: creating the pod 02/13/23 13:54:00.739
STEP: submitting the pod to kubernetes 02/13/23 13:54:00.739
Feb 13 13:54:00.753: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f" in namespace "pods-4669" to be "running and ready"
Feb 13 13:54:00.757: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.159952ms
Feb 13 13:54:00.757: INFO: The phase of Pod pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:54:02.764: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010571973s
Feb 13 13:54:02.764: INFO: The phase of Pod pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f is Running (Ready = true)
Feb 13 13:54:02.764: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 13:54:02.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4669" for this suite. 02/13/23 13:54:02.894
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":116,"skipped":2144,"failed":0}
------------------------------
• [2.195 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:00.706
    Feb 13 13:54:00.707: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 13:54:00.711
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:00.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:00.731
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Feb 13 13:54:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: creating the pod 02/13/23 13:54:00.739
    STEP: submitting the pod to kubernetes 02/13/23 13:54:00.739
    Feb 13 13:54:00.753: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f" in namespace "pods-4669" to be "running and ready"
    Feb 13 13:54:00.757: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.159952ms
    Feb 13 13:54:00.757: INFO: The phase of Pod pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:54:02.764: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010571973s
    Feb 13 13:54:02.764: INFO: The phase of Pod pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f is Running (Ready = true)
    Feb 13 13:54:02.764: INFO: Pod "pod-exec-websocket-911943d5-e52f-4890-8926-dce060a1c42f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 13:54:02.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4669" for this suite. 02/13/23 13:54:02.894
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:02.906
Feb 13 13:54:02.906: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 13:54:02.909
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:02.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:02.935
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c in namespace container-probe-244 02/13/23 13:54:02.939
W0213 13:54:02.950808      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:54:02.951: INFO: Waiting up to 5m0s for pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c" in namespace "container-probe-244" to be "not pending"
Feb 13 13:54:02.955: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129919ms
Feb 13 13:54:04.961: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010548337s
Feb 13 13:54:04.961: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c" satisfied condition "not pending"
Feb 13 13:54:04.961: INFO: Started pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c in namespace container-probe-244
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 13:54:04.961
Feb 13 13:54:04.965: INFO: Initial restart count of pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c is 0
Feb 13 13:54:55.140: INFO: Restart count of pod container-probe-244/busybox-d6bca680-5775-494e-a1fc-4bff9d69885c is now 1 (50.175089097s elapsed)
STEP: deleting the pod 02/13/23 13:54:55.14
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 13:54:55.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-244" for this suite. 02/13/23 13:54:55.156
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":117,"skipped":2154,"failed":0}
------------------------------
• [SLOW TEST] [52.260 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:02.906
    Feb 13 13:54:02.906: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 13:54:02.909
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:02.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:02.935
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c in namespace container-probe-244 02/13/23 13:54:02.939
    W0213 13:54:02.950808      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:54:02.951: INFO: Waiting up to 5m0s for pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c" in namespace "container-probe-244" to be "not pending"
    Feb 13 13:54:02.955: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129919ms
    Feb 13 13:54:04.961: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010548337s
    Feb 13 13:54:04.961: INFO: Pod "busybox-d6bca680-5775-494e-a1fc-4bff9d69885c" satisfied condition "not pending"
    Feb 13 13:54:04.961: INFO: Started pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c in namespace container-probe-244
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 13:54:04.961
    Feb 13 13:54:04.965: INFO: Initial restart count of pod busybox-d6bca680-5775-494e-a1fc-4bff9d69885c is 0
    Feb 13 13:54:55.140: INFO: Restart count of pod container-probe-244/busybox-d6bca680-5775-494e-a1fc-4bff9d69885c is now 1 (50.175089097s elapsed)
    STEP: deleting the pod 02/13/23 13:54:55.14
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 13:54:55.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-244" for this suite. 02/13/23 13:54:55.156
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:55.173
Feb 13 13:54:55.174: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replication-controller 02/13/23 13:54:55.176
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:55.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:55.199
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Feb 13 13:54:55.205: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 02/13/23 13:54:55.218
W0213 13:54:55.227881      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Checking rc "condition-test" has the desired failure condition set 02/13/23 13:54:55.228
STEP: Scaling down rc "condition-test" to satisfy pod quota 02/13/23 13:54:56.238
W0213 13:54:56.254953      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:54:56.255: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 02/13/23 13:54:56.255
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Feb 13 13:54:57.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1619" for this suite. 02/13/23 13:54:57.27
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":118,"skipped":2170,"failed":0}
------------------------------
• [2.103 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:55.173
    Feb 13 13:54:55.174: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replication-controller 02/13/23 13:54:55.176
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:55.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:55.199
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Feb 13 13:54:55.205: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 02/13/23 13:54:55.218
    W0213 13:54:55.227881      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Checking rc "condition-test" has the desired failure condition set 02/13/23 13:54:55.228
    STEP: Scaling down rc "condition-test" to satisfy pod quota 02/13/23 13:54:56.238
    W0213 13:54:56.254953      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:54:56.255: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 02/13/23 13:54:56.255
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Feb 13 13:54:57.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1619" for this suite. 02/13/23 13:54:57.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:54:57.278
Feb 13 13:54:57.278: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:54:57.279
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:57.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:57.296
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:54:57.3
W0213 13:54:57.309505      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:54:57.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978" in namespace "downward-api-4552" to be "Succeeded or Failed"
Feb 13 13:54:57.318: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Pending", Reason="", readiness=false. Elapsed: 8.282089ms
Feb 13 13:54:59.329: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019182186s
Feb 13 13:55:01.327: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017459247s
STEP: Saw pod success 02/13/23 13:55:01.327
Feb 13 13:55:01.328: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978" satisfied condition "Succeeded or Failed"
Feb 13 13:55:01.333: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 container client-container: <nil>
STEP: delete the pod 02/13/23 13:55:01.346
Feb 13 13:55:01.367: INFO: Waiting for pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 to disappear
Feb 13 13:55:01.372: INFO: Pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:55:01.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4552" for this suite. 02/13/23 13:55:01.379
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":119,"skipped":2180,"failed":0}
------------------------------
• [4.115 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:54:57.278
    Feb 13 13:54:57.278: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:54:57.279
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:54:57.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:54:57.296
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:54:57.3
    W0213 13:54:57.309505      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:54:57.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978" in namespace "downward-api-4552" to be "Succeeded or Failed"
    Feb 13 13:54:57.318: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Pending", Reason="", readiness=false. Elapsed: 8.282089ms
    Feb 13 13:54:59.329: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019182186s
    Feb 13 13:55:01.327: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017459247s
    STEP: Saw pod success 02/13/23 13:55:01.327
    Feb 13 13:55:01.328: INFO: Pod "downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978" satisfied condition "Succeeded or Failed"
    Feb 13 13:55:01.333: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:55:01.346
    Feb 13 13:55:01.367: INFO: Waiting for pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 to disappear
    Feb 13 13:55:01.372: INFO: Pod downwardapi-volume-1758363c-a634-4e4a-992a-2b3e5d826978 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:55:01.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4552" for this suite. 02/13/23 13:55:01.379
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:01.412
Feb 13 13:55:01.412: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename aggregator 02/13/23 13:55:01.414
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:01.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:01.44
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Feb 13 13:55:01.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 02/13/23 13:55:01.448
W0213 13:55:02.158724      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "sample-apiserver", "etcd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "sample-apiserver", "etcd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "sample-apiserver", "etcd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "sample-apiserver", "etcd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:55:02.175: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 13 13:55:04.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:06.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:08.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:10.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:12.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:14.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:16.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:18.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:20.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:22.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:24.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 13:55:26.390: INFO: Waited 139.489244ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 02/13/23 13:55:26.481
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 02/13/23 13:55:26.486
STEP: List APIServices 02/13/23 13:55:26.502
Feb 13 13:55:26.512: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Feb 13 13:55:26.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-809" for this suite. 02/13/23 13:55:26.678
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":120,"skipped":2274,"failed":0}
------------------------------
• [SLOW TEST] [25.272 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:01.412
    Feb 13 13:55:01.412: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename aggregator 02/13/23 13:55:01.414
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:01.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:01.44
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Feb 13 13:55:01.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 02/13/23 13:55:01.448
    W0213 13:55:02.158724      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "sample-apiserver", "etcd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "sample-apiserver", "etcd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "sample-apiserver", "etcd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "sample-apiserver", "etcd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:55:02.175: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Feb 13 13:55:04.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:06.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:08.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:10.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:12.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:14.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:16.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:18.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:20.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:22.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:24.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 55, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 13:55:26.390: INFO: Waited 139.489244ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 02/13/23 13:55:26.481
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 02/13/23 13:55:26.486
    STEP: List APIServices 02/13/23 13:55:26.502
    Feb 13 13:55:26.512: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Feb 13 13:55:26.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-809" for this suite. 02/13/23 13:55:26.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:26.69
Feb 13 13:55:26.690: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption 02/13/23 13:55:26.691
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:26.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:26.707
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 02/13/23 13:55:26.709
STEP: Waiting for the pdb to be processed 02/13/23 13:55:26.713
STEP: updating the pdb 02/13/23 13:55:28.722
STEP: Waiting for the pdb to be processed 02/13/23 13:55:28.738
STEP: patching the pdb 02/13/23 13:55:30.751
STEP: Waiting for the pdb to be processed 02/13/23 13:55:30.769
STEP: Waiting for the pdb to be deleted 02/13/23 13:55:30.79
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Feb 13 13:55:30.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7394" for this suite. 02/13/23 13:55:30.799
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":121,"skipped":2284,"failed":0}
------------------------------
• [4.119 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:26.69
    Feb 13 13:55:26.690: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption 02/13/23 13:55:26.691
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:26.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:26.707
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 02/13/23 13:55:26.709
    STEP: Waiting for the pdb to be processed 02/13/23 13:55:26.713
    STEP: updating the pdb 02/13/23 13:55:28.722
    STEP: Waiting for the pdb to be processed 02/13/23 13:55:28.738
    STEP: patching the pdb 02/13/23 13:55:30.751
    STEP: Waiting for the pdb to be processed 02/13/23 13:55:30.769
    STEP: Waiting for the pdb to be deleted 02/13/23 13:55:30.79
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Feb 13 13:55:30.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-7394" for this suite. 02/13/23 13:55:30.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:30.812
Feb 13 13:55:30.812: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 13:55:30.813
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:30.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:30.846
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 02/13/23 13:55:30.858
W0213 13:55:30.868485      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:55:30.869: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8599" to be "running and ready"
Feb 13 13:55:30.872: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.385887ms
Feb 13 13:55:30.872: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:55:32.877: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008833637s
Feb 13 13:55:32.877: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Feb 13 13:55:32.877: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 02/13/23 13:55:32.882
W0213 13:55:32.889604      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:55:32.889: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-8599" to be "running and ready"
Feb 13 13:55:32.899: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.734699ms
Feb 13 13:55:32.899: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:55:34.903: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014193173s
Feb 13 13:55:34.903: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Feb 13 13:55:34.903: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 02/13/23 13:55:34.906
STEP: delete the pod with lifecycle hook 02/13/23 13:55:34.913
Feb 13 13:55:34.922: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 13:55:34.925: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 13:55:36.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 13:55:36.934: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 13:55:38.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 13:55:38.932: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Feb 13 13:55:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8599" for this suite. 02/13/23 13:55:38.938
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":122,"skipped":2290,"failed":0}
------------------------------
• [SLOW TEST] [8.133 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:30.812
    Feb 13 13:55:30.812: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 13:55:30.813
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:30.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:30.846
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 02/13/23 13:55:30.858
    W0213 13:55:30.868485      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:55:30.869: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8599" to be "running and ready"
    Feb 13 13:55:30.872: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.385887ms
    Feb 13 13:55:30.872: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:55:32.877: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008833637s
    Feb 13 13:55:32.877: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Feb 13 13:55:32.877: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 02/13/23 13:55:32.882
    W0213 13:55:32.889604      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:55:32.889: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-8599" to be "running and ready"
    Feb 13 13:55:32.899: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.734699ms
    Feb 13 13:55:32.899: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:55:34.903: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014193173s
    Feb 13 13:55:34.903: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Feb 13 13:55:34.903: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 02/13/23 13:55:34.906
    STEP: delete the pod with lifecycle hook 02/13/23 13:55:34.913
    Feb 13 13:55:34.922: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Feb 13 13:55:34.925: INFO: Pod pod-with-poststart-http-hook still exists
    Feb 13 13:55:36.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Feb 13 13:55:36.934: INFO: Pod pod-with-poststart-http-hook still exists
    Feb 13 13:55:38.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Feb 13 13:55:38.932: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Feb 13 13:55:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8599" for this suite. 02/13/23 13:55:38.938
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:38.952
Feb 13 13:55:38.953: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:55:38.955
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:38.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:38.979
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:55:38.984
W0213 13:55:38.991670      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:55:38.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726" in namespace "downward-api-5065" to be "Succeeded or Failed"
Feb 13 13:55:38.994: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545148ms
Feb 13 13:55:41.011: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01950707s
Feb 13 13:55:43.002: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010986955s
STEP: Saw pod success 02/13/23 13:55:43.003
Feb 13 13:55:43.003: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726" satisfied condition "Succeeded or Failed"
Feb 13 13:55:43.010: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 container client-container: <nil>
STEP: delete the pod 02/13/23 13:55:43.046
Feb 13 13:55:43.061: INFO: Waiting for pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 to disappear
Feb 13 13:55:43.066: INFO: Pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:55:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5065" for this suite. 02/13/23 13:55:43.073
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":123,"skipped":2294,"failed":0}
------------------------------
• [4.129 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:38.952
    Feb 13 13:55:38.953: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:55:38.955
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:38.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:38.979
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:55:38.984
    W0213 13:55:38.991670      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:55:38.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726" in namespace "downward-api-5065" to be "Succeeded or Failed"
    Feb 13 13:55:38.994: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545148ms
    Feb 13 13:55:41.011: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01950707s
    Feb 13 13:55:43.002: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010986955s
    STEP: Saw pod success 02/13/23 13:55:43.003
    Feb 13 13:55:43.003: INFO: Pod "downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726" satisfied condition "Succeeded or Failed"
    Feb 13 13:55:43.010: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 container client-container: <nil>
    STEP: delete the pod 02/13/23 13:55:43.046
    Feb 13 13:55:43.061: INFO: Waiting for pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 to disappear
    Feb 13 13:55:43.066: INFO: Pod downwardapi-volume-fa7d7c98-8130-44e2-9a13-3dfe2551b726 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:55:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5065" for this suite. 02/13/23 13:55:43.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:43.091
Feb 13 13:55:43.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 13:55:43.093
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:43.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:43.115
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 13:55:43.134
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:55:43.559
STEP: Deploying the webhook pod 02/13/23 13:55:43.575
W0213 13:55:43.595049      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 13:55:43.595
Feb 13 13:55:43.606: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 13:55:45.624
STEP: Verifying the service has paired with the endpoint 02/13/23 13:55:45.64
Feb 13 13:55:46.641: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Feb 13 13:55:46.647: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Registering the custom resource webhook via the AdmissionRegistration API 02/13/23 13:55:47.164
STEP: Creating a custom resource that should be denied by the webhook 02/13/23 13:55:47.197
STEP: Creating a custom resource whose deletion would be denied by the webhook 02/13/23 13:55:49.282
STEP: Updating the custom resource with disallowed data should be denied 02/13/23 13:55:49.297
STEP: Deleting the custom resource should be denied 02/13/23 13:55:49.312
STEP: Remove the offending key and value from the custom resource data 02/13/23 13:55:49.323
STEP: Deleting the updated custom resource should be successful 02/13/23 13:55:49.342
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:55:49.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3123" for this suite. 02/13/23 13:55:49.898
STEP: Destroying namespace "webhook-3123-markers" for this suite. 02/13/23 13:55:49.909
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":124,"skipped":2305,"failed":0}
------------------------------
• [SLOW TEST] [6.869 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:43.091
    Feb 13 13:55:43.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 13:55:43.093
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:43.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:43.115
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 13:55:43.134
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 13:55:43.559
    STEP: Deploying the webhook pod 02/13/23 13:55:43.575
    W0213 13:55:43.595049      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 13:55:43.595
    Feb 13 13:55:43.606: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 13:55:45.624
    STEP: Verifying the service has paired with the endpoint 02/13/23 13:55:45.64
    Feb 13 13:55:46.641: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Feb 13 13:55:46.647: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 02/13/23 13:55:47.164
    STEP: Creating a custom resource that should be denied by the webhook 02/13/23 13:55:47.197
    STEP: Creating a custom resource whose deletion would be denied by the webhook 02/13/23 13:55:49.282
    STEP: Updating the custom resource with disallowed data should be denied 02/13/23 13:55:49.297
    STEP: Deleting the custom resource should be denied 02/13/23 13:55:49.312
    STEP: Remove the offending key and value from the custom resource data 02/13/23 13:55:49.323
    STEP: Deleting the updated custom resource should be successful 02/13/23 13:55:49.342
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:55:49.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3123" for this suite. 02/13/23 13:55:49.898
    STEP: Destroying namespace "webhook-3123-markers" for this suite. 02/13/23 13:55:49.909
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:49.976
Feb 13 13:55:49.976: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 13:55:49.977
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:49.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:49.997
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-7998 02/13/23 13:55:50
STEP: creating service affinity-nodeport in namespace services-7998 02/13/23 13:55:50
STEP: creating replication controller affinity-nodeport in namespace services-7998 02/13/23 13:55:50.015
W0213 13:55:50.023644      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 13:55:50.024000      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-7998, replica count: 3
I0213 13:55:53.075157      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 13:55:53.093: INFO: Creating new exec pod
W0213 13:55:53.104885      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:55:53.105: INFO: Waiting up to 5m0s for pod "execpod-affinitywwng8" in namespace "services-7998" to be "running"
Feb 13 13:55:53.109: INFO: Pod "execpod-affinitywwng8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28322ms
Feb 13 13:55:55.112: INFO: Pod "execpod-affinitywwng8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007138377s
Feb 13 13:55:55.112: INFO: Pod "execpod-affinitywwng8" satisfied condition "running"
Feb 13 13:55:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Feb 13 13:55:56.378: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Feb 13 13:55:56.378: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:55:56.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.160.230 80'
Feb 13 13:55:56.610: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.102.160.230 80\nConnection to 10.102.160.230 80 port [tcp/http] succeeded!\n"
Feb 13 13:55:56.610: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:55:56.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 31562'
Feb 13 13:55:56.846: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 31562\nConnection to 192.168.1.12 31562 port [tcp/*] succeeded!\n"
Feb 13 13:55:56.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:55:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 31562'
Feb 13 13:55:57.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 31562\nConnection to 192.168.1.10 31562 port [tcp/*] succeeded!\n"
Feb 13 13:55:57.070: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 13:55:57.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:31562/ ; done'
Feb 13 13:55:57.483: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n"
Feb 13 13:55:57.483: INFO: stdout: "\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw"
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
Feb 13 13:55:57.483: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-7998, will wait for the garbage collector to delete the pods 02/13/23 13:55:57.502
Feb 13 13:55:57.566: INFO: Deleting ReplicationController affinity-nodeport took: 9.774869ms
Feb 13 13:55:57.667: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.628555ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 13:55:59.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7998" for this suite. 02/13/23 13:55:59.307
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":125,"skipped":2391,"failed":0}
------------------------------
• [SLOW TEST] [9.338 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:49.976
    Feb 13 13:55:49.976: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 13:55:49.977
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:49.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:49.997
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-7998 02/13/23 13:55:50
    STEP: creating service affinity-nodeport in namespace services-7998 02/13/23 13:55:50
    STEP: creating replication controller affinity-nodeport in namespace services-7998 02/13/23 13:55:50.015
    W0213 13:55:50.023644      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 13:55:50.024000      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-7998, replica count: 3
    I0213 13:55:53.075157      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 13:55:53.093: INFO: Creating new exec pod
    W0213 13:55:53.104885      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:55:53.105: INFO: Waiting up to 5m0s for pod "execpod-affinitywwng8" in namespace "services-7998" to be "running"
    Feb 13 13:55:53.109: INFO: Pod "execpod-affinitywwng8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28322ms
    Feb 13 13:55:55.112: INFO: Pod "execpod-affinitywwng8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007138377s
    Feb 13 13:55:55.112: INFO: Pod "execpod-affinitywwng8" satisfied condition "running"
    Feb 13 13:55:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Feb 13 13:55:56.378: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Feb 13 13:55:56.378: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:55:56.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.160.230 80'
    Feb 13 13:55:56.610: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.102.160.230 80\nConnection to 10.102.160.230 80 port [tcp/http] succeeded!\n"
    Feb 13 13:55:56.610: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:55:56.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 31562'
    Feb 13 13:55:56.846: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 31562\nConnection to 192.168.1.12 31562 port [tcp/*] succeeded!\n"
    Feb 13 13:55:56.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:55:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 31562'
    Feb 13 13:55:57.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 31562\nConnection to 192.168.1.10 31562 port [tcp/*] succeeded!\n"
    Feb 13 13:55:57.070: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 13:55:57.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-7998 exec execpod-affinitywwng8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:31562/ ; done'
    Feb 13 13:55:57.483: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31562/\n"
    Feb 13 13:55:57.483: INFO: stdout: "\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw\naffinity-nodeport-5kflw"
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Received response from host: affinity-nodeport-5kflw
    Feb 13 13:55:57.483: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-7998, will wait for the garbage collector to delete the pods 02/13/23 13:55:57.502
    Feb 13 13:55:57.566: INFO: Deleting ReplicationController affinity-nodeport took: 9.774869ms
    Feb 13 13:55:57.667: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.628555ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 13:55:59.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7998" for this suite. 02/13/23 13:55:59.307
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:55:59.316
Feb 13 13:55:59.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:55:59.317
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:59.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:59.332
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Feb 13 13:55:59.351: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 13:56:59.383: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 02/13/23 13:56:59.387
Feb 13 13:56:59.419: INFO: Created pod: pod0-0-sched-preemption-low-priority
Feb 13 13:56:59.431: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Feb 13 13:56:59.455: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Feb 13 13:56:59.464: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Feb 13 13:56:59.481: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Feb 13 13:56:59.489: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 02/13/23 13:56:59.49
Feb 13 13:56:59.490: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:56:59.496: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.409826ms
Feb 13 13:57:01.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015382434s
Feb 13 13:57:03.503: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012693778s
Feb 13 13:57:05.502: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012061587s
Feb 13 13:57:07.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013767911s
Feb 13 13:57:09.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014671475s
Feb 13 13:57:11.503: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.013514177s
Feb 13 13:57:11.504: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Feb 13 13:57:11.504: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:57:11.510: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.024021ms
Feb 13 13:57:11.510: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:57:11.510: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:57:11.518: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.489655ms
Feb 13 13:57:11.518: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:57:11.518: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:57:11.524: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.36765ms
Feb 13 13:57:11.524: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:57:11.524: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:57:11.529: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.842916ms
Feb 13 13:57:11.529: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:57:11.529: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
Feb 13 13:57:11.534: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.491601ms
Feb 13 13:57:11.534: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 02/13/23 13:57:11.534
Feb 13 13:57:11.553: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Feb 13 13:57:11.557: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307095ms
Feb 13 13:57:13.564: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011282909s
Feb 13 13:57:15.563: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010310638s
Feb 13 13:57:15.563: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:57:15.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8020" for this suite. 02/13/23 13:57:15.609
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":126,"skipped":2397,"failed":0}
------------------------------
• [SLOW TEST] [76.352 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:55:59.316
    Feb 13 13:55:59.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:55:59.317
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:55:59.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:55:59.332
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Feb 13 13:55:59.351: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 13:56:59.383: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 02/13/23 13:56:59.387
    Feb 13 13:56:59.419: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Feb 13 13:56:59.431: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Feb 13 13:56:59.455: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Feb 13 13:56:59.464: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Feb 13 13:56:59.481: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Feb 13 13:56:59.489: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 02/13/23 13:56:59.49
    Feb 13 13:56:59.490: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:56:59.496: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.409826ms
    Feb 13 13:57:01.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015382434s
    Feb 13 13:57:03.503: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012693778s
    Feb 13 13:57:05.502: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012061587s
    Feb 13 13:57:07.504: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013767911s
    Feb 13 13:57:09.505: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014671475s
    Feb 13 13:57:11.503: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.013514177s
    Feb 13 13:57:11.504: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Feb 13 13:57:11.504: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:57:11.510: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.024021ms
    Feb 13 13:57:11.510: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:57:11.510: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:57:11.518: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.489655ms
    Feb 13 13:57:11.518: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:57:11.518: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:57:11.524: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.36765ms
    Feb 13 13:57:11.524: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:57:11.524: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:57:11.529: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.842916ms
    Feb 13 13:57:11.529: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:57:11.529: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8020" to be "running"
    Feb 13 13:57:11.534: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.491601ms
    Feb 13 13:57:11.534: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 02/13/23 13:57:11.534
    Feb 13 13:57:11.553: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Feb 13 13:57:11.557: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307095ms
    Feb 13 13:57:13.564: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011282909s
    Feb 13 13:57:15.563: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010310638s
    Feb 13 13:57:15.563: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:57:15.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8020" for this suite. 02/13/23 13:57:15.609
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:57:15.674
Feb 13 13:57:15.674: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:57:15.675
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:57:15.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:57:15.692
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
W0213 13:57:15.707305      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "oidc-discovery-validator" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "oidc-discovery-validator" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "oidc-discovery-validator" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "oidc-discovery-validator" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:57:15.707: INFO: created pod
Feb 13 13:57:15.707: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4131" to be "Succeeded or Failed"
Feb 13 13:57:15.712: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.686294ms
Feb 13 13:57:17.721: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013429914s
Feb 13 13:57:19.719: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01194907s
STEP: Saw pod success 02/13/23 13:57:19.719
Feb 13 13:57:19.720: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Feb 13 13:57:49.720: INFO: polling logs
Feb 13 13:57:49.764: INFO: Pod logs: 
I0213 13:57:16.384366       1 log.go:195] OK: Got token
I0213 13:57:16.384433       1 log.go:195] validating with in-cluster discovery
I0213 13:57:16.385240       1 log.go:195] OK: got issuer https://74.220.30.122:6443
I0213 13:57:16.385295       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://74.220.30.122:6443", Subject:"system:serviceaccount:svcaccounts-4131:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1676297235, NotBefore:1676296635, IssuedAt:1676296635, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4131", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be1fb048-7cd3-41a6-af11-8d35837e0444"}}}
I0213 13:57:16.394658       1 log.go:195] OK: Constructed OIDC provider for issuer https://74.220.30.122:6443
I0213 13:57:16.405014       1 log.go:195] OK: Validated signature on JWT
I0213 13:57:16.405459       1 log.go:195] OK: Got valid claims from token!
I0213 13:57:16.405651       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://74.220.30.122:6443", Subject:"system:serviceaccount:svcaccounts-4131:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1676297235, NotBefore:1676296635, IssuedAt:1676296635, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4131", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be1fb048-7cd3-41a6-af11-8d35837e0444"}}}

Feb 13 13:57:49.764: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 13:57:49.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4131" for this suite. 02/13/23 13:57:49.779
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":127,"skipped":2427,"failed":0}
------------------------------
• [SLOW TEST] [34.112 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:57:15.674
    Feb 13 13:57:15.674: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 13:57:15.675
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:57:15.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:57:15.692
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    W0213 13:57:15.707305      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "oidc-discovery-validator" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "oidc-discovery-validator" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "oidc-discovery-validator" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "oidc-discovery-validator" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:57:15.707: INFO: created pod
    Feb 13 13:57:15.707: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4131" to be "Succeeded or Failed"
    Feb 13 13:57:15.712: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.686294ms
    Feb 13 13:57:17.721: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013429914s
    Feb 13 13:57:19.719: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01194907s
    STEP: Saw pod success 02/13/23 13:57:19.719
    Feb 13 13:57:19.720: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Feb 13 13:57:49.720: INFO: polling logs
    Feb 13 13:57:49.764: INFO: Pod logs: 
    I0213 13:57:16.384366       1 log.go:195] OK: Got token
    I0213 13:57:16.384433       1 log.go:195] validating with in-cluster discovery
    I0213 13:57:16.385240       1 log.go:195] OK: got issuer https://74.220.30.122:6443
    I0213 13:57:16.385295       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://74.220.30.122:6443", Subject:"system:serviceaccount:svcaccounts-4131:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1676297235, NotBefore:1676296635, IssuedAt:1676296635, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4131", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be1fb048-7cd3-41a6-af11-8d35837e0444"}}}
    I0213 13:57:16.394658       1 log.go:195] OK: Constructed OIDC provider for issuer https://74.220.30.122:6443
    I0213 13:57:16.405014       1 log.go:195] OK: Validated signature on JWT
    I0213 13:57:16.405459       1 log.go:195] OK: Got valid claims from token!
    I0213 13:57:16.405651       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://74.220.30.122:6443", Subject:"system:serviceaccount:svcaccounts-4131:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1676297235, NotBefore:1676296635, IssuedAt:1676296635, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4131", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"be1fb048-7cd3-41a6-af11-8d35837e0444"}}}

    Feb 13 13:57:49.764: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 13:57:49.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4131" for this suite. 02/13/23 13:57:49.779
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:57:49.794
Feb 13 13:57:49.794: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:57:49.796
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:57:49.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:57:49.832
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Feb 13 13:57:49.858: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 13:58:49.890: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 02/13/23 13:58:49.893
Feb 13 13:58:49.918: INFO: Created pod: pod0-0-sched-preemption-low-priority
Feb 13 13:58:49.927: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Feb 13 13:58:49.943: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Feb 13 13:58:49.950: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Feb 13 13:58:49.974: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Feb 13 13:58:49.981: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 02/13/23 13:58:49.981
Feb 13 13:58:49.981: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:49.986: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513171ms
Feb 13 13:58:51.993: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.011784369s
Feb 13 13:58:51.993: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Feb 13 13:58:51.993: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:51.998: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.869087ms
Feb 13 13:58:51.998: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:58:51.998: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:52.003: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.748953ms
Feb 13 13:58:52.003: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:58:52.003: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:52.008: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.636801ms
Feb 13 13:58:52.008: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:58:52.008: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:52.012: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.466593ms
Feb 13 13:58:52.012: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Feb 13 13:58:52.013: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:52.018: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.243095ms
Feb 13 13:58:52.018: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 02/13/23 13:58:52.018
Feb 13 13:58:52.028: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4222" to be "running"
Feb 13 13:58:52.032: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075656ms
Feb 13 13:58:54.039: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011746793s
Feb 13 13:58:56.040: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012037999s
Feb 13 13:58:58.038: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.010565982s
Feb 13 13:58:58.038: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:58:58.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4222" for this suite. 02/13/23 13:58:58.066
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":128,"skipped":2455,"failed":0}
------------------------------
• [SLOW TEST] [68.342 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:57:49.794
    Feb 13 13:57:49.794: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption 02/13/23 13:57:49.796
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:57:49.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:57:49.832
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Feb 13 13:57:49.858: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 13:58:49.890: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 02/13/23 13:58:49.893
    Feb 13 13:58:49.918: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Feb 13 13:58:49.927: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Feb 13 13:58:49.943: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Feb 13 13:58:49.950: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Feb 13 13:58:49.974: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Feb 13 13:58:49.981: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 02/13/23 13:58:49.981
    Feb 13 13:58:49.981: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:49.986: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513171ms
    Feb 13 13:58:51.993: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.011784369s
    Feb 13 13:58:51.993: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Feb 13 13:58:51.993: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:51.998: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.869087ms
    Feb 13 13:58:51.998: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:58:51.998: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:52.003: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.748953ms
    Feb 13 13:58:52.003: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:58:52.003: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:52.008: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.636801ms
    Feb 13 13:58:52.008: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:58:52.008: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:52.012: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.466593ms
    Feb 13 13:58:52.012: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Feb 13 13:58:52.013: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:52.018: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.243095ms
    Feb 13 13:58:52.018: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 02/13/23 13:58:52.018
    Feb 13 13:58:52.028: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4222" to be "running"
    Feb 13 13:58:52.032: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075656ms
    Feb 13 13:58:54.039: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011746793s
    Feb 13 13:58:56.040: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012037999s
    Feb 13 13:58:58.038: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.010565982s
    Feb 13 13:58:58.038: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:58:58.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4222" for this suite. 02/13/23 13:58:58.066
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:58:58.139
Feb 13 13:58:58.139: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 13:58:58.141
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:58:58.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:58:58.162
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 02/13/23 13:58:58.167
W0213 13:58:58.176917      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:58:58.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e" in namespace "downward-api-8267" to be "Succeeded or Failed"
Feb 13 13:58:58.179: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.54302ms
Feb 13 13:59:00.186: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008875169s
Feb 13 13:59:02.187: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010597472s
STEP: Saw pod success 02/13/23 13:59:02.187
Feb 13 13:59:02.188: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e" satisfied condition "Succeeded or Failed"
Feb 13 13:59:02.194: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e container client-container: <nil>
STEP: delete the pod 02/13/23 13:59:02.213
Feb 13 13:59:02.233: INFO: Waiting for pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e to disappear
Feb 13 13:59:02.236: INFO: Pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 13:59:02.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8267" for this suite. 02/13/23 13:59:02.242
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":129,"skipped":2468,"failed":0}
------------------------------
• [4.111 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:58:58.139
    Feb 13 13:58:58.139: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 13:58:58.141
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:58:58.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:58:58.162
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 02/13/23 13:58:58.167
    W0213 13:58:58.176917      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:58:58.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e" in namespace "downward-api-8267" to be "Succeeded or Failed"
    Feb 13 13:58:58.179: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.54302ms
    Feb 13 13:59:00.186: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008875169s
    Feb 13 13:59:02.187: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010597472s
    STEP: Saw pod success 02/13/23 13:59:02.187
    Feb 13 13:59:02.188: INFO: Pod "downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e" satisfied condition "Succeeded or Failed"
    Feb 13 13:59:02.194: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e container client-container: <nil>
    STEP: delete the pod 02/13/23 13:59:02.213
    Feb 13 13:59:02.233: INFO: Waiting for pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e to disappear
    Feb 13 13:59:02.236: INFO: Pod downwardapi-volume-3fa6ebf1-e64d-4648-94eb-8e1783715e6e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 13:59:02.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8267" for this suite. 02/13/23 13:59:02.242
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:02.254
Feb 13 13:59:02.254: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pod-network-test 02/13/23 13:59:02.256
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:02.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:02.279
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-5509 02/13/23 13:59:02.286
STEP: creating a selector 02/13/23 13:59:02.286
STEP: Creating the service pods in kubernetes 02/13/23 13:59:02.286
Feb 13 13:59:02.287: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
W0213 13:59:02.306556      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:59:02.323205      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 13:59:02.343880      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:02.344: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5509" to be "running and ready"
Feb 13 13:59:02.351: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.290637ms
Feb 13 13:59:02.352: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:59:04.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.015266313s
Feb 13 13:59:04.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 13:59:06.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014317668s
Feb 13 13:59:06.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 13:59:08.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.019319402s
Feb 13 13:59:08.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 13:59:10.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015745402s
Feb 13 13:59:10.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 13:59:12.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014359652s
Feb 13 13:59:12.358: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 13:59:14.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.01571485s
Feb 13 13:59:14.359: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Feb 13 13:59:14.359: INFO: Pod "netserver-0" satisfied condition "running and ready"
Feb 13 13:59:14.365: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5509" to be "running and ready"
Feb 13 13:59:14.371: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.867178ms
Feb 13 13:59:14.371: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Feb 13 13:59:14.372: INFO: Pod "netserver-1" satisfied condition "running and ready"
Feb 13 13:59:14.378: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5509" to be "running and ready"
Feb 13 13:59:14.382: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032388ms
Feb 13 13:59:14.382: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Feb 13 13:59:14.382: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 02/13/23 13:59:14.386
W0213 13:59:14.396538      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:14.397: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5509" to be "running"
Feb 13 13:59:14.404: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.832167ms
Feb 13 13:59:16.414: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017039743s
Feb 13 13:59:16.414: INFO: Pod "test-container-pod" satisfied condition "running"
Feb 13 13:59:16.423: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Feb 13 13:59:16.424: INFO: Breadth first check of 10.244.1.76 on host 192.168.1.12...
Feb 13 13:59:16.428: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.1.76&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:59:16.428: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:59:16.429: INFO: ExecWithOptions: Clientset creation
Feb 13 13:59:16.429: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.76%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 13:59:16.606: INFO: Waiting for responses: map[]
Feb 13 13:59:16.606: INFO: reached 10.244.1.76 after 0/1 tries
Feb 13 13:59:16.606: INFO: Breadth first check of 10.244.0.156 on host 192.168.1.11...
Feb 13 13:59:16.613: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.0.156&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:59:16.614: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:59:16.616: INFO: ExecWithOptions: Clientset creation
Feb 13 13:59:16.616: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.156%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 13:59:16.746: INFO: Waiting for responses: map[]
Feb 13 13:59:16.746: INFO: reached 10.244.0.156 after 0/1 tries
Feb 13 13:59:16.746: INFO: Breadth first check of 10.244.2.109 on host 192.168.1.10...
Feb 13 13:59:16.755: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.2.109&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:59:16.755: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:59:16.757: INFO: ExecWithOptions: Clientset creation
Feb 13 13:59:16.757: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.2.109%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 13:59:16.934: INFO: Waiting for responses: map[]
Feb 13 13:59:16.934: INFO: reached 10.244.2.109 after 0/1 tries
Feb 13 13:59:16.934: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Feb 13 13:59:16.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5509" for this suite. 02/13/23 13:59:16.943
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":130,"skipped":2481,"failed":0}
------------------------------
• [SLOW TEST] [14.699 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:02.254
    Feb 13 13:59:02.254: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pod-network-test 02/13/23 13:59:02.256
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:02.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:02.279
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-5509 02/13/23 13:59:02.286
    STEP: creating a selector 02/13/23 13:59:02.286
    STEP: Creating the service pods in kubernetes 02/13/23 13:59:02.286
    Feb 13 13:59:02.287: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    W0213 13:59:02.306556      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:59:02.323205      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 13:59:02.343880      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:02.344: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5509" to be "running and ready"
    Feb 13 13:59:02.351: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.290637ms
    Feb 13 13:59:02.352: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:59:04.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.015266313s
    Feb 13 13:59:04.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 13:59:06.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014317668s
    Feb 13 13:59:06.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 13:59:08.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.019319402s
    Feb 13 13:59:08.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 13:59:10.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015745402s
    Feb 13 13:59:10.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 13:59:12.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014359652s
    Feb 13 13:59:12.358: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 13:59:14.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.01571485s
    Feb 13 13:59:14.359: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Feb 13 13:59:14.359: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Feb 13 13:59:14.365: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5509" to be "running and ready"
    Feb 13 13:59:14.371: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.867178ms
    Feb 13 13:59:14.371: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Feb 13 13:59:14.372: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Feb 13 13:59:14.378: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5509" to be "running and ready"
    Feb 13 13:59:14.382: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032388ms
    Feb 13 13:59:14.382: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Feb 13 13:59:14.382: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 02/13/23 13:59:14.386
    W0213 13:59:14.396538      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:14.397: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5509" to be "running"
    Feb 13 13:59:14.404: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.832167ms
    Feb 13 13:59:16.414: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017039743s
    Feb 13 13:59:16.414: INFO: Pod "test-container-pod" satisfied condition "running"
    Feb 13 13:59:16.423: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Feb 13 13:59:16.424: INFO: Breadth first check of 10.244.1.76 on host 192.168.1.12...
    Feb 13 13:59:16.428: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.1.76&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:59:16.428: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:59:16.429: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:59:16.429: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.76%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 13:59:16.606: INFO: Waiting for responses: map[]
    Feb 13 13:59:16.606: INFO: reached 10.244.1.76 after 0/1 tries
    Feb 13 13:59:16.606: INFO: Breadth first check of 10.244.0.156 on host 192.168.1.11...
    Feb 13 13:59:16.613: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.0.156&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:59:16.614: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:59:16.616: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:59:16.616: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.156%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 13:59:16.746: INFO: Waiting for responses: map[]
    Feb 13 13:59:16.746: INFO: reached 10.244.0.156 after 0/1 tries
    Feb 13 13:59:16.746: INFO: Breadth first check of 10.244.2.109 on host 192.168.1.10...
    Feb 13 13:59:16.755: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.157:9080/dial?request=hostname&protocol=http&host=10.244.2.109&port=8083&tries=1'] Namespace:pod-network-test-5509 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:59:16.755: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:59:16.757: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:59:16.757: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5509/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.157%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.2.109%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 13:59:16.934: INFO: Waiting for responses: map[]
    Feb 13 13:59:16.934: INFO: reached 10.244.2.109 after 0/1 tries
    Feb 13 13:59:16.934: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Feb 13 13:59:16.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5509" for this suite. 02/13/23 13:59:16.943
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:16.96
Feb 13 13:59:16.960: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename containers 02/13/23 13:59:16.962
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:16.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:16.992
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 02/13/23 13:59:16.996
W0213 13:59:17.011004      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:17.011: INFO: Waiting up to 5m0s for pod "client-containers-85b312b2-8870-4107-8962-0367499385ce" in namespace "containers-7946" to be "Succeeded or Failed"
Feb 13 13:59:17.016: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.768723ms
Feb 13 13:59:19.023: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012656095s
Feb 13 13:59:21.024: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013258312s
STEP: Saw pod success 02/13/23 13:59:21.024
Feb 13 13:59:21.025: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce" satisfied condition "Succeeded or Failed"
Feb 13 13:59:21.030: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod client-containers-85b312b2-8870-4107-8962-0367499385ce container agnhost-container: <nil>
STEP: delete the pod 02/13/23 13:59:21.063
Feb 13 13:59:21.076: INFO: Waiting for pod client-containers-85b312b2-8870-4107-8962-0367499385ce to disappear
Feb 13 13:59:21.079: INFO: Pod client-containers-85b312b2-8870-4107-8962-0367499385ce no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Feb 13 13:59:21.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7946" for this suite. 02/13/23 13:59:21.086
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":131,"skipped":2484,"failed":0}
------------------------------
• [4.137 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:16.96
    Feb 13 13:59:16.960: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename containers 02/13/23 13:59:16.962
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:16.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:16.992
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 02/13/23 13:59:16.996
    W0213 13:59:17.011004      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:17.011: INFO: Waiting up to 5m0s for pod "client-containers-85b312b2-8870-4107-8962-0367499385ce" in namespace "containers-7946" to be "Succeeded or Failed"
    Feb 13 13:59:17.016: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.768723ms
    Feb 13 13:59:19.023: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012656095s
    Feb 13 13:59:21.024: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013258312s
    STEP: Saw pod success 02/13/23 13:59:21.024
    Feb 13 13:59:21.025: INFO: Pod "client-containers-85b312b2-8870-4107-8962-0367499385ce" satisfied condition "Succeeded or Failed"
    Feb 13 13:59:21.030: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod client-containers-85b312b2-8870-4107-8962-0367499385ce container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 13:59:21.063
    Feb 13 13:59:21.076: INFO: Waiting for pod client-containers-85b312b2-8870-4107-8962-0367499385ce to disappear
    Feb 13 13:59:21.079: INFO: Pod client-containers-85b312b2-8870-4107-8962-0367499385ce no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Feb 13 13:59:21.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7946" for this suite. 02/13/23 13:59:21.086
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:21.099
Feb 13 13:59:21.100: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename podtemplate 02/13/23 13:59:21.101
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:21.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:21.122
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 02/13/23 13:59:21.126
W0213 13:59:21.132735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Replace a pod template 02/13/23 13:59:21.133
W0213 13:59:21.146581      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:21.147: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Feb 13 13:59:21.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-807" for this suite. 02/13/23 13:59:21.152
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":132,"skipped":2489,"failed":0}
------------------------------
• [0.066 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:21.099
    Feb 13 13:59:21.100: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename podtemplate 02/13/23 13:59:21.101
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:21.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:21.122
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 02/13/23 13:59:21.126
    W0213 13:59:21.132735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Replace a pod template 02/13/23 13:59:21.133
    W0213 13:59:21.146581      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:21.147: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Feb 13 13:59:21.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-807" for this suite. 02/13/23 13:59:21.152
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:21.167
Feb 13 13:59:21.167: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename containers 02/13/23 13:59:21.169
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:21.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:21.188
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
W0213 13:59:21.200314      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:21.200: INFO: Waiting up to 5m0s for pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2" in namespace "containers-3965" to be "running"
Feb 13 13:59:21.203: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.866609ms
Feb 13 13:59:23.211: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010075659s
Feb 13 13:59:23.211: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Feb 13 13:59:23.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3965" for this suite. 02/13/23 13:59:23.232
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":133,"skipped":2494,"failed":0}
------------------------------
• [2.073 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:21.167
    Feb 13 13:59:21.167: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename containers 02/13/23 13:59:21.169
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:21.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:21.188
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    W0213 13:59:21.200314      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:21.200: INFO: Waiting up to 5m0s for pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2" in namespace "containers-3965" to be "running"
    Feb 13 13:59:21.203: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.866609ms
    Feb 13 13:59:23.211: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010075659s
    Feb 13 13:59:23.211: INFO: Pod "client-containers-3ec2f5cc-9e61-4937-b8d0-e1082ef6fec2" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Feb 13 13:59:23.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3965" for this suite. 02/13/23 13:59:23.232
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:23.242
Feb 13 13:59:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 13:59:23.245
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:23.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:23.27
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 02/13/23 13:59:23.279
Feb 13 13:59:23.280: INFO: Creating simple deployment test-deployment-gxhxg
W0213 13:59:23.287193      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:23.297: INFO: deployment "test-deployment-gxhxg" doesn't have the required revision set
STEP: Getting /status 02/13/23 13:59:25.315
Feb 13 13:59:25.322: INFO: Deployment test-deployment-gxhxg has Conditions: [{Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 02/13/23 13:59:25.322
Feb 13 13:59:25.334: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 59, 23, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-gxhxg-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 02/13/23 13:59:25.335
Feb 13 13:59:25.339: INFO: Observed &Deployment event: ADDED
Feb 13 13:59:25.340: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
Feb 13 13:59:25.341: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.341: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
Feb 13 13:59:25.342: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Feb 13 13:59:25.342: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.342: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Feb 13 13:59:25.343: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-gxhxg-777898ffcc" is progressing.}
Feb 13 13:59:25.344: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.344: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Feb 13 13:59:25.344: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
Feb 13 13:59:25.345: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.345: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Feb 13 13:59:25.345: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
Feb 13 13:59:25.345: INFO: Found Deployment test-deployment-gxhxg in namespace deployment-5877 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Feb 13 13:59:25.345: INFO: Deployment test-deployment-gxhxg has an updated status
STEP: patching the Statefulset Status 02/13/23 13:59:25.345
Feb 13 13:59:25.345: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Feb 13 13:59:25.357: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 02/13/23 13:59:25.358
Feb 13 13:59:25.362: INFO: Observed &Deployment event: ADDED
Feb 13 13:59:25.362: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
Feb 13 13:59:25.363: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.363: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
Feb 13 13:59:25.363: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-gxhxg-777898ffcc" is progressing.}
Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Feb 13 13:59:25.365: INFO: Observed &Deployment event: MODIFIED
Feb 13 13:59:25.365: INFO: Found deployment test-deployment-gxhxg in namespace deployment-5877 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Feb 13 13:59:25.365: INFO: Deployment test-deployment-gxhxg has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 13:59:25.377: INFO: Deployment "test-deployment-gxhxg":
&Deployment{ObjectMeta:{test-deployment-gxhxg  deployment-5877  a1795cf1-8ded-46d0-8e64-dba23941f80d 16488 1 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-02-13 13:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-02-13 13:59:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049535c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-gxhxg-777898ffcc",LastUpdateTime:2023-02-13 13:59:25 +0000 UTC,LastTransitionTime:2023-02-13 13:59:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 13:59:25.384: INFO: New ReplicaSet "test-deployment-gxhxg-777898ffcc" of Deployment "test-deployment-gxhxg":
&ReplicaSet{ObjectMeta:{test-deployment-gxhxg-777898ffcc  deployment-5877  e463f295-55ae-4e39-bc09-1603330abd5b 16484 1 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-gxhxg a1795cf1-8ded-46d0-8e64-dba23941f80d 0xc0040897d0 0xc0040897d1}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a1795cf1-8ded-46d0-8e64-dba23941f80d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:59:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004089878 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 13 13:59:25.388: INFO: Pod "test-deployment-gxhxg-777898ffcc-hcsxp" is available:
&Pod{ObjectMeta:{test-deployment-gxhxg-777898ffcc-hcsxp test-deployment-gxhxg-777898ffcc- deployment-5877  c2cdc600-eb3e-46dd-8ba4-8e4a28f7da39 16483 0 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-gxhxg-777898ffcc e463f295-55ae-4e39-bc09-1603330abd5b 0xc004953980 0xc004953981}] [] [{kube-controller-manager Update v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e463f295-55ae-4e39-bc09-1603330abd5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x7g22,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x7g22,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.158,StartTime:2023-02-13 13:59:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:59:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://982c2f8f86686c04f18e4b85a9980321e47a85e768bb99c155f49646de170dd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 13:59:25.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5877" for this suite. 02/13/23 13:59:25.395
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":134,"skipped":2494,"failed":0}
------------------------------
• [2.160 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:23.242
    Feb 13 13:59:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 13:59:23.245
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:23.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:23.27
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 02/13/23 13:59:23.279
    Feb 13 13:59:23.280: INFO: Creating simple deployment test-deployment-gxhxg
    W0213 13:59:23.287193      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:23.297: INFO: deployment "test-deployment-gxhxg" doesn't have the required revision set
    STEP: Getting /status 02/13/23 13:59:25.315
    Feb 13 13:59:25.322: INFO: Deployment test-deployment-gxhxg has Conditions: [{Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 02/13/23 13:59:25.322
    Feb 13 13:59:25.334: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 13, 59, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 13, 59, 23, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-gxhxg-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 02/13/23 13:59:25.335
    Feb 13 13:59:25.339: INFO: Observed &Deployment event: ADDED
    Feb 13 13:59:25.340: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
    Feb 13 13:59:25.341: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.341: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
    Feb 13 13:59:25.342: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Feb 13 13:59:25.342: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.342: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Feb 13 13:59:25.343: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-gxhxg-777898ffcc" is progressing.}
    Feb 13 13:59:25.344: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.344: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Feb 13 13:59:25.344: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
    Feb 13 13:59:25.345: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.345: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Feb 13 13:59:25.345: INFO: Observed Deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
    Feb 13 13:59:25.345: INFO: Found Deployment test-deployment-gxhxg in namespace deployment-5877 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Feb 13 13:59:25.345: INFO: Deployment test-deployment-gxhxg has an updated status
    STEP: patching the Statefulset Status 02/13/23 13:59:25.345
    Feb 13 13:59:25.345: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Feb 13 13:59:25.357: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 02/13/23 13:59:25.358
    Feb 13 13:59:25.362: INFO: Observed &Deployment event: ADDED
    Feb 13 13:59:25.362: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
    Feb 13 13:59:25.363: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.363: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-gxhxg-777898ffcc"}
    Feb 13 13:59:25.363: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:23 +0000 UTC 2023-02-13 13:59:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-gxhxg-777898ffcc" is progressing.}
    Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
    Feb 13 13:59:25.364: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-02-13 13:59:24 +0000 UTC 2023-02-13 13:59:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-gxhxg-777898ffcc" has successfully progressed.}
    Feb 13 13:59:25.364: INFO: Observed deployment test-deployment-gxhxg in namespace deployment-5877 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Feb 13 13:59:25.365: INFO: Observed &Deployment event: MODIFIED
    Feb 13 13:59:25.365: INFO: Found deployment test-deployment-gxhxg in namespace deployment-5877 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Feb 13 13:59:25.365: INFO: Deployment test-deployment-gxhxg has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 13:59:25.377: INFO: Deployment "test-deployment-gxhxg":
    &Deployment{ObjectMeta:{test-deployment-gxhxg  deployment-5877  a1795cf1-8ded-46d0-8e64-dba23941f80d 16488 1 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-02-13 13:59:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-02-13 13:59:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049535c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-gxhxg-777898ffcc",LastUpdateTime:2023-02-13 13:59:25 +0000 UTC,LastTransitionTime:2023-02-13 13:59:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Feb 13 13:59:25.384: INFO: New ReplicaSet "test-deployment-gxhxg-777898ffcc" of Deployment "test-deployment-gxhxg":
    &ReplicaSet{ObjectMeta:{test-deployment-gxhxg-777898ffcc  deployment-5877  e463f295-55ae-4e39-bc09-1603330abd5b 16484 1 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-gxhxg a1795cf1-8ded-46d0-8e64-dba23941f80d 0xc0040897d0 0xc0040897d1}] [] [{kube-controller-manager Update apps/v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a1795cf1-8ded-46d0-8e64-dba23941f80d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 13:59:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004089878 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 13:59:25.388: INFO: Pod "test-deployment-gxhxg-777898ffcc-hcsxp" is available:
    &Pod{ObjectMeta:{test-deployment-gxhxg-777898ffcc-hcsxp test-deployment-gxhxg-777898ffcc- deployment-5877  c2cdc600-eb3e-46dd-8ba4-8e4a28f7da39 16483 0 2023-02-13 13:59:23 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-gxhxg-777898ffcc e463f295-55ae-4e39-bc09-1603330abd5b 0xc004953980 0xc004953981}] [] [{kube-controller-manager Update v1 2023-02-13 13:59:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e463f295-55ae-4e39-bc09-1603330abd5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 13:59:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x7g22,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x7g22,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 13:59:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.158,StartTime:2023-02-13 13:59:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 13:59:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://982c2f8f86686c04f18e4b85a9980321e47a85e768bb99c155f49646de170dd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 13:59:25.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5877" for this suite. 02/13/23 13:59:25.395
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:25.41
Feb 13 13:59:25.411: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:59:25.413
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:25.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:25.435
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 02/13/23 13:59:25.441
W0213 13:59:25.450377      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:25.451: INFO: Waiting up to 5m0s for pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031" in namespace "projected-7020" to be "running and ready"
Feb 13 13:59:25.461: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031": Phase="Pending", Reason="", readiness=false. Elapsed: 10.158043ms
Feb 13 13:59:25.461: INFO: The phase of Pod annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 13:59:27.466: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031": Phase="Running", Reason="", readiness=true. Elapsed: 2.015491998s
Feb 13 13:59:27.466: INFO: The phase of Pod annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031 is Running (Ready = true)
Feb 13 13:59:27.466: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031" satisfied condition "running and ready"
Feb 13 13:59:28.013: INFO: Successfully updated pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 13:59:32.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7020" for this suite. 02/13/23 13:59:32.065
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":135,"skipped":2497,"failed":0}
------------------------------
• [SLOW TEST] [6.664 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:25.41
    Feb 13 13:59:25.411: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:59:25.413
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:25.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:25.435
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 02/13/23 13:59:25.441
    W0213 13:59:25.450377      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:25.451: INFO: Waiting up to 5m0s for pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031" in namespace "projected-7020" to be "running and ready"
    Feb 13 13:59:25.461: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031": Phase="Pending", Reason="", readiness=false. Elapsed: 10.158043ms
    Feb 13 13:59:25.461: INFO: The phase of Pod annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 13:59:27.466: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031": Phase="Running", Reason="", readiness=true. Elapsed: 2.015491998s
    Feb 13 13:59:27.466: INFO: The phase of Pod annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031 is Running (Ready = true)
    Feb 13 13:59:27.466: INFO: Pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031" satisfied condition "running and ready"
    Feb 13 13:59:28.013: INFO: Successfully updated pod "annotationupdate5ca49519-1c86-404b-ac3a-d7ad8dc3d031"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 13:59:32.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7020" for this suite. 02/13/23 13:59:32.065
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:32.083
Feb 13 13:59:32.084: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 13:59:32.086
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:32.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:32.111
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-f944ed70-31b6-4d37-9aa3-3358ee8fe298 02/13/23 13:59:32.115
STEP: Creating a pod to test consume secrets 02/13/23 13:59:32.121
W0213 13:59:32.128859      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 13:59:32.129: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3" in namespace "projected-9587" to be "Succeeded or Failed"
Feb 13 13:59:32.135: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.736706ms
Feb 13 13:59:34.141: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012184085s
Feb 13 13:59:36.140: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010600385s
STEP: Saw pod success 02/13/23 13:59:36.14
Feb 13 13:59:36.140: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3" satisfied condition "Succeeded or Failed"
Feb 13 13:59:36.145: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 container projected-secret-volume-test: <nil>
STEP: delete the pod 02/13/23 13:59:36.155
Feb 13 13:59:36.169: INFO: Waiting for pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 to disappear
Feb 13 13:59:36.173: INFO: Pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 13:59:36.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9587" for this suite. 02/13/23 13:59:36.177
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":136,"skipped":2526,"failed":0}
------------------------------
• [4.099 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:32.083
    Feb 13 13:59:32.084: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 13:59:32.086
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:32.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:32.111
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-f944ed70-31b6-4d37-9aa3-3358ee8fe298 02/13/23 13:59:32.115
    STEP: Creating a pod to test consume secrets 02/13/23 13:59:32.121
    W0213 13:59:32.128859      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 13:59:32.129: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3" in namespace "projected-9587" to be "Succeeded or Failed"
    Feb 13 13:59:32.135: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.736706ms
    Feb 13 13:59:34.141: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012184085s
    Feb 13 13:59:36.140: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010600385s
    STEP: Saw pod success 02/13/23 13:59:36.14
    Feb 13 13:59:36.140: INFO: Pod "pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3" satisfied condition "Succeeded or Failed"
    Feb 13 13:59:36.145: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 container projected-secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 13:59:36.155
    Feb 13 13:59:36.169: INFO: Waiting for pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 to disappear
    Feb 13 13:59:36.173: INFO: Pod pod-projected-secrets-87250547-7fa2-46a1-abba-1a21cc4901c3 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 13:59:36.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9587" for this suite. 02/13/23 13:59:36.177
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:36.186
Feb 13 13:59:36.186: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename init-container 02/13/23 13:59:36.188
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:36.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:36.208
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 02/13/23 13:59:36.212
Feb 13 13:59:36.212: INFO: PodSpec: initContainers in spec.initContainers
W0213 13:59:36.220566      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 13:59:41.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1395" for this suite. 02/13/23 13:59:41.846
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":137,"skipped":2545,"failed":0}
------------------------------
• [SLOW TEST] [5.671 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:36.186
    Feb 13 13:59:36.186: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename init-container 02/13/23 13:59:36.188
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:36.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:36.208
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 02/13/23 13:59:36.212
    Feb 13 13:59:36.212: INFO: PodSpec: initContainers in spec.initContainers
    W0213 13:59:36.220566      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 13:59:41.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1395" for this suite. 02/13/23 13:59:41.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:41.87
Feb 13 13:59:41.871: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename endpointslicemirroring 02/13/23 13:59:41.873
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:41.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:41.901
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 02/13/23 13:59:41.921
Feb 13 13:59:41.929: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 02/13/23 13:59:43.938
STEP: mirroring deletion of a custom Endpoint 02/13/23 13:59:43.955
Feb 13 13:59:43.971: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Feb 13 13:59:45.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-4902" for this suite. 02/13/23 13:59:45.987
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":138,"skipped":2618,"failed":0}
------------------------------
• [4.126 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:41.87
    Feb 13 13:59:41.871: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename endpointslicemirroring 02/13/23 13:59:41.873
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:41.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:41.901
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 02/13/23 13:59:41.921
    Feb 13 13:59:41.929: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 02/13/23 13:59:43.938
    STEP: mirroring deletion of a custom Endpoint 02/13/23 13:59:43.955
    Feb 13 13:59:43.971: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Feb 13 13:59:45.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-4902" for this suite. 02/13/23 13:59:45.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:46.006
Feb 13 13:59:46.007: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 13:59:46.008
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:46.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:46.027
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Feb 13 13:59:46.031: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 13:59:48.178
Feb 13 13:59:48.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 create -f -'
Feb 13 13:59:48.833: INFO: stderr: ""
Feb 13 13:59:48.833: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 13 13:59:48.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 delete e2e-test-crd-publish-openapi-4953-crds test-cr'
Feb 13 13:59:48.935: INFO: stderr: ""
Feb 13 13:59:48.935: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 13 13:59:48.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 apply -f -'
Feb 13 13:59:49.224: INFO: stderr: ""
Feb 13 13:59:49.224: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 13 13:59:49.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 delete e2e-test-crd-publish-openapi-4953-crds test-cr'
Feb 13 13:59:49.327: INFO: stderr: ""
Feb 13 13:59:49.327: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 02/13/23 13:59:49.327
Feb 13 13:59:49.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 explain e2e-test-crd-publish-openapi-4953-crds'
Feb 13 13:59:49.576: INFO: stderr: ""
Feb 13 13:59:49.576: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4953-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 13:59:51.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9418" for this suite. 02/13/23 13:59:51.681
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":139,"skipped":2666,"failed":0}
------------------------------
• [SLOW TEST] [5.684 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:46.006
    Feb 13 13:59:46.007: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 13:59:46.008
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:46.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:46.027
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Feb 13 13:59:46.031: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 13:59:48.178
    Feb 13 13:59:48.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 create -f -'
    Feb 13 13:59:48.833: INFO: stderr: ""
    Feb 13 13:59:48.833: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Feb 13 13:59:48.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 delete e2e-test-crd-publish-openapi-4953-crds test-cr'
    Feb 13 13:59:48.935: INFO: stderr: ""
    Feb 13 13:59:48.935: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Feb 13 13:59:48.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 apply -f -'
    Feb 13 13:59:49.224: INFO: stderr: ""
    Feb 13 13:59:49.224: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Feb 13 13:59:49.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 --namespace=crd-publish-openapi-9418 delete e2e-test-crd-publish-openapi-4953-crds test-cr'
    Feb 13 13:59:49.327: INFO: stderr: ""
    Feb 13 13:59:49.327: INFO: stdout: "e2e-test-crd-publish-openapi-4953-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 02/13/23 13:59:49.327
    Feb 13 13:59:49.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9418 explain e2e-test-crd-publish-openapi-4953-crds'
    Feb 13 13:59:49.576: INFO: stderr: ""
    Feb 13 13:59:49.576: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4953-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 13:59:51.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9418" for this suite. 02/13/23 13:59:51.681
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:51.691
Feb 13 13:59:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename namespaces 02/13/23 13:59:51.692
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.713
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 02/13/23 13:59:51.717
STEP: patching the Namespace 02/13/23 13:59:51.73
STEP: get the Namespace and ensuring it has the label 02/13/23 13:59:51.735
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Feb 13 13:59:51.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7736" for this suite. 02/13/23 13:59:51.741
STEP: Destroying namespace "nspatchtest-8fefa06e-c652-429d-83f1-6a9f646422de-3044" for this suite. 02/13/23 13:59:51.748
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":140,"skipped":2667,"failed":0}
------------------------------
• [0.062 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:51.691
    Feb 13 13:59:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename namespaces 02/13/23 13:59:51.692
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.713
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 02/13/23 13:59:51.717
    STEP: patching the Namespace 02/13/23 13:59:51.73
    STEP: get the Namespace and ensuring it has the label 02/13/23 13:59:51.735
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 13:59:51.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7736" for this suite. 02/13/23 13:59:51.741
    STEP: Destroying namespace "nspatchtest-8fefa06e-c652-429d-83f1-6a9f646422de-3044" for this suite. 02/13/23 13:59:51.748
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:51.765
Feb 13 13:59:51.766: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 13:59:51.767
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.786
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-3dddd7ac-e494-4bb0-9741-9b8654b084e5 02/13/23 13:59:51.79
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 13:59:51.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5155" for this suite. 02/13/23 13:59:51.798
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":141,"skipped":2692,"failed":0}
------------------------------
• [0.041 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:51.765
    Feb 13 13:59:51.766: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 13:59:51.767
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.786
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-3dddd7ac-e494-4bb0-9741-9b8654b084e5 02/13/23 13:59:51.79
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 13:59:51.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5155" for this suite. 02/13/23 13:59:51.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 13:59:51.823
Feb 13 13:59:51.824: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 13:59:51.825
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.85
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 02/13/23 13:59:51.854
W0213 13:59:51.866724      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: waiting for pod running 02/13/23 13:59:51.866
Feb 13 13:59:51.867: INFO: Waiting up to 2m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226" to be "running"
Feb 13 13:59:51.873: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.952485ms
Feb 13 13:59:53.878: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01103548s
Feb 13 13:59:53.878: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" satisfied condition "running"
STEP: creating a file in subpath 02/13/23 13:59:53.878
Feb 13 13:59:53.882: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-226 PodName:var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:59:53.882: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:59:53.883: INFO: ExecWithOptions: Clientset creation
Feb 13 13:59:53.884: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-226/pods/var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 02/13/23 13:59:54.021
Feb 13 13:59:54.029: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-226 PodName:var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 13:59:54.029: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 13:59:54.031: INFO: ExecWithOptions: Clientset creation
Feb 13 13:59:54.031: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-226/pods/var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 02/13/23 13:59:54.186
Feb 13 13:59:54.703: INFO: Successfully updated pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c"
STEP: waiting for annotated pod running 02/13/23 13:59:54.703
Feb 13 13:59:54.704: INFO: Waiting up to 2m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226" to be "running"
Feb 13 13:59:54.707: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Running", Reason="", readiness=true. Elapsed: 3.81795ms
Feb 13 13:59:54.707: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" satisfied condition "running"
STEP: deleting the pod gracefully 02/13/23 13:59:54.707
Feb 13 13:59:54.708: INFO: Deleting pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226"
Feb 13 13:59:54.716: INFO: Wait up to 5m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 14:00:28.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-226" for this suite. 02/13/23 14:00:28.731
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":142,"skipped":2758,"failed":0}
------------------------------
• [SLOW TEST] [36.916 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 13:59:51.823
    Feb 13 13:59:51.824: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 13:59:51.825
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 13:59:51.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 13:59:51.85
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 02/13/23 13:59:51.854
    W0213 13:59:51.866724      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: waiting for pod running 02/13/23 13:59:51.866
    Feb 13 13:59:51.867: INFO: Waiting up to 2m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226" to be "running"
    Feb 13 13:59:51.873: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.952485ms
    Feb 13 13:59:53.878: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01103548s
    Feb 13 13:59:53.878: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" satisfied condition "running"
    STEP: creating a file in subpath 02/13/23 13:59:53.878
    Feb 13 13:59:53.882: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-226 PodName:var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:59:53.882: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:59:53.883: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:59:53.884: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-226/pods/var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 02/13/23 13:59:54.021
    Feb 13 13:59:54.029: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-226 PodName:var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 13:59:54.029: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 13:59:54.031: INFO: ExecWithOptions: Clientset creation
    Feb 13 13:59:54.031: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-226/pods/var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 02/13/23 13:59:54.186
    Feb 13 13:59:54.703: INFO: Successfully updated pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c"
    STEP: waiting for annotated pod running 02/13/23 13:59:54.703
    Feb 13 13:59:54.704: INFO: Waiting up to 2m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226" to be "running"
    Feb 13 13:59:54.707: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c": Phase="Running", Reason="", readiness=true. Elapsed: 3.81795ms
    Feb 13 13:59:54.707: INFO: Pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" satisfied condition "running"
    STEP: deleting the pod gracefully 02/13/23 13:59:54.707
    Feb 13 13:59:54.708: INFO: Deleting pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" in namespace "var-expansion-226"
    Feb 13 13:59:54.716: INFO: Wait up to 5m0s for pod "var-expansion-df347eaa-e254-4c12-a867-a4af1f717e6c" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 14:00:28.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-226" for this suite. 02/13/23 14:00:28.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:28.753
Feb 13 14:00:28.754: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:00:28.756
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:28.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:28.795
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 14:00:28.799
Feb 13 14:00:28.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Feb 13 14:00:28.889: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:00:28.889: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 02/13/23 14:00:28.889
STEP: verifying the pod e2e-test-httpd-pod was created 02/13/23 14:00:33.941
Feb 13 14:00:33.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 get pod e2e-test-httpd-pod -o json'
Feb 13 14:00:34.036: INFO: stderr: ""
Feb 13 14:00:34.036: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-02-13T14:00:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-298\",\n        \"resourceVersion\": \"16840\",\n        \"uid\": \"c6175b7f-e011-4b41-96f7-67b25a763bd6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-s69gt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance-5500-0ccfa5-pool-bf9f-o7jrw\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-s69gt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://fa430ece1638a7e68f43cdcb1a8de0bd4de228bb16cf1d869f387e92307d4e3e\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-02-13T14:00:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.11\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.163\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.0.163\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-02-13T14:00:28Z\"\n    }\n}\n"
STEP: replace the image in the pod 02/13/23 14:00:34.037
Feb 13 14:00:34.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 replace -f -'
Feb 13 14:00:34.642: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:00:34.642: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 02/13/23 14:00:34.642
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Feb 13 14:00:34.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 delete pods e2e-test-httpd-pod'
Feb 13 14:00:36.058: INFO: stderr: ""
Feb 13 14:00:36.058: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:00:36.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-298" for this suite. 02/13/23 14:00:36.066
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":143,"skipped":2791,"failed":0}
------------------------------
• [SLOW TEST] [7.321 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:28.753
    Feb 13 14:00:28.754: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:00:28.756
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:28.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:28.795
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 14:00:28.799
    Feb 13 14:00:28.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Feb 13 14:00:28.889: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:00:28.889: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 02/13/23 14:00:28.889
    STEP: verifying the pod e2e-test-httpd-pod was created 02/13/23 14:00:33.941
    Feb 13 14:00:33.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 get pod e2e-test-httpd-pod -o json'
    Feb 13 14:00:34.036: INFO: stderr: ""
    Feb 13 14:00:34.036: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-02-13T14:00:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-298\",\n        \"resourceVersion\": \"16840\",\n        \"uid\": \"c6175b7f-e011-4b41-96f7-67b25a763bd6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-s69gt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance-5500-0ccfa5-pool-bf9f-o7jrw\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-s69gt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-02-13T14:00:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://fa430ece1638a7e68f43cdcb1a8de0bd4de228bb16cf1d869f387e92307d4e3e\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-02-13T14:00:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.11\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.163\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.0.163\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-02-13T14:00:28Z\"\n    }\n}\n"
    STEP: replace the image in the pod 02/13/23 14:00:34.037
    Feb 13 14:00:34.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 replace -f -'
    Feb 13 14:00:34.642: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:00:34.642: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 02/13/23 14:00:34.642
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Feb 13 14:00:34.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-298 delete pods e2e-test-httpd-pod'
    Feb 13 14:00:36.058: INFO: stderr: ""
    Feb 13 14:00:36.058: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:00:36.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-298" for this suite. 02/13/23 14:00:36.066
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:36.077
Feb 13 14:00:36.077: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename events 02/13/23 14:00:36.079
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:36.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:36.097
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 02/13/23 14:00:36.109
STEP: listing events in all namespaces 02/13/23 14:00:36.117
STEP: listing events in test namespace 02/13/23 14:00:36.127
STEP: listing events with field selection filtering on source 02/13/23 14:00:36.131
STEP: listing events with field selection filtering on reportingController 02/13/23 14:00:36.135
STEP: getting the test event 02/13/23 14:00:36.138
STEP: patching the test event 02/13/23 14:00:36.141
STEP: getting the test event 02/13/23 14:00:36.149
STEP: updating the test event 02/13/23 14:00:36.152
STEP: getting the test event 02/13/23 14:00:36.158
STEP: deleting the test event 02/13/23 14:00:36.161
STEP: listing events in all namespaces 02/13/23 14:00:36.166
STEP: listing events in test namespace 02/13/23 14:00:36.172
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Feb 13 14:00:36.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6752" for this suite. 02/13/23 14:00:36.178
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":144,"skipped":2811,"failed":0}
------------------------------
• [0.106 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:36.077
    Feb 13 14:00:36.077: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename events 02/13/23 14:00:36.079
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:36.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:36.097
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 02/13/23 14:00:36.109
    STEP: listing events in all namespaces 02/13/23 14:00:36.117
    STEP: listing events in test namespace 02/13/23 14:00:36.127
    STEP: listing events with field selection filtering on source 02/13/23 14:00:36.131
    STEP: listing events with field selection filtering on reportingController 02/13/23 14:00:36.135
    STEP: getting the test event 02/13/23 14:00:36.138
    STEP: patching the test event 02/13/23 14:00:36.141
    STEP: getting the test event 02/13/23 14:00:36.149
    STEP: updating the test event 02/13/23 14:00:36.152
    STEP: getting the test event 02/13/23 14:00:36.158
    STEP: deleting the test event 02/13/23 14:00:36.161
    STEP: listing events in all namespaces 02/13/23 14:00:36.166
    STEP: listing events in test namespace 02/13/23 14:00:36.172
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Feb 13 14:00:36.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6752" for this suite. 02/13/23 14:00:36.178
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:36.184
Feb 13 14:00:36.184: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:00:36.185
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:36.203
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:36.208
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3781 02/13/23 14:00:36.213
STEP: changing the ExternalName service to type=NodePort 02/13/23 14:00:36.222
STEP: creating replication controller externalname-service in namespace services-3781 02/13/23 14:00:36.252
W0213 14:00:36.258840      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:00:36.260245      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3781, replica count: 2
I0213 14:00:39.312664      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:00:39.313: INFO: Creating new exec pod
W0213 14:00:39.324825      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:00:39.325: INFO: Waiting up to 5m0s for pod "execpodjkvtn" in namespace "services-3781" to be "running"
Feb 13 14:00:39.333: INFO: Pod "execpodjkvtn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.46194ms
Feb 13 14:00:41.338: INFO: Pod "execpodjkvtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.013470958s
Feb 13 14:00:41.338: INFO: Pod "execpodjkvtn" satisfied condition "running"
Feb 13 14:00:42.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Feb 13 14:00:42.596: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 13 14:00:42.596: INFO: stdout: "externalname-service-9nkrq"
Feb 13 14:00:42.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.140.182 80'
Feb 13 14:00:42.882: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.140.182 80\nConnection to 10.104.140.182 80 port [tcp/http] succeeded!\n"
Feb 13 14:00:42.882: INFO: stdout: ""
Feb 13 14:00:43.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.140.182 80'
Feb 13 14:00:44.157: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.140.182 80\nConnection to 10.104.140.182 80 port [tcp/http] succeeded!\n"
Feb 13 14:00:44.157: INFO: stdout: "externalname-service-9nkrq"
Feb 13 14:00:44.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 32104'
Feb 13 14:00:44.424: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.11 32104\nConnection to 192.168.1.11 32104 port [tcp/*] succeeded!\n"
Feb 13 14:00:44.424: INFO: stdout: "externalname-service-9nkrq"
Feb 13 14:00:44.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 32104'
Feb 13 14:00:44.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 32104\nConnection to 192.168.1.12 32104 port [tcp/*] succeeded!\n"
Feb 13 14:00:44.682: INFO: stdout: "externalname-service-k4d6j"
Feb 13 14:00:44.682: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:00:44.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3781" for this suite. 02/13/23 14:00:44.721
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":145,"skipped":2814,"failed":0}
------------------------------
• [SLOW TEST] [8.542 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:36.184
    Feb 13 14:00:36.184: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:00:36.185
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:36.203
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:36.208
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-3781 02/13/23 14:00:36.213
    STEP: changing the ExternalName service to type=NodePort 02/13/23 14:00:36.222
    STEP: creating replication controller externalname-service in namespace services-3781 02/13/23 14:00:36.252
    W0213 14:00:36.258840      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:00:36.260245      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3781, replica count: 2
    I0213 14:00:39.312664      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:00:39.313: INFO: Creating new exec pod
    W0213 14:00:39.324825      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:00:39.325: INFO: Waiting up to 5m0s for pod "execpodjkvtn" in namespace "services-3781" to be "running"
    Feb 13 14:00:39.333: INFO: Pod "execpodjkvtn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.46194ms
    Feb 13 14:00:41.338: INFO: Pod "execpodjkvtn": Phase="Running", Reason="", readiness=true. Elapsed: 2.013470958s
    Feb 13 14:00:41.338: INFO: Pod "execpodjkvtn" satisfied condition "running"
    Feb 13 14:00:42.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Feb 13 14:00:42.596: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Feb 13 14:00:42.596: INFO: stdout: "externalname-service-9nkrq"
    Feb 13 14:00:42.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.140.182 80'
    Feb 13 14:00:42.882: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.140.182 80\nConnection to 10.104.140.182 80 port [tcp/http] succeeded!\n"
    Feb 13 14:00:42.882: INFO: stdout: ""
    Feb 13 14:00:43.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.140.182 80'
    Feb 13 14:00:44.157: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.140.182 80\nConnection to 10.104.140.182 80 port [tcp/http] succeeded!\n"
    Feb 13 14:00:44.157: INFO: stdout: "externalname-service-9nkrq"
    Feb 13 14:00:44.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 32104'
    Feb 13 14:00:44.424: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.11 32104\nConnection to 192.168.1.11 32104 port [tcp/*] succeeded!\n"
    Feb 13 14:00:44.424: INFO: stdout: "externalname-service-9nkrq"
    Feb 13 14:00:44.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-3781 exec execpodjkvtn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 32104'
    Feb 13 14:00:44.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 32104\nConnection to 192.168.1.12 32104 port [tcp/*] succeeded!\n"
    Feb 13 14:00:44.682: INFO: stdout: "externalname-service-k4d6j"
    Feb 13 14:00:44.682: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:00:44.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3781" for this suite. 02/13/23 14:00:44.721
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:44.737
Feb 13 14:00:44.737: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:00:44.739
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:44.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:44.761
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-e4e2d25d-3751-43cc-8f61-74162c4249af 02/13/23 14:00:44.765
STEP: Creating a pod to test consume secrets 02/13/23 14:00:44.772
W0213 14:00:44.783399      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:00:44.784: INFO: Waiting up to 5m0s for pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1" in namespace "secrets-9206" to be "Succeeded or Failed"
Feb 13 14:00:44.789: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139149ms
Feb 13 14:00:46.796: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012132264s
Feb 13 14:00:48.797: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012837888s
STEP: Saw pod success 02/13/23 14:00:48.797
Feb 13 14:00:48.797: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1" satisfied condition "Succeeded or Failed"
Feb 13 14:00:48.802: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:00:48.817
Feb 13 14:00:48.846: INFO: Waiting for pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 to disappear
Feb 13 14:00:48.851: INFO: Pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:00:48.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9206" for this suite. 02/13/23 14:00:48.858
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":146,"skipped":2867,"failed":0}
------------------------------
• [4.131 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:44.737
    Feb 13 14:00:44.737: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:00:44.739
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:44.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:44.761
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-e4e2d25d-3751-43cc-8f61-74162c4249af 02/13/23 14:00:44.765
    STEP: Creating a pod to test consume secrets 02/13/23 14:00:44.772
    W0213 14:00:44.783399      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:00:44.784: INFO: Waiting up to 5m0s for pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1" in namespace "secrets-9206" to be "Succeeded or Failed"
    Feb 13 14:00:44.789: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139149ms
    Feb 13 14:00:46.796: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012132264s
    Feb 13 14:00:48.797: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012837888s
    STEP: Saw pod success 02/13/23 14:00:48.797
    Feb 13 14:00:48.797: INFO: Pod "pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1" satisfied condition "Succeeded or Failed"
    Feb 13 14:00:48.802: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:00:48.817
    Feb 13 14:00:48.846: INFO: Waiting for pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 to disappear
    Feb 13 14:00:48.851: INFO: Pod pod-secrets-367eba90-49e4-4ed4-a231-6d8dcd97feb1 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:00:48.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9206" for this suite. 02/13/23 14:00:48.858
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:48.869
Feb 13 14:00:48.869: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:00:48.872
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:48.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:48.897
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
W0213 14:00:48.920085      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Feb 13 14:00:48.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3606" for this suite. 02/13/23 14:00:48.95
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":147,"skipped":2869,"failed":0}
------------------------------
• [0.086 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:48.869
    Feb 13 14:00:48.869: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:00:48.872
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:48.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:48.897
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    W0213 14:00:48.920085      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-falsec99485d8-c70a-4067-81eb-ee69f6c29ca3" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Feb 13 14:00:48.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3606" for this suite. 02/13/23 14:00:48.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:48.958
Feb 13 14:00:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:00:48.959
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:48.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:48.98
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 02/13/23 14:00:48.982
W0213 14:00:48.994225      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:00:48.994: INFO: Waiting up to 5m0s for pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63" in namespace "downward-api-4344" to be "Succeeded or Failed"
Feb 13 14:00:49.001: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Pending", Reason="", readiness=false. Elapsed: 6.5672ms
Feb 13 14:00:51.004: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009718674s
Feb 13 14:00:53.006: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011824175s
STEP: Saw pod success 02/13/23 14:00:53.006
Feb 13 14:00:53.006: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63" satisfied condition "Succeeded or Failed"
Feb 13 14:00:53.010: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 container dapi-container: <nil>
STEP: delete the pod 02/13/23 14:00:53.022
Feb 13 14:00:53.036: INFO: Waiting for pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 to disappear
Feb 13 14:00:53.039: INFO: Pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Feb 13 14:00:53.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4344" for this suite. 02/13/23 14:00:53.044
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":148,"skipped":2885,"failed":0}
------------------------------
• [4.092 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:48.958
    Feb 13 14:00:48.958: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:00:48.959
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:48.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:48.98
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 02/13/23 14:00:48.982
    W0213 14:00:48.994225      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:00:48.994: INFO: Waiting up to 5m0s for pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63" in namespace "downward-api-4344" to be "Succeeded or Failed"
    Feb 13 14:00:49.001: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Pending", Reason="", readiness=false. Elapsed: 6.5672ms
    Feb 13 14:00:51.004: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009718674s
    Feb 13 14:00:53.006: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011824175s
    STEP: Saw pod success 02/13/23 14:00:53.006
    Feb 13 14:00:53.006: INFO: Pod "downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63" satisfied condition "Succeeded or Failed"
    Feb 13 14:00:53.010: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 container dapi-container: <nil>
    STEP: delete the pod 02/13/23 14:00:53.022
    Feb 13 14:00:53.036: INFO: Waiting for pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 to disappear
    Feb 13 14:00:53.039: INFO: Pod downward-api-d309d9b9-5e90-41d8-b000-65bc36b6fb63 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Feb 13 14:00:53.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4344" for this suite. 02/13/23 14:00:53.044
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:53.052
Feb 13 14:00:53.052: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename namespaces 02/13/23 14:00:53.054
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:53.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:53.075
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 02/13/23 14:00:53.079
Feb 13 14:00:53.082: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 02/13/23 14:00:53.082
Feb 13 14:00:53.087: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 02/13/23 14:00:53.088
Feb 13 14:00:53.096: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:00:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4726" for this suite. 02/13/23 14:00:53.1
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":149,"skipped":2885,"failed":0}
------------------------------
• [0.056 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:53.052
    Feb 13 14:00:53.052: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename namespaces 02/13/23 14:00:53.054
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:53.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:53.075
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 02/13/23 14:00:53.079
    Feb 13 14:00:53.082: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 02/13/23 14:00:53.082
    Feb 13 14:00:53.087: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 02/13/23 14:00:53.088
    Feb 13 14:00:53.096: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:00:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4726" for this suite. 02/13/23 14:00:53.1
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:53.109
Feb 13 14:00:53.109: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:00:53.11
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:53.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:53.123
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 02/13/23 14:00:53.126
Feb 13 14:00:53.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7396 create -f -'
Feb 13 14:00:53.382: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:00:53.382: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 02/13/23 14:00:53.382
Feb 13 14:00:54.391: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:00:54.391: INFO: Found 1 / 1
Feb 13 14:00:54.391: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 02/13/23 14:00:54.391
Feb 13 14:00:54.398: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:00:54.398: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 14:00:54.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7396 patch pod agnhost-primary-95hcw -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 13 14:00:54.559: INFO: stderr: ""
Feb 13 14:00:54.559: INFO: stdout: "pod/agnhost-primary-95hcw patched\n"
STEP: checking annotations 02/13/23 14:00:54.559
Feb 13 14:00:54.564: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:00:54.564: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:00:54.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7396" for this suite. 02/13/23 14:00:54.57
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":150,"skipped":2886,"failed":0}
------------------------------
• [1.469 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:53.109
    Feb 13 14:00:53.109: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:00:53.11
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:53.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:53.123
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 02/13/23 14:00:53.126
    Feb 13 14:00:53.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7396 create -f -'
    Feb 13 14:00:53.382: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:00:53.382: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 02/13/23 14:00:53.382
    Feb 13 14:00:54.391: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:00:54.391: INFO: Found 1 / 1
    Feb 13 14:00:54.391: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 02/13/23 14:00:54.391
    Feb 13 14:00:54.398: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:00:54.398: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Feb 13 14:00:54.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7396 patch pod agnhost-primary-95hcw -p {"metadata":{"annotations":{"x":"y"}}}'
    Feb 13 14:00:54.559: INFO: stderr: ""
    Feb 13 14:00:54.559: INFO: stdout: "pod/agnhost-primary-95hcw patched\n"
    STEP: checking annotations 02/13/23 14:00:54.559
    Feb 13 14:00:54.564: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:00:54.564: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:00:54.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7396" for this suite. 02/13/23 14:00:54.57
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:00:54.59
Feb 13 14:00:54.590: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-webhook 02/13/23 14:00:54.591
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:54.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:54.623
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 02/13/23 14:00:54.627
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 02/13/23 14:00:54.925
STEP: Deploying the custom resource conversion webhook pod 02/13/23 14:00:54.935
W0213 14:00:54.954889      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:00:54.955
Feb 13 14:00:54.967: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:00:56.994
STEP: Verifying the service has paired with the endpoint 02/13/23 14:00:57.017
Feb 13 14:00:58.018: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Feb 13 14:00:58.025: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Creating a v1 custom resource 02/13/23 14:01:00.63
STEP: v2 custom resource should be converted 02/13/23 14:01:00.638
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:01:01.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2143" for this suite. 02/13/23 14:01:01.184
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":151,"skipped":2922,"failed":0}
------------------------------
• [SLOW TEST] [6.650 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:00:54.59
    Feb 13 14:00:54.590: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-webhook 02/13/23 14:00:54.591
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:00:54.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:00:54.623
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 02/13/23 14:00:54.627
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 02/13/23 14:00:54.925
    STEP: Deploying the custom resource conversion webhook pod 02/13/23 14:00:54.935
    W0213 14:00:54.954889      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:00:54.955
    Feb 13 14:00:54.967: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:00:56.994
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:00:57.017
    Feb 13 14:00:58.018: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Feb 13 14:00:58.025: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Creating a v1 custom resource 02/13/23 14:01:00.63
    STEP: v2 custom resource should be converted 02/13/23 14:01:00.638
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:01:01.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-2143" for this suite. 02/13/23 14:01:01.184
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:01:01.254
Feb 13 14:01:01.256: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:01:01.257
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:01:01.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:01:01.286
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-f7ddd014-bd0d-4ad8-bc4e-4845dbb75ee2 02/13/23 14:01:01.289
STEP: Creating a pod to test consume secrets 02/13/23 14:01:01.294
W0213 14:01:01.303889      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:01:01.304: INFO: Waiting up to 5m0s for pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423" in namespace "secrets-2556" to be "Succeeded or Failed"
Feb 13 14:01:01.310: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Pending", Reason="", readiness=false. Elapsed: 6.806519ms
Feb 13 14:01:03.317: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013381293s
Feb 13 14:01:05.314: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010866875s
STEP: Saw pod success 02/13/23 14:01:05.315
Feb 13 14:01:05.315: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423" satisfied condition "Succeeded or Failed"
Feb 13 14:01:05.318: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:01:05.327
Feb 13 14:01:05.340: INFO: Waiting for pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 to disappear
Feb 13 14:01:05.343: INFO: Pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:01:05.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2556" for this suite. 02/13/23 14:01:05.348
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":152,"skipped":2993,"failed":0}
------------------------------
• [4.099 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:01:01.254
    Feb 13 14:01:01.256: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:01:01.257
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:01:01.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:01:01.286
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-f7ddd014-bd0d-4ad8-bc4e-4845dbb75ee2 02/13/23 14:01:01.289
    STEP: Creating a pod to test consume secrets 02/13/23 14:01:01.294
    W0213 14:01:01.303889      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:01:01.304: INFO: Waiting up to 5m0s for pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423" in namespace "secrets-2556" to be "Succeeded or Failed"
    Feb 13 14:01:01.310: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Pending", Reason="", readiness=false. Elapsed: 6.806519ms
    Feb 13 14:01:03.317: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013381293s
    Feb 13 14:01:05.314: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010866875s
    STEP: Saw pod success 02/13/23 14:01:05.315
    Feb 13 14:01:05.315: INFO: Pod "pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423" satisfied condition "Succeeded or Failed"
    Feb 13 14:01:05.318: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:01:05.327
    Feb 13 14:01:05.340: INFO: Waiting for pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 to disappear
    Feb 13 14:01:05.343: INFO: Pod pod-secrets-0a5516fd-bbff-4122-8cda-5254a34e4423 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:01:05.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2556" for this suite. 02/13/23 14:01:05.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:01:05.356
Feb 13 14:01:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 14:01:05.357
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:01:05.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:01:05.375
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-623 02/13/23 14:01:05.381
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-623 02/13/23 14:01:05.39
W0213 14:01:05.399804      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-623 02/13/23 14:01:05.4
Feb 13 14:01:05.406: INFO: Found 0 stateful pods, waiting for 1
Feb 13 14:01:15.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 02/13/23 14:01:15.415
Feb 13 14:01:15.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:01:15.708: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:01:15.708: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:01:15.708: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:01:15.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 14:01:25.721: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:01:25.721: INFO: Waiting for statefulset status.replicas updated to 0
W0213 14:01:25.743230      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:01:25.748: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 13 14:01:25.748: INFO: ss-0  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  }]
Feb 13 14:01:25.749: INFO: 
Feb 13 14:01:25.749: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 13 14:01:26.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993925351s
Feb 13 14:01:27.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983535747s
Feb 13 14:01:28.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97585041s
Feb 13 14:01:29.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965729207s
Feb 13 14:01:30.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.956869853s
Feb 13 14:01:31.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952393679s
Feb 13 14:01:32.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943309273s
Feb 13 14:01:33.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.934203493s
Feb 13 14:01:34.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.373827ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-623 02/13/23 14:01:35.822
Feb 13 14:01:35.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:01:36.099: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:01:36.099: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:01:36.099: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:01:36.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:01:36.366: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 13 14:01:36.366: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:01:36.366: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:01:36.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:01:36.618: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 13 14:01:36.618: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:01:36.618: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:01:36.625: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb 13 14:01:46.638: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:01:46.638: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:01:46.638: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 02/13/23 14:01:46.638
Feb 13 14:01:46.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:01:46.895: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:01:46.895: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:01:46.895: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:01:46.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:01:47.165: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:01:47.165: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:01:47.165: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:01:47.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:01:47.439: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:01:47.439: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:01:47.439: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:01:47.439: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:01:47.444: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 13 14:01:57.459: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:01:57.459: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:01:57.459: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
W0213 14:01:57.475941      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:01:57.483: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 13 14:01:57.483: INFO: ss-0  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  }]
Feb 13 14:01:57.483: INFO: ss-1  conformance-5500-0ccfa5-pool-bf9f-vfwrl  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  }]
Feb 13 14:01:57.483: INFO: ss-2  conformance-5500-0ccfa5-pool-bf9f-myudo  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  }]
Feb 13 14:01:57.484: INFO: 
Feb 13 14:01:57.484: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:01:58.496: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.988462924s
Feb 13 14:01:59.502: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.979809242s
Feb 13 14:02:00.508: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.973669658s
Feb 13 14:02:01.515: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.967552874s
Feb 13 14:02:02.522: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.960324756s
Feb 13 14:02:03.529: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.953403762s
Feb 13 14:02:04.537: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.946224694s
Feb 13 14:02:05.543: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.938710188s
Feb 13 14:02:06.548: INFO: Verifying statefulset ss doesn't scale past 0 for another 932.140369ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-623 02/13/23 14:02:07.549
Feb 13 14:02:07.557: INFO: Scaling statefulset ss to 0
W0213 14:02:07.571237      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:02:07.577: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 14:02:07.582: INFO: Deleting all statefulset in ns statefulset-623
Feb 13 14:02:07.587: INFO: Scaling statefulset ss to 0
W0213 14:02:07.599301      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:02:07.604: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:02:07.608: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 14:02:07.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-623" for this suite. 02/13/23 14:02:07.635
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":153,"skipped":3041,"failed":0}
------------------------------
• [SLOW TEST] [62.287 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:01:05.356
    Feb 13 14:01:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 14:01:05.357
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:01:05.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:01:05.375
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-623 02/13/23 14:01:05.381
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-623 02/13/23 14:01:05.39
    W0213 14:01:05.399804      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-623 02/13/23 14:01:05.4
    Feb 13 14:01:05.406: INFO: Found 0 stateful pods, waiting for 1
    Feb 13 14:01:15.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 02/13/23 14:01:15.415
    Feb 13 14:01:15.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:01:15.708: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:01:15.708: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:01:15.708: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:01:15.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Feb 13 14:01:25.721: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:01:25.721: INFO: Waiting for statefulset status.replicas updated to 0
    W0213 14:01:25.743230      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:01:25.748: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
    Feb 13 14:01:25.748: INFO: ss-0  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  }]
    Feb 13 14:01:25.749: INFO: 
    Feb 13 14:01:25.749: INFO: StatefulSet ss has not reached scale 3, at 1
    Feb 13 14:01:26.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993925351s
    Feb 13 14:01:27.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983535747s
    Feb 13 14:01:28.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97585041s
    Feb 13 14:01:29.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965729207s
    Feb 13 14:01:30.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.956869853s
    Feb 13 14:01:31.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952393679s
    Feb 13 14:01:32.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943309273s
    Feb 13 14:01:33.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.934203493s
    Feb 13 14:01:34.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.373827ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-623 02/13/23 14:01:35.822
    Feb 13 14:01:35.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:01:36.099: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:01:36.099: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:01:36.099: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:01:36.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:01:36.366: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Feb 13 14:01:36.366: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:01:36.366: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:01:36.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:01:36.618: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Feb 13 14:01:36.618: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:01:36.618: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:01:36.625: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Feb 13 14:01:46.638: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:01:46.638: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:01:46.638: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 02/13/23 14:01:46.638
    Feb 13 14:01:46.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:01:46.895: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:01:46.895: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:01:46.895: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:01:46.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:01:47.165: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:01:47.165: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:01:47.165: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:01:47.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-623 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:01:47.439: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:01:47.439: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:01:47.439: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:01:47.439: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:01:47.444: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Feb 13 14:01:57.459: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:01:57.459: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:01:57.459: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    W0213 14:01:57.475941      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:01:57.483: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
    Feb 13 14:01:57.483: INFO: ss-0  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:05 +0000 UTC  }]
    Feb 13 14:01:57.483: INFO: ss-1  conformance-5500-0ccfa5-pool-bf9f-vfwrl  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  }]
    Feb 13 14:01:57.483: INFO: ss-2  conformance-5500-0ccfa5-pool-bf9f-myudo  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:01:25 +0000 UTC  }]
    Feb 13 14:01:57.484: INFO: 
    Feb 13 14:01:57.484: INFO: StatefulSet ss has not reached scale 0, at 3
    Feb 13 14:01:58.496: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.988462924s
    Feb 13 14:01:59.502: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.979809242s
    Feb 13 14:02:00.508: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.973669658s
    Feb 13 14:02:01.515: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.967552874s
    Feb 13 14:02:02.522: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.960324756s
    Feb 13 14:02:03.529: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.953403762s
    Feb 13 14:02:04.537: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.946224694s
    Feb 13 14:02:05.543: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.938710188s
    Feb 13 14:02:06.548: INFO: Verifying statefulset ss doesn't scale past 0 for another 932.140369ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-623 02/13/23 14:02:07.549
    Feb 13 14:02:07.557: INFO: Scaling statefulset ss to 0
    W0213 14:02:07.571237      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:02:07.577: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 14:02:07.582: INFO: Deleting all statefulset in ns statefulset-623
    Feb 13 14:02:07.587: INFO: Scaling statefulset ss to 0
    W0213 14:02:07.599301      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:02:07.604: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:02:07.608: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 14:02:07.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-623" for this suite. 02/13/23 14:02:07.635
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:02:07.66
Feb 13 14:02:07.661: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:02:07.662
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:02:07.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:02:07.684
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
W0213 14:02:07.699269      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:02:07.699: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4830 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Feb 13 14:02:07.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4830" for this suite. 02/13/23 14:02:07.713
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":154,"skipped":3045,"failed":0}
------------------------------
• [0.061 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:02:07.66
    Feb 13 14:02:07.661: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:02:07.662
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:02:07.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:02:07.684
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    W0213 14:02:07.699269      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:02:07.699: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4830 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Feb 13 14:02:07.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4830" for this suite. 02/13/23 14:02:07.713
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:02:07.735
Feb 13 14:02:07.735: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 14:02:07.737
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:02:07.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:02:07.754
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
W0213 14:02:07.766270      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 14:03:07.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4710" for this suite. 02/13/23 14:03:07.78
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":155,"skipped":3071,"failed":0}
------------------------------
• [SLOW TEST] [60.055 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:02:07.735
    Feb 13 14:02:07.735: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 14:02:07.737
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:02:07.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:02:07.754
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    W0213 14:02:07.766270      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 14:03:07.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4710" for this suite. 02/13/23 14:03:07.78
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:03:07.796
Feb 13 14:03:07.796: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:03:07.798
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:07.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:07.821
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:03:07.83
W0213 14:03:07.839719      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:07.840: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8523" to be "running and ready"
Feb 13 14:03:07.846: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042181ms
Feb 13 14:03:07.846: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:03:09.855: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.014840189s
Feb 13 14:03:09.855: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Feb 13 14:03:09.855: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 02/13/23 14:03:09.861
W0213 14:03:09.873028      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:09.873: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8523" to be "running and ready"
Feb 13 14:03:09.878: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.094415ms
Feb 13 14:03:09.878: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:03:11.886: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012802487s
Feb 13 14:03:11.886: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Feb 13 14:03:11.886: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 02/13/23 14:03:11.891
STEP: delete the pod with lifecycle hook 02/13/23 14:03:11.916
Feb 13 14:03:11.927: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:03:11.932: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:03:13.933: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:03:13.940: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:03:15.933: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:03:15.939: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Feb 13 14:03:15.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8523" for this suite. 02/13/23 14:03:15.945
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":156,"skipped":3088,"failed":0}
------------------------------
• [SLOW TEST] [8.158 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:03:07.796
    Feb 13 14:03:07.796: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:03:07.798
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:07.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:07.821
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:03:07.83
    W0213 14:03:07.839719      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:07.840: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8523" to be "running and ready"
    Feb 13 14:03:07.846: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042181ms
    Feb 13 14:03:07.846: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:03:09.855: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.014840189s
    Feb 13 14:03:09.855: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Feb 13 14:03:09.855: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 02/13/23 14:03:09.861
    W0213 14:03:09.873028      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:09.873: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8523" to be "running and ready"
    Feb 13 14:03:09.878: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.094415ms
    Feb 13 14:03:09.878: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:03:11.886: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012802487s
    Feb 13 14:03:11.886: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Feb 13 14:03:11.886: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 02/13/23 14:03:11.891
    STEP: delete the pod with lifecycle hook 02/13/23 14:03:11.916
    Feb 13 14:03:11.927: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Feb 13 14:03:11.932: INFO: Pod pod-with-poststart-exec-hook still exists
    Feb 13 14:03:13.933: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Feb 13 14:03:13.940: INFO: Pod pod-with-poststart-exec-hook still exists
    Feb 13 14:03:15.933: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Feb 13 14:03:15.939: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Feb 13 14:03:15.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8523" for this suite. 02/13/23 14:03:15.945
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:03:15.956
Feb 13 14:03:15.956: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename events 02/13/23 14:03:15.958
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:15.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:15.978
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 02/13/23 14:03:15.986
STEP: get a list of Events with a label in the current namespace 02/13/23 14:03:16.012
STEP: delete a list of events 02/13/23 14:03:16.017
Feb 13 14:03:16.017: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 02/13/23 14:03:16.035
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Feb 13 14:03:16.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-699" for this suite. 02/13/23 14:03:16.045
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":157,"skipped":3097,"failed":0}
------------------------------
• [0.096 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:03:15.956
    Feb 13 14:03:15.956: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename events 02/13/23 14:03:15.958
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:15.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:15.978
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 02/13/23 14:03:15.986
    STEP: get a list of Events with a label in the current namespace 02/13/23 14:03:16.012
    STEP: delete a list of events 02/13/23 14:03:16.017
    Feb 13 14:03:16.017: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 02/13/23 14:03:16.035
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Feb 13 14:03:16.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-699" for this suite. 02/13/23 14:03:16.045
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:03:16.055
Feb 13 14:03:16.056: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename subpath 02/13/23 14:03:16.057
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:16.073
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:16.077
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 02/13/23 14:03:16.08
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-b9t6 02/13/23 14:03:16.09
STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:03:16.091
W0213 14:03:16.101259      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-b9t6" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-b9t6" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-b9t6" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-b9t6" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:16.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-b9t6" in namespace "subpath-1141" to be "Succeeded or Failed"
Feb 13 14:03:16.106: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.857328ms
Feb 13 14:03:18.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010481805s
Feb 13 14:03:20.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 4.013037379s
Feb 13 14:03:22.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 6.012066716s
Feb 13 14:03:24.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 8.012989575s
Feb 13 14:03:26.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 10.010724158s
Feb 13 14:03:28.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 12.012395749s
Feb 13 14:03:30.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 14.011553676s
Feb 13 14:03:32.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 16.012527952s
Feb 13 14:03:34.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 18.010533586s
Feb 13 14:03:36.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 20.012261729s
Feb 13 14:03:38.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=false. Elapsed: 22.010712818s
Feb 13 14:03:40.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013021904s
STEP: Saw pod success 02/13/23 14:03:40.114
Feb 13 14:03:40.115: INFO: Pod "pod-subpath-test-configmap-b9t6" satisfied condition "Succeeded or Failed"
Feb 13 14:03:40.119: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-configmap-b9t6 container test-container-subpath-configmap-b9t6: <nil>
STEP: delete the pod 02/13/23 14:03:40.135
Feb 13 14:03:40.151: INFO: Waiting for pod pod-subpath-test-configmap-b9t6 to disappear
Feb 13 14:03:40.157: INFO: Pod pod-subpath-test-configmap-b9t6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-b9t6 02/13/23 14:03:40.157
Feb 13 14:03:40.158: INFO: Deleting pod "pod-subpath-test-configmap-b9t6" in namespace "subpath-1141"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Feb 13 14:03:40.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1141" for this suite. 02/13/23 14:03:40.168
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":158,"skipped":3100,"failed":0}
------------------------------
• [SLOW TEST] [24.123 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:03:16.055
    Feb 13 14:03:16.056: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename subpath 02/13/23 14:03:16.057
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:16.073
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:16.077
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 02/13/23 14:03:16.08
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-b9t6 02/13/23 14:03:16.09
    STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:03:16.091
    W0213 14:03:16.101259      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-b9t6" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-b9t6" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-b9t6" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-b9t6" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:16.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-b9t6" in namespace "subpath-1141" to be "Succeeded or Failed"
    Feb 13 14:03:16.106: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.857328ms
    Feb 13 14:03:18.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010481805s
    Feb 13 14:03:20.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 4.013037379s
    Feb 13 14:03:22.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 6.012066716s
    Feb 13 14:03:24.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 8.012989575s
    Feb 13 14:03:26.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 10.010724158s
    Feb 13 14:03:28.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 12.012395749s
    Feb 13 14:03:30.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 14.011553676s
    Feb 13 14:03:32.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 16.012527952s
    Feb 13 14:03:34.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 18.010533586s
    Feb 13 14:03:36.113: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=true. Elapsed: 20.012261729s
    Feb 13 14:03:38.112: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Running", Reason="", readiness=false. Elapsed: 22.010712818s
    Feb 13 14:03:40.114: INFO: Pod "pod-subpath-test-configmap-b9t6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013021904s
    STEP: Saw pod success 02/13/23 14:03:40.114
    Feb 13 14:03:40.115: INFO: Pod "pod-subpath-test-configmap-b9t6" satisfied condition "Succeeded or Failed"
    Feb 13 14:03:40.119: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-configmap-b9t6 container test-container-subpath-configmap-b9t6: <nil>
    STEP: delete the pod 02/13/23 14:03:40.135
    Feb 13 14:03:40.151: INFO: Waiting for pod pod-subpath-test-configmap-b9t6 to disappear
    Feb 13 14:03:40.157: INFO: Pod pod-subpath-test-configmap-b9t6 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-b9t6 02/13/23 14:03:40.157
    Feb 13 14:03:40.158: INFO: Deleting pod "pod-subpath-test-configmap-b9t6" in namespace "subpath-1141"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Feb 13 14:03:40.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1141" for this suite. 02/13/23 14:03:40.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:03:40.179
Feb 13 14:03:40.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:03:40.184
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:40.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:40.209
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-78e6100b-23b9-420b-909f-3fd23c2645f7 02/13/23 14:03:40.213
STEP: Creating a pod to test consume configMaps 02/13/23 14:03:40.219
W0213 14:03:40.228848      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:40.229: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17" in namespace "projected-6974" to be "Succeeded or Failed"
Feb 13 14:03:40.232: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Pending", Reason="", readiness=false. Elapsed: 3.443286ms
Feb 13 14:03:42.239: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009595269s
Feb 13 14:03:44.240: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010972423s
STEP: Saw pod success 02/13/23 14:03:44.24
Feb 13 14:03:44.240: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17" satisfied condition "Succeeded or Failed"
Feb 13 14:03:44.245: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:03:44.257
Feb 13 14:03:44.280: INFO: Waiting for pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 to disappear
Feb 13 14:03:44.282: INFO: Pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 14:03:44.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6974" for this suite. 02/13/23 14:03:44.286
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":159,"skipped":3109,"failed":0}
------------------------------
• [4.112 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:03:40.179
    Feb 13 14:03:40.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:03:40.184
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:40.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:40.209
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-78e6100b-23b9-420b-909f-3fd23c2645f7 02/13/23 14:03:40.213
    STEP: Creating a pod to test consume configMaps 02/13/23 14:03:40.219
    W0213 14:03:40.228848      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:40.229: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17" in namespace "projected-6974" to be "Succeeded or Failed"
    Feb 13 14:03:40.232: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Pending", Reason="", readiness=false. Elapsed: 3.443286ms
    Feb 13 14:03:42.239: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009595269s
    Feb 13 14:03:44.240: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010972423s
    STEP: Saw pod success 02/13/23 14:03:44.24
    Feb 13 14:03:44.240: INFO: Pod "pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17" satisfied condition "Succeeded or Failed"
    Feb 13 14:03:44.245: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:03:44.257
    Feb 13 14:03:44.280: INFO: Waiting for pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 to disappear
    Feb 13 14:03:44.282: INFO: Pod pod-projected-configmaps-03a44969-614e-4078-8b49-7651bf629b17 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 14:03:44.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6974" for this suite. 02/13/23 14:03:44.286
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:03:44.3
Feb 13 14:03:44.301: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 14:03:44.303
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:44.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:44.323
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
W0213 14:03:44.338837      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:44.348: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 14:03:44.348
Feb 13 14:03:44.349: INFO: Waiting up to 5m0s for pod "test-rollover-controller-njqnx" in namespace "deployment-3638" to be "running"
Feb 13 14:03:44.357: INFO: Pod "test-rollover-controller-njqnx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.451159ms
Feb 13 14:03:46.364: INFO: Pod "test-rollover-controller-njqnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.015631882s
Feb 13 14:03:46.364: INFO: Pod "test-rollover-controller-njqnx" satisfied condition "running"
Feb 13 14:03:46.364: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 13 14:03:48.372: INFO: Creating deployment "test-rollover-deployment"
W0213 14:03:48.379065      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "redis-slave" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "redis-slave" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "redis-slave" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "redis-slave" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:48.383: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 13 14:03:50.397: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 13 14:03:50.409: INFO: Ensure that both replica sets have 1 created replica
Feb 13 14:03:50.416: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
W0213 14:03:50.433325      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:03:50.433: INFO: Updating deployment test-rollover-deployment
Feb 13 14:03:50.433: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 13 14:03:52.447: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 13 14:03:52.459: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 13 14:03:52.467: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 14:03:52.467: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:03:54.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 14:03:54.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:03:56.478: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 14:03:56.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:03:58.481: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 14:03:58.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:04:00.476: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 14:04:00.477: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:04:02.482: INFO: 
Feb 13 14:04:02.482: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 14:04:02.495: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3638  d70c5d08-c403-4bb4-862c-47d305763f63 18001 2 2023-02-13 14:03:48 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c46b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 14:03:48 +0000 UTC,LastTransitionTime:2023-02-13 14:03:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-02-13 14:04:01 +0000 UTC,LastTransitionTime:2023-02-13 14:03:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 14:04:02.501: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-3638  149908b0-5bf9-4364-88b6-bb2125628f63 17991 2 2023-02-13 14:03:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4f87 0xc0036c4f88}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c5038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 13 14:04:02.501: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 13 14:04:02.501: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3638  37a79159-d896-49e2-9c44-d0813180ab35 18000 2 2023-02-13 14:03:44 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4a67 0xc0036c4a68}] [] [{e2e.test Update apps/v1 2023-02-13 14:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0036c4b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 14:04:02.501: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-3638  cc0e7db5-1f61-4840-87e7-79bc07ffe432 17955 2 2023-02-13 14:03:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4b97 0xc0036c4b98}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c4d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 13 14:04:02.505: INFO: Pod "test-rollover-deployment-6d45fd857b-75gxn" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-75gxn test-rollover-deployment-6d45fd857b- deployment-3638  41797c77-595b-4da8-9ed6-de35f95278c0 17969 0 2023-02-13 14:03:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 149908b0-5bf9-4364-88b6-bb2125628f63 0xc003a5bde7 0xc003a5bde8}] [] [{kube-controller-manager Update v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"149908b0-5bf9-4364-88b6-bb2125628f63\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:03:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g95lj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g95lj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.176,StartTime:2023-02-13 14:03:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:03:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://62afe2dde734b1318dd72f8d4dcc604e17689408e6792c3447126bd38ed41844,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 14:04:02.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3638" for this suite. 02/13/23 14:04:02.509
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":160,"skipped":3126,"failed":0}
------------------------------
• [SLOW TEST] [18.217 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:03:44.3
    Feb 13 14:03:44.301: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 14:03:44.303
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:03:44.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:03:44.323
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    W0213 14:03:44.338837      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:44.348: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 14:03:44.348
    Feb 13 14:03:44.349: INFO: Waiting up to 5m0s for pod "test-rollover-controller-njqnx" in namespace "deployment-3638" to be "running"
    Feb 13 14:03:44.357: INFO: Pod "test-rollover-controller-njqnx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.451159ms
    Feb 13 14:03:46.364: INFO: Pod "test-rollover-controller-njqnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.015631882s
    Feb 13 14:03:46.364: INFO: Pod "test-rollover-controller-njqnx" satisfied condition "running"
    Feb 13 14:03:46.364: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Feb 13 14:03:48.372: INFO: Creating deployment "test-rollover-deployment"
    W0213 14:03:48.379065      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "redis-slave" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "redis-slave" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "redis-slave" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "redis-slave" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:48.383: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Feb 13 14:03:50.397: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Feb 13 14:03:50.409: INFO: Ensure that both replica sets have 1 created replica
    Feb 13 14:03:50.416: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    W0213 14:03:50.433325      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:03:50.433: INFO: Updating deployment test-rollover-deployment
    Feb 13 14:03:50.433: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Feb 13 14:03:52.447: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Feb 13 14:03:52.459: INFO: Make sure deployment "test-rollover-deployment" is complete
    Feb 13 14:03:52.467: INFO: all replica sets need to contain the pod-template-hash label
    Feb 13 14:03:52.467: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:03:54.482: INFO: all replica sets need to contain the pod-template-hash label
    Feb 13 14:03:54.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:03:56.478: INFO: all replica sets need to contain the pod-template-hash label
    Feb 13 14:03:56.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:03:58.481: INFO: all replica sets need to contain the pod-template-hash label
    Feb 13 14:03:58.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:04:00.476: INFO: all replica sets need to contain the pod-template-hash label
    Feb 13 14:04:00.477: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 3, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 3, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:04:02.482: INFO: 
    Feb 13 14:04:02.482: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 14:04:02.495: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-3638  d70c5d08-c403-4bb4-862c-47d305763f63 18001 2 2023-02-13 14:03:48 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c46b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-02-13 14:03:48 +0000 UTC,LastTransitionTime:2023-02-13 14:03:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-02-13 14:04:01 +0000 UTC,LastTransitionTime:2023-02-13 14:03:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Feb 13 14:04:02.501: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-3638  149908b0-5bf9-4364-88b6-bb2125628f63 17991 2 2023-02-13 14:03:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4f87 0xc0036c4f88}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c5038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 14:04:02.501: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Feb 13 14:04:02.501: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3638  37a79159-d896-49e2-9c44-d0813180ab35 18000 2 2023-02-13 14:03:44 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4a67 0xc0036c4a68}] [] [{e2e.test Update apps/v1 2023-02-13 14:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:04:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0036c4b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 14:04:02.501: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-3638  cc0e7db5-1f61-4840-87e7-79bc07ffe432 17955 2 2023-02-13 14:03:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d70c5d08-c403-4bb4-862c-47d305763f63 0xc0036c4b97 0xc0036c4b98}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d70c5d08-c403-4bb4-862c-47d305763f63\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036c4d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Feb 13 14:04:02.505: INFO: Pod "test-rollover-deployment-6d45fd857b-75gxn" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-75gxn test-rollover-deployment-6d45fd857b- deployment-3638  41797c77-595b-4da8-9ed6-de35f95278c0 17969 0 2023-02-13 14:03:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 149908b0-5bf9-4364-88b6-bb2125628f63 0xc003a5bde7 0xc003a5bde8}] [] [{kube-controller-manager Update v1 2023-02-13 14:03:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"149908b0-5bf9-4364-88b6-bb2125628f63\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:03:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g95lj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g95lj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:03:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.176,StartTime:2023-02-13 14:03:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:03:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://62afe2dde734b1318dd72f8d4dcc604e17689408e6792c3447126bd38ed41844,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 14:04:02.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3638" for this suite. 02/13/23 14:04:02.509
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:02.523
Feb 13 14:04:02.524: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:04:02.525
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:02.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:02.547
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5957 02/13/23 14:04:02.552
STEP: changing the ExternalName service to type=ClusterIP 02/13/23 14:04:02.562
STEP: creating replication controller externalname-service in namespace services-5957 02/13/23 14:04:02.586
W0213 14:04:02.593230      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:04:02.593651      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5957, replica count: 2
I0213 14:04:05.645146      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:04:05.645: INFO: Creating new exec pod
W0213 14:04:05.661003      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:04:05.661: INFO: Waiting up to 5m0s for pod "execpod7fxtl" in namespace "services-5957" to be "running"
Feb 13 14:04:05.666: INFO: Pod "execpod7fxtl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.006139ms
Feb 13 14:04:07.671: INFO: Pod "execpod7fxtl": Phase="Running", Reason="", readiness=true. Elapsed: 2.009965954s
Feb 13 14:04:07.671: INFO: Pod "execpod7fxtl" satisfied condition "running"
Feb 13 14:04:08.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Feb 13 14:04:08.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 13 14:04:08.957: INFO: stdout: ""
Feb 13 14:04:09.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Feb 13 14:04:10.211: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 13 14:04:10.211: INFO: stdout: "externalname-service-8n9d6"
Feb 13 14:04:10.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.114.27 80'
Feb 13 14:04:10.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.114.27 80\nConnection to 10.110.114.27 80 port [tcp/http] succeeded!\n"
Feb 13 14:04:10.457: INFO: stdout: ""
Feb 13 14:04:11.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.114.27 80'
Feb 13 14:04:11.707: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.114.27 80\nConnection to 10.110.114.27 80 port [tcp/http] succeeded!\n"
Feb 13 14:04:11.708: INFO: stdout: "externalname-service-b55kf"
Feb 13 14:04:11.708: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:04:11.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5957" for this suite. 02/13/23 14:04:11.737
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":161,"skipped":3134,"failed":0}
------------------------------
• [SLOW TEST] [9.220 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:02.523
    Feb 13 14:04:02.524: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:04:02.525
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:02.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:02.547
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5957 02/13/23 14:04:02.552
    STEP: changing the ExternalName service to type=ClusterIP 02/13/23 14:04:02.562
    STEP: creating replication controller externalname-service in namespace services-5957 02/13/23 14:04:02.586
    W0213 14:04:02.593230      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:04:02.593651      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5957, replica count: 2
    I0213 14:04:05.645146      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:04:05.645: INFO: Creating new exec pod
    W0213 14:04:05.661003      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:04:05.661: INFO: Waiting up to 5m0s for pod "execpod7fxtl" in namespace "services-5957" to be "running"
    Feb 13 14:04:05.666: INFO: Pod "execpod7fxtl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.006139ms
    Feb 13 14:04:07.671: INFO: Pod "execpod7fxtl": Phase="Running", Reason="", readiness=true. Elapsed: 2.009965954s
    Feb 13 14:04:07.671: INFO: Pod "execpod7fxtl" satisfied condition "running"
    Feb 13 14:04:08.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Feb 13 14:04:08.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Feb 13 14:04:08.957: INFO: stdout: ""
    Feb 13 14:04:09.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Feb 13 14:04:10.211: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Feb 13 14:04:10.211: INFO: stdout: "externalname-service-8n9d6"
    Feb 13 14:04:10.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.114.27 80'
    Feb 13 14:04:10.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.114.27 80\nConnection to 10.110.114.27 80 port [tcp/http] succeeded!\n"
    Feb 13 14:04:10.457: INFO: stdout: ""
    Feb 13 14:04:11.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-5957 exec execpod7fxtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.114.27 80'
    Feb 13 14:04:11.707: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.114.27 80\nConnection to 10.110.114.27 80 port [tcp/http] succeeded!\n"
    Feb 13 14:04:11.708: INFO: stdout: "externalname-service-b55kf"
    Feb 13 14:04:11.708: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:04:11.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5957" for this suite. 02/13/23 14:04:11.737
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:11.746
Feb 13 14:04:11.746: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 14:04:11.747
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:11.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:11.765
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Feb 13 14:04:11.790: INFO: Create a RollingUpdate DaemonSet
W0213 14:04:11.798973      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:04:11.799: INFO: Check that daemon pods launch on every node of the cluster
Feb 13 14:04:11.808: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:04:11.809: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:04:12.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:04:12.819: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:04:13.822: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 14:04:13.822: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Feb 13 14:04:13.822: INFO: Update the DaemonSet to trigger a rollout
W0213 14:04:13.835304      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:04:13.835: INFO: Updating DaemonSet daemon-set
Feb 13 14:04:16.854: INFO: Roll back the DaemonSet before rollout is complete
W0213 14:04:16.865074      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:04:16.865: INFO: Updating DaemonSet daemon-set
Feb 13 14:04:16.865: INFO: Make sure DaemonSet rollback is complete
Feb 13 14:04:16.869: INFO: Wrong image for pod: daemon-set-zbmsq. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Feb 13 14:04:16.869: INFO: Pod daemon-set-zbmsq is not available
Feb 13 14:04:19.880: INFO: Pod daemon-set-vbxtn is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:04:19.892
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1759, will wait for the garbage collector to delete the pods 02/13/23 14:04:19.892
Feb 13 14:04:19.956: INFO: Deleting DaemonSet.extensions daemon-set took: 9.523301ms
Feb 13 14:04:20.056: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.749655ms
Feb 13 14:04:22.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:04:22.961: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 14:04:22.965: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18264"},"items":null}

Feb 13 14:04:22.968: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18264"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:04:22.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1759" for this suite. 02/13/23 14:04:22.987
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":162,"skipped":3193,"failed":0}
------------------------------
• [SLOW TEST] [11.247 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:11.746
    Feb 13 14:04:11.746: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 14:04:11.747
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:11.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:11.765
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Feb 13 14:04:11.790: INFO: Create a RollingUpdate DaemonSet
    W0213 14:04:11.798973      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:04:11.799: INFO: Check that daemon pods launch on every node of the cluster
    Feb 13 14:04:11.808: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:04:11.809: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:04:12.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:04:12.819: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:04:13.822: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 14:04:13.822: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Feb 13 14:04:13.822: INFO: Update the DaemonSet to trigger a rollout
    W0213 14:04:13.835304      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:04:13.835: INFO: Updating DaemonSet daemon-set
    Feb 13 14:04:16.854: INFO: Roll back the DaemonSet before rollout is complete
    W0213 14:04:16.865074      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:04:16.865: INFO: Updating DaemonSet daemon-set
    Feb 13 14:04:16.865: INFO: Make sure DaemonSet rollback is complete
    Feb 13 14:04:16.869: INFO: Wrong image for pod: daemon-set-zbmsq. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Feb 13 14:04:16.869: INFO: Pod daemon-set-zbmsq is not available
    Feb 13 14:04:19.880: INFO: Pod daemon-set-vbxtn is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:04:19.892
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1759, will wait for the garbage collector to delete the pods 02/13/23 14:04:19.892
    Feb 13 14:04:19.956: INFO: Deleting DaemonSet.extensions daemon-set took: 9.523301ms
    Feb 13 14:04:20.056: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.749655ms
    Feb 13 14:04:22.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:04:22.961: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 14:04:22.965: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18264"},"items":null}

    Feb 13 14:04:22.968: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18264"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:04:22.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1759" for this suite. 02/13/23 14:04:22.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:23.001
Feb 13 14:04:23.001: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-webhook 02/13/23 14:04:23.003
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:23.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:23.034
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 02/13/23 14:04:23.039
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 02/13/23 14:04:23.362
STEP: Deploying the custom resource conversion webhook pod 02/13/23 14:04:23.372
W0213 14:04:23.391768      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:04:23.391
Feb 13 14:04:23.402: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:04:25.416
STEP: Verifying the service has paired with the endpoint 02/13/23 14:04:25.43
Feb 13 14:04:26.431: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Feb 13 14:04:26.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Creating a v1 custom resource 02/13/23 14:04:29.075
STEP: Create a v2 custom resource 02/13/23 14:04:29.098
STEP: List CRs in v1 02/13/23 14:04:29.167
STEP: List CRs in v2 02/13/23 14:04:29.176
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:04:29.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5177" for this suite. 02/13/23 14:04:29.704
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":163,"skipped":3246,"failed":0}
------------------------------
• [SLOW TEST] [6.754 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:23.001
    Feb 13 14:04:23.001: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-webhook 02/13/23 14:04:23.003
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:23.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:23.034
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 02/13/23 14:04:23.039
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 02/13/23 14:04:23.362
    STEP: Deploying the custom resource conversion webhook pod 02/13/23 14:04:23.372
    W0213 14:04:23.391768      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:04:23.391
    Feb 13 14:04:23.402: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:04:25.416
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:04:25.43
    Feb 13 14:04:26.431: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Feb 13 14:04:26.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Creating a v1 custom resource 02/13/23 14:04:29.075
    STEP: Create a v2 custom resource 02/13/23 14:04:29.098
    STEP: List CRs in v1 02/13/23 14:04:29.167
    STEP: List CRs in v2 02/13/23 14:04:29.176
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:04:29.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-5177" for this suite. 02/13/23 14:04:29.704
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:29.76
Feb 13 14:04:29.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename cronjob 02/13/23 14:04:29.761
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:29.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:29.787
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 02/13/23 14:04:29.791
STEP: creating 02/13/23 14:04:29.791
W0213 14:04:29.799306      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: getting 02/13/23 14:04:29.799
STEP: listing 02/13/23 14:04:29.803
STEP: watching 02/13/23 14:04:29.806
Feb 13 14:04:29.807: INFO: starting watch
STEP: cluster-wide listing 02/13/23 14:04:29.809
STEP: cluster-wide watching 02/13/23 14:04:29.816
Feb 13 14:04:29.817: INFO: starting watch
STEP: patching 02/13/23 14:04:29.819
W0213 14:04:29.827264      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: updating 02/13/23 14:04:29.827
W0213 14:04:29.838937      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:04:29.839: INFO: waiting for watch events with expected annotations
Feb 13 14:04:29.839: INFO: saw patched and updated annotations
STEP: patching /status 02/13/23 14:04:29.839
STEP: updating /status 02/13/23 14:04:29.846
STEP: get /status 02/13/23 14:04:29.855
STEP: deleting 02/13/23 14:04:29.858
W0213 14:04:29.866463      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: deleting a collection 02/13/23 14:04:29.874
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Feb 13 14:04:29.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6399" for this suite. 02/13/23 14:04:29.886
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":164,"skipped":3250,"failed":0}
------------------------------
• [0.132 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:29.76
    Feb 13 14:04:29.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename cronjob 02/13/23 14:04:29.761
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:29.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:29.787
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 02/13/23 14:04:29.791
    STEP: creating 02/13/23 14:04:29.791
    W0213 14:04:29.799306      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: getting 02/13/23 14:04:29.799
    STEP: listing 02/13/23 14:04:29.803
    STEP: watching 02/13/23 14:04:29.806
    Feb 13 14:04:29.807: INFO: starting watch
    STEP: cluster-wide listing 02/13/23 14:04:29.809
    STEP: cluster-wide watching 02/13/23 14:04:29.816
    Feb 13 14:04:29.817: INFO: starting watch
    STEP: patching 02/13/23 14:04:29.819
    W0213 14:04:29.827264      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: updating 02/13/23 14:04:29.827
    W0213 14:04:29.838937      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:04:29.839: INFO: waiting for watch events with expected annotations
    Feb 13 14:04:29.839: INFO: saw patched and updated annotations
    STEP: patching /status 02/13/23 14:04:29.839
    STEP: updating /status 02/13/23 14:04:29.846
    STEP: get /status 02/13/23 14:04:29.855
    STEP: deleting 02/13/23 14:04:29.858
    W0213 14:04:29.866463      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: deleting a collection 02/13/23 14:04:29.874
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Feb 13 14:04:29.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6399" for this suite. 02/13/23 14:04:29.886
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:29.893
Feb 13 14:04:29.893: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-pred 02/13/23 14:04:29.894
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:29.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:29.909
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Feb 13 14:04:29.912: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:04:29.919: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:04:29.923: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
Feb 13 14:04:29.929: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container civo-ccm ready: true, restart count 0
Feb 13 14:04:29.929: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:04:29.929: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 13 14:04:29.929: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 13 14:04:29.929: INFO: 	Container csi-resizer ready: true, restart count 0
Feb 13 14:04:29.929: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:04:29.929: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:04:29.929: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:04:29.929: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:04:29.929: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:04:29.929: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:04:29.929: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.929: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:04:29.929: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
Feb 13 14:04:29.934: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
Feb 13 14:04:29.934: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:04:29.934: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:04:29.934: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.934: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:04:29.934: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.934: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:04:29.934: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.934: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:04:29.934: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.935: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:04:29.935: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
Feb 13 14:04:29.941: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
Feb 13 14:04:29.941: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:04:29.941: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:04:29.941: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.941: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:04:29.941: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.941: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:04:29.941: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:04:29.941: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:04:29.941: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
Feb 13 14:04:29.941: INFO: 	Container e2e ready: true, restart count 0
Feb 13 14:04:29.941: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 14:04:29.942
Feb 13 14:04:29.952: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8348" to be "running"
Feb 13 14:04:29.955: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.648382ms
Feb 13 14:04:31.962: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.009674867s
Feb 13 14:04:31.962: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 14:04:31.97
STEP: Trying to apply a random label on the found node. 02/13/23 14:04:31.985
STEP: verifying the node has the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 42 02/13/23 14:04:31.996
STEP: Trying to relaunch the pod, now with labels. 02/13/23 14:04:32
Feb 13 14:04:32.009: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8348" to be "not pending"
Feb 13 14:04:32.013: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789185ms
Feb 13 14:04:34.018: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.009498251s
Feb 13 14:04:34.019: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:04:34.023
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 02/13/23 14:04:34.045
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:04:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8348" for this suite. 02/13/23 14:04:34.054
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":165,"skipped":3255,"failed":0}
------------------------------
• [4.168 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:29.893
    Feb 13 14:04:29.893: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-pred 02/13/23 14:04:29.894
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:29.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:29.909
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Feb 13 14:04:29.912: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Feb 13 14:04:29.919: INFO: Waiting for terminating namespaces to be deleted...
    Feb 13 14:04:29.923: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
    Feb 13 14:04:29.929: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container civo-ccm ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: 	Container csi-attacher ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: 	Container csi-provisioner ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: 	Container csi-resizer ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.929: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:04:29.929: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
    Feb 13 14:04:29.934: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
    Feb 13 14:04:29.934: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:04:29.934: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:04:29.934: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.934: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:04:29.934: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.934: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:04:29.934: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.934: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:04:29.934: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.935: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Feb 13 14:04:29.935: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
    Feb 13 14:04:29.941: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
    Feb 13 14:04:29.941: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.941: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.941: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:04:29.941: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
    Feb 13 14:04:29.941: INFO: 	Container e2e ready: true, restart count 0
    Feb 13 14:04:29.941: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 14:04:29.942
    Feb 13 14:04:29.952: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8348" to be "running"
    Feb 13 14:04:29.955: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.648382ms
    Feb 13 14:04:31.962: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.009674867s
    Feb 13 14:04:31.962: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 14:04:31.97
    STEP: Trying to apply a random label on the found node. 02/13/23 14:04:31.985
    STEP: verifying the node has the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 42 02/13/23 14:04:31.996
    STEP: Trying to relaunch the pod, now with labels. 02/13/23 14:04:32
    Feb 13 14:04:32.009: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8348" to be "not pending"
    Feb 13 14:04:32.013: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789185ms
    Feb 13 14:04:34.018: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.009498251s
    Feb 13 14:04:34.019: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:04:34.023
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-b4e5f445-43dd-4bce-a947-3fcd43d30979 02/13/23 14:04:34.045
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:04:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8348" for this suite. 02/13/23 14:04:34.054
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:34.065
Feb 13 14:04:34.065: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:04:34.066
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:34.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:34.1
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 02/13/23 14:04:34.104
Feb 13 14:04:34.106: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 02/13/23 14:04:44.258
Feb 13 14:04:44.259: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:04:46.385: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:04:55.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8019" for this suite. 02/13/23 14:04:55.724
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":166,"skipped":3268,"failed":0}
------------------------------
• [SLOW TEST] [21.667 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:34.065
    Feb 13 14:04:34.065: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:04:34.066
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:34.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:34.1
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 02/13/23 14:04:34.104
    Feb 13 14:04:34.106: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 02/13/23 14:04:44.258
    Feb 13 14:04:44.259: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:04:46.385: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:04:55.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8019" for this suite. 02/13/23 14:04:55.724
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:04:55.735
Feb 13 14:04:55.735: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:04:55.736
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:55.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:55.758
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:04:55.776
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:04:56.202
STEP: Deploying the webhook pod 02/13/23 14:04:56.211
W0213 14:04:56.226081      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:04:56.226
Feb 13 14:04:56.232: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 02/13/23 14:04:58.243
STEP: Verifying the service has paired with the endpoint 02/13/23 14:04:58.26
Feb 13 14:04:59.261: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Feb 13 14:04:59.267: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4266-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:04:59.783
STEP: Creating a custom resource while v1 is storage version 02/13/23 14:04:59.818
STEP: Patching Custom Resource Definition to set v2 as storage 02/13/23 14:05:01.891
STEP: Patching the custom resource while v2 is storage version 02/13/23 14:05:01.914
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:05:02.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-221" for this suite. 02/13/23 14:05:02.505
STEP: Destroying namespace "webhook-221-markers" for this suite. 02/13/23 14:05:02.514
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":167,"skipped":3286,"failed":0}
------------------------------
• [SLOW TEST] [6.843 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:04:55.735
    Feb 13 14:04:55.735: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:04:55.736
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:04:55.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:04:55.758
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:04:55.776
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:04:56.202
    STEP: Deploying the webhook pod 02/13/23 14:04:56.211
    W0213 14:04:56.226081      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:04:56.226
    Feb 13 14:04:56.232: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 02/13/23 14:04:58.243
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:04:58.26
    Feb 13 14:04:59.261: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Feb 13 14:04:59.267: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4266-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:04:59.783
    STEP: Creating a custom resource while v1 is storage version 02/13/23 14:04:59.818
    STEP: Patching Custom Resource Definition to set v2 as storage 02/13/23 14:05:01.891
    STEP: Patching the custom resource while v2 is storage version 02/13/23 14:05:01.914
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:05:02.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-221" for this suite. 02/13/23 14:05:02.505
    STEP: Destroying namespace "webhook-221-markers" for this suite. 02/13/23 14:05:02.514
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:02.581
Feb 13 14:05:02.581: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:05:02.582
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:02.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:02.609
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:05:02.614
W0213 14:05:02.622513      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:05:02.622: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4" in namespace "projected-1820" to be "Succeeded or Failed"
Feb 13 14:05:02.627: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.003728ms
Feb 13 14:05:04.632: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009856434s
Feb 13 14:05:06.634: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01104681s
STEP: Saw pod success 02/13/23 14:05:06.634
Feb 13 14:05:06.634: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4" satisfied condition "Succeeded or Failed"
Feb 13 14:05:06.640: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 container client-container: <nil>
STEP: delete the pod 02/13/23 14:05:06.654
Feb 13 14:05:06.666: INFO: Waiting for pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 to disappear
Feb 13 14:05:06.671: INFO: Pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:05:06.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1820" for this suite. 02/13/23 14:05:06.676
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":168,"skipped":3286,"failed":0}
------------------------------
• [4.103 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:02.581
    Feb 13 14:05:02.581: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:05:02.582
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:02.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:02.609
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:05:02.614
    W0213 14:05:02.622513      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:05:02.622: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4" in namespace "projected-1820" to be "Succeeded or Failed"
    Feb 13 14:05:02.627: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.003728ms
    Feb 13 14:05:04.632: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009856434s
    Feb 13 14:05:06.634: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01104681s
    STEP: Saw pod success 02/13/23 14:05:06.634
    Feb 13 14:05:06.634: INFO: Pod "downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4" satisfied condition "Succeeded or Failed"
    Feb 13 14:05:06.640: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:05:06.654
    Feb 13 14:05:06.666: INFO: Waiting for pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 to disappear
    Feb 13 14:05:06.671: INFO: Pod downwardapi-volume-3803d9e7-8482-4127-8c68-2bb6fb834ad4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:05:06.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1820" for this suite. 02/13/23 14:05:06.676
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:06.692
Feb 13 14:05:06.692: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 14:05:06.695
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:06.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:06.72
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 02/13/23 14:05:06.727
W0213 14:05:06.732827      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: create the rc2 02/13/23 14:05:06.733
W0213 14:05:06.748554      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 02/13/23 14:05:11.754
STEP: delete the rc simpletest-rc-to-be-deleted 02/13/23 14:05:12.484
STEP: wait for the rc to be deleted 02/13/23 14:05:12.499
Feb 13 14:05:17.518: INFO: 71 pods remaining
Feb 13 14:05:17.518: INFO: 71 pods has nil DeletionTimestamp
Feb 13 14:05:17.518: INFO: 
STEP: Gathering metrics 02/13/23 14:05:22.52
W0213 14:05:22.531333      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 14:05:22.531: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Feb 13 14:05:22.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-257pm" in namespace "gc-9860"
Feb 13 14:05:22.547: INFO: Deleting pod "simpletest-rc-to-be-deleted-28g8f" in namespace "gc-9860"
Feb 13 14:05:22.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fbhm" in namespace "gc-9860"
Feb 13 14:05:22.569: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hxc2" in namespace "gc-9860"
Feb 13 14:05:22.585: INFO: Deleting pod "simpletest-rc-to-be-deleted-2j89d" in namespace "gc-9860"
Feb 13 14:05:22.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ld95" in namespace "gc-9860"
Feb 13 14:05:22.618: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qc4g" in namespace "gc-9860"
Feb 13 14:05:22.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zxb4" in namespace "gc-9860"
Feb 13 14:05:22.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-47qgt" in namespace "gc-9860"
Feb 13 14:05:22.669: INFO: Deleting pod "simpletest-rc-to-be-deleted-49749" in namespace "gc-9860"
Feb 13 14:05:22.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jtbp" in namespace "gc-9860"
Feb 13 14:05:22.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4mrmf" in namespace "gc-9860"
Feb 13 14:05:22.715: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nrm2" in namespace "gc-9860"
Feb 13 14:05:22.727: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s9th" in namespace "gc-9860"
Feb 13 14:05:22.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vwjn" in namespace "gc-9860"
Feb 13 14:05:22.756: INFO: Deleting pod "simpletest-rc-to-be-deleted-5j5xh" in namespace "gc-9860"
Feb 13 14:05:22.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qs5z" in namespace "gc-9860"
Feb 13 14:05:22.780: INFO: Deleting pod "simpletest-rc-to-be-deleted-69jlf" in namespace "gc-9860"
Feb 13 14:05:22.800: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bfzs" in namespace "gc-9860"
Feb 13 14:05:22.808: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dhtk" in namespace "gc-9860"
Feb 13 14:05:22.822: INFO: Deleting pod "simpletest-rc-to-be-deleted-7spst" in namespace "gc-9860"
Feb 13 14:05:22.833: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tmsj" in namespace "gc-9860"
Feb 13 14:05:22.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-7v7lp" in namespace "gc-9860"
Feb 13 14:05:22.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xpz2" in namespace "gc-9860"
Feb 13 14:05:22.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-859p8" in namespace "gc-9860"
Feb 13 14:05:22.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hfxs" in namespace "gc-9860"
Feb 13 14:05:22.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ncmv" in namespace "gc-9860"
Feb 13 14:05:22.905: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nfj6" in namespace "gc-9860"
Feb 13 14:05:22.914: INFO: Deleting pod "simpletest-rc-to-be-deleted-966wb" in namespace "gc-9860"
Feb 13 14:05:22.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hk99" in namespace "gc-9860"
Feb 13 14:05:22.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qgp4" in namespace "gc-9860"
Feb 13 14:05:22.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-bb4tn" in namespace "gc-9860"
Feb 13 14:05:22.971: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkjx9" in namespace "gc-9860"
Feb 13 14:05:22.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-bndmk" in namespace "gc-9860"
Feb 13 14:05:22.996: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqxsn" in namespace "gc-9860"
Feb 13 14:05:23.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-ck7k5" in namespace "gc-9860"
Feb 13 14:05:23.021: INFO: Deleting pod "simpletest-rc-to-be-deleted-clgrh" in namespace "gc-9860"
Feb 13 14:05:23.038: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5tx2" in namespace "gc-9860"
Feb 13 14:05:23.048: INFO: Deleting pod "simpletest-rc-to-be-deleted-dcqjg" in namespace "gc-9860"
Feb 13 14:05:23.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-f45q6" in namespace "gc-9860"
Feb 13 14:05:23.073: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkzkf" in namespace "gc-9860"
Feb 13 14:05:23.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpsds" in namespace "gc-9860"
Feb 13 14:05:23.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvtvw" in namespace "gc-9860"
Feb 13 14:05:23.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-g474h" in namespace "gc-9860"
Feb 13 14:05:23.123: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbvzx" in namespace "gc-9860"
Feb 13 14:05:23.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfwqt" in namespace "gc-9860"
Feb 13 14:05:23.147: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtcfx" in namespace "gc-9860"
Feb 13 14:05:23.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwpnp" in namespace "gc-9860"
Feb 13 14:05:23.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-hbfbt" in namespace "gc-9860"
Feb 13 14:05:23.187: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjzv7" in namespace "gc-9860"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 14:05:23.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9860" for this suite. 02/13/23 14:05:23.209
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":169,"skipped":3307,"failed":0}
------------------------------
• [SLOW TEST] [16.526 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:06.692
    Feb 13 14:05:06.692: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 14:05:06.695
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:06.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:06.72
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 02/13/23 14:05:06.727
    W0213 14:05:06.732827      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: create the rc2 02/13/23 14:05:06.733
    W0213 14:05:06.748554      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 02/13/23 14:05:11.754
    STEP: delete the rc simpletest-rc-to-be-deleted 02/13/23 14:05:12.484
    STEP: wait for the rc to be deleted 02/13/23 14:05:12.499
    Feb 13 14:05:17.518: INFO: 71 pods remaining
    Feb 13 14:05:17.518: INFO: 71 pods has nil DeletionTimestamp
    Feb 13 14:05:17.518: INFO: 
    STEP: Gathering metrics 02/13/23 14:05:22.52
    W0213 14:05:22.531333      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 14:05:22.531: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Feb 13 14:05:22.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-257pm" in namespace "gc-9860"
    Feb 13 14:05:22.547: INFO: Deleting pod "simpletest-rc-to-be-deleted-28g8f" in namespace "gc-9860"
    Feb 13 14:05:22.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fbhm" in namespace "gc-9860"
    Feb 13 14:05:22.569: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hxc2" in namespace "gc-9860"
    Feb 13 14:05:22.585: INFO: Deleting pod "simpletest-rc-to-be-deleted-2j89d" in namespace "gc-9860"
    Feb 13 14:05:22.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ld95" in namespace "gc-9860"
    Feb 13 14:05:22.618: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qc4g" in namespace "gc-9860"
    Feb 13 14:05:22.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zxb4" in namespace "gc-9860"
    Feb 13 14:05:22.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-47qgt" in namespace "gc-9860"
    Feb 13 14:05:22.669: INFO: Deleting pod "simpletest-rc-to-be-deleted-49749" in namespace "gc-9860"
    Feb 13 14:05:22.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jtbp" in namespace "gc-9860"
    Feb 13 14:05:22.701: INFO: Deleting pod "simpletest-rc-to-be-deleted-4mrmf" in namespace "gc-9860"
    Feb 13 14:05:22.715: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nrm2" in namespace "gc-9860"
    Feb 13 14:05:22.727: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s9th" in namespace "gc-9860"
    Feb 13 14:05:22.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vwjn" in namespace "gc-9860"
    Feb 13 14:05:22.756: INFO: Deleting pod "simpletest-rc-to-be-deleted-5j5xh" in namespace "gc-9860"
    Feb 13 14:05:22.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qs5z" in namespace "gc-9860"
    Feb 13 14:05:22.780: INFO: Deleting pod "simpletest-rc-to-be-deleted-69jlf" in namespace "gc-9860"
    Feb 13 14:05:22.800: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bfzs" in namespace "gc-9860"
    Feb 13 14:05:22.808: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dhtk" in namespace "gc-9860"
    Feb 13 14:05:22.822: INFO: Deleting pod "simpletest-rc-to-be-deleted-7spst" in namespace "gc-9860"
    Feb 13 14:05:22.833: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tmsj" in namespace "gc-9860"
    Feb 13 14:05:22.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-7v7lp" in namespace "gc-9860"
    Feb 13 14:05:22.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xpz2" in namespace "gc-9860"
    Feb 13 14:05:22.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-859p8" in namespace "gc-9860"
    Feb 13 14:05:22.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hfxs" in namespace "gc-9860"
    Feb 13 14:05:22.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ncmv" in namespace "gc-9860"
    Feb 13 14:05:22.905: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nfj6" in namespace "gc-9860"
    Feb 13 14:05:22.914: INFO: Deleting pod "simpletest-rc-to-be-deleted-966wb" in namespace "gc-9860"
    Feb 13 14:05:22.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hk99" in namespace "gc-9860"
    Feb 13 14:05:22.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qgp4" in namespace "gc-9860"
    Feb 13 14:05:22.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-bb4tn" in namespace "gc-9860"
    Feb 13 14:05:22.971: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkjx9" in namespace "gc-9860"
    Feb 13 14:05:22.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-bndmk" in namespace "gc-9860"
    Feb 13 14:05:22.996: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqxsn" in namespace "gc-9860"
    Feb 13 14:05:23.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-ck7k5" in namespace "gc-9860"
    Feb 13 14:05:23.021: INFO: Deleting pod "simpletest-rc-to-be-deleted-clgrh" in namespace "gc-9860"
    Feb 13 14:05:23.038: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5tx2" in namespace "gc-9860"
    Feb 13 14:05:23.048: INFO: Deleting pod "simpletest-rc-to-be-deleted-dcqjg" in namespace "gc-9860"
    Feb 13 14:05:23.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-f45q6" in namespace "gc-9860"
    Feb 13 14:05:23.073: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkzkf" in namespace "gc-9860"
    Feb 13 14:05:23.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpsds" in namespace "gc-9860"
    Feb 13 14:05:23.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvtvw" in namespace "gc-9860"
    Feb 13 14:05:23.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-g474h" in namespace "gc-9860"
    Feb 13 14:05:23.123: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbvzx" in namespace "gc-9860"
    Feb 13 14:05:23.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfwqt" in namespace "gc-9860"
    Feb 13 14:05:23.147: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtcfx" in namespace "gc-9860"
    Feb 13 14:05:23.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwpnp" in namespace "gc-9860"
    Feb 13 14:05:23.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-hbfbt" in namespace "gc-9860"
    Feb 13 14:05:23.187: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjzv7" in namespace "gc-9860"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 14:05:23.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9860" for this suite. 02/13/23 14:05:23.209
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:23.219
Feb 13 14:05:23.219: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:05:23.221
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:23.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:23.239
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Feb 13 14:05:23.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5236 version'
Feb 13 14:05:23.341: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Feb 13 14:05:23.341: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:05:23.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5236" for this suite. 02/13/23 14:05:23.346
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":170,"skipped":3316,"failed":0}
------------------------------
• [0.135 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:23.219
    Feb 13 14:05:23.219: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:05:23.221
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:23.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:23.239
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Feb 13 14:05:23.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5236 version'
    Feb 13 14:05:23.341: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Feb 13 14:05:23.341: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:05:23.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5236" for this suite. 02/13/23 14:05:23.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:23.363
Feb 13 14:05:23.363: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 14:05:23.367
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:23.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:23.396
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Feb 13 14:05:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:05:29.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3176" for this suite. 02/13/23 14:05:29.745
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":171,"skipped":3343,"failed":0}
------------------------------
• [SLOW TEST] [6.395 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:23.363
    Feb 13 14:05:23.363: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 14:05:23.367
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:23.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:23.396
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Feb 13 14:05:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:05:29.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3176" for this suite. 02/13/23 14:05:29.745
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:29.765
Feb 13 14:05:29.766: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename server-version 02/13/23 14:05:29.768
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:29.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:29.794
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 02/13/23 14:05:29.801
STEP: Confirm major version 02/13/23 14:05:29.806
Feb 13 14:05:29.806: INFO: Major version: 1
STEP: Confirm minor version 02/13/23 14:05:29.806
Feb 13 14:05:29.807: INFO: cleanMinorVersion: 25
Feb 13 14:05:29.807: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Feb 13 14:05:29.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-9240" for this suite. 02/13/23 14:05:29.813
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":172,"skipped":3354,"failed":0}
------------------------------
• [0.054 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:29.765
    Feb 13 14:05:29.766: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename server-version 02/13/23 14:05:29.768
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:29.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:29.794
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 02/13/23 14:05:29.801
    STEP: Confirm major version 02/13/23 14:05:29.806
    Feb 13 14:05:29.806: INFO: Major version: 1
    STEP: Confirm minor version 02/13/23 14:05:29.806
    Feb 13 14:05:29.807: INFO: cleanMinorVersion: 25
    Feb 13 14:05:29.807: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Feb 13 14:05:29.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-9240" for this suite. 02/13/23 14:05:29.813
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:29.822
Feb 13 14:05:29.822: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 14:05:29.823
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:29.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:29.842
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 02/13/23 14:05:29.85
W0213 14:05:29.859752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: delete the rc 02/13/23 14:05:34.864
STEP: wait for the rc to be deleted 02/13/23 14:05:34.872
Feb 13 14:05:35.898: INFO: 80 pods remaining
Feb 13 14:05:35.898: INFO: 80 pods has nil DeletionTimestamp
Feb 13 14:05:35.898: INFO: 
Feb 13 14:05:36.892: INFO: 72 pods remaining
Feb 13 14:05:36.892: INFO: 72 pods has nil DeletionTimestamp
Feb 13 14:05:36.892: INFO: 
Feb 13 14:05:37.887: INFO: 60 pods remaining
Feb 13 14:05:37.887: INFO: 60 pods has nil DeletionTimestamp
Feb 13 14:05:37.887: INFO: 
Feb 13 14:05:38.884: INFO: 40 pods remaining
Feb 13 14:05:38.884: INFO: 40 pods has nil DeletionTimestamp
Feb 13 14:05:38.884: INFO: 
Feb 13 14:05:39.892: INFO: 32 pods remaining
Feb 13 14:05:39.892: INFO: 32 pods has nil DeletionTimestamp
Feb 13 14:05:39.892: INFO: 
Feb 13 14:05:40.885: INFO: 20 pods remaining
Feb 13 14:05:40.885: INFO: 20 pods has nil DeletionTimestamp
Feb 13 14:05:40.885: INFO: 
STEP: Gathering metrics 02/13/23 14:05:41.879
W0213 14:05:41.885864      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 14:05:41.885: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 14:05:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4031" for this suite. 02/13/23 14:05:41.889
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":173,"skipped":3363,"failed":0}
------------------------------
• [SLOW TEST] [12.075 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:29.822
    Feb 13 14:05:29.822: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 14:05:29.823
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:29.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:29.842
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 02/13/23 14:05:29.85
    W0213 14:05:29.859752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: delete the rc 02/13/23 14:05:34.864
    STEP: wait for the rc to be deleted 02/13/23 14:05:34.872
    Feb 13 14:05:35.898: INFO: 80 pods remaining
    Feb 13 14:05:35.898: INFO: 80 pods has nil DeletionTimestamp
    Feb 13 14:05:35.898: INFO: 
    Feb 13 14:05:36.892: INFO: 72 pods remaining
    Feb 13 14:05:36.892: INFO: 72 pods has nil DeletionTimestamp
    Feb 13 14:05:36.892: INFO: 
    Feb 13 14:05:37.887: INFO: 60 pods remaining
    Feb 13 14:05:37.887: INFO: 60 pods has nil DeletionTimestamp
    Feb 13 14:05:37.887: INFO: 
    Feb 13 14:05:38.884: INFO: 40 pods remaining
    Feb 13 14:05:38.884: INFO: 40 pods has nil DeletionTimestamp
    Feb 13 14:05:38.884: INFO: 
    Feb 13 14:05:39.892: INFO: 32 pods remaining
    Feb 13 14:05:39.892: INFO: 32 pods has nil DeletionTimestamp
    Feb 13 14:05:39.892: INFO: 
    Feb 13 14:05:40.885: INFO: 20 pods remaining
    Feb 13 14:05:40.885: INFO: 20 pods has nil DeletionTimestamp
    Feb 13 14:05:40.885: INFO: 
    STEP: Gathering metrics 02/13/23 14:05:41.879
    W0213 14:05:41.885864      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 14:05:41.885: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 14:05:41.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4031" for this suite. 02/13/23 14:05:41.889
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:41.898
Feb 13 14:05:41.898: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:05:41.9
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:41.918
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:41.921
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 02/13/23 14:05:41.924
Feb 13 14:05:41.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 create -f -'
Feb 13 14:05:42.939: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"httpd\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"httpd\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"httpd\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"httpd\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:05:42.939: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 02/13/23 14:05:42.939
Feb 13 14:05:42.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 diff -f -'
Feb 13 14:05:43.209: INFO: rc: 1
Feb 13 14:05:43.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 delete -f -'
Feb 13 14:05:43.296: INFO: stderr: ""
Feb 13 14:05:43.296: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:05:43.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8886" for this suite. 02/13/23 14:05:43.31
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":174,"skipped":3363,"failed":0}
------------------------------
• [1.427 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:41.898
    Feb 13 14:05:41.898: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:05:41.9
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:41.918
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:41.921
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 02/13/23 14:05:41.924
    Feb 13 14:05:41.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 create -f -'
    Feb 13 14:05:42.939: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"httpd\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"httpd\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"httpd\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"httpd\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:05:42.939: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 02/13/23 14:05:42.939
    Feb 13 14:05:42.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 diff -f -'
    Feb 13 14:05:43.209: INFO: rc: 1
    Feb 13 14:05:43.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8886 delete -f -'
    Feb 13 14:05:43.296: INFO: stderr: ""
    Feb 13 14:05:43.296: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:05:43.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8886" for this suite. 02/13/23 14:05:43.31
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:43.326
Feb 13 14:05:43.326: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 14:05:43.327
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:43.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:43.348
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 02/13/23 14:05:43.353
W0213 14:05:43.363838      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:05:43.364: INFO: Waiting up to 5m0s for pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a" in namespace "var-expansion-2923" to be "Succeeded or Failed"
Feb 13 14:05:43.368: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379419ms
Feb 13 14:05:45.373: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008901571s
Feb 13 14:05:47.377: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012867459s
Feb 13 14:05:49.374: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009798875s
Feb 13 14:05:51.376: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.012310183s
STEP: Saw pod success 02/13/23 14:05:51.376
Feb 13 14:05:51.376: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a" satisfied condition "Succeeded or Failed"
Feb 13 14:05:51.382: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a container dapi-container: <nil>
STEP: delete the pod 02/13/23 14:05:51.427
Feb 13 14:05:51.447: INFO: Waiting for pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a to disappear
Feb 13 14:05:51.451: INFO: Pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 14:05:51.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2923" for this suite. 02/13/23 14:05:51.457
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":175,"skipped":3373,"failed":0}
------------------------------
• [SLOW TEST] [8.137 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:43.326
    Feb 13 14:05:43.326: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 14:05:43.327
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:43.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:43.348
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 02/13/23 14:05:43.353
    W0213 14:05:43.363838      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:05:43.364: INFO: Waiting up to 5m0s for pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a" in namespace "var-expansion-2923" to be "Succeeded or Failed"
    Feb 13 14:05:43.368: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379419ms
    Feb 13 14:05:45.373: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008901571s
    Feb 13 14:05:47.377: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012867459s
    Feb 13 14:05:49.374: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009798875s
    Feb 13 14:05:51.376: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.012310183s
    STEP: Saw pod success 02/13/23 14:05:51.376
    Feb 13 14:05:51.376: INFO: Pod "var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a" satisfied condition "Succeeded or Failed"
    Feb 13 14:05:51.382: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a container dapi-container: <nil>
    STEP: delete the pod 02/13/23 14:05:51.427
    Feb 13 14:05:51.447: INFO: Waiting for pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a to disappear
    Feb 13 14:05:51.451: INFO: Pod var-expansion-9044b5de-9756-432c-b4b2-7ba4faf86f2a no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 14:05:51.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2923" for this suite. 02/13/23 14:05:51.457
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:51.464
Feb 13 14:05:51.464: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 14:05:51.465
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:51.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:51.48
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
W0213 14:05:51.491100      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:05:51.491: INFO: Waiting up to 2m0s for pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" in namespace "var-expansion-9459" to be "container 0 failed with reason CreateContainerConfigError"
Feb 13 14:05:51.494: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.180574ms
Feb 13 14:05:53.500: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0088428s
Feb 13 14:05:53.500: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Feb 13 14:05:53.500: INFO: Deleting pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" in namespace "var-expansion-9459"
Feb 13 14:05:53.513: INFO: Wait up to 5m0s for pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 14:05:55.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9459" for this suite. 02/13/23 14:05:55.529
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":176,"skipped":3380,"failed":0}
------------------------------
• [4.073 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:51.464
    Feb 13 14:05:51.464: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 14:05:51.465
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:51.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:51.48
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    W0213 14:05:51.491100      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:05:51.491: INFO: Waiting up to 2m0s for pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" in namespace "var-expansion-9459" to be "container 0 failed with reason CreateContainerConfigError"
    Feb 13 14:05:51.494: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.180574ms
    Feb 13 14:05:53.500: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0088428s
    Feb 13 14:05:53.500: INFO: Pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Feb 13 14:05:53.500: INFO: Deleting pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" in namespace "var-expansion-9459"
    Feb 13 14:05:53.513: INFO: Wait up to 5m0s for pod "var-expansion-978b127e-4880-4470-9871-99ff6e9a27fa" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 14:05:55.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9459" for this suite. 02/13/23 14:05:55.529
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:05:55.537
Feb 13 14:05:55.538: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 14:05:55.54
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:55.564
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:55.57
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Feb 13 14:05:55.607: INFO: Creating simple daemon set daemon-set
W0213 14:05:55.618463      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 14:05:55.618
Feb 13 14:05:55.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:05:55.629: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:05:56.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:05:56.638: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:05:57.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 14:05:57.639: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 02/13/23 14:05:57.651
W0213 14:05:57.660056      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods images are updated. 02/13/23 14:05:57.665
Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-cwnb7. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:58.681: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:58.681: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:59.680: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:05:59.680: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:06:00.679: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:06:00.679: INFO: Pod daemon-set-qtfrk is not available
Feb 13 14:06:00.679: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:06:01.681: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:06:02.680: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Feb 13 14:06:02.680: INFO: Pod daemon-set-swmwh is not available
Feb 13 14:06:04.681: INFO: Pod daemon-set-qs299 is not available
STEP: Check that daemon pods are still running on every node of the cluster. 02/13/23 14:06:04.687
Feb 13 14:06:04.699: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:06:04.699: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:06:05.713: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 14:06:05.713: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:06:05.738
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-768, will wait for the garbage collector to delete the pods 02/13/23 14:06:05.738
Feb 13 14:06:05.808: INFO: Deleting DaemonSet.extensions daemon-set took: 14.253023ms
Feb 13 14:06:05.909: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.009747ms
Feb 13 14:06:08.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:06:08.016: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 14:06:08.020: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21437"},"items":null}

Feb 13 14:06:08.024: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21437"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:06:08.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-768" for this suite. 02/13/23 14:06:08.047
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":177,"skipped":3380,"failed":0}
------------------------------
• [SLOW TEST] [12.518 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:05:55.537
    Feb 13 14:05:55.538: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 14:05:55.54
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:05:55.564
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:05:55.57
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Feb 13 14:05:55.607: INFO: Creating simple daemon set daemon-set
    W0213 14:05:55.618463      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 14:05:55.618
    Feb 13 14:05:55.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:05:55.629: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:05:56.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:05:56.638: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:05:57.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 14:05:57.639: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 02/13/23 14:05:57.651
    W0213 14:05:57.660056      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods images are updated. 02/13/23 14:05:57.665
    Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-cwnb7. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:57.670: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:58.681: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:58.681: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:59.680: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:05:59.680: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:06:00.679: INFO: Wrong image for pod: daemon-set-chv8t. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:06:00.679: INFO: Pod daemon-set-qtfrk is not available
    Feb 13 14:06:00.679: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:06:01.681: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:06:02.680: INFO: Wrong image for pod: daemon-set-s7842. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Feb 13 14:06:02.680: INFO: Pod daemon-set-swmwh is not available
    Feb 13 14:06:04.681: INFO: Pod daemon-set-qs299 is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 02/13/23 14:06:04.687
    Feb 13 14:06:04.699: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:06:04.699: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:06:05.713: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 14:06:05.713: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:06:05.738
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-768, will wait for the garbage collector to delete the pods 02/13/23 14:06:05.738
    Feb 13 14:06:05.808: INFO: Deleting DaemonSet.extensions daemon-set took: 14.253023ms
    Feb 13 14:06:05.909: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.009747ms
    Feb 13 14:06:08.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:06:08.016: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 14:06:08.020: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21437"},"items":null}

    Feb 13 14:06:08.024: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21437"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:06:08.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-768" for this suite. 02/13/23 14:06:08.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:06:08.073
Feb 13 14:06:08.073: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 14:06:08.075
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:08.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:08.098
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 02/13/23 14:06:08.104
W0213 14:06:08.119319      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the Deployment to create new ReplicaSet 02/13/23 14:06:08.12
STEP: delete the deployment 02/13/23 14:06:08.638
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 02/13/23 14:06:08.655
STEP: Gathering metrics 02/13/23 14:06:09.188
W0213 14:06:09.197556      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 14:06:09.197: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 14:06:09.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1966" for this suite. 02/13/23 14:06:09.203
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":178,"skipped":3432,"failed":0}
------------------------------
• [1.140 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:06:08.073
    Feb 13 14:06:08.073: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 14:06:08.075
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:08.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:08.098
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 02/13/23 14:06:08.104
    W0213 14:06:08.119319      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the Deployment to create new ReplicaSet 02/13/23 14:06:08.12
    STEP: delete the deployment 02/13/23 14:06:08.638
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 02/13/23 14:06:08.655
    STEP: Gathering metrics 02/13/23 14:06:09.188
    W0213 14:06:09.197556      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 14:06:09.197: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 14:06:09.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1966" for this suite. 02/13/23 14:06:09.203
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:06:09.214
Feb 13 14:06:09.214: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:06:09.216
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:09.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:09.245
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 02/13/23 14:06:09.252
STEP: submitting the pod to kubernetes 02/13/23 14:06:09.253
Feb 13 14:06:09.266: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" in namespace "pods-2268" to be "running and ready"
Feb 13 14:06:09.276: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.126939ms
Feb 13 14:06:09.276: INFO: The phase of Pod pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:06:11.282: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015242954s
Feb 13 14:06:11.282: INFO: The phase of Pod pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1 is Running (Ready = true)
Feb 13 14:06:11.282: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 02/13/23 14:06:11.287
STEP: updating the pod 02/13/23 14:06:11.292
Feb 13 14:06:11.807: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1"
Feb 13 14:06:11.807: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" in namespace "pods-2268" to be "terminated with reason DeadlineExceeded"
Feb 13 14:06:11.810: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 3.091403ms
Feb 13 14:06:13.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008899673s
Feb 13 14:06:15.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008771137s
Feb 13 14:06:15.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:06:15.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2268" for this suite. 02/13/23 14:06:15.823
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":179,"skipped":3436,"failed":0}
------------------------------
• [SLOW TEST] [6.616 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:06:09.214
    Feb 13 14:06:09.214: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:06:09.216
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:09.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:09.245
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 02/13/23 14:06:09.252
    STEP: submitting the pod to kubernetes 02/13/23 14:06:09.253
    Feb 13 14:06:09.266: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" in namespace "pods-2268" to be "running and ready"
    Feb 13 14:06:09.276: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.126939ms
    Feb 13 14:06:09.276: INFO: The phase of Pod pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:06:11.282: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015242954s
    Feb 13 14:06:11.282: INFO: The phase of Pod pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1 is Running (Ready = true)
    Feb 13 14:06:11.282: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 02/13/23 14:06:11.287
    STEP: updating the pod 02/13/23 14:06:11.292
    Feb 13 14:06:11.807: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1"
    Feb 13 14:06:11.807: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" in namespace "pods-2268" to be "terminated with reason DeadlineExceeded"
    Feb 13 14:06:11.810: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 3.091403ms
    Feb 13 14:06:13.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008899673s
    Feb 13 14:06:15.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008771137s
    Feb 13 14:06:15.816: INFO: Pod "pod-update-activedeadlineseconds-e2fa1769-0ad2-4df4-9b23-4dd52944a0c1" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:06:15.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2268" for this suite. 02/13/23 14:06:15.823
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:06:15.83
Feb 13 14:06:15.830: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:06:15.831
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:15.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:15.849
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 02/13/23 14:06:15.853
Feb 13 14:06:15.853: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7788 proxy --unix-socket=/tmp/kubectl-proxy-unix3308119555/test'
STEP: retrieving proxy /api/ output 02/13/23 14:06:15.927
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:06:15.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7788" for this suite. 02/13/23 14:06:15.933
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":180,"skipped":3436,"failed":0}
------------------------------
• [0.113 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:06:15.83
    Feb 13 14:06:15.830: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:06:15.831
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:15.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:15.849
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 02/13/23 14:06:15.853
    Feb 13 14:06:15.853: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7788 proxy --unix-socket=/tmp/kubectl-proxy-unix3308119555/test'
    STEP: retrieving proxy /api/ output 02/13/23 14:06:15.927
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:06:15.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7788" for this suite. 02/13/23 14:06:15.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:06:15.951
Feb 13 14:06:15.951: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename cronjob 02/13/23 14:06:15.953
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:15.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:15.972
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 02/13/23 14:06:15.976
W0213 14:06:15.983841      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring a job is scheduled 02/13/23 14:06:15.984
STEP: Ensuring exactly one is scheduled 02/13/23 14:07:01.988
STEP: Ensuring exactly one running job exists by listing jobs explicitly 02/13/23 14:07:01.991
STEP: Ensuring the job is replaced with a new one 02/13/23 14:07:01.995
STEP: Removing cronjob 02/13/23 14:08:02.001
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Feb 13 14:08:02.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9476" for this suite. 02/13/23 14:08:02.015
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":181,"skipped":3490,"failed":0}
------------------------------
• [SLOW TEST] [106.076 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:06:15.951
    Feb 13 14:06:15.951: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename cronjob 02/13/23 14:06:15.953
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:06:15.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:06:15.972
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 02/13/23 14:06:15.976
    W0213 14:06:15.983841      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring a job is scheduled 02/13/23 14:06:15.984
    STEP: Ensuring exactly one is scheduled 02/13/23 14:07:01.988
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 02/13/23 14:07:01.991
    STEP: Ensuring the job is replaced with a new one 02/13/23 14:07:01.995
    STEP: Removing cronjob 02/13/23 14:08:02.001
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Feb 13 14:08:02.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9476" for this suite. 02/13/23 14:08:02.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:02.03
Feb 13 14:08:02.030: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir-wrapper 02/13/23 14:08:02.033
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:02.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:02.062
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
W0213 14:08:02.095894      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:02.096: INFO: Waiting up to 5m0s for pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff" in namespace "emptydir-wrapper-994" to be "running and ready"
Feb 13 14:08:02.101: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.162044ms
Feb 13 14:08:02.101: INFO: The phase of Pod pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:04.106: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff": Phase="Running", Reason="", readiness=true. Elapsed: 2.009978879s
Feb 13 14:08:04.106: INFO: The phase of Pod pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff is Running (Ready = true)
Feb 13 14:08:04.106: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff" satisfied condition "running and ready"
STEP: Cleaning up the secret 02/13/23 14:08:04.11
STEP: Cleaning up the configmap 02/13/23 14:08:04.119
STEP: Cleaning up the pod 02/13/23 14:08:04.126
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Feb 13 14:08:04.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-994" for this suite. 02/13/23 14:08:04.148
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":182,"skipped":3497,"failed":0}
------------------------------
• [2.126 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:02.03
    Feb 13 14:08:02.030: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir-wrapper 02/13/23 14:08:02.033
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:02.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:02.062
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    W0213 14:08:02.095894      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:02.096: INFO: Waiting up to 5m0s for pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff" in namespace "emptydir-wrapper-994" to be "running and ready"
    Feb 13 14:08:02.101: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.162044ms
    Feb 13 14:08:02.101: INFO: The phase of Pod pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:04.106: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff": Phase="Running", Reason="", readiness=true. Elapsed: 2.009978879s
    Feb 13 14:08:04.106: INFO: The phase of Pod pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff is Running (Ready = true)
    Feb 13 14:08:04.106: INFO: Pod "pod-secrets-ad7cc081-9a7f-4454-9f87-b079c8c53aff" satisfied condition "running and ready"
    STEP: Cleaning up the secret 02/13/23 14:08:04.11
    STEP: Cleaning up the configmap 02/13/23 14:08:04.119
    STEP: Cleaning up the pod 02/13/23 14:08:04.126
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:08:04.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-994" for this suite. 02/13/23 14:08:04.148
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:04.158
Feb 13 14:08:04.158: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-pred 02/13/23 14:08:04.162
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:04.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:04.182
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Feb 13 14:08:04.187: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:08:04.200: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:08:04.205: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
Feb 13 14:08:04.213: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.213: INFO: 	Container civo-ccm ready: true, restart count 0
Feb 13 14:08:04.213: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
Feb 13 14:08:04.213: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:08:04.213: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 13 14:08:04.213: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 13 14:08:04.214: INFO: 	Container csi-resizer ready: true, restart count 0
Feb 13 14:08:04.214: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:08:04.214: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:08:04.214: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:08:04.214: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:08:04.214: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:08:04.214: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:08:04.214: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.214: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:08:04.214: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
Feb 13 14:08:04.222: INFO: replace-27938288-csmqs from cronjob-9476 started at 2023-02-13 14:08:00 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.222: INFO: 	Container c ready: true, restart count 0
Feb 13 14:08:04.222: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
Feb 13 14:08:04.222: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:08:04.222: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:08:04.222: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.222: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:08:04.222: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.222: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:08:04.222: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.222: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:08:04.222: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.223: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:08:04.232: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
Feb 13 14:08:04.240: INFO: replace-27938287-sffmh from cronjob-9476 started at 2023-02-13 14:07:00 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container c ready: true, restart count 0
Feb 13 14:08:04.240: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:08:04.240: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:08:04.240: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:08:04.240: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:08:04.240: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:08:04.240: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
Feb 13 14:08:04.240: INFO: 	Container e2e ready: true, restart count 0
Feb 13 14:08:04.240: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-myudo 02/13/23 14:08:04.261
STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:08:04.28
STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-vfwrl 02/13/23 14:08:04.296
Feb 13 14:08:04.312: INFO: Pod replace-27938287-sffmh requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.314: INFO: Pod replace-27938288-csmqs requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.314: INFO: Pod civo-ccm-69cdbdd6c5-5h8vx requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.315: INFO: Pod civo-csi-controller-0 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.315: INFO: Pod civo-csi-node-ggrnh requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.315: INFO: Pod civo-csi-node-kr4tf requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.316: INFO: Pod civo-csi-node-kzhfv requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.316: INFO: Pod coredns-584d5df445-c4zbq requesting resource cpu=100m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.316: INFO: Pod coredns-584d5df445-fgktn requesting resource cpu=100m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.317: INFO: Pod konnectivity-agent-hbzh6 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.317: INFO: Pod konnectivity-agent-tzdhw requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.318: INFO: Pod konnectivity-agent-xsjnx requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.318: INFO: Pod kube-flannel-7phdp requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.318: INFO: Pod kube-flannel-gwjn2 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.318: INFO: Pod kube-flannel-vdl8c requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.319: INFO: Pod kube-proxy-8rwqk requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.319: INFO: Pod kube-proxy-mffzd requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.319: INFO: Pod kube-proxy-v8znv requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.319: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.320: INFO: Pod sonobuoy-e2e-job-43a812b6f8b849b0 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
STEP: Starting Pods to consume most of the cluster CPU. 02/13/23 14:08:04.32
Feb 13 14:08:04.320: INFO: Creating a pod which consumes cpu=1225m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
Feb 13 14:08:04.329: INFO: Creating a pod which consumes cpu=1365m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
Feb 13 14:08:04.337: INFO: Creating a pod which consumes cpu=1365m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
Feb 13 14:08:04.350: INFO: Waiting up to 5m0s for pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579" in namespace "sched-pred-4131" to be "running"
Feb 13 14:08:04.363: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579": Phase="Pending", Reason="", readiness=false. Elapsed: 11.836489ms
Feb 13 14:08:06.367: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579": Phase="Running", Reason="", readiness=true. Elapsed: 2.016761098s
Feb 13 14:08:06.368: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579" satisfied condition "running"
Feb 13 14:08:06.368: INFO: Waiting up to 5m0s for pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136" in namespace "sched-pred-4131" to be "running"
Feb 13 14:08:06.372: INFO: Pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136": Phase="Running", Reason="", readiness=true. Elapsed: 4.289372ms
Feb 13 14:08:06.372: INFO: Pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136" satisfied condition "running"
Feb 13 14:08:06.372: INFO: Waiting up to 5m0s for pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8" in namespace "sched-pred-4131" to be "running"
Feb 13 14:08:06.376: INFO: Pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8": Phase="Running", Reason="", readiness=true. Elapsed: 3.935392ms
Feb 13 14:08:06.376: INFO: Pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 02/13/23 14:08:06.376
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677faa78b4e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136 to conformance-5500-0ccfa5-pool-bf9f-o7jrw] 02/13/23 14:08:06.381
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fca5d3b5d], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.381
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fcc3b1f33], Reason = [Created], Message = [Created container filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136] 02/13/23 14:08:06.382
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fd22e4795], Reason = [Started], Message = [Started container filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136] 02/13/23 14:08:06.382
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677faa23befc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-36d602eb-168d-425a-8e8c-5428a4227579 to conformance-5500-0ccfa5-pool-bf9f-myudo] 02/13/23 14:08:06.382
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fc822e842], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.382
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fc974c52d], Reason = [Created], Message = [Created container filler-pod-36d602eb-168d-425a-8e8c-5428a4227579] 02/13/23 14:08:06.383
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fd01c4e0b], Reason = [Started], Message = [Started container filler-pod-36d602eb-168d-425a-8e8c-5428a4227579] 02/13/23 14:08:06.383
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fac223c13], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8 to conformance-5500-0ccfa5-pool-bf9f-vfwrl] 02/13/23 14:08:06.383
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fcb685a2b], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.383
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fcccbd5ff], Reason = [Created], Message = [Created container filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8] 02/13/23 14:08:06.384
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fd32249f9], Reason = [Started], Message = [Started container filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8] 02/13/23 14:08:06.384
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17436780246d5d29], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 02/13/23 14:08:06.405
STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-myudo 02/13/23 14:08:07.403
STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.42
STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:08:07.424
STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.439
STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-vfwrl 02/13/23 14:08:07.443
STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.458
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:08:07.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4131" for this suite. 02/13/23 14:08:07.469
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":183,"skipped":3508,"failed":0}
------------------------------
• [3.319 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:04.158
    Feb 13 14:08:04.158: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-pred 02/13/23 14:08:04.162
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:04.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:04.182
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Feb 13 14:08:04.187: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Feb 13 14:08:04.200: INFO: Waiting for terminating namespaces to be deleted...
    Feb 13 14:08:04.205: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
    Feb 13 14:08:04.213: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.213: INFO: 	Container civo-ccm ready: true, restart count 0
    Feb 13 14:08:04.213: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
    Feb 13 14:08:04.213: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:08:04.213: INFO: 	Container csi-attacher ready: true, restart count 0
    Feb 13 14:08:04.213: INFO: 	Container csi-provisioner ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: 	Container csi-resizer ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.214: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:08:04.214: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
    Feb 13 14:08:04.222: INFO: replace-27938288-csmqs from cronjob-9476 started at 2023-02-13 14:08:00 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.222: INFO: 	Container c ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
    Feb 13 14:08:04.222: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.222: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.222: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.222: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:08:04.222: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.223: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Feb 13 14:08:04.232: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
    Feb 13 14:08:04.240: INFO: replace-27938287-sffmh from cronjob-9476 started at 2023-02-13 14:07:00 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container c ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
    Feb 13 14:08:04.240: INFO: 	Container e2e ready: true, restart count 0
    Feb 13 14:08:04.240: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-myudo 02/13/23 14:08:04.261
    STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:08:04.28
    STEP: verifying the node has the label node conformance-5500-0ccfa5-pool-bf9f-vfwrl 02/13/23 14:08:04.296
    Feb 13 14:08:04.312: INFO: Pod replace-27938287-sffmh requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.314: INFO: Pod replace-27938288-csmqs requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.314: INFO: Pod civo-ccm-69cdbdd6c5-5h8vx requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.315: INFO: Pod civo-csi-controller-0 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.315: INFO: Pod civo-csi-node-ggrnh requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.315: INFO: Pod civo-csi-node-kr4tf requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.316: INFO: Pod civo-csi-node-kzhfv requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.316: INFO: Pod coredns-584d5df445-c4zbq requesting resource cpu=100m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.316: INFO: Pod coredns-584d5df445-fgktn requesting resource cpu=100m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.317: INFO: Pod konnectivity-agent-hbzh6 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.317: INFO: Pod konnectivity-agent-tzdhw requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.318: INFO: Pod konnectivity-agent-xsjnx requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.318: INFO: Pod kube-flannel-7phdp requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.318: INFO: Pod kube-flannel-gwjn2 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.318: INFO: Pod kube-flannel-vdl8c requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.319: INFO: Pod kube-proxy-8rwqk requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.319: INFO: Pod kube-proxy-mffzd requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.319: INFO: Pod kube-proxy-v8znv requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.319: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.320: INFO: Pod sonobuoy-e2e-job-43a812b6f8b849b0 requesting resource cpu=0m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    STEP: Starting Pods to consume most of the cluster CPU. 02/13/23 14:08:04.32
    Feb 13 14:08:04.320: INFO: Creating a pod which consumes cpu=1225m on Node conformance-5500-0ccfa5-pool-bf9f-myudo
    Feb 13 14:08:04.329: INFO: Creating a pod which consumes cpu=1365m on Node conformance-5500-0ccfa5-pool-bf9f-o7jrw
    Feb 13 14:08:04.337: INFO: Creating a pod which consumes cpu=1365m on Node conformance-5500-0ccfa5-pool-bf9f-vfwrl
    Feb 13 14:08:04.350: INFO: Waiting up to 5m0s for pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579" in namespace "sched-pred-4131" to be "running"
    Feb 13 14:08:04.363: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579": Phase="Pending", Reason="", readiness=false. Elapsed: 11.836489ms
    Feb 13 14:08:06.367: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579": Phase="Running", Reason="", readiness=true. Elapsed: 2.016761098s
    Feb 13 14:08:06.368: INFO: Pod "filler-pod-36d602eb-168d-425a-8e8c-5428a4227579" satisfied condition "running"
    Feb 13 14:08:06.368: INFO: Waiting up to 5m0s for pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136" in namespace "sched-pred-4131" to be "running"
    Feb 13 14:08:06.372: INFO: Pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136": Phase="Running", Reason="", readiness=true. Elapsed: 4.289372ms
    Feb 13 14:08:06.372: INFO: Pod "filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136" satisfied condition "running"
    Feb 13 14:08:06.372: INFO: Waiting up to 5m0s for pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8" in namespace "sched-pred-4131" to be "running"
    Feb 13 14:08:06.376: INFO: Pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8": Phase="Running", Reason="", readiness=true. Elapsed: 3.935392ms
    Feb 13 14:08:06.376: INFO: Pod "filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 02/13/23 14:08:06.376
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677faa78b4e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136 to conformance-5500-0ccfa5-pool-bf9f-o7jrw] 02/13/23 14:08:06.381
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fca5d3b5d], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.381
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fcc3b1f33], Reason = [Created], Message = [Created container filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136] 02/13/23 14:08:06.382
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136.1743677fd22e4795], Reason = [Started], Message = [Started container filler-pod-007d2b4a-e6e9-4d0a-a727-de07229dc136] 02/13/23 14:08:06.382
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677faa23befc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-36d602eb-168d-425a-8e8c-5428a4227579 to conformance-5500-0ccfa5-pool-bf9f-myudo] 02/13/23 14:08:06.382
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fc822e842], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.382
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fc974c52d], Reason = [Created], Message = [Created container filler-pod-36d602eb-168d-425a-8e8c-5428a4227579] 02/13/23 14:08:06.383
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-36d602eb-168d-425a-8e8c-5428a4227579.1743677fd01c4e0b], Reason = [Started], Message = [Started container filler-pod-36d602eb-168d-425a-8e8c-5428a4227579] 02/13/23 14:08:06.383
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fac223c13], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4131/filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8 to conformance-5500-0ccfa5-pool-bf9f-vfwrl] 02/13/23 14:08:06.383
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fcb685a2b], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 02/13/23 14:08:06.383
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fcccbd5ff], Reason = [Created], Message = [Created container filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8] 02/13/23 14:08:06.384
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8.1743677fd32249f9], Reason = [Started], Message = [Started container filler-pod-472aaf6b-ca34-4f5c-a995-fe632a211fb8] 02/13/23 14:08:06.384
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17436780246d5d29], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 02/13/23 14:08:06.405
    STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-myudo 02/13/23 14:08:07.403
    STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.42
    STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:08:07.424
    STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.439
    STEP: removing the label node off the node conformance-5500-0ccfa5-pool-bf9f-vfwrl 02/13/23 14:08:07.443
    STEP: verifying the node doesn't have the label node 02/13/23 14:08:07.458
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:08:07.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4131" for this suite. 02/13/23 14:08:07.469
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:07.483
Feb 13 14:08:07.483: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:08:07.484
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:07.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:07.504
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:08:07.51
W0213 14:08:07.517022      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:07.517: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4371" to be "running and ready"
Feb 13 14:08:07.520: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830921ms
Feb 13 14:08:07.520: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:09.528: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.011084784s
Feb 13 14:08:09.528: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Feb 13 14:08:09.528: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 02/13/23 14:08:09.534
W0213 14:08:09.544952      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:09.545: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4371" to be "running and ready"
Feb 13 14:08:09.551: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.130269ms
Feb 13 14:08:09.551: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:11.556: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011860129s
Feb 13 14:08:11.557: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Feb 13 14:08:11.557: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 02/13/23 14:08:11.56
Feb 13 14:08:11.569: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:11.576: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:13.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:13.582: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:15.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:15.580: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:17.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:17.580: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:19.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:19.585: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:21.578: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:21.583: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:23.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:23.583: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:25.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:25.582: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:27.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:27.580: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:08:29.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:08:29.581: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 02/13/23 14:08:29.581
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Feb 13 14:08:29.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4371" for this suite. 02/13/23 14:08:29.611
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":184,"skipped":3509,"failed":0}
------------------------------
• [SLOW TEST] [22.135 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:07.483
    Feb 13 14:08:07.483: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:08:07.484
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:07.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:07.504
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:08:07.51
    W0213 14:08:07.517022      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:07.517: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4371" to be "running and ready"
    Feb 13 14:08:07.520: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830921ms
    Feb 13 14:08:07.520: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:09.528: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.011084784s
    Feb 13 14:08:09.528: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Feb 13 14:08:09.528: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 02/13/23 14:08:09.534
    W0213 14:08:09.544952      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:09.545: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4371" to be "running and ready"
    Feb 13 14:08:09.551: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.130269ms
    Feb 13 14:08:09.551: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:11.556: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011860129s
    Feb 13 14:08:11.557: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Feb 13 14:08:11.557: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 02/13/23 14:08:11.56
    Feb 13 14:08:11.569: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:11.576: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:13.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:13.582: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:15.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:15.580: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:17.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:17.580: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:19.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:19.585: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:21.578: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:21.583: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:23.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:23.583: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:25.577: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:25.582: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:27.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:27.580: INFO: Pod pod-with-prestop-http-hook still exists
    Feb 13 14:08:29.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Feb 13 14:08:29.581: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 02/13/23 14:08:29.581
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Feb 13 14:08:29.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4371" for this suite. 02/13/23 14:08:29.611
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:29.62
Feb 13 14:08:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:08:29.621
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:29.641
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:29.649
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 02/13/23 14:08:29.662
STEP: watching for Pod to be ready 02/13/23 14:08:29.671
Feb 13 14:08:29.675: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions []
Feb 13 14:08:29.680: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
Feb 13 14:08:29.695: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
Feb 13 14:08:31.193: INFO: Found Pod pod-test in namespace pods-1536 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 02/13/23 14:08:31.196
STEP: getting the Pod and ensuring that it's patched 02/13/23 14:08:31.208
STEP: replacing the Pod's status Ready condition to False 02/13/23 14:08:31.211
STEP: check the Pod again to ensure its Ready conditions are False 02/13/23 14:08:31.228
STEP: deleting the Pod via a Collection with a LabelSelector 02/13/23 14:08:31.228
STEP: watching for the Pod to be deleted 02/13/23 14:08:31.237
Feb 13 14:08:31.239: INFO: observed event type MODIFIED
Feb 13 14:08:32.914: INFO: observed event type MODIFIED
Feb 13 14:08:34.242: INFO: observed event type MODIFIED
Feb 13 14:08:34.249: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:08:34.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1536" for this suite. 02/13/23 14:08:34.261
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":185,"skipped":3515,"failed":0}
------------------------------
• [4.648 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:29.62
    Feb 13 14:08:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:08:29.621
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:29.641
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:29.649
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 02/13/23 14:08:29.662
    STEP: watching for Pod to be ready 02/13/23 14:08:29.671
    Feb 13 14:08:29.675: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Feb 13 14:08:29.680: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
    Feb 13 14:08:29.695: INFO: observed Pod pod-test in namespace pods-1536 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
    Feb 13 14:08:31.193: INFO: Found Pod pod-test in namespace pods-1536 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:08:29 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 02/13/23 14:08:31.196
    STEP: getting the Pod and ensuring that it's patched 02/13/23 14:08:31.208
    STEP: replacing the Pod's status Ready condition to False 02/13/23 14:08:31.211
    STEP: check the Pod again to ensure its Ready conditions are False 02/13/23 14:08:31.228
    STEP: deleting the Pod via a Collection with a LabelSelector 02/13/23 14:08:31.228
    STEP: watching for the Pod to be deleted 02/13/23 14:08:31.237
    Feb 13 14:08:31.239: INFO: observed event type MODIFIED
    Feb 13 14:08:32.914: INFO: observed event type MODIFIED
    Feb 13 14:08:34.242: INFO: observed event type MODIFIED
    Feb 13 14:08:34.249: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:08:34.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1536" for this suite. 02/13/23 14:08:34.261
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:34.271
Feb 13 14:08:34.272: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:08:34.273
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:34.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:34.29
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-8230 02/13/23 14:08:34.294
STEP: creating service affinity-nodeport-transition in namespace services-8230 02/13/23 14:08:34.295
STEP: creating replication controller affinity-nodeport-transition in namespace services-8230 02/13/23 14:08:34.311
W0213 14:08:34.319405      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:08:34.319542      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-8230, replica count: 3
I0213 14:08:37.370591      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:08:37.383: INFO: Creating new exec pod
W0213 14:08:37.390719      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:37.390: INFO: Waiting up to 5m0s for pod "execpod-affinity8rqn6" in namespace "services-8230" to be "running"
Feb 13 14:08:37.397: INFO: Pod "execpod-affinity8rqn6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400428ms
Feb 13 14:08:39.405: INFO: Pod "execpod-affinity8rqn6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014517466s
Feb 13 14:08:39.405: INFO: Pod "execpod-affinity8rqn6" satisfied condition "running"
Feb 13 14:08:40.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Feb 13 14:08:40.669: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Feb 13 14:08:40.669: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:08:40.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.215.198 80'
Feb 13 14:08:40.908: INFO: stderr: "+ nc -v -t+ echo hostName\n -w 2 10.106.215.198 80\nConnection to 10.106.215.198 80 port [tcp/http] succeeded!\n"
Feb 13 14:08:40.908: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:08:40.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 30499'
Feb 13 14:08:41.166: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.11 30499\nConnection to 192.168.1.11 30499 port [tcp/*] succeeded!\n"
Feb 13 14:08:41.166: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:08:41.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 30499'
Feb 13 14:08:41.392: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 30499\nConnection to 192.168.1.10 30499 port [tcp/*] succeeded!\n"
Feb 13 14:08:41.392: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:08:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:30499/ ; done'
Feb 13 14:08:41.813: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n"
Feb 13 14:08:41.813: INFO: stdout: "\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn"
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:41.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:30499/ ; done'
Feb 13 14:08:42.215: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n"
Feb 13 14:08:42.215: INFO: stdout: "\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn"
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
Feb 13 14:08:42.215: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8230, will wait for the garbage collector to delete the pods 02/13/23 14:08:42.232
Feb 13 14:08:42.297: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.097596ms
Feb 13 14:08:42.398: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.914332ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:08:44.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8230" for this suite. 02/13/23 14:08:44.435
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":186,"skipped":3519,"failed":0}
------------------------------
• [SLOW TEST] [10.171 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:34.271
    Feb 13 14:08:34.272: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:08:34.273
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:34.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:34.29
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-8230 02/13/23 14:08:34.294
    STEP: creating service affinity-nodeport-transition in namespace services-8230 02/13/23 14:08:34.295
    STEP: creating replication controller affinity-nodeport-transition in namespace services-8230 02/13/23 14:08:34.311
    W0213 14:08:34.319405      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:08:34.319542      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-8230, replica count: 3
    I0213 14:08:37.370591      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:08:37.383: INFO: Creating new exec pod
    W0213 14:08:37.390719      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:37.390: INFO: Waiting up to 5m0s for pod "execpod-affinity8rqn6" in namespace "services-8230" to be "running"
    Feb 13 14:08:37.397: INFO: Pod "execpod-affinity8rqn6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400428ms
    Feb 13 14:08:39.405: INFO: Pod "execpod-affinity8rqn6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014517466s
    Feb 13 14:08:39.405: INFO: Pod "execpod-affinity8rqn6" satisfied condition "running"
    Feb 13 14:08:40.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Feb 13 14:08:40.669: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Feb 13 14:08:40.669: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:08:40.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.215.198 80'
    Feb 13 14:08:40.908: INFO: stderr: "+ nc -v -t+ echo hostName\n -w 2 10.106.215.198 80\nConnection to 10.106.215.198 80 port [tcp/http] succeeded!\n"
    Feb 13 14:08:40.908: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:08:40.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 30499'
    Feb 13 14:08:41.166: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.11 30499\nConnection to 192.168.1.11 30499 port [tcp/*] succeeded!\n"
    Feb 13 14:08:41.166: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:08:41.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.10 30499'
    Feb 13 14:08:41.392: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.10 30499\nConnection to 192.168.1.10 30499 port [tcp/*] succeeded!\n"
    Feb 13 14:08:41.392: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:08:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:30499/ ; done'
    Feb 13 14:08:41.813: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n"
    Feb 13 14:08:41.813: INFO: stdout: "\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gx2dx\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-9c2w4\naffinity-nodeport-transition-gfddn"
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gx2dx
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-9c2w4
    Feb 13 14:08:41.813: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:41.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-8230 exec execpod-affinity8rqn6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:30499/ ; done'
    Feb 13 14:08:42.215: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:30499/\n"
    Feb 13 14:08:42.215: INFO: stdout: "\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn\naffinity-nodeport-transition-gfddn"
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Received response from host: affinity-nodeport-transition-gfddn
    Feb 13 14:08:42.215: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8230, will wait for the garbage collector to delete the pods 02/13/23 14:08:42.232
    Feb 13 14:08:42.297: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.097596ms
    Feb 13 14:08:42.398: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.914332ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:08:44.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8230" for this suite. 02/13/23 14:08:44.435
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:44.445
Feb 13 14:08:44.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:08:44.446
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:44.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:44.469
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 02/13/23 14:08:44.473
STEP: setting up watch 02/13/23 14:08:44.474
STEP: submitting the pod to kubernetes 02/13/23 14:08:44.577
STEP: verifying the pod is in kubernetes 02/13/23 14:08:44.587
STEP: verifying pod creation was observed 02/13/23 14:08:44.599
Feb 13 14:08:44.599: INFO: Waiting up to 5m0s for pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c" in namespace "pods-1109" to be "running"
Feb 13 14:08:44.606: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.517682ms
Feb 13 14:08:46.613: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013425953s
Feb 13 14:08:46.613: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c" satisfied condition "running"
STEP: deleting the pod gracefully 02/13/23 14:08:46.619
STEP: verifying pod deletion was observed 02/13/23 14:08:46.63
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:08:49.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1109" for this suite. 02/13/23 14:08:49.308
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":187,"skipped":3526,"failed":0}
------------------------------
• [4.871 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:44.445
    Feb 13 14:08:44.445: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:08:44.446
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:44.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:44.469
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 02/13/23 14:08:44.473
    STEP: setting up watch 02/13/23 14:08:44.474
    STEP: submitting the pod to kubernetes 02/13/23 14:08:44.577
    STEP: verifying the pod is in kubernetes 02/13/23 14:08:44.587
    STEP: verifying pod creation was observed 02/13/23 14:08:44.599
    Feb 13 14:08:44.599: INFO: Waiting up to 5m0s for pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c" in namespace "pods-1109" to be "running"
    Feb 13 14:08:44.606: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.517682ms
    Feb 13 14:08:46.613: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013425953s
    Feb 13 14:08:46.613: INFO: Pod "pod-submit-remove-3d7cb71f-4727-46b9-8cf3-ed8ab1878a2c" satisfied condition "running"
    STEP: deleting the pod gracefully 02/13/23 14:08:46.619
    STEP: verifying pod deletion was observed 02/13/23 14:08:46.63
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:08:49.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1109" for this suite. 02/13/23 14:08:49.308
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:49.316
Feb 13 14:08:49.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:08:49.318
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:49.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:49.341
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-c90d5ffb-526d-4b95-8651-6d02c526dac8 02/13/23 14:08:49.347
STEP: Creating a pod to test consume configMaps 02/13/23 14:08:49.356
W0213 14:08:49.371892      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:49.372: INFO: Waiting up to 5m0s for pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981" in namespace "configmap-109" to be "Succeeded or Failed"
Feb 13 14:08:49.377: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Pending", Reason="", readiness=false. Elapsed: 4.810011ms
Feb 13 14:08:51.386: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014450528s
Feb 13 14:08:53.382: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010246968s
STEP: Saw pod success 02/13/23 14:08:53.382
Feb 13 14:08:53.383: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981" satisfied condition "Succeeded or Failed"
Feb 13 14:08:53.387: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:08:53.396
Feb 13 14:08:53.409: INFO: Waiting for pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 to disappear
Feb 13 14:08:53.413: INFO: Pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:08:53.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-109" for this suite. 02/13/23 14:08:53.418
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":188,"skipped":3526,"failed":0}
------------------------------
• [4.111 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:49.316
    Feb 13 14:08:49.316: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:08:49.318
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:49.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:49.341
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-c90d5ffb-526d-4b95-8651-6d02c526dac8 02/13/23 14:08:49.347
    STEP: Creating a pod to test consume configMaps 02/13/23 14:08:49.356
    W0213 14:08:49.371892      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:49.372: INFO: Waiting up to 5m0s for pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981" in namespace "configmap-109" to be "Succeeded or Failed"
    Feb 13 14:08:49.377: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Pending", Reason="", readiness=false. Elapsed: 4.810011ms
    Feb 13 14:08:51.386: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014450528s
    Feb 13 14:08:53.382: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010246968s
    STEP: Saw pod success 02/13/23 14:08:53.382
    Feb 13 14:08:53.383: INFO: Pod "pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981" satisfied condition "Succeeded or Failed"
    Feb 13 14:08:53.387: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:08:53.396
    Feb 13 14:08:53.409: INFO: Waiting for pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 to disappear
    Feb 13 14:08:53.413: INFO: Pod pod-configmaps-973ee742-498f-4036-b99b-6fd0e4735981 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:08:53.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-109" for this suite. 02/13/23 14:08:53.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:08:53.437
Feb 13 14:08:53.437: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename hostport 02/13/23 14:08:53.438
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:53.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:53.466
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 02/13/23 14:08:53.476
W0213 14:08:53.491223      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:53.491: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-75" to be "running and ready"
Feb 13 14:08:53.496: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.084257ms
Feb 13 14:08:53.496: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:55.502: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010794349s
Feb 13 14:08:55.502: INFO: The phase of Pod pod1 is Running (Ready = true)
Feb 13 14:08:55.502: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.1.12 on the node which pod1 resides and expect scheduled 02/13/23 14:08:55.502
W0213 14:08:55.513121      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:55.513: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-75" to be "running and ready"
Feb 13 14:08:55.519: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.162298ms
Feb 13 14:08:55.519: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:57.528: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.014791607s
Feb 13 14:08:57.528: INFO: The phase of Pod pod2 is Running (Ready = true)
Feb 13 14:08:57.528: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.1.12 but use UDP protocol on the node which pod2 resides 02/13/23 14:08:57.528
W0213 14:08:57.536675      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:57.537: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-75" to be "running and ready"
Feb 13 14:08:57.541: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092189ms
Feb 13 14:08:57.541: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:08:59.548: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.011024863s
Feb 13 14:08:59.548: INFO: The phase of Pod pod3 is Running (Ready = true)
Feb 13 14:08:59.548: INFO: Pod "pod3" satisfied condition "running and ready"
W0213 14:08:59.560632      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "e2e-host-exec" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-host-exec" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-host-exec" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-host-exec" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:08:59.561: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-75" to be "running and ready"
Feb 13 14:08:59.567: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240709ms
Feb 13 14:08:59.567: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:09:01.574: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013064624s
Feb 13 14:09:01.574: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Feb 13 14:09:01.574: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 02/13/23 14:09:01.579
Feb 13 14:09:01.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.1.12 http://127.0.0.1:54323/hostname] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:01.579: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:01.580: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:01.580: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.1.12+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.12, port: 54323 02/13/23 14:09:01.722
Feb 13 14:09:01.722: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.1.12:54323/hostname] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:01.722: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:01.723: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:01.723: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.1.12%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.12, port: 54323 UDP 02/13/23 14:09:01.864
Feb 13 14:09:01.864: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.1.12 54323] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:01.864: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:01.865: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:01.865: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.1.12+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Feb 13 14:09:07.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-75" for this suite. 02/13/23 14:09:07.045
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":189,"skipped":3567,"failed":0}
------------------------------
• [SLOW TEST] [13.617 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:08:53.437
    Feb 13 14:08:53.437: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename hostport 02/13/23 14:08:53.438
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:08:53.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:08:53.466
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 02/13/23 14:08:53.476
    W0213 14:08:53.491223      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:53.491: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-75" to be "running and ready"
    Feb 13 14:08:53.496: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.084257ms
    Feb 13 14:08:53.496: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:55.502: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010794349s
    Feb 13 14:08:55.502: INFO: The phase of Pod pod1 is Running (Ready = true)
    Feb 13 14:08:55.502: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.1.12 on the node which pod1 resides and expect scheduled 02/13/23 14:08:55.502
    W0213 14:08:55.513121      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:55.513: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-75" to be "running and ready"
    Feb 13 14:08:55.519: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.162298ms
    Feb 13 14:08:55.519: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:57.528: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.014791607s
    Feb 13 14:08:57.528: INFO: The phase of Pod pod2 is Running (Ready = true)
    Feb 13 14:08:57.528: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.1.12 but use UDP protocol on the node which pod2 resides 02/13/23 14:08:57.528
    W0213 14:08:57.536675      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:57.537: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-75" to be "running and ready"
    Feb 13 14:08:57.541: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092189ms
    Feb 13 14:08:57.541: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:08:59.548: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.011024863s
    Feb 13 14:08:59.548: INFO: The phase of Pod pod3 is Running (Ready = true)
    Feb 13 14:08:59.548: INFO: Pod "pod3" satisfied condition "running and ready"
    W0213 14:08:59.560632      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "e2e-host-exec" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-host-exec" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-host-exec" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-host-exec" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:08:59.561: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-75" to be "running and ready"
    Feb 13 14:08:59.567: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240709ms
    Feb 13 14:08:59.567: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:09:01.574: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013064624s
    Feb 13 14:09:01.574: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Feb 13 14:09:01.574: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 02/13/23 14:09:01.579
    Feb 13 14:09:01.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.1.12 http://127.0.0.1:54323/hostname] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:01.579: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:01.580: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:01.580: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.1.12+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.12, port: 54323 02/13/23 14:09:01.722
    Feb 13 14:09:01.722: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.1.12:54323/hostname] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:01.722: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:01.723: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:01.723: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.1.12%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.12, port: 54323 UDP 02/13/23 14:09:01.864
    Feb 13 14:09:01.864: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.1.12 54323] Namespace:hostport-75 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:01.864: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:01.865: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:01.865: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-75/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.1.12+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Feb 13 14:09:07.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-75" for this suite. 02/13/23 14:09:07.045
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:07.055
Feb 13 14:09:07.055: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:09:07.058
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:07.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:07.092
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-eb776156-0790-4400-8ca1-fedff69db1b5 02/13/23 14:09:07.097
STEP: Creating a pod to test consume secrets 02/13/23 14:09:07.104
W0213 14:09:07.117860      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:07.118: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66" in namespace "projected-845" to be "Succeeded or Failed"
Feb 13 14:09:07.124: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Pending", Reason="", readiness=false. Elapsed: 5.882034ms
Feb 13 14:09:09.132: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013841958s
Feb 13 14:09:11.134: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015975417s
STEP: Saw pod success 02/13/23 14:09:11.134
Feb 13 14:09:11.134: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66" satisfied condition "Succeeded or Failed"
Feb 13 14:09:11.139: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 container projected-secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:09:11.149
Feb 13 14:09:11.168: INFO: Waiting for pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 to disappear
Feb 13 14:09:11.172: INFO: Pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 14:09:11.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-845" for this suite. 02/13/23 14:09:11.178
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":190,"skipped":3569,"failed":0}
------------------------------
• [4.142 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:07.055
    Feb 13 14:09:07.055: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:09:07.058
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:07.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:07.092
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-eb776156-0790-4400-8ca1-fedff69db1b5 02/13/23 14:09:07.097
    STEP: Creating a pod to test consume secrets 02/13/23 14:09:07.104
    W0213 14:09:07.117860      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:07.118: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66" in namespace "projected-845" to be "Succeeded or Failed"
    Feb 13 14:09:07.124: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Pending", Reason="", readiness=false. Elapsed: 5.882034ms
    Feb 13 14:09:09.132: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013841958s
    Feb 13 14:09:11.134: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015975417s
    STEP: Saw pod success 02/13/23 14:09:11.134
    Feb 13 14:09:11.134: INFO: Pod "pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66" satisfied condition "Succeeded or Failed"
    Feb 13 14:09:11.139: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 container projected-secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:09:11.149
    Feb 13 14:09:11.168: INFO: Waiting for pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 to disappear
    Feb 13 14:09:11.172: INFO: Pod pod-projected-secrets-79ce4ccb-6829-4f68-9057-292f56552c66 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 14:09:11.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-845" for this suite. 02/13/23 14:09:11.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:11.199
Feb 13 14:09:11.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 14:09:11.201
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:11.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:11.233
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 02/13/23 14:09:11.237
W0213 14:09:11.248091      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:11.248: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8265" to be "running and ready"
Feb 13 14:09:11.252: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.369788ms
Feb 13 14:09:11.252: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:09:13.257: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008802093s
Feb 13 14:09:13.257: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Feb 13 14:09:13.257: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 02/13/23 14:09:13.261
W0213 14:09:13.269896      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Then the orphan pod is adopted 02/13/23 14:09:13.27
STEP: When the matched label of one of its pods change 02/13/23 14:09:14.285
Feb 13 14:09:14.289: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 02/13/23 14:09:14.304
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 14:09:15.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8265" for this suite. 02/13/23 14:09:15.32
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":191,"skipped":3575,"failed":0}
------------------------------
• [4.129 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:11.199
    Feb 13 14:09:11.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 14:09:11.201
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:11.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:11.233
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 02/13/23 14:09:11.237
    W0213 14:09:11.248091      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:11.248: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8265" to be "running and ready"
    Feb 13 14:09:11.252: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.369788ms
    Feb 13 14:09:11.252: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:09:13.257: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008802093s
    Feb 13 14:09:13.257: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Feb 13 14:09:13.257: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 02/13/23 14:09:13.261
    W0213 14:09:13.269896      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Then the orphan pod is adopted 02/13/23 14:09:13.27
    STEP: When the matched label of one of its pods change 02/13/23 14:09:14.285
    Feb 13 14:09:14.289: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 02/13/23 14:09:14.304
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 14:09:15.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8265" for this suite. 02/13/23 14:09:15.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:15.332
Feb 13 14:09:15.332: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:09:15.333
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:15.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:15.366
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:09:15.389
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:09:16.037
STEP: Deploying the webhook pod 02/13/23 14:09:16.05
W0213 14:09:16.071714      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:09:16.071
Feb 13 14:09:16.098: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:09:18.118
STEP: Verifying the service has paired with the endpoint 02/13/23 14:09:18.141
Feb 13 14:09:19.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Feb 13 14:09:19.149: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-603-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:09:19.675
STEP: Creating a custom resource that should be mutated by the webhook 02/13/23 14:09:19.708
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:09:22.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1713" for this suite. 02/13/23 14:09:22.334
STEP: Destroying namespace "webhook-1713-markers" for this suite. 02/13/23 14:09:22.342
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":192,"skipped":3589,"failed":0}
------------------------------
• [SLOW TEST] [7.061 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:15.332
    Feb 13 14:09:15.332: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:09:15.333
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:15.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:15.366
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:09:15.389
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:09:16.037
    STEP: Deploying the webhook pod 02/13/23 14:09:16.05
    W0213 14:09:16.071714      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:09:16.071
    Feb 13 14:09:16.098: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:09:18.118
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:09:18.141
    Feb 13 14:09:19.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Feb 13 14:09:19.149: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-603-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:09:19.675
    STEP: Creating a custom resource that should be mutated by the webhook 02/13/23 14:09:19.708
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:09:22.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1713" for this suite. 02/13/23 14:09:22.334
    STEP: Destroying namespace "webhook-1713-markers" for this suite. 02/13/23 14:09:22.342
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:22.405
Feb 13 14:09:22.405: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:09:22.41
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:22.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:22.44
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 02/13/23 14:09:22.446
Feb 13 14:09:22.461: INFO: Waiting up to 5m0s for pod "pod-dk5cb" in namespace "pods-6946" to be "running"
Feb 13 14:09:22.470: INFO: Pod "pod-dk5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.173071ms
Feb 13 14:09:24.477: INFO: Pod "pod-dk5cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.01495521s
Feb 13 14:09:24.477: INFO: Pod "pod-dk5cb" satisfied condition "running"
STEP: patching /status 02/13/23 14:09:24.477
Feb 13 14:09:24.490: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:09:24.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6946" for this suite. 02/13/23 14:09:24.497
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":193,"skipped":3624,"failed":0}
------------------------------
• [2.105 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:22.405
    Feb 13 14:09:22.405: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:09:22.41
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:22.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:22.44
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 02/13/23 14:09:22.446
    Feb 13 14:09:22.461: INFO: Waiting up to 5m0s for pod "pod-dk5cb" in namespace "pods-6946" to be "running"
    Feb 13 14:09:22.470: INFO: Pod "pod-dk5cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.173071ms
    Feb 13 14:09:24.477: INFO: Pod "pod-dk5cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.01495521s
    Feb 13 14:09:24.477: INFO: Pod "pod-dk5cb" satisfied condition "running"
    STEP: patching /status 02/13/23 14:09:24.477
    Feb 13 14:09:24.490: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:09:24.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6946" for this suite. 02/13/23 14:09:24.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:24.516
Feb 13 14:09:24.517: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:09:24.518
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:24.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:24.546
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 02/13/23 14:09:24.551
Feb 13 14:09:24.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-9363 cluster-info'
Feb 13 14:09:24.671: INFO: stderr: ""
Feb 13 14:09:24.671: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:09:24.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9363" for this suite. 02/13/23 14:09:24.676
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":194,"skipped":3701,"failed":0}
------------------------------
• [0.166 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:24.516
    Feb 13 14:09:24.517: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:09:24.518
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:24.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:24.546
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 02/13/23 14:09:24.551
    Feb 13 14:09:24.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-9363 cluster-info'
    Feb 13 14:09:24.671: INFO: stderr: ""
    Feb 13 14:09:24.671: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:09:24.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9363" for this suite. 02/13/23 14:09:24.676
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:24.684
Feb 13 14:09:24.684: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:09:24.685
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:24.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:24.707
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-51e84e32-3cf3-479b-92b6-10b894b716ac 02/13/23 14:09:24.712
STEP: Creating a pod to test consume secrets 02/13/23 14:09:24.718
W0213 14:09:24.728895      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:24.729: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b" in namespace "projected-346" to be "Succeeded or Failed"
Feb 13 14:09:24.735: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.794586ms
Feb 13 14:09:26.741: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012505197s
Feb 13 14:09:28.743: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0146307s
STEP: Saw pod success 02/13/23 14:09:28.744
Feb 13 14:09:28.744: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b" satisfied condition "Succeeded or Failed"
Feb 13 14:09:28.748: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b container projected-secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:09:28.772
Feb 13 14:09:28.789: INFO: Waiting for pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b to disappear
Feb 13 14:09:28.793: INFO: Pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 14:09:28.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-346" for this suite. 02/13/23 14:09:28.798
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":195,"skipped":3702,"failed":0}
------------------------------
• [4.122 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:24.684
    Feb 13 14:09:24.684: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:09:24.685
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:24.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:24.707
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-51e84e32-3cf3-479b-92b6-10b894b716ac 02/13/23 14:09:24.712
    STEP: Creating a pod to test consume secrets 02/13/23 14:09:24.718
    W0213 14:09:24.728895      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:24.729: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b" in namespace "projected-346" to be "Succeeded or Failed"
    Feb 13 14:09:24.735: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.794586ms
    Feb 13 14:09:26.741: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012505197s
    Feb 13 14:09:28.743: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0146307s
    STEP: Saw pod success 02/13/23 14:09:28.744
    Feb 13 14:09:28.744: INFO: Pod "pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b" satisfied condition "Succeeded or Failed"
    Feb 13 14:09:28.748: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b container projected-secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:09:28.772
    Feb 13 14:09:28.789: INFO: Waiting for pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b to disappear
    Feb 13 14:09:28.793: INFO: Pod pod-projected-secrets-3195bdb9-dd26-4f52-8bb8-ab21f639147b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 14:09:28.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-346" for this suite. 02/13/23 14:09:28.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:28.809
Feb 13 14:09:28.809: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:09:28.811
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:28.829
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:28.833
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:09:28.837
W0213 14:09:28.845975      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:28.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9" in namespace "downward-api-1943" to be "Succeeded or Failed"
Feb 13 14:09:28.854: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269912ms
Feb 13 14:09:30.860: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014279515s
Feb 13 14:09:32.859: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013131719s
STEP: Saw pod success 02/13/23 14:09:32.859
Feb 13 14:09:32.860: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9" satisfied condition "Succeeded or Failed"
Feb 13 14:09:32.864: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 container client-container: <nil>
STEP: delete the pod 02/13/23 14:09:32.872
Feb 13 14:09:32.883: INFO: Waiting for pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 to disappear
Feb 13 14:09:32.887: INFO: Pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 14:09:32.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1943" for this suite. 02/13/23 14:09:32.892
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":196,"skipped":3736,"failed":0}
------------------------------
• [4.088 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:28.809
    Feb 13 14:09:28.809: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:09:28.811
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:28.829
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:28.833
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:09:28.837
    W0213 14:09:28.845975      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:28.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9" in namespace "downward-api-1943" to be "Succeeded or Failed"
    Feb 13 14:09:28.854: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269912ms
    Feb 13 14:09:30.860: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014279515s
    Feb 13 14:09:32.859: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013131719s
    STEP: Saw pod success 02/13/23 14:09:32.859
    Feb 13 14:09:32.860: INFO: Pod "downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9" satisfied condition "Succeeded or Failed"
    Feb 13 14:09:32.864: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:09:32.872
    Feb 13 14:09:32.883: INFO: Waiting for pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 to disappear
    Feb 13 14:09:32.887: INFO: Pod downwardapi-volume-d7e19fe5-6e23-4ee2-b89c-633835d5e0c9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 14:09:32.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1943" for this suite. 02/13/23 14:09:32.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:32.9
Feb 13 14:09:32.900: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:09:32.902
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:32.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:32.944
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3904 02/13/23 14:09:32.954
STEP: creating a selector 02/13/23 14:09:32.954
STEP: Creating the service pods in kubernetes 02/13/23 14:09:32.955
Feb 13 14:09:32.955: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
W0213 14:09:32.983548      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:09:32.991752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:09:33.003265      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:33.003: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3904" to be "running and ready"
Feb 13 14:09:33.017: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.748898ms
Feb 13 14:09:33.017: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:09:35.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.020180815s
Feb 13 14:09:35.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:09:37.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.019982003s
Feb 13 14:09:37.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:09:39.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018513508s
Feb 13 14:09:39.022: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:09:41.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019563427s
Feb 13 14:09:41.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:09:43.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018703702s
Feb 13 14:09:43.022: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:09:45.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.018627358s
Feb 13 14:09:45.022: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Feb 13 14:09:45.022: INFO: Pod "netserver-0" satisfied condition "running and ready"
Feb 13 14:09:45.026: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3904" to be "running and ready"
Feb 13 14:09:45.029: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.276474ms
Feb 13 14:09:45.029: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Feb 13 14:09:45.029: INFO: Pod "netserver-1" satisfied condition "running and ready"
Feb 13 14:09:45.033: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3904" to be "running and ready"
Feb 13 14:09:45.036: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.140044ms
Feb 13 14:09:45.036: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Feb 13 14:09:45.036: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 02/13/23 14:09:45.04
W0213 14:09:45.046288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:45.046: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3904" to be "running"
Feb 13 14:09:45.049: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057608ms
Feb 13 14:09:47.056: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009361827s
Feb 13 14:09:47.056: INFO: Pod "test-container-pod" satisfied condition "running"
Feb 13 14:09:47.061: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Feb 13 14:09:47.061: INFO: Breadth first check of 10.244.1.149 on host 192.168.1.12...
Feb 13 14:09:47.066: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.1.149&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:47.066: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:47.067: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:47.067: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.149%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 14:09:47.230: INFO: Waiting for responses: map[]
Feb 13 14:09:47.230: INFO: reached 10.244.1.149 after 0/1 tries
Feb 13 14:09:47.230: INFO: Breadth first check of 10.244.0.14 on host 192.168.1.11...
Feb 13 14:09:47.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.0.14&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:47.237: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:47.238: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:47.238: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.14%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 14:09:47.358: INFO: Waiting for responses: map[]
Feb 13 14:09:47.358: INFO: reached 10.244.0.14 after 0/1 tries
Feb 13 14:09:47.358: INFO: Breadth first check of 10.244.2.201 on host 192.168.1.10...
Feb 13 14:09:47.362: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.2.201&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:09:47.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:09:47.363: INFO: ExecWithOptions: Clientset creation
Feb 13 14:09:47.363: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.2.201%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Feb 13 14:09:47.511: INFO: Waiting for responses: map[]
Feb 13 14:09:47.511: INFO: reached 10.244.2.201 after 0/1 tries
Feb 13 14:09:47.511: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Feb 13 14:09:47.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3904" for this suite. 02/13/23 14:09:47.519
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":197,"skipped":3753,"failed":0}
------------------------------
• [SLOW TEST] [14.629 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:32.9
    Feb 13 14:09:32.900: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:09:32.902
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:32.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:32.944
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3904 02/13/23 14:09:32.954
    STEP: creating a selector 02/13/23 14:09:32.954
    STEP: Creating the service pods in kubernetes 02/13/23 14:09:32.955
    Feb 13 14:09:32.955: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    W0213 14:09:32.983548      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:09:32.991752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:09:33.003265      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:33.003: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3904" to be "running and ready"
    Feb 13 14:09:33.017: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.748898ms
    Feb 13 14:09:33.017: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:09:35.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.020180815s
    Feb 13 14:09:35.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:09:37.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.019982003s
    Feb 13 14:09:37.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:09:39.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018513508s
    Feb 13 14:09:39.022: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:09:41.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.019563427s
    Feb 13 14:09:41.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:09:43.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018703702s
    Feb 13 14:09:43.022: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:09:45.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.018627358s
    Feb 13 14:09:45.022: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Feb 13 14:09:45.022: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Feb 13 14:09:45.026: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3904" to be "running and ready"
    Feb 13 14:09:45.029: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.276474ms
    Feb 13 14:09:45.029: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Feb 13 14:09:45.029: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Feb 13 14:09:45.033: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3904" to be "running and ready"
    Feb 13 14:09:45.036: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.140044ms
    Feb 13 14:09:45.036: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Feb 13 14:09:45.036: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 02/13/23 14:09:45.04
    W0213 14:09:45.046288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:45.046: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3904" to be "running"
    Feb 13 14:09:45.049: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057608ms
    Feb 13 14:09:47.056: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009361827s
    Feb 13 14:09:47.056: INFO: Pod "test-container-pod" satisfied condition "running"
    Feb 13 14:09:47.061: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Feb 13 14:09:47.061: INFO: Breadth first check of 10.244.1.149 on host 192.168.1.12...
    Feb 13 14:09:47.066: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.1.149&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:47.066: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:47.067: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:47.067: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.149%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 14:09:47.230: INFO: Waiting for responses: map[]
    Feb 13 14:09:47.230: INFO: reached 10.244.1.149 after 0/1 tries
    Feb 13 14:09:47.230: INFO: Breadth first check of 10.244.0.14 on host 192.168.1.11...
    Feb 13 14:09:47.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.0.14&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:47.237: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:47.238: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:47.238: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.14%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 14:09:47.358: INFO: Waiting for responses: map[]
    Feb 13 14:09:47.358: INFO: reached 10.244.0.14 after 0/1 tries
    Feb 13 14:09:47.358: INFO: Breadth first check of 10.244.2.201 on host 192.168.1.10...
    Feb 13 14:09:47.362: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.15:9080/dial?request=hostname&protocol=udp&host=10.244.2.201&port=8081&tries=1'] Namespace:pod-network-test-3904 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:09:47.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:09:47.363: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:09:47.363: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3904/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.0.15%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.2.201%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Feb 13 14:09:47.511: INFO: Waiting for responses: map[]
    Feb 13 14:09:47.511: INFO: reached 10.244.2.201 after 0/1 tries
    Feb 13 14:09:47.511: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Feb 13 14:09:47.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3904" for this suite. 02/13/23 14:09:47.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:47.53
Feb 13 14:09:47.530: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename limitrange 02/13/23 14:09:47.531
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:47.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:47.554
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 02/13/23 14:09:47.558
STEP: Setting up watch 02/13/23 14:09:47.558
STEP: Submitting a LimitRange 02/13/23 14:09:47.661
STEP: Verifying LimitRange creation was observed 02/13/23 14:09:47.674
STEP: Fetching the LimitRange to ensure it has proper values 02/13/23 14:09:47.674
Feb 13 14:09:47.678: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Feb 13 14:09:47.678: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 02/13/23 14:09:47.678
W0213 14:09:47.684668      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring Pod has resource requirements applied from LimitRange 02/13/23 14:09:47.684
Feb 13 14:09:47.687: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Feb 13 14:09:47.688: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 02/13/23 14:09:47.688
W0213 14:09:47.699571      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 02/13/23 14:09:47.699
Feb 13 14:09:47.704: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Feb 13 14:09:47.704: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 02/13/23 14:09:47.704
STEP: Failing to create a Pod with more than max resources 02/13/23 14:09:47.707
STEP: Updating a LimitRange 02/13/23 14:09:47.71
STEP: Verifying LimitRange updating is effective 02/13/23 14:09:47.715
STEP: Creating a Pod with less than former min resources 02/13/23 14:09:49.72
W0213 14:09:49.725873      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Failing to create a Pod with more than max resources 02/13/23 14:09:49.726
STEP: Deleting a LimitRange 02/13/23 14:09:49.729
STEP: Verifying the LimitRange was deleted 02/13/23 14:09:49.74
Feb 13 14:09:54.745: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 02/13/23 14:09:54.745
W0213 14:09:54.759281      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Feb 13 14:09:54.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2958" for this suite. 02/13/23 14:09:54.764
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":198,"skipped":3760,"failed":0}
------------------------------
• [SLOW TEST] [7.245 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:47.53
    Feb 13 14:09:47.530: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename limitrange 02/13/23 14:09:47.531
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:47.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:47.554
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 02/13/23 14:09:47.558
    STEP: Setting up watch 02/13/23 14:09:47.558
    STEP: Submitting a LimitRange 02/13/23 14:09:47.661
    STEP: Verifying LimitRange creation was observed 02/13/23 14:09:47.674
    STEP: Fetching the LimitRange to ensure it has proper values 02/13/23 14:09:47.674
    Feb 13 14:09:47.678: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Feb 13 14:09:47.678: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 02/13/23 14:09:47.678
    W0213 14:09:47.684668      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring Pod has resource requirements applied from LimitRange 02/13/23 14:09:47.684
    Feb 13 14:09:47.687: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Feb 13 14:09:47.688: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 02/13/23 14:09:47.688
    W0213 14:09:47.699571      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 02/13/23 14:09:47.699
    Feb 13 14:09:47.704: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Feb 13 14:09:47.704: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 02/13/23 14:09:47.704
    STEP: Failing to create a Pod with more than max resources 02/13/23 14:09:47.707
    STEP: Updating a LimitRange 02/13/23 14:09:47.71
    STEP: Verifying LimitRange updating is effective 02/13/23 14:09:47.715
    STEP: Creating a Pod with less than former min resources 02/13/23 14:09:49.72
    W0213 14:09:49.725873      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Failing to create a Pod with more than max resources 02/13/23 14:09:49.726
    STEP: Deleting a LimitRange 02/13/23 14:09:49.729
    STEP: Verifying the LimitRange was deleted 02/13/23 14:09:49.74
    Feb 13 14:09:54.745: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 02/13/23 14:09:54.745
    W0213 14:09:54.759281      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Feb 13 14:09:54.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-2958" for this suite. 02/13/23 14:09:54.764
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:54.777
Feb 13 14:09:54.777: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:09:54.778
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:54.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:54.793
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 02/13/23 14:09:54.797
STEP: submitting the pod to kubernetes 02/13/23 14:09:54.797
Feb 13 14:09:54.808: INFO: Waiting up to 5m0s for pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" in namespace "pods-900" to be "running and ready"
Feb 13 14:09:54.811: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338297ms
Feb 13 14:09:54.812: INFO: The phase of Pod pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:09:56.816: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008158387s
Feb 13 14:09:56.816: INFO: The phase of Pod pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b is Running (Ready = true)
Feb 13 14:09:56.816: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 02/13/23 14:09:56.82
STEP: updating the pod 02/13/23 14:09:56.824
Feb 13 14:09:57.342: INFO: Successfully updated pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b"
Feb 13 14:09:57.342: INFO: Waiting up to 5m0s for pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" in namespace "pods-900" to be "running"
Feb 13 14:09:57.346: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Running", Reason="", readiness=true. Elapsed: 4.032955ms
Feb 13 14:09:57.346: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 02/13/23 14:09:57.346
Feb 13 14:09:57.350: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:09:57.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-900" for this suite. 02/13/23 14:09:57.354
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":199,"skipped":3771,"failed":0}
------------------------------
• [2.583 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:54.777
    Feb 13 14:09:54.777: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:09:54.778
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:54.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:54.793
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 02/13/23 14:09:54.797
    STEP: submitting the pod to kubernetes 02/13/23 14:09:54.797
    Feb 13 14:09:54.808: INFO: Waiting up to 5m0s for pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" in namespace "pods-900" to be "running and ready"
    Feb 13 14:09:54.811: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338297ms
    Feb 13 14:09:54.812: INFO: The phase of Pod pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:09:56.816: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008158387s
    Feb 13 14:09:56.816: INFO: The phase of Pod pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b is Running (Ready = true)
    Feb 13 14:09:56.816: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 02/13/23 14:09:56.82
    STEP: updating the pod 02/13/23 14:09:56.824
    Feb 13 14:09:57.342: INFO: Successfully updated pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b"
    Feb 13 14:09:57.342: INFO: Waiting up to 5m0s for pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" in namespace "pods-900" to be "running"
    Feb 13 14:09:57.346: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b": Phase="Running", Reason="", readiness=true. Elapsed: 4.032955ms
    Feb 13 14:09:57.346: INFO: Pod "pod-update-5186e9a6-ff29-4a78-9440-48655797bd2b" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 02/13/23 14:09:57.346
    Feb 13 14:09:57.350: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:09:57.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-900" for this suite. 02/13/23 14:09:57.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:09:57.362
Feb 13 14:09:57.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 14:09:57.364
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:57.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:57.386
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 in namespace container-probe-3885 02/13/23 14:09:57.391
W0213 14:09:57.401219      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:09:57.401: INFO: Waiting up to 5m0s for pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873" in namespace "container-probe-3885" to be "not pending"
Feb 13 14:09:57.407: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873": Phase="Pending", Reason="", readiness=false. Elapsed: 6.290771ms
Feb 13 14:09:59.413: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873": Phase="Running", Reason="", readiness=true. Elapsed: 2.012562104s
Feb 13 14:09:59.413: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873" satisfied condition "not pending"
Feb 13 14:09:59.413: INFO: Started pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 in namespace container-probe-3885
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:09:59.413
Feb 13 14:09:59.417: INFO: Initial restart count of pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 is 0
STEP: deleting the pod 02/13/23 14:14:00.127
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 14:14:00.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3885" for this suite. 02/13/23 14:14:00.153
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":200,"skipped":3785,"failed":0}
------------------------------
• [SLOW TEST] [242.797 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:09:57.362
    Feb 13 14:09:57.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 14:09:57.364
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:09:57.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:09:57.386
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 in namespace container-probe-3885 02/13/23 14:09:57.391
    W0213 14:09:57.401219      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:09:57.401: INFO: Waiting up to 5m0s for pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873" in namespace "container-probe-3885" to be "not pending"
    Feb 13 14:09:57.407: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873": Phase="Pending", Reason="", readiness=false. Elapsed: 6.290771ms
    Feb 13 14:09:59.413: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873": Phase="Running", Reason="", readiness=true. Elapsed: 2.012562104s
    Feb 13 14:09:59.413: INFO: Pod "test-webserver-2770cbca-9029-4275-a943-4d00eb17f873" satisfied condition "not pending"
    Feb 13 14:09:59.413: INFO: Started pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 in namespace container-probe-3885
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:09:59.413
    Feb 13 14:09:59.417: INFO: Initial restart count of pod test-webserver-2770cbca-9029-4275-a943-4d00eb17f873 is 0
    STEP: deleting the pod 02/13/23 14:14:00.127
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 14:14:00.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3885" for this suite. 02/13/23 14:14:00.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:14:00.162
Feb 13 14:14:00.162: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:14:00.164
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:00.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:00.181
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-ccdd48b0-83f4-4661-b4e2-20f77690e09e 02/13/23 14:14:00.184
STEP: Creating a pod to test consume configMaps 02/13/23 14:14:00.189
W0213 14:14:00.198735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:14:00.198: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a" in namespace "configmap-6650" to be "Succeeded or Failed"
Feb 13 14:14:00.206: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009654ms
Feb 13 14:14:02.212: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013586159s
Feb 13 14:14:04.214: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015545129s
STEP: Saw pod success 02/13/23 14:14:04.214
Feb 13 14:14:04.214: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a" satisfied condition "Succeeded or Failed"
Feb 13 14:14:04.219: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a container configmap-volume-test: <nil>
STEP: delete the pod 02/13/23 14:14:04.247
Feb 13 14:14:04.264: INFO: Waiting for pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a to disappear
Feb 13 14:14:04.267: INFO: Pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:14:04.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6650" for this suite. 02/13/23 14:14:04.273
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":201,"skipped":3814,"failed":0}
------------------------------
• [4.118 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:14:00.162
    Feb 13 14:14:00.162: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:14:00.164
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:00.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:00.181
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-ccdd48b0-83f4-4661-b4e2-20f77690e09e 02/13/23 14:14:00.184
    STEP: Creating a pod to test consume configMaps 02/13/23 14:14:00.189
    W0213 14:14:00.198735      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:14:00.198: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a" in namespace "configmap-6650" to be "Succeeded or Failed"
    Feb 13 14:14:00.206: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009654ms
    Feb 13 14:14:02.212: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013586159s
    Feb 13 14:14:04.214: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015545129s
    STEP: Saw pod success 02/13/23 14:14:04.214
    Feb 13 14:14:04.214: INFO: Pod "pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a" satisfied condition "Succeeded or Failed"
    Feb 13 14:14:04.219: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a container configmap-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:14:04.247
    Feb 13 14:14:04.264: INFO: Waiting for pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a to disappear
    Feb 13 14:14:04.267: INFO: Pod pod-configmaps-fb63c963-f82a-4d09-a0f3-6b35cf3cee8a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:14:04.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6650" for this suite. 02/13/23 14:14:04.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:14:04.284
Feb 13 14:14:04.284: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:14:04.285
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:04.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:04.308
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-5d5246c9-55b8-4016-9527-812f40409a4b 02/13/23 14:14:04.312
STEP: Creating a pod to test consume configMaps 02/13/23 14:14:04.319
W0213 14:14:04.329292      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:14:04.329: INFO: Waiting up to 5m0s for pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a" in namespace "configmap-9922" to be "Succeeded or Failed"
Feb 13 14:14:04.334: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.398105ms
Feb 13 14:14:06.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010552494s
Feb 13 14:14:08.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010540488s
STEP: Saw pod success 02/13/23 14:14:08.34
Feb 13 14:14:08.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a" satisfied condition "Succeeded or Failed"
Feb 13 14:14:08.343: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:14:08.351
Feb 13 14:14:08.366: INFO: Waiting for pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a to disappear
Feb 13 14:14:08.369: INFO: Pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:14:08.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9922" for this suite. 02/13/23 14:14:08.374
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":202,"skipped":3849,"failed":0}
------------------------------
• [4.097 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:14:04.284
    Feb 13 14:14:04.284: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:14:04.285
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:04.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:04.308
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-5d5246c9-55b8-4016-9527-812f40409a4b 02/13/23 14:14:04.312
    STEP: Creating a pod to test consume configMaps 02/13/23 14:14:04.319
    W0213 14:14:04.329292      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:14:04.329: INFO: Waiting up to 5m0s for pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a" in namespace "configmap-9922" to be "Succeeded or Failed"
    Feb 13 14:14:04.334: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.398105ms
    Feb 13 14:14:06.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010552494s
    Feb 13 14:14:08.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010540488s
    STEP: Saw pod success 02/13/23 14:14:08.34
    Feb 13 14:14:08.340: INFO: Pod "pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a" satisfied condition "Succeeded or Failed"
    Feb 13 14:14:08.343: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:14:08.351
    Feb 13 14:14:08.366: INFO: Waiting for pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a to disappear
    Feb 13 14:14:08.369: INFO: Pod pod-configmaps-8485a3ea-7b20-454f-86e9-69f925ed907a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:14:08.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9922" for this suite. 02/13/23 14:14:08.374
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:14:08.388
Feb 13 14:14:08.389: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 14:14:08.39
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:08.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:08.41
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 02/13/23 14:14:08.414
W0213 14:14:08.424524      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:14:08.424: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5940  986a700e-900d-438b-9452-d2f99fcea753 23385 0 2023-02-13 14:14:08 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-02-13 14:14:08 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwjqj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwjqj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 13 14:14:08.425: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5940" to be "running and ready"
Feb 13 14:14:08.428: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 3.642693ms
Feb 13 14:14:08.428: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:14:10.433: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.00820003s
Feb 13 14:14:10.433: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Feb 13 14:14:10.433: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 02/13/23 14:14:10.433
Feb 13 14:14:10.433: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5940 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:14:10.433: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:14:10.434: INFO: ExecWithOptions: Clientset creation
Feb 13 14:14:10.434: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5940/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 02/13/23 14:14:10.584
Feb 13 14:14:10.584: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5940 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:14:10.584: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:14:10.585: INFO: ExecWithOptions: Clientset creation
Feb 13 14:14:10.586: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5940/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:14:10.740: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 14:14:10.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5940" for this suite. 02/13/23 14:14:10.765
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":203,"skipped":3883,"failed":0}
------------------------------
• [2.384 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:14:08.388
    Feb 13 14:14:08.389: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 14:14:08.39
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:08.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:08.41
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 02/13/23 14:14:08.414
    W0213 14:14:08.424524      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:14:08.424: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5940  986a700e-900d-438b-9452-d2f99fcea753 23385 0 2023-02-13 14:14:08 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-02-13 14:14:08 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwjqj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwjqj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Feb 13 14:14:08.425: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5940" to be "running and ready"
    Feb 13 14:14:08.428: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 3.642693ms
    Feb 13 14:14:08.428: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:14:10.433: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.00820003s
    Feb 13 14:14:10.433: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Feb 13 14:14:10.433: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 02/13/23 14:14:10.433
    Feb 13 14:14:10.433: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5940 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:14:10.433: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:14:10.434: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:14:10.434: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5940/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 02/13/23 14:14:10.584
    Feb 13 14:14:10.584: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5940 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:14:10.584: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:14:10.585: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:14:10.586: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-5940/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:14:10.740: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 14:14:10.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5940" for this suite. 02/13/23 14:14:10.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:14:10.777
Feb 13 14:14:10.778: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-watch 02/13/23 14:14:10.779
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:10.803
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:10.807
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Feb 13 14:14:10.811: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Creating first CR  02/13/23 14:14:13.382
Feb 13 14:14:13.388: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:13Z]] name:name1 resourceVersion:23421 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 02/13/23 14:14:23.388
Feb 13 14:14:23.397: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:23Z]] name:name2 resourceVersion:23462 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 02/13/23 14:14:33.397
Feb 13 14:14:33.407: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:33Z]] name:name1 resourceVersion:23482 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 02/13/23 14:14:43.407
Feb 13 14:14:43.414: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:43Z]] name:name2 resourceVersion:23502 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 02/13/23 14:14:53.415
Feb 13 14:14:53.424: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:33Z]] name:name1 resourceVersion:23522 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 02/13/23 14:15:03.424
Feb 13 14:15:03.438: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:43Z]] name:name2 resourceVersion:23542 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:15:13.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2011" for this suite. 02/13/23 14:15:13.968
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":204,"skipped":3893,"failed":0}
------------------------------
• [SLOW TEST] [63.200 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:14:10.777
    Feb 13 14:14:10.778: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-watch 02/13/23 14:14:10.779
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:14:10.803
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:14:10.807
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Feb 13 14:14:10.811: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Creating first CR  02/13/23 14:14:13.382
    Feb 13 14:14:13.388: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:13Z]] name:name1 resourceVersion:23421 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 02/13/23 14:14:23.388
    Feb 13 14:14:23.397: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:23Z]] name:name2 resourceVersion:23462 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 02/13/23 14:14:33.397
    Feb 13 14:14:33.407: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:33Z]] name:name1 resourceVersion:23482 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 02/13/23 14:14:43.407
    Feb 13 14:14:43.414: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:43Z]] name:name2 resourceVersion:23502 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 02/13/23 14:14:53.415
    Feb 13 14:14:53.424: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:33Z]] name:name1 resourceVersion:23522 uid:0e161dce-5d55-4f07-a215-c467097169bd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 02/13/23 14:15:03.424
    Feb 13 14:15:03.438: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-02-13T14:14:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-02-13T14:14:43Z]] name:name2 resourceVersion:23542 uid:8ee15199-f065-49fb-a785-9a89645c79e9] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:15:13.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-2011" for this suite. 02/13/23 14:15:13.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:13.983
Feb 13 14:15:13.983: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:15:13.984
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:14.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:14.01
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:15:14.015
W0213 14:15:14.023939      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:15:14.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2" in namespace "projected-8777" to be "Succeeded or Failed"
Feb 13 14:15:14.033: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.391695ms
Feb 13 14:15:16.040: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015430345s
Feb 13 14:15:18.040: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015758178s
STEP: Saw pod success 02/13/23 14:15:18.04
Feb 13 14:15:18.041: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2" satisfied condition "Succeeded or Failed"
Feb 13 14:15:18.047: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 container client-container: <nil>
STEP: delete the pod 02/13/23 14:15:18.06
Feb 13 14:15:18.075: INFO: Waiting for pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 to disappear
Feb 13 14:15:18.079: INFO: Pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:15:18.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8777" for this suite. 02/13/23 14:15:18.084
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":205,"skipped":3906,"failed":0}
------------------------------
• [4.107 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:13.983
    Feb 13 14:15:13.983: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:15:13.984
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:14.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:14.01
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:15:14.015
    W0213 14:15:14.023939      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:15:14.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2" in namespace "projected-8777" to be "Succeeded or Failed"
    Feb 13 14:15:14.033: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.391695ms
    Feb 13 14:15:16.040: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015430345s
    Feb 13 14:15:18.040: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015758178s
    STEP: Saw pod success 02/13/23 14:15:18.04
    Feb 13 14:15:18.041: INFO: Pod "downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2" satisfied condition "Succeeded or Failed"
    Feb 13 14:15:18.047: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:15:18.06
    Feb 13 14:15:18.075: INFO: Waiting for pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 to disappear
    Feb 13 14:15:18.079: INFO: Pod downwardapi-volume-39e5cd0d-04c1-482a-95c8-1ec8b40403a2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:15:18.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8777" for this suite. 02/13/23 14:15:18.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:18.093
Feb 13 14:15:18.094: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-runtime 02/13/23 14:15:18.096
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:18.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:18.116
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 02/13/23 14:15:18.12
W0213 14:15:18.127280      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: wait for the container to reach Failed 02/13/23 14:15:18.127
STEP: get the container status 02/13/23 14:15:22.157
STEP: the container should be terminated 02/13/23 14:15:22.164
STEP: the termination message should be set 02/13/23 14:15:22.164
Feb 13 14:15:22.164: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 02/13/23 14:15:22.164
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Feb 13 14:15:22.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3620" for this suite. 02/13/23 14:15:22.191
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":206,"skipped":3945,"failed":0}
------------------------------
• [4.104 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:18.093
    Feb 13 14:15:18.094: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-runtime 02/13/23 14:15:18.096
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:18.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:18.116
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 02/13/23 14:15:18.12
    W0213 14:15:18.127280      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: wait for the container to reach Failed 02/13/23 14:15:18.127
    STEP: get the container status 02/13/23 14:15:22.157
    STEP: the container should be terminated 02/13/23 14:15:22.164
    STEP: the termination message should be set 02/13/23 14:15:22.164
    Feb 13 14:15:22.164: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 02/13/23 14:15:22.164
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Feb 13 14:15:22.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3620" for this suite. 02/13/23 14:15:22.191
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:22.198
Feb 13 14:15:22.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:15:22.199
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:22.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:22.222
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:15:22.231
W0213 14:15:22.240469      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:15:22.240: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5448" to be "running and ready"
Feb 13 14:15:22.247: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.059655ms
Feb 13 14:15:22.247: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:15:24.254: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013685317s
Feb 13 14:15:24.254: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Feb 13 14:15:24.254: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 02/13/23 14:15:24.259
W0213 14:15:24.267882      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:15:24.268: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-5448" to be "running and ready"
Feb 13 14:15:24.271: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624072ms
Feb 13 14:15:24.271: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:15:26.276: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.008683282s
Feb 13 14:15:26.277: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Feb 13 14:15:26.277: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 02/13/23 14:15:26.28
Feb 13 14:15:26.288: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:15:26.292: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:15:28.293: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:15:28.300: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:15:30.293: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:15:30.299: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 02/13/23 14:15:30.299
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Feb 13 14:15:30.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5448" for this suite. 02/13/23 14:15:30.337
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":207,"skipped":3954,"failed":0}
------------------------------
• [SLOW TEST] [8.149 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:22.198
    Feb 13 14:15:22.199: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-lifecycle-hook 02/13/23 14:15:22.199
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:22.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:22.222
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 02/13/23 14:15:22.231
    W0213 14:15:22.240469      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:15:22.240: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5448" to be "running and ready"
    Feb 13 14:15:22.247: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.059655ms
    Feb 13 14:15:22.247: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:15:24.254: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013685317s
    Feb 13 14:15:24.254: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Feb 13 14:15:24.254: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 02/13/23 14:15:24.259
    W0213 14:15:24.267882      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:15:24.268: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-5448" to be "running and ready"
    Feb 13 14:15:24.271: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624072ms
    Feb 13 14:15:24.271: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:15:26.276: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.008683282s
    Feb 13 14:15:26.277: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Feb 13 14:15:26.277: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 02/13/23 14:15:26.28
    Feb 13 14:15:26.288: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Feb 13 14:15:26.292: INFO: Pod pod-with-prestop-exec-hook still exists
    Feb 13 14:15:28.293: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Feb 13 14:15:28.300: INFO: Pod pod-with-prestop-exec-hook still exists
    Feb 13 14:15:30.293: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Feb 13 14:15:30.299: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 02/13/23 14:15:30.299
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Feb 13 14:15:30.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5448" for this suite. 02/13/23 14:15:30.337
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:30.351
Feb 13 14:15:30.351: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-pred 02/13/23 14:15:30.352
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:30.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:30.368
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Feb 13 14:15:30.370: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:15:30.376: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:15:30.379: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
Feb 13 14:15:30.397: INFO: pod-handle-http-request from container-lifecycle-hook-5448 started at 2023-02-13 14:15:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container agnhost-container ready: true, restart count 0
Feb 13 14:15:30.397: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container civo-ccm ready: true, restart count 0
Feb 13 14:15:30.397: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:15:30.397: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 13 14:15:30.397: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 13 14:15:30.397: INFO: 	Container csi-resizer ready: true, restart count 0
Feb 13 14:15:30.397: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:15:30.397: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:15:30.397: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:15:30.397: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:15:30.397: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:15:30.397: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:15:30.397: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.397: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:15:30.397: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
Feb 13 14:15:30.404: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
Feb 13 14:15:30.404: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:15:30.404: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:15:30.404: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.405: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:15:30.405: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.405: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:15:30.405: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.405: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:15:30.405: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.405: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:15:30.405: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
Feb 13 14:15:30.410: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
Feb 13 14:15:30.410: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:15:30.410: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:15:30.410: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.410: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:15:30.410: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.410: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:15:30.410: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:15:30.410: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:15:30.410: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
Feb 13 14:15:30.410: INFO: 	Container e2e ready: true, restart count 0
Feb 13 14:15:30.410: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 02/13/23 14:15:30.41
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.174367e7890609ec], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 02/13/23 14:15:30.475
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:15:31.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8252" for this suite. 02/13/23 14:15:31.46
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":208,"skipped":3963,"failed":0}
------------------------------
• [1.118 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:30.351
    Feb 13 14:15:30.351: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-pred 02/13/23 14:15:30.352
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:30.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:30.368
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Feb 13 14:15:30.370: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Feb 13 14:15:30.376: INFO: Waiting for terminating namespaces to be deleted...
    Feb 13 14:15:30.379: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
    Feb 13 14:15:30.397: INFO: pod-handle-http-request from container-lifecycle-hook-5448 started at 2023-02-13 14:15:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container agnhost-container ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container civo-ccm ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: 	Container csi-attacher ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: 	Container csi-provisioner ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: 	Container csi-resizer ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.397: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:15:30.397: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
    Feb 13 14:15:30.404: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
    Feb 13 14:15:30.404: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:15:30.404: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:15:30.404: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.405: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:15:30.405: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.405: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:15:30.405: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.405: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:15:30.405: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.405: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Feb 13 14:15:30.405: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
    Feb 13 14:15:30.410: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
    Feb 13 14:15:30.410: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.410: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.410: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:15:30.410: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
    Feb 13 14:15:30.410: INFO: 	Container e2e ready: true, restart count 0
    Feb 13 14:15:30.410: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 02/13/23 14:15:30.41
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.174367e7890609ec], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 02/13/23 14:15:30.475
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:15:31.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8252" for this suite. 02/13/23 14:15:31.46
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:31.478
Feb 13 14:15:31.478: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename namespaces 02/13/23 14:15:31.479
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:31.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:31.502
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 02/13/23 14:15:31.508
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:31.522
STEP: Creating a service in the namespace 02/13/23 14:15:31.526
STEP: Deleting the namespace 02/13/23 14:15:31.55
STEP: Waiting for the namespace to be removed. 02/13/23 14:15:31.56
STEP: Recreating the namespace 02/13/23 14:15:37.568
STEP: Verifying there is no service in the namespace 02/13/23 14:15:37.587
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:15:37.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7698" for this suite. 02/13/23 14:15:37.594
STEP: Destroying namespace "nsdeletetest-8568" for this suite. 02/13/23 14:15:37.603
Feb 13 14:15:37.607: INFO: Namespace nsdeletetest-8568 was already deleted
STEP: Destroying namespace "nsdeletetest-6686" for this suite. 02/13/23 14:15:37.607
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":209,"skipped":4001,"failed":0}
------------------------------
• [SLOW TEST] [6.137 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:31.478
    Feb 13 14:15:31.478: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename namespaces 02/13/23 14:15:31.479
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:31.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:31.502
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 02/13/23 14:15:31.508
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:31.522
    STEP: Creating a service in the namespace 02/13/23 14:15:31.526
    STEP: Deleting the namespace 02/13/23 14:15:31.55
    STEP: Waiting for the namespace to be removed. 02/13/23 14:15:31.56
    STEP: Recreating the namespace 02/13/23 14:15:37.568
    STEP: Verifying there is no service in the namespace 02/13/23 14:15:37.587
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:15:37.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7698" for this suite. 02/13/23 14:15:37.594
    STEP: Destroying namespace "nsdeletetest-8568" for this suite. 02/13/23 14:15:37.603
    Feb 13 14:15:37.607: INFO: Namespace nsdeletetest-8568 was already deleted
    STEP: Destroying namespace "nsdeletetest-6686" for this suite. 02/13/23 14:15:37.607
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:15:37.616
Feb 13 14:15:37.616: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:15:37.617
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:37.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:37.642
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 02/13/23 14:15:54.651
STEP: Creating a ResourceQuota 02/13/23 14:15:59.656
STEP: Ensuring resource quota status is calculated 02/13/23 14:15:59.662
STEP: Creating a ConfigMap 02/13/23 14:16:01.671
STEP: Ensuring resource quota status captures configMap creation 02/13/23 14:16:01.698
STEP: Deleting a ConfigMap 02/13/23 14:16:03.704
STEP: Ensuring resource quota status released usage 02/13/23 14:16:03.715
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:16:05.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5654" for this suite. 02/13/23 14:16:05.731
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":210,"skipped":4002,"failed":0}
------------------------------
• [SLOW TEST] [28.124 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:15:37.616
    Feb 13 14:15:37.616: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:15:37.617
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:15:37.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:15:37.642
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 02/13/23 14:15:54.651
    STEP: Creating a ResourceQuota 02/13/23 14:15:59.656
    STEP: Ensuring resource quota status is calculated 02/13/23 14:15:59.662
    STEP: Creating a ConfigMap 02/13/23 14:16:01.671
    STEP: Ensuring resource quota status captures configMap creation 02/13/23 14:16:01.698
    STEP: Deleting a ConfigMap 02/13/23 14:16:03.704
    STEP: Ensuring resource quota status released usage 02/13/23 14:16:03.715
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:16:05.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5654" for this suite. 02/13/23 14:16:05.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:05.748
Feb 13 14:16:05.748: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:16:05.75
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:05.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:05.776
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-551d1e8e-e2e8-4d81-8d52-4c9cdb207e71 02/13/23 14:16:05.781
STEP: Creating a pod to test consume configMaps 02/13/23 14:16:05.787
W0213 14:16:05.795954      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:05.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e" in namespace "projected-6052" to be "Succeeded or Failed"
Feb 13 14:16:05.800: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733529ms
Feb 13 14:16:07.806: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010055221s
Feb 13 14:16:09.809: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013436149s
STEP: Saw pod success 02/13/23 14:16:09.809
Feb 13 14:16:09.809: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e" satisfied condition "Succeeded or Failed"
Feb 13 14:16:09.815: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:16:09.825
Feb 13 14:16:09.847: INFO: Waiting for pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e to disappear
Feb 13 14:16:09.850: INFO: Pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 14:16:09.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6052" for this suite. 02/13/23 14:16:09.856
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":211,"skipped":4018,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:05.748
    Feb 13 14:16:05.748: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:16:05.75
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:05.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:05.776
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-551d1e8e-e2e8-4d81-8d52-4c9cdb207e71 02/13/23 14:16:05.781
    STEP: Creating a pod to test consume configMaps 02/13/23 14:16:05.787
    W0213 14:16:05.795954      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:05.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e" in namespace "projected-6052" to be "Succeeded or Failed"
    Feb 13 14:16:05.800: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733529ms
    Feb 13 14:16:07.806: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010055221s
    Feb 13 14:16:09.809: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013436149s
    STEP: Saw pod success 02/13/23 14:16:09.809
    Feb 13 14:16:09.809: INFO: Pod "pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e" satisfied condition "Succeeded or Failed"
    Feb 13 14:16:09.815: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:16:09.825
    Feb 13 14:16:09.847: INFO: Waiting for pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e to disappear
    Feb 13 14:16:09.850: INFO: Pod pod-projected-configmaps-f18b8445-e51f-468c-aa13-c021aca6a90e no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 14:16:09.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6052" for this suite. 02/13/23 14:16:09.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:09.868
Feb 13 14:16:09.869: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:16:09.87
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:09.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:09.896
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 02/13/23 14:16:09.9
Feb 13 14:16:09.901: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:16:12.130: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:16:21.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7628" for this suite. 02/13/23 14:16:21.661
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":212,"skipped":4026,"failed":0}
------------------------------
• [SLOW TEST] [11.800 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:09.868
    Feb 13 14:16:09.869: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:16:09.87
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:09.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:09.896
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 02/13/23 14:16:09.9
    Feb 13 14:16:09.901: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:16:12.130: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:16:21.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7628" for this suite. 02/13/23 14:16:21.661
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:21.669
Feb 13 14:16:21.669: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:16:21.67
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:21.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:21.691
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-9865f5a6-dd61-468d-872d-7e39eee477ac 02/13/23 14:16:21.695
STEP: Creating a pod to test consume secrets 02/13/23 14:16:21.701
W0213 14:16:21.710342      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:21.710: INFO: Waiting up to 5m0s for pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e" in namespace "secrets-9229" to be "Succeeded or Failed"
Feb 13 14:16:21.714: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3115ms
Feb 13 14:16:23.721: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010231155s
Feb 13 14:16:25.720: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009517724s
STEP: Saw pod success 02/13/23 14:16:25.72
Feb 13 14:16:25.720: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e" satisfied condition "Succeeded or Failed"
Feb 13 14:16:25.727: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:16:25.738
Feb 13 14:16:25.751: INFO: Waiting for pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e to disappear
Feb 13 14:16:25.755: INFO: Pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:16:25.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9229" for this suite. 02/13/23 14:16:25.759
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":213,"skipped":4032,"failed":0}
------------------------------
• [4.101 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:21.669
    Feb 13 14:16:21.669: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:16:21.67
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:21.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:21.691
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-9865f5a6-dd61-468d-872d-7e39eee477ac 02/13/23 14:16:21.695
    STEP: Creating a pod to test consume secrets 02/13/23 14:16:21.701
    W0213 14:16:21.710342      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:21.710: INFO: Waiting up to 5m0s for pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e" in namespace "secrets-9229" to be "Succeeded or Failed"
    Feb 13 14:16:21.714: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3115ms
    Feb 13 14:16:23.721: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010231155s
    Feb 13 14:16:25.720: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009517724s
    STEP: Saw pod success 02/13/23 14:16:25.72
    Feb 13 14:16:25.720: INFO: Pod "pod-secrets-e04ce222-0542-462c-b595-714b2a70228e" satisfied condition "Succeeded or Failed"
    Feb 13 14:16:25.727: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:16:25.738
    Feb 13 14:16:25.751: INFO: Waiting for pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e to disappear
    Feb 13 14:16:25.755: INFO: Pod pod-secrets-e04ce222-0542-462c-b595-714b2a70228e no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:16:25.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9229" for this suite. 02/13/23 14:16:25.759
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:25.773
Feb 13 14:16:25.773: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:16:25.775
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:25.794
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:25.798
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-ddd5b6f0-6eab-4c37-a9a5-05f31243d2d9 02/13/23 14:16:25.803
STEP: Creating a pod to test consume secrets 02/13/23 14:16:25.808
W0213 14:16:25.823021      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:25.823: INFO: Waiting up to 5m0s for pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5" in namespace "secrets-3574" to be "Succeeded or Failed"
Feb 13 14:16:25.826: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.490383ms
Feb 13 14:16:27.834: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01120396s
Feb 13 14:16:29.831: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007651151s
STEP: Saw pod success 02/13/23 14:16:29.831
Feb 13 14:16:29.831: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5" satisfied condition "Succeeded or Failed"
Feb 13 14:16:29.834: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 container secret-volume-test: <nil>
STEP: delete the pod 02/13/23 14:16:29.843
Feb 13 14:16:29.857: INFO: Waiting for pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 to disappear
Feb 13 14:16:29.860: INFO: Pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:16:29.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3574" for this suite. 02/13/23 14:16:29.865
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":214,"skipped":4033,"failed":0}
------------------------------
• [4.099 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:25.773
    Feb 13 14:16:25.773: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:16:25.775
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:25.794
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:25.798
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-ddd5b6f0-6eab-4c37-a9a5-05f31243d2d9 02/13/23 14:16:25.803
    STEP: Creating a pod to test consume secrets 02/13/23 14:16:25.808
    W0213 14:16:25.823021      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:25.823: INFO: Waiting up to 5m0s for pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5" in namespace "secrets-3574" to be "Succeeded or Failed"
    Feb 13 14:16:25.826: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.490383ms
    Feb 13 14:16:27.834: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01120396s
    Feb 13 14:16:29.831: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007651151s
    STEP: Saw pod success 02/13/23 14:16:29.831
    Feb 13 14:16:29.831: INFO: Pod "pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5" satisfied condition "Succeeded or Failed"
    Feb 13 14:16:29.834: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 container secret-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:16:29.843
    Feb 13 14:16:29.857: INFO: Waiting for pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 to disappear
    Feb 13 14:16:29.860: INFO: Pod pod-secrets-917e74b5-478e-4c1b-9f65-f171afc0c2e5 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:16:29.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3574" for this suite. 02/13/23 14:16:29.865
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:29.877
Feb 13 14:16:29.878: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 14:16:29.879
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:29.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:29.899
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 02/13/23 14:16:29.909
W0213 14:16:29.915881      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Verify that the required pods have come up. 02/13/23 14:16:29.916
Feb 13 14:16:29.919: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 13 14:16:34.928: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 14:16:34.928
STEP: Getting /status 02/13/23 14:16:34.928
Feb 13 14:16:34.937: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 02/13/23 14:16:34.938
Feb 13 14:16:34.953: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 02/13/23 14:16:34.953
Feb 13 14:16:34.958: INFO: Observed &ReplicaSet event: ADDED
Feb 13 14:16:34.958: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.959: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.959: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.959: INFO: Found replicaset test-rs in namespace replicaset-4558 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Feb 13 14:16:34.959: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 02/13/23 14:16:34.959
Feb 13 14:16:34.960: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Feb 13 14:16:34.971: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 02/13/23 14:16:34.971
Feb 13 14:16:34.974: INFO: Observed &ReplicaSet event: ADDED
Feb 13 14:16:34.974: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.975: INFO: Observed replicaset test-rs in namespace replicaset-4558 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
Feb 13 14:16:34.975: INFO: Found replicaset test-rs in namespace replicaset-4558 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Feb 13 14:16:34.976: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 14:16:34.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4558" for this suite. 02/13/23 14:16:34.979
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":215,"skipped":4075,"failed":0}
------------------------------
• [SLOW TEST] [5.109 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:29.877
    Feb 13 14:16:29.878: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 14:16:29.879
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:29.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:29.899
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 02/13/23 14:16:29.909
    W0213 14:16:29.915881      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Verify that the required pods have come up. 02/13/23 14:16:29.916
    Feb 13 14:16:29.919: INFO: Pod name sample-pod: Found 0 pods out of 1
    Feb 13 14:16:34.928: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 14:16:34.928
    STEP: Getting /status 02/13/23 14:16:34.928
    Feb 13 14:16:34.937: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 02/13/23 14:16:34.938
    Feb 13 14:16:34.953: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 02/13/23 14:16:34.953
    Feb 13 14:16:34.958: INFO: Observed &ReplicaSet event: ADDED
    Feb 13 14:16:34.958: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.959: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.959: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.959: INFO: Found replicaset test-rs in namespace replicaset-4558 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Feb 13 14:16:34.959: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 02/13/23 14:16:34.959
    Feb 13 14:16:34.960: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Feb 13 14:16:34.971: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 02/13/23 14:16:34.971
    Feb 13 14:16:34.974: INFO: Observed &ReplicaSet event: ADDED
    Feb 13 14:16:34.974: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.975: INFO: Observed replicaset test-rs in namespace replicaset-4558 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Feb 13 14:16:34.975: INFO: Observed &ReplicaSet event: MODIFIED
    Feb 13 14:16:34.975: INFO: Found replicaset test-rs in namespace replicaset-4558 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Feb 13 14:16:34.976: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 14:16:34.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4558" for this suite. 02/13/23 14:16:34.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:34.987
Feb 13 14:16:34.988: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:16:34.989
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:35.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:35.013
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-88d5b973-c9bc-4f7e-9e68-2b19f69758b8 02/13/23 14:16:35.017
STEP: Creating a pod to test consume configMaps 02/13/23 14:16:35.023
W0213 14:16:35.036662      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:35.036: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4" in namespace "projected-3340" to be "Succeeded or Failed"
Feb 13 14:16:35.047: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.622926ms
Feb 13 14:16:37.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018467843s
Feb 13 14:16:39.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018282859s
STEP: Saw pod success 02/13/23 14:16:39.055
Feb 13 14:16:39.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4" satisfied condition "Succeeded or Failed"
Feb 13 14:16:39.060: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod 02/13/23 14:16:39.085
Feb 13 14:16:39.099: INFO: Waiting for pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 to disappear
Feb 13 14:16:39.102: INFO: Pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 14:16:39.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3340" for this suite. 02/13/23 14:16:39.107
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":216,"skipped":4085,"failed":0}
------------------------------
• [4.125 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:34.987
    Feb 13 14:16:34.988: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:16:34.989
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:35.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:35.013
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-88d5b973-c9bc-4f7e-9e68-2b19f69758b8 02/13/23 14:16:35.017
    STEP: Creating a pod to test consume configMaps 02/13/23 14:16:35.023
    W0213 14:16:35.036662      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:35.036: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4" in namespace "projected-3340" to be "Succeeded or Failed"
    Feb 13 14:16:35.047: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.622926ms
    Feb 13 14:16:37.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018467843s
    Feb 13 14:16:39.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018282859s
    STEP: Saw pod success 02/13/23 14:16:39.055
    Feb 13 14:16:39.055: INFO: Pod "pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4" satisfied condition "Succeeded or Failed"
    Feb 13 14:16:39.060: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 02/13/23 14:16:39.085
    Feb 13 14:16:39.099: INFO: Waiting for pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 to disappear
    Feb 13 14:16:39.102: INFO: Pod pod-projected-configmaps-b7984fbb-30ab-40f2-b77e-6d4a0b2149a4 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 14:16:39.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3340" for this suite. 02/13/23 14:16:39.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:39.114
Feb 13 14:16:39.114: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 14:16:39.115
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:39.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:39.136
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6001 02/13/23 14:16:39.139
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
W0213 14:16:39.157971      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:39.164: INFO: Found 0 stateful pods, waiting for 1
Feb 13 14:16:49.170: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 02/13/23 14:16:49.179
W0213 14:16:49.195255      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
W0213 14:16:49.195301      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-ss", "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-ss", "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-ss", "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-ss", "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:49.204: INFO: Found 1 stateful pods, waiting for 2
Feb 13 14:16:59.212: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:16:59.212: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 02/13/23 14:16:59.222
STEP: Delete all of the StatefulSets 02/13/23 14:16:59.229
STEP: Verify that StatefulSets have been deleted 02/13/23 14:16:59.24
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 14:16:59.243: INFO: Deleting all statefulset in ns statefulset-6001
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 14:16:59.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6001" for this suite. 02/13/23 14:16:59.273
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":217,"skipped":4095,"failed":0}
------------------------------
• [SLOW TEST] [20.172 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:39.114
    Feb 13 14:16:39.114: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 14:16:39.115
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:39.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:39.136
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6001 02/13/23 14:16:39.139
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    W0213 14:16:39.157971      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:39.164: INFO: Found 0 stateful pods, waiting for 1
    Feb 13 14:16:49.170: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 02/13/23 14:16:49.179
    W0213 14:16:49.195255      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    W0213 14:16:49.195301      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-ss", "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-ss", "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-ss", "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-ss", "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:49.204: INFO: Found 1 stateful pods, waiting for 2
    Feb 13 14:16:59.212: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:16:59.212: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 02/13/23 14:16:59.222
    STEP: Delete all of the StatefulSets 02/13/23 14:16:59.229
    STEP: Verify that StatefulSets have been deleted 02/13/23 14:16:59.24
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 14:16:59.243: INFO: Deleting all statefulset in ns statefulset-6001
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 14:16:59.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6001" for this suite. 02/13/23 14:16:59.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:16:59.312
Feb 13 14:16:59.312: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 14:16:59.313
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:59.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:59.339
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
W0213 14:16:59.355308      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:16:59.355: INFO: Waiting up to 5m0s for pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac" in namespace "container-probe-8809" to be "running and ready"
Feb 13 14:16:59.363: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167309ms
Feb 13 14:16:59.363: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:17:01.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 2.013835347s
Feb 13 14:17:01.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:03.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 4.013278866s
Feb 13 14:17:03.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:05.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 6.014533993s
Feb 13 14:17:05.370: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:07.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 8.013821435s
Feb 13 14:17:07.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:09.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 10.014206614s
Feb 13 14:17:09.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:11.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 12.014146835s
Feb 13 14:17:11.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:13.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 14.012545678s
Feb 13 14:17:13.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:15.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 16.012633188s
Feb 13 14:17:15.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:17.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 18.013701024s
Feb 13 14:17:17.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:19.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 20.012463726s
Feb 13 14:17:19.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
Feb 13 14:17:21.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=true. Elapsed: 22.014736111s
Feb 13 14:17:21.370: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = true)
Feb 13 14:17:21.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac" satisfied condition "running and ready"
Feb 13 14:17:21.375: INFO: Container started at 2023-02-13 14:16:59 +0000 UTC, pod became ready at 2023-02-13 14:17:19 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 14:17:21.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8809" for this suite. 02/13/23 14:17:21.38
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":218,"skipped":4100,"failed":0}
------------------------------
• [SLOW TEST] [22.075 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:16:59.312
    Feb 13 14:16:59.312: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 14:16:59.313
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:16:59.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:16:59.339
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    W0213 14:16:59.355308      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:16:59.355: INFO: Waiting up to 5m0s for pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac" in namespace "container-probe-8809" to be "running and ready"
    Feb 13 14:16:59.363: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167309ms
    Feb 13 14:16:59.363: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:17:01.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 2.013835347s
    Feb 13 14:17:01.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:03.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 4.013278866s
    Feb 13 14:17:03.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:05.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 6.014533993s
    Feb 13 14:17:05.370: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:07.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 8.013821435s
    Feb 13 14:17:07.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:09.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 10.014206614s
    Feb 13 14:17:09.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:11.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 12.014146835s
    Feb 13 14:17:11.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:13.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 14.012545678s
    Feb 13 14:17:13.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:15.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 16.012633188s
    Feb 13 14:17:15.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:17.369: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 18.013701024s
    Feb 13 14:17:17.369: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:19.368: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=false. Elapsed: 20.012463726s
    Feb 13 14:17:19.368: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = false)
    Feb 13 14:17:21.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac": Phase="Running", Reason="", readiness=true. Elapsed: 22.014736111s
    Feb 13 14:17:21.370: INFO: The phase of Pod test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac is Running (Ready = true)
    Feb 13 14:17:21.370: INFO: Pod "test-webserver-d173aecb-7c02-4452-96d6-69dcf674d3ac" satisfied condition "running and ready"
    Feb 13 14:17:21.375: INFO: Container started at 2023-02-13 14:16:59 +0000 UTC, pod became ready at 2023-02-13 14:17:19 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 14:17:21.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8809" for this suite. 02/13/23 14:17:21.38
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:17:21.388
Feb 13 14:17:21.389: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:17:21.39
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:21.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:21.407
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 02/13/23 14:17:21.411
Feb 13 14:17:21.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 13 14:17:21.536: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"logs-generator\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"logs-generator\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"logs-generator\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"logs-generator\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:17:21.536: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 02/13/23 14:17:21.536
Feb 13 14:17:21.536: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 13 14:17:21.536: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5430" to be "running and ready, or succeeded"
Feb 13 14:17:21.540: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033947ms
Feb 13 14:17:21.540: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'conformance-5500-0ccfa5-pool-bf9f-o7jrw' to be 'Running' but was 'Pending'
Feb 13 14:17:23.547: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01089077s
Feb 13 14:17:23.547: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 13 14:17:23.547: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 02/13/23 14:17:23.547
Feb 13 14:17:23.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator'
Feb 13 14:17:23.660: INFO: stderr: ""
Feb 13 14:17:23.660: INFO: stdout: "I0213 14:17:22.209119       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/x88 300\nI0213 14:17:22.409677       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/w5gg 282\nI0213 14:17:22.610012       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/tkb 399\nI0213 14:17:22.809299       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bb8k 370\nI0213 14:17:23.009683       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/nlw 426\nI0213 14:17:23.210147       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/t2h9 249\nI0213 14:17:23.409514       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xj5 485\nI0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
STEP: limiting log lines 02/13/23 14:17:23.66
Feb 13 14:17:23.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --tail=1'
Feb 13 14:17:23.764: INFO: stderr: ""
Feb 13 14:17:23.764: INFO: stdout: "I0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
Feb 13 14:17:23.764: INFO: got output "I0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
STEP: limiting log bytes 02/13/23 14:17:23.764
Feb 13 14:17:23.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --limit-bytes=1'
Feb 13 14:17:23.867: INFO: stderr: ""
Feb 13 14:17:23.867: INFO: stdout: "I"
Feb 13 14:17:23.867: INFO: got output "I"
STEP: exposing timestamps 02/13/23 14:17:23.867
Feb 13 14:17:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --tail=1 --timestamps'
Feb 13 14:17:23.957: INFO: stderr: ""
Feb 13 14:17:23.957: INFO: stdout: "2023-02-13T14:17:23.809589187Z I0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\n"
Feb 13 14:17:23.957: INFO: got output "2023-02-13T14:17:23.809589187Z I0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\n"
STEP: restricting to a time range 02/13/23 14:17:23.958
Feb 13 14:17:26.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --since=1s'
Feb 13 14:17:26.561: INFO: stderr: ""
Feb 13 14:17:26.561: INFO: stdout: "I0213 14:17:25.609172       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dnj 318\nI0213 14:17:25.809662       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/8n5n 398\nI0213 14:17:26.010034       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/gpg2 451\nI0213 14:17:26.209283       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7p7 518\nI0213 14:17:26.409630       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/zqsz 304\n"
Feb 13 14:17:26.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --since=24h'
Feb 13 14:17:26.657: INFO: stderr: ""
Feb 13 14:17:26.657: INFO: stdout: "I0213 14:17:22.209119       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/x88 300\nI0213 14:17:22.409677       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/w5gg 282\nI0213 14:17:22.610012       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/tkb 399\nI0213 14:17:22.809299       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bb8k 370\nI0213 14:17:23.009683       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/nlw 426\nI0213 14:17:23.210147       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/t2h9 249\nI0213 14:17:23.409514       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xj5 485\nI0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\nI0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\nI0213 14:17:24.009762       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/mdgn 565\nI0213 14:17:24.210267       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/vc6 558\nI0213 14:17:24.409632       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/6jz 205\nI0213 14:17:24.610121       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/vxvd 584\nI0213 14:17:24.809797       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/j7g 437\nI0213 14:17:25.010041       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/6cf 321\nI0213 14:17:25.209404       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/w6g 362\nI0213 14:17:25.409796       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/ms7 471\nI0213 14:17:25.609172       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dnj 318\nI0213 14:17:25.809662       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/8n5n 398\nI0213 14:17:26.010034       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/gpg2 451\nI0213 14:17:26.209283       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7p7 518\nI0213 14:17:26.409630       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/zqsz 304\nI0213 14:17:26.609968       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/hmnz 483\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Feb 13 14:17:26.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 delete pod logs-generator'
Feb 13 14:17:27.864: INFO: stderr: ""
Feb 13 14:17:27.864: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:17:27.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5430" for this suite. 02/13/23 14:17:27.869
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":219,"skipped":4114,"failed":0}
------------------------------
• [SLOW TEST] [6.492 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:17:21.388
    Feb 13 14:17:21.389: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:17:21.39
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:21.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:21.407
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 02/13/23 14:17:21.411
    Feb 13 14:17:21.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Feb 13 14:17:21.536: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"logs-generator\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"logs-generator\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"logs-generator\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"logs-generator\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:17:21.536: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 02/13/23 14:17:21.536
    Feb 13 14:17:21.536: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Feb 13 14:17:21.536: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5430" to be "running and ready, or succeeded"
    Feb 13 14:17:21.540: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033947ms
    Feb 13 14:17:21.540: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'conformance-5500-0ccfa5-pool-bf9f-o7jrw' to be 'Running' but was 'Pending'
    Feb 13 14:17:23.547: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01089077s
    Feb 13 14:17:23.547: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Feb 13 14:17:23.547: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 02/13/23 14:17:23.547
    Feb 13 14:17:23.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator'
    Feb 13 14:17:23.660: INFO: stderr: ""
    Feb 13 14:17:23.660: INFO: stdout: "I0213 14:17:22.209119       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/x88 300\nI0213 14:17:22.409677       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/w5gg 282\nI0213 14:17:22.610012       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/tkb 399\nI0213 14:17:22.809299       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bb8k 370\nI0213 14:17:23.009683       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/nlw 426\nI0213 14:17:23.210147       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/t2h9 249\nI0213 14:17:23.409514       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xj5 485\nI0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
    STEP: limiting log lines 02/13/23 14:17:23.66
    Feb 13 14:17:23.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --tail=1'
    Feb 13 14:17:23.764: INFO: stderr: ""
    Feb 13 14:17:23.764: INFO: stdout: "I0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
    Feb 13 14:17:23.764: INFO: got output "I0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\n"
    STEP: limiting log bytes 02/13/23 14:17:23.764
    Feb 13 14:17:23.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --limit-bytes=1'
    Feb 13 14:17:23.867: INFO: stderr: ""
    Feb 13 14:17:23.867: INFO: stdout: "I"
    Feb 13 14:17:23.867: INFO: got output "I"
    STEP: exposing timestamps 02/13/23 14:17:23.867
    Feb 13 14:17:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --tail=1 --timestamps'
    Feb 13 14:17:23.957: INFO: stderr: ""
    Feb 13 14:17:23.957: INFO: stdout: "2023-02-13T14:17:23.809589187Z I0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\n"
    Feb 13 14:17:23.957: INFO: got output "2023-02-13T14:17:23.809589187Z I0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\n"
    STEP: restricting to a time range 02/13/23 14:17:23.958
    Feb 13 14:17:26.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --since=1s'
    Feb 13 14:17:26.561: INFO: stderr: ""
    Feb 13 14:17:26.561: INFO: stdout: "I0213 14:17:25.609172       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dnj 318\nI0213 14:17:25.809662       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/8n5n 398\nI0213 14:17:26.010034       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/gpg2 451\nI0213 14:17:26.209283       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7p7 518\nI0213 14:17:26.409630       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/zqsz 304\n"
    Feb 13 14:17:26.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 logs logs-generator logs-generator --since=24h'
    Feb 13 14:17:26.657: INFO: stderr: ""
    Feb 13 14:17:26.657: INFO: stdout: "I0213 14:17:22.209119       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/x88 300\nI0213 14:17:22.409677       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/w5gg 282\nI0213 14:17:22.610012       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/tkb 399\nI0213 14:17:22.809299       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bb8k 370\nI0213 14:17:23.009683       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/nlw 426\nI0213 14:17:23.210147       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/t2h9 249\nI0213 14:17:23.409514       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xj5 485\nI0213 14:17:23.609911       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/sr7 486\nI0213 14:17:23.809334       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/k8v 384\nI0213 14:17:24.009762       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/mdgn 565\nI0213 14:17:24.210267       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/vc6 558\nI0213 14:17:24.409632       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/6jz 205\nI0213 14:17:24.610121       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/vxvd 584\nI0213 14:17:24.809797       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/j7g 437\nI0213 14:17:25.010041       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/6cf 321\nI0213 14:17:25.209404       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/w6g 362\nI0213 14:17:25.409796       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/ms7 471\nI0213 14:17:25.609172       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dnj 318\nI0213 14:17:25.809662       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/8n5n 398\nI0213 14:17:26.010034       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/gpg2 451\nI0213 14:17:26.209283       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7p7 518\nI0213 14:17:26.409630       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/zqsz 304\nI0213 14:17:26.609968       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/hmnz 483\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Feb 13 14:17:26.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-5430 delete pod logs-generator'
    Feb 13 14:17:27.864: INFO: stderr: ""
    Feb 13 14:17:27.864: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:17:27.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5430" for this suite. 02/13/23 14:17:27.869
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:17:27.882
Feb 13 14:17:27.882: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:17:27.884
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:27.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:27.904
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Feb 13 14:17:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 02/13/23 14:17:30.16
Feb 13 14:17:30.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
Feb 13 14:17:30.952: INFO: stderr: ""
Feb 13 14:17:30.952: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 13 14:17:30.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 delete e2e-test-crd-publish-openapi-6773-crds test-foo'
Feb 13 14:17:31.056: INFO: stderr: ""
Feb 13 14:17:31.056: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 13 14:17:31.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
Feb 13 14:17:31.346: INFO: stderr: ""
Feb 13 14:17:31.346: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 13 14:17:31.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 delete e2e-test-crd-publish-openapi-6773-crds test-foo'
Feb 13 14:17:31.455: INFO: stderr: ""
Feb 13 14:17:31.455: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 02/13/23 14:17:31.455
Feb 13 14:17:31.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
Feb 13 14:17:31.736: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 02/13/23 14:17:31.736
Feb 13 14:17:31.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
Feb 13 14:17:32.018: INFO: rc: 1
Feb 13 14:17:32.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
Feb 13 14:17:32.321: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 02/13/23 14:17:32.321
Feb 13 14:17:32.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
Feb 13 14:17:32.594: INFO: rc: 1
Feb 13 14:17:32.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
Feb 13 14:17:32.899: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 02/13/23 14:17:32.899
Feb 13 14:17:32.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds'
Feb 13 14:17:33.140: INFO: stderr: ""
Feb 13 14:17:33.140: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 02/13/23 14:17:33.141
Feb 13 14:17:33.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.metadata'
Feb 13 14:17:33.442: INFO: stderr: ""
Feb 13 14:17:33.442: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 13 14:17:33.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec'
Feb 13 14:17:33.679: INFO: stderr: ""
Feb 13 14:17:33.679: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 13 14:17:33.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec.bars'
Feb 13 14:17:33.978: INFO: stderr: ""
Feb 13 14:17:33.978: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 02/13/23 14:17:33.978
Feb 13 14:17:33.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec.bars2'
Feb 13 14:17:34.234: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:17:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4141" for this suite. 02/13/23 14:17:36.471
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":220,"skipped":4115,"failed":0}
------------------------------
• [SLOW TEST] [8.595 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:17:27.882
    Feb 13 14:17:27.882: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:17:27.884
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:27.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:27.904
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Feb 13 14:17:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 02/13/23 14:17:30.16
    Feb 13 14:17:30.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
    Feb 13 14:17:30.952: INFO: stderr: ""
    Feb 13 14:17:30.952: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Feb 13 14:17:30.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 delete e2e-test-crd-publish-openapi-6773-crds test-foo'
    Feb 13 14:17:31.056: INFO: stderr: ""
    Feb 13 14:17:31.056: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Feb 13 14:17:31.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
    Feb 13 14:17:31.346: INFO: stderr: ""
    Feb 13 14:17:31.346: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Feb 13 14:17:31.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 delete e2e-test-crd-publish-openapi-6773-crds test-foo'
    Feb 13 14:17:31.455: INFO: stderr: ""
    Feb 13 14:17:31.455: INFO: stdout: "e2e-test-crd-publish-openapi-6773-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 02/13/23 14:17:31.455
    Feb 13 14:17:31.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
    Feb 13 14:17:31.736: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 02/13/23 14:17:31.736
    Feb 13 14:17:31.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
    Feb 13 14:17:32.018: INFO: rc: 1
    Feb 13 14:17:32.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
    Feb 13 14:17:32.321: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 02/13/23 14:17:32.321
    Feb 13 14:17:32.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 create -f -'
    Feb 13 14:17:32.594: INFO: rc: 1
    Feb 13 14:17:32.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 --namespace=crd-publish-openapi-4141 apply -f -'
    Feb 13 14:17:32.899: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 02/13/23 14:17:32.899
    Feb 13 14:17:32.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds'
    Feb 13 14:17:33.140: INFO: stderr: ""
    Feb 13 14:17:33.140: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 02/13/23 14:17:33.141
    Feb 13 14:17:33.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.metadata'
    Feb 13 14:17:33.442: INFO: stderr: ""
    Feb 13 14:17:33.442: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Feb 13 14:17:33.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec'
    Feb 13 14:17:33.679: INFO: stderr: ""
    Feb 13 14:17:33.679: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Feb 13 14:17:33.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec.bars'
    Feb 13 14:17:33.978: INFO: stderr: ""
    Feb 13 14:17:33.978: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6773-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 02/13/23 14:17:33.978
    Feb 13 14:17:33.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-4141 explain e2e-test-crd-publish-openapi-6773-crds.spec.bars2'
    Feb 13 14:17:34.234: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:17:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4141" for this suite. 02/13/23 14:17:36.471
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:17:36.48
Feb 13 14:17:36.480: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename containers 02/13/23 14:17:36.482
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:36.496
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:36.5
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 02/13/23 14:17:36.505
W0213 14:17:36.515346      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:17:36.515: INFO: Waiting up to 5m0s for pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7" in namespace "containers-1243" to be "Succeeded or Failed"
Feb 13 14:17:36.518: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.205945ms
Feb 13 14:17:38.523: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007612159s
Feb 13 14:17:40.524: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008972723s
STEP: Saw pod success 02/13/23 14:17:40.524
Feb 13 14:17:40.525: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7" satisfied condition "Succeeded or Failed"
Feb 13 14:17:40.529: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:17:40.539
Feb 13 14:17:40.554: INFO: Waiting for pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 to disappear
Feb 13 14:17:40.558: INFO: Pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Feb 13 14:17:40.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1243" for this suite. 02/13/23 14:17:40.563
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":221,"skipped":4117,"failed":0}
------------------------------
• [4.090 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:17:36.48
    Feb 13 14:17:36.480: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename containers 02/13/23 14:17:36.482
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:36.496
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:36.5
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 02/13/23 14:17:36.505
    W0213 14:17:36.515346      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:17:36.515: INFO: Waiting up to 5m0s for pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7" in namespace "containers-1243" to be "Succeeded or Failed"
    Feb 13 14:17:36.518: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.205945ms
    Feb 13 14:17:38.523: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007612159s
    Feb 13 14:17:40.524: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008972723s
    STEP: Saw pod success 02/13/23 14:17:40.524
    Feb 13 14:17:40.525: INFO: Pod "client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7" satisfied condition "Succeeded or Failed"
    Feb 13 14:17:40.529: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:17:40.539
    Feb 13 14:17:40.554: INFO: Waiting for pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 to disappear
    Feb 13 14:17:40.558: INFO: Pod client-containers-9760b72a-55ee-46a8-80b9-be584a9ebbb7 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Feb 13 14:17:40.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1243" for this suite. 02/13/23 14:17:40.563
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:17:40.575
Feb 13 14:17:40.575: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-runtime 02/13/23 14:17:40.577
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:40.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:40.597
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
W0213 14:17:40.615875      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpa" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpa" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpa" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpa" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 02/13/23 14:17:40.616
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 02/13/23 14:18:00.721
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 02/13/23 14:18:00.726
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 02/13/23 14:18:00.735
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 02/13/23 14:18:00.735
W0213 14:18:00.759449      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpof" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpof" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpof" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpof" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 02/13/23 14:18:00.759
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 02/13/23 14:18:03.785
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 02/13/23 14:18:05.805
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 02/13/23 14:18:05.811
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 02/13/23 14:18:05.812
W0213 14:18:05.836177      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpn" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpn" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpn" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpn" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 02/13/23 14:18:05.836
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 02/13/23 14:18:06.846
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 02/13/23 14:18:09.865
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 02/13/23 14:18:09.872
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 02/13/23 14:18:09.872
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Feb 13 14:18:09.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5351" for this suite. 02/13/23 14:18:09.9
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":222,"skipped":4144,"failed":0}
------------------------------
• [SLOW TEST] [29.330 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:17:40.575
    Feb 13 14:17:40.575: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-runtime 02/13/23 14:17:40.577
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:17:40.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:17:40.597
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    W0213 14:17:40.615875      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpa" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpa" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpa" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpa" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 02/13/23 14:17:40.616
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 02/13/23 14:18:00.721
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 02/13/23 14:18:00.726
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 02/13/23 14:18:00.735
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 02/13/23 14:18:00.735
    W0213 14:18:00.759449      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpof" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpof" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpof" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpof" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 02/13/23 14:18:00.759
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 02/13/23 14:18:03.785
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 02/13/23 14:18:05.805
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 02/13/23 14:18:05.811
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 02/13/23 14:18:05.812
    W0213 14:18:05.836177      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpn" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpn" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpn" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpn" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 02/13/23 14:18:05.836
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 02/13/23 14:18:06.846
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 02/13/23 14:18:09.865
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 02/13/23 14:18:09.872
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 02/13/23 14:18:09.872
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Feb 13 14:18:09.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5351" for this suite. 02/13/23 14:18:09.9
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:09.908
Feb 13 14:18:09.908: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sysctl 02/13/23 14:18:09.909
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:09.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:09.932
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 02/13/23 14:18:09.936
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 14:18:09.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3738" for this suite. 02/13/23 14:18:09.949
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":223,"skipped":4162,"failed":0}
------------------------------
• [0.048 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:09.908
    Feb 13 14:18:09.908: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sysctl 02/13/23 14:18:09.909
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:09.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:09.932
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 02/13/23 14:18:09.936
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 14:18:09.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3738" for this suite. 02/13/23 14:18:09.949
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:09.958
Feb 13 14:18:09.959: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:18:09.96
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:09.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:09.982
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:18:10.001
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:18:10.251
STEP: Deploying the webhook pod 02/13/23 14:18:10.263
W0213 14:18:10.279562      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:18:10.279
Feb 13 14:18:10.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 13 14:18:12.309: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:18:14.319: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:18:16.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:18:18.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:18:20.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 02/13/23 14:18:22.316
STEP: Verifying the service has paired with the endpoint 02/13/23 14:18:22.331
Feb 13 14:18:23.331: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 02/13/23 14:18:23.336
STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:23.336
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 02/13/23 14:18:23.374
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 02/13/23 14:18:24.392
STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:24.392
STEP: Having no error when timeout is longer than webhook latency 02/13/23 14:18:25.431
STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:25.431
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 02/13/23 14:18:30.481
STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:30.481
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:18:35.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1856" for this suite. 02/13/23 14:18:35.523
STEP: Destroying namespace "webhook-1856-markers" for this suite. 02/13/23 14:18:35.528
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":224,"skipped":4178,"failed":0}
------------------------------
• [SLOW TEST] [25.623 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:09.958
    Feb 13 14:18:09.959: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:18:09.96
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:09.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:09.982
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:18:10.001
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:18:10.251
    STEP: Deploying the webhook pod 02/13/23 14:18:10.263
    W0213 14:18:10.279562      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:18:10.279
    Feb 13 14:18:10.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Feb 13 14:18:12.309: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:18:14.319: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:18:16.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:18:18.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 14:18:20.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 14, 18, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 02/13/23 14:18:22.316
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:18:22.331
    Feb 13 14:18:23.331: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 02/13/23 14:18:23.336
    STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:23.336
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 02/13/23 14:18:23.374
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 02/13/23 14:18:24.392
    STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:24.392
    STEP: Having no error when timeout is longer than webhook latency 02/13/23 14:18:25.431
    STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:25.431
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 02/13/23 14:18:30.481
    STEP: Registering slow webhook via the AdmissionRegistration API 02/13/23 14:18:30.481
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:18:35.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1856" for this suite. 02/13/23 14:18:35.523
    STEP: Destroying namespace "webhook-1856-markers" for this suite. 02/13/23 14:18:35.528
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:35.585
Feb 13 14:18:35.585: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 14:18:35.586
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:35.603
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:35.61
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 02/13/23 14:18:35.617
W0213 14:18:35.627641      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:18:35.628: INFO: Waiting up to 5m0s for pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde" in namespace "emptydir-6352" to be "Succeeded or Failed"
Feb 13 14:18:35.632: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461227ms
Feb 13 14:18:37.637: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008998623s
Feb 13 14:18:39.639: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011184534s
STEP: Saw pod success 02/13/23 14:18:39.639
Feb 13 14:18:39.639: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde" satisfied condition "Succeeded or Failed"
Feb 13 14:18:39.644: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde container test-container: <nil>
STEP: delete the pod 02/13/23 14:18:39.656
Feb 13 14:18:39.670: INFO: Waiting for pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde to disappear
Feb 13 14:18:39.673: INFO: Pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 14:18:39.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6352" for this suite. 02/13/23 14:18:39.678
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":225,"skipped":4216,"failed":0}
------------------------------
• [4.100 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:35.585
    Feb 13 14:18:35.585: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 14:18:35.586
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:35.603
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:35.61
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 02/13/23 14:18:35.617
    W0213 14:18:35.627641      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:18:35.628: INFO: Waiting up to 5m0s for pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde" in namespace "emptydir-6352" to be "Succeeded or Failed"
    Feb 13 14:18:35.632: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461227ms
    Feb 13 14:18:37.637: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008998623s
    Feb 13 14:18:39.639: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011184534s
    STEP: Saw pod success 02/13/23 14:18:39.639
    Feb 13 14:18:39.639: INFO: Pod "pod-08c0836f-b4cb-4155-9086-5f347c35cfde" satisfied condition "Succeeded or Failed"
    Feb 13 14:18:39.644: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde container test-container: <nil>
    STEP: delete the pod 02/13/23 14:18:39.656
    Feb 13 14:18:39.670: INFO: Waiting for pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde to disappear
    Feb 13 14:18:39.673: INFO: Pod pod-08c0836f-b4cb-4155-9086-5f347c35cfde no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:18:39.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6352" for this suite. 02/13/23 14:18:39.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:39.694
Feb 13 14:18:39.694: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 14:18:39.695
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:39.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:39.718
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 02/13/23 14:18:39.75
W0213 14:18:39.758507      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 14:18:39.758
Feb 13 14:18:39.773: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:18:39.773: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:18:40.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:18:40.788: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:18:41.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:18:41.783: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
Feb 13 14:18:42.782: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 14:18:42.782: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 02/13/23 14:18:42.785
Feb 13 14:18:42.804: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:18:42.804: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
Feb 13 14:18:43.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:18:43.813: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
Feb 13 14:18:44.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Feb 13 14:18:44.814: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
Feb 13 14:18:45.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Feb 13 14:18:45.814: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:18:45.817
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3379, will wait for the garbage collector to delete the pods 02/13/23 14:18:45.817
Feb 13 14:18:45.879: INFO: Deleting DaemonSet.extensions daemon-set took: 7.816126ms
Feb 13 14:18:45.980: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.445863ms
Feb 13 14:18:48.186: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:18:48.186: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 14:18:48.189: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24749"},"items":null}

Feb 13 14:18:48.193: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24749"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:18:48.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3379" for this suite. 02/13/23 14:18:48.214
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":226,"skipped":4291,"failed":0}
------------------------------
• [SLOW TEST] [8.528 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:39.694
    Feb 13 14:18:39.694: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 14:18:39.695
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:39.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:39.718
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 02/13/23 14:18:39.75
    W0213 14:18:39.758507      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Check that daemon pods launch on every node of the cluster. 02/13/23 14:18:39.758
    Feb 13 14:18:39.773: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:18:39.773: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:18:40.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:18:40.788: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:18:41.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:18:41.783: INFO: Node conformance-5500-0ccfa5-pool-bf9f-myudo is running 0 daemon pod, expected 1
    Feb 13 14:18:42.782: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 14:18:42.782: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 02/13/23 14:18:42.785
    Feb 13 14:18:42.804: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:18:42.804: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
    Feb 13 14:18:43.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:18:43.813: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
    Feb 13 14:18:44.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Feb 13 14:18:44.814: INFO: Node conformance-5500-0ccfa5-pool-bf9f-o7jrw is running 0 daemon pod, expected 1
    Feb 13 14:18:45.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Feb 13 14:18:45.814: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:18:45.817
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3379, will wait for the garbage collector to delete the pods 02/13/23 14:18:45.817
    Feb 13 14:18:45.879: INFO: Deleting DaemonSet.extensions daemon-set took: 7.816126ms
    Feb 13 14:18:45.980: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.445863ms
    Feb 13 14:18:48.186: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:18:48.186: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 14:18:48.189: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24749"},"items":null}

    Feb 13 14:18:48.193: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24749"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:18:48.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3379" for this suite. 02/13/23 14:18:48.214
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:48.226
Feb 13 14:18:48.226: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:18:48.227
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:48.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:48.251
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 02/13/23 14:18:48.255
Feb 13 14:18:48.256: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-1713 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 02/13/23 14:18:48.354
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:18:48.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1713" for this suite. 02/13/23 14:18:48.396
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":227,"skipped":4298,"failed":0}
------------------------------
• [0.180 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:48.226
    Feb 13 14:18:48.226: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:18:48.227
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:48.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:48.251
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 02/13/23 14:18:48.255
    Feb 13 14:18:48.256: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-1713 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 02/13/23 14:18:48.354
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:18:48.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1713" for this suite. 02/13/23 14:18:48.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:48.407
Feb 13 14:18:48.407: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:18:48.409
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:48.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:48.439
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:18:48.49
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:18:48.92
STEP: Deploying the webhook pod 02/13/23 14:18:48.93
W0213 14:18:48.948438      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:18:48.949
Feb 13 14:18:48.960: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:18:50.973
STEP: Verifying the service has paired with the endpoint 02/13/23 14:18:50.988
Feb 13 14:18:51.989: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 02/13/23 14:18:51.997
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 02/13/23 14:18:52.039
STEP: Creating a dummy validating-webhook-configuration object 02/13/23 14:18:52.066
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 02/13/23 14:18:52.08
STEP: Creating a dummy mutating-webhook-configuration object 02/13/23 14:18:52.086
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 02/13/23 14:18:52.097
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:18:52.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8299" for this suite. 02/13/23 14:18:52.12
STEP: Destroying namespace "webhook-8299-markers" for this suite. 02/13/23 14:18:52.126
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":228,"skipped":4316,"failed":0}
------------------------------
• [3.780 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:48.407
    Feb 13 14:18:48.407: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:18:48.409
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:48.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:48.439
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:18:48.49
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:18:48.92
    STEP: Deploying the webhook pod 02/13/23 14:18:48.93
    W0213 14:18:48.948438      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:18:48.949
    Feb 13 14:18:48.960: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:18:50.973
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:18:50.988
    Feb 13 14:18:51.989: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 02/13/23 14:18:51.997
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 02/13/23 14:18:52.039
    STEP: Creating a dummy validating-webhook-configuration object 02/13/23 14:18:52.066
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 02/13/23 14:18:52.08
    STEP: Creating a dummy mutating-webhook-configuration object 02/13/23 14:18:52.086
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 02/13/23 14:18:52.097
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:18:52.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8299" for this suite. 02/13/23 14:18:52.12
    STEP: Destroying namespace "webhook-8299-markers" for this suite. 02/13/23 14:18:52.126
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:52.197
Feb 13 14:18:52.198: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:18:52.199
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:52.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:52.22
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 14:18:52.223
Feb 13 14:18:52.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3351 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Feb 13 14:18:52.330: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:18:52.330: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 02/13/23 14:18:52.33
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Feb 13 14:18:52.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3351 delete pods e2e-test-httpd-pod'
Feb 13 14:18:54.167: INFO: stderr: ""
Feb 13 14:18:54.167: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:18:54.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3351" for this suite. 02/13/23 14:18:54.173
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":229,"skipped":4335,"failed":0}
------------------------------
• [1.983 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:52.197
    Feb 13 14:18:52.198: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:18:52.199
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:52.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:52.22
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 02/13/23 14:18:52.223
    Feb 13 14:18:52.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3351 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Feb 13 14:18:52.330: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:18:52.330: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 02/13/23 14:18:52.33
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Feb 13 14:18:52.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3351 delete pods e2e-test-httpd-pod'
    Feb 13 14:18:54.167: INFO: stderr: ""
    Feb 13 14:18:54.167: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:18:54.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3351" for this suite. 02/13/23 14:18:54.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:18:54.181
Feb 13 14:18:54.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:18:54.183
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:54.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:54.202
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Feb 13 14:18:54.207: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 14:18:57.435
Feb 13 14:18:57.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 create -f -'
Feb 13 14:18:58.204: INFO: stderr: ""
Feb 13 14:18:58.204: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 13 14:18:58.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 delete e2e-test-crd-publish-openapi-5687-crds test-cr'
Feb 13 14:18:58.311: INFO: stderr: ""
Feb 13 14:18:58.311: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 13 14:18:58.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 apply -f -'
Feb 13 14:18:58.620: INFO: stderr: ""
Feb 13 14:18:58.620: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 13 14:18:58.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 delete e2e-test-crd-publish-openapi-5687-crds test-cr'
Feb 13 14:18:58.720: INFO: stderr: ""
Feb 13 14:18:58.720: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 02/13/23 14:18:58.72
Feb 13 14:18:58.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 explain e2e-test-crd-publish-openapi-5687-crds'
Feb 13 14:18:58.954: INFO: stderr: ""
Feb 13 14:18:58.954: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5687-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:19:01.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9694" for this suite. 02/13/23 14:19:01.257
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":230,"skipped":4344,"failed":0}
------------------------------
• [SLOW TEST] [7.086 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:18:54.181
    Feb 13 14:18:54.181: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:18:54.183
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:18:54.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:18:54.202
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Feb 13 14:18:54.207: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 02/13/23 14:18:57.435
    Feb 13 14:18:57.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 create -f -'
    Feb 13 14:18:58.204: INFO: stderr: ""
    Feb 13 14:18:58.204: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Feb 13 14:18:58.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 delete e2e-test-crd-publish-openapi-5687-crds test-cr'
    Feb 13 14:18:58.311: INFO: stderr: ""
    Feb 13 14:18:58.311: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Feb 13 14:18:58.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 apply -f -'
    Feb 13 14:18:58.620: INFO: stderr: ""
    Feb 13 14:18:58.620: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Feb 13 14:18:58.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 --namespace=crd-publish-openapi-9694 delete e2e-test-crd-publish-openapi-5687-crds test-cr'
    Feb 13 14:18:58.720: INFO: stderr: ""
    Feb 13 14:18:58.720: INFO: stdout: "e2e-test-crd-publish-openapi-5687-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 02/13/23 14:18:58.72
    Feb 13 14:18:58.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=crd-publish-openapi-9694 explain e2e-test-crd-publish-openapi-5687-crds'
    Feb 13 14:18:58.954: INFO: stderr: ""
    Feb 13 14:18:58.954: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5687-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:19:01.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9694" for this suite. 02/13/23 14:19:01.257
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:01.284
Feb 13 14:19:01.284: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:19:01.286
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.311
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 02/13/23 14:19:01.317
STEP: fetching the ConfigMap 02/13/23 14:19:01.325
STEP: patching the ConfigMap 02/13/23 14:19:01.328
STEP: listing all ConfigMaps in all namespaces with a label selector 02/13/23 14:19:01.334
STEP: deleting the ConfigMap by collection with a label selector 02/13/23 14:19:01.338
STEP: listing all ConfigMaps in test namespace 02/13/23 14:19:01.346
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:19:01.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8588" for this suite. 02/13/23 14:19:01.354
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":231,"skipped":4390,"failed":0}
------------------------------
• [0.077 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:01.284
    Feb 13 14:19:01.284: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:19:01.286
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.311
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 02/13/23 14:19:01.317
    STEP: fetching the ConfigMap 02/13/23 14:19:01.325
    STEP: patching the ConfigMap 02/13/23 14:19:01.328
    STEP: listing all ConfigMaps in all namespaces with a label selector 02/13/23 14:19:01.334
    STEP: deleting the ConfigMap by collection with a label selector 02/13/23 14:19:01.338
    STEP: listing all ConfigMaps in test namespace 02/13/23 14:19:01.346
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:19:01.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8588" for this suite. 02/13/23 14:19:01.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:01.362
Feb 13 14:19:01.363: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption 02/13/23 14:19:01.364
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.387
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:01.392
Feb 13 14:19:01.392: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename disruption-2 02/13/23 14:19:01.393
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.421
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 02/13/23 14:19:01.436
STEP: Waiting for the pdb to be processed 02/13/23 14:19:01.452
STEP: Waiting for the pdb to be processed 02/13/23 14:19:03.471
STEP: listing a collection of PDBs across all namespaces 02/13/23 14:19:03.48
STEP: listing a collection of PDBs in namespace disruption-8337 02/13/23 14:19:03.486
STEP: deleting a collection of PDBs 02/13/23 14:19:03.493
STEP: Waiting for the PDB collection to be deleted 02/13/23 14:19:03.506
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Feb 13 14:19:03.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-4801" for this suite. 02/13/23 14:19:03.515
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Feb 13 14:19:03.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8337" for this suite. 02/13/23 14:19:03.526
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":232,"skipped":4396,"failed":0}
------------------------------
• [2.172 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:01.362
    Feb 13 14:19:01.363: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption 02/13/23 14:19:01.364
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.387
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:01.392
    Feb 13 14:19:01.392: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename disruption-2 02/13/23 14:19:01.393
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:01.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:01.421
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 02/13/23 14:19:01.436
    STEP: Waiting for the pdb to be processed 02/13/23 14:19:01.452
    STEP: Waiting for the pdb to be processed 02/13/23 14:19:03.471
    STEP: listing a collection of PDBs across all namespaces 02/13/23 14:19:03.48
    STEP: listing a collection of PDBs in namespace disruption-8337 02/13/23 14:19:03.486
    STEP: deleting a collection of PDBs 02/13/23 14:19:03.493
    STEP: Waiting for the PDB collection to be deleted 02/13/23 14:19:03.506
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Feb 13 14:19:03.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-4801" for this suite. 02/13/23 14:19:03.515
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Feb 13 14:19:03.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8337" for this suite. 02/13/23 14:19:03.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:03.54
Feb 13 14:19:03.541: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:19:03.543
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:03.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:03.577
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Feb 13 14:19:03.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 create -f -'
Feb 13 14:19:04.252: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:19:04.252: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Feb 13 14:19:04.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 create -f -'
Feb 13 14:19:04.508: INFO: stderr: ""
Feb 13 14:19:04.508: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 02/13/23 14:19:04.508
Feb 13 14:19:05.513: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:19:05.513: INFO: Found 1 / 1
Feb 13 14:19:05.513: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 14:19:05.516: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:19:05.516: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 14:19:05.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe pod agnhost-primary-qs797'
Feb 13 14:19:05.639: INFO: stderr: ""
Feb 13 14:19:05.639: INFO: stdout: "Name:             agnhost-primary-qs797\nNamespace:        kubectl-2500\nPriority:         0\nService Account:  default\nNode:             conformance-5500-0ccfa5-pool-bf9f-o7jrw/192.168.1.11\nStart Time:       Mon, 13 Feb 2023 14:19:04 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.0.41\nIPs:\n  IP:           10.244.0.41\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://49abebaa41bcea808e11c9c1de439329205056cf6c458d1a548e9a3cd72b8dcb\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 13 Feb 2023 14:19:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-cfdzj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-cfdzj:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-2500/agnhost-primary-qs797 to conformance-5500-0ccfa5-pool-bf9f-o7jrw\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Feb 13 14:19:05.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe rc agnhost-primary'
Feb 13 14:19:05.756: INFO: stderr: ""
Feb 13 14:19:05.756: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2500\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-qs797\n"
Feb 13 14:19:05.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe service agnhost-primary'
Feb 13 14:19:05.848: INFO: stderr: ""
Feb 13 14:19:05.848: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2500\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.104.193.4\nIPs:               10.104.193.4\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.0.41:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 13 14:19:05.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe node conformance-5500-0ccfa5-pool-bf9f-myudo'
Feb 13 14:19:05.987: INFO: stderr: ""
Feb 13 14:19:05.987: INFO: stdout: "Name:               conformance-5500-0ccfa5-pool-bf9f-myudo\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=g4s.kube.medium\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=conformance-5500-0ccfa5-pool-bf9f-myudo\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=g4s.kube.medium\n                    region=\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"csi.civo.com\":\"a15fe799-1665-4142-8dc2-78bd4ab7dba3\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"c2:4a:9d:83:77:a8\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.12\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 Feb 2023 13:01:08 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  conformance-5500-0ccfa5-pool-bf9f-myudo\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 13 Feb 2023 14:19:03 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 13 Feb 2023 13:01:33 +0000   Mon, 13 Feb 2023 13:01:33 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:29 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.12\n  Hostname:    conformance-5500-0ccfa5-pool-bf9f-myudo\nCapacity:\n  cpu:                2\n  ephemeral-storage:  48288732Ki\n  hugepages-2Mi:      0\n  memory:             3807324Ki\n  pods:               110\nAllocatable:\n  cpu:                1950m\n  ephemeral-storage:  44234459882\n  hugepages-2Mi:      0\n  memory:             3508316Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 d7042be5dd2d299d340d71209da95bad\n  System UUID:                b22d410c-1b47-572f-bffc-63b39d2feb4c\n  Boot ID:                    d60c68d3-04d7-4693-8980-a38dd8ba754b\n  Kernel Version:             5.15.83-talos\n  OS Image:                   Talos (v1.2.8)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.12\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      10.244.1.0/24\nPodCIDRs:                     10.244.1.0/24\nProviderID:                   civo://a15fe799-1665-4142-8dc2-78bd4ab7dba3\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                         ------------  ----------  ---------------  -------------  ---\n  kube-system                 civo-ccm-69cdbdd6c5-5h8vx    0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 civo-csi-controller-0        0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 civo-csi-node-ggrnh          0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 coredns-584d5df445-c4zbq     100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     78m\n  kube-system                 coredns-584d5df445-fgktn     100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     78m\n  kube-system                 konnectivity-agent-xsjnx     0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 kube-flannel-gwjn2           0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 kube-proxy-mffzd             0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                200m (10%)  0 (0%)\n  memory             140Mi (4%)  340Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Feb 13 14:19:05.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe namespace kubectl-2500'
Feb 13 14:19:06.067: INFO: stderr: ""
Feb 13 14:19:06.067: INFO: stdout: "Name:         kubectl-2500\nLabels:       e2e-framework=kubectl\n              e2e-run=8a5a0cb0-4dbb-4dde-8847-35c08d716de3\n              kubernetes.io/metadata.name=kubectl-2500\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:19:06.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2500" for this suite. 02/13/23 14:19:06.072
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":233,"skipped":4410,"failed":0}
------------------------------
• [2.538 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:03.54
    Feb 13 14:19:03.541: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:19:03.543
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:03.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:03.577
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Feb 13 14:19:03.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 create -f -'
    Feb 13 14:19:04.252: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:19:04.252: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Feb 13 14:19:04.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 create -f -'
    Feb 13 14:19:04.508: INFO: stderr: ""
    Feb 13 14:19:04.508: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 02/13/23 14:19:04.508
    Feb 13 14:19:05.513: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:19:05.513: INFO: Found 1 / 1
    Feb 13 14:19:05.513: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Feb 13 14:19:05.516: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:19:05.516: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Feb 13 14:19:05.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe pod agnhost-primary-qs797'
    Feb 13 14:19:05.639: INFO: stderr: ""
    Feb 13 14:19:05.639: INFO: stdout: "Name:             agnhost-primary-qs797\nNamespace:        kubectl-2500\nPriority:         0\nService Account:  default\nNode:             conformance-5500-0ccfa5-pool-bf9f-o7jrw/192.168.1.11\nStart Time:       Mon, 13 Feb 2023 14:19:04 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.0.41\nIPs:\n  IP:           10.244.0.41\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://49abebaa41bcea808e11c9c1de439329205056cf6c458d1a548e9a3cd72b8dcb\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 13 Feb 2023 14:19:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-cfdzj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-cfdzj:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-2500/agnhost-primary-qs797 to conformance-5500-0ccfa5-pool-bf9f-o7jrw\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Feb 13 14:19:05.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe rc agnhost-primary'
    Feb 13 14:19:05.756: INFO: stderr: ""
    Feb 13 14:19:05.756: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2500\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-qs797\n"
    Feb 13 14:19:05.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe service agnhost-primary'
    Feb 13 14:19:05.848: INFO: stderr: ""
    Feb 13 14:19:05.848: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2500\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.104.193.4\nIPs:               10.104.193.4\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.0.41:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Feb 13 14:19:05.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe node conformance-5500-0ccfa5-pool-bf9f-myudo'
    Feb 13 14:19:05.987: INFO: stderr: ""
    Feb 13 14:19:05.987: INFO: stdout: "Name:               conformance-5500-0ccfa5-pool-bf9f-myudo\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=g4s.kube.medium\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=conformance-5500-0ccfa5-pool-bf9f-myudo\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=g4s.kube.medium\n                    region=\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"csi.civo.com\":\"a15fe799-1665-4142-8dc2-78bd4ab7dba3\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"c2:4a:9d:83:77:a8\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.12\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 Feb 2023 13:01:08 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  conformance-5500-0ccfa5-pool-bf9f-myudo\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 13 Feb 2023 14:19:03 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 13 Feb 2023 13:01:33 +0000   Mon, 13 Feb 2023 13:01:33 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 13 Feb 2023 14:14:19 +0000   Mon, 13 Feb 2023 13:01:29 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.12\n  Hostname:    conformance-5500-0ccfa5-pool-bf9f-myudo\nCapacity:\n  cpu:                2\n  ephemeral-storage:  48288732Ki\n  hugepages-2Mi:      0\n  memory:             3807324Ki\n  pods:               110\nAllocatable:\n  cpu:                1950m\n  ephemeral-storage:  44234459882\n  hugepages-2Mi:      0\n  memory:             3508316Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 d7042be5dd2d299d340d71209da95bad\n  System UUID:                b22d410c-1b47-572f-bffc-63b39d2feb4c\n  Boot ID:                    d60c68d3-04d7-4693-8980-a38dd8ba754b\n  Kernel Version:             5.15.83-talos\n  OS Image:                   Talos (v1.2.8)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.12\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      10.244.1.0/24\nPodCIDRs:                     10.244.1.0/24\nProviderID:                   civo://a15fe799-1665-4142-8dc2-78bd4ab7dba3\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                         ------------  ----------  ---------------  -------------  ---\n  kube-system                 civo-ccm-69cdbdd6c5-5h8vx    0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 civo-csi-controller-0        0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 civo-csi-node-ggrnh          0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 coredns-584d5df445-c4zbq     100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     78m\n  kube-system                 coredns-584d5df445-fgktn     100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     78m\n  kube-system                 konnectivity-agent-xsjnx     0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 kube-flannel-gwjn2           0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                 kube-proxy-mffzd             0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                200m (10%)  0 (0%)\n  memory             140Mi (4%)  340Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    Feb 13 14:19:05.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-2500 describe namespace kubectl-2500'
    Feb 13 14:19:06.067: INFO: stderr: ""
    Feb 13 14:19:06.067: INFO: stdout: "Name:         kubectl-2500\nLabels:       e2e-framework=kubectl\n              e2e-run=8a5a0cb0-4dbb-4dde-8847-35c08d716de3\n              kubernetes.io/metadata.name=kubectl-2500\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:19:06.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2500" for this suite. 02/13/23 14:19:06.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:06.082
Feb 13 14:19:06.083: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:19:06.085
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:06.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:06.103
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:19:06.106
W0213 14:19:06.119431      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:19:06.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb" in namespace "projected-464" to be "Succeeded or Failed"
Feb 13 14:19:06.129: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379647ms
Feb 13 14:19:08.134: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01496429s
Feb 13 14:19:10.136: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01660396s
STEP: Saw pod success 02/13/23 14:19:10.136
Feb 13 14:19:10.137: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb" satisfied condition "Succeeded or Failed"
Feb 13 14:19:10.142: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb container client-container: <nil>
STEP: delete the pod 02/13/23 14:19:10.166
Feb 13 14:19:10.181: INFO: Waiting for pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb to disappear
Feb 13 14:19:10.185: INFO: Pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:19:10.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-464" for this suite. 02/13/23 14:19:10.189
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":234,"skipped":4436,"failed":0}
------------------------------
• [4.112 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:06.082
    Feb 13 14:19:06.083: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:19:06.085
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:06.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:06.103
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:19:06.106
    W0213 14:19:06.119431      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:19:06.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb" in namespace "projected-464" to be "Succeeded or Failed"
    Feb 13 14:19:06.129: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379647ms
    Feb 13 14:19:08.134: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01496429s
    Feb 13 14:19:10.136: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01660396s
    STEP: Saw pod success 02/13/23 14:19:10.136
    Feb 13 14:19:10.137: INFO: Pod "downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb" satisfied condition "Succeeded or Failed"
    Feb 13 14:19:10.142: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb container client-container: <nil>
    STEP: delete the pod 02/13/23 14:19:10.166
    Feb 13 14:19:10.181: INFO: Waiting for pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb to disappear
    Feb 13 14:19:10.185: INFO: Pod downwardapi-volume-1211b48d-d466-412f-baf5-5b61227ccbdb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:19:10.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-464" for this suite. 02/13/23 14:19:10.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:10.199
Feb 13 14:19:10.200: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 14:19:10.201
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:10.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:10.218
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 02/13/23 14:19:10.221
W0213 14:19:10.230859      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:19:10.231: INFO: Waiting up to 5m0s for pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08" in namespace "var-expansion-5789" to be "Succeeded or Failed"
Feb 13 14:19:10.234: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324004ms
Feb 13 14:19:12.238: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007724817s
Feb 13 14:19:14.238: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007718497s
STEP: Saw pod success 02/13/23 14:19:14.239
Feb 13 14:19:14.239: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08" satisfied condition "Succeeded or Failed"
Feb 13 14:19:14.242: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 container dapi-container: <nil>
STEP: delete the pod 02/13/23 14:19:14.254
Feb 13 14:19:14.265: INFO: Waiting for pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 to disappear
Feb 13 14:19:14.268: INFO: Pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 14:19:14.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5789" for this suite. 02/13/23 14:19:14.272
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":235,"skipped":4448,"failed":0}
------------------------------
• [4.079 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:10.199
    Feb 13 14:19:10.200: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 14:19:10.201
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:10.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:10.218
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 02/13/23 14:19:10.221
    W0213 14:19:10.230859      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:19:10.231: INFO: Waiting up to 5m0s for pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08" in namespace "var-expansion-5789" to be "Succeeded or Failed"
    Feb 13 14:19:10.234: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324004ms
    Feb 13 14:19:12.238: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007724817s
    Feb 13 14:19:14.238: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007718497s
    STEP: Saw pod success 02/13/23 14:19:14.239
    Feb 13 14:19:14.239: INFO: Pod "var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08" satisfied condition "Succeeded or Failed"
    Feb 13 14:19:14.242: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 container dapi-container: <nil>
    STEP: delete the pod 02/13/23 14:19:14.254
    Feb 13 14:19:14.265: INFO: Waiting for pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 to disappear
    Feb 13 14:19:14.268: INFO: Pod var-expansion-2ce64372-4391-4709-ae1d-ff96af4e8c08 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 14:19:14.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5789" for this suite. 02/13/23 14:19:14.272
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:14.281
Feb 13 14:19:14.282: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pods 02/13/23 14:19:14.283
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:14.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:14.306
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 02/13/23 14:19:14.31
Feb 13 14:19:14.321: INFO: created test-pod-1
Feb 13 14:19:14.333: INFO: created test-pod-2
Feb 13 14:19:14.347: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 02/13/23 14:19:14.347
Feb 13 14:19:14.347: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-9224' to be running and ready
Feb 13 14:19:14.363: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Feb 13 14:19:14.363: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Feb 13 14:19:14.363: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Feb 13 14:19:14.363: INFO: 0 / 3 pods in namespace 'pods-9224' are running and ready (0 seconds elapsed)
Feb 13 14:19:14.363: INFO: expected 0 pod replicas in namespace 'pods-9224', 0 are Running and Ready.
Feb 13 14:19:14.363: INFO: POD         NODE                                     PHASE    GRACE  CONDITIONS
Feb 13 14:19:14.363: INFO: test-pod-1  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
Feb 13 14:19:14.363: INFO: test-pod-2  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
Feb 13 14:19:14.363: INFO: test-pod-3  conformance-5500-0ccfa5-pool-bf9f-vfwrl  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
Feb 13 14:19:14.363: INFO: 
Feb 13 14:19:16.377: INFO: 3 / 3 pods in namespace 'pods-9224' are running and ready (2 seconds elapsed)
Feb 13 14:19:16.377: INFO: expected 0 pod replicas in namespace 'pods-9224', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 02/13/23 14:19:16.402
Feb 13 14:19:16.407: INFO: Pod quantity 3 is different from expected quantity 0
Feb 13 14:19:17.415: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Feb 13 14:19:18.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9224" for this suite. 02/13/23 14:19:18.428
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":236,"skipped":4455,"failed":0}
------------------------------
• [4.154 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:14.281
    Feb 13 14:19:14.282: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pods 02/13/23 14:19:14.283
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:14.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:14.306
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 02/13/23 14:19:14.31
    Feb 13 14:19:14.321: INFO: created test-pod-1
    Feb 13 14:19:14.333: INFO: created test-pod-2
    Feb 13 14:19:14.347: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 02/13/23 14:19:14.347
    Feb 13 14:19:14.347: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-9224' to be running and ready
    Feb 13 14:19:14.363: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Feb 13 14:19:14.363: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Feb 13 14:19:14.363: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Feb 13 14:19:14.363: INFO: 0 / 3 pods in namespace 'pods-9224' are running and ready (0 seconds elapsed)
    Feb 13 14:19:14.363: INFO: expected 0 pod replicas in namespace 'pods-9224', 0 are Running and Ready.
    Feb 13 14:19:14.363: INFO: POD         NODE                                     PHASE    GRACE  CONDITIONS
    Feb 13 14:19:14.363: INFO: test-pod-1  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
    Feb 13 14:19:14.363: INFO: test-pod-2  conformance-5500-0ccfa5-pool-bf9f-o7jrw  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
    Feb 13 14:19:14.363: INFO: test-pod-3  conformance-5500-0ccfa5-pool-bf9f-vfwrl  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-02-13 14:19:14 +0000 UTC  }]
    Feb 13 14:19:14.363: INFO: 
    Feb 13 14:19:16.377: INFO: 3 / 3 pods in namespace 'pods-9224' are running and ready (2 seconds elapsed)
    Feb 13 14:19:16.377: INFO: expected 0 pod replicas in namespace 'pods-9224', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 02/13/23 14:19:16.402
    Feb 13 14:19:16.407: INFO: Pod quantity 3 is different from expected quantity 0
    Feb 13 14:19:17.415: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Feb 13 14:19:18.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9224" for this suite. 02/13/23 14:19:18.428
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:19:18.436
Feb 13 14:19:18.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename init-container 02/13/23 14:19:18.437
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:18.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:18.469
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 02/13/23 14:19:18.473
Feb 13 14:19:18.474: INFO: PodSpec: initContainers in spec.initContainers
W0213 14:19:18.489440      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:20:04.397: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-05cf82a8-351f-411f-b1fc-30e9211cd01d", GenerateName:"", Namespace:"init-container-130", SelfLink:"", UID:"c93f4a14-809c-48ab-a0e4-8def6d6f31b3", ResourceVersion:"25276", Generation:0, CreationTimestamp:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"474517721"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005316030), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.February, 13, 14, 20, 4, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005316060), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-cgwvc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00678bec0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0042c1e28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-5500-0ccfa5-pool-bf9f-o7jrw", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0066e9b20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0042c1ea0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0042c1ec0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0042c1ec8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0042c1ecc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004570f10), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.11", PodIP:"10.244.0.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.0.45"}}, StartTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0066e9c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0066e9c70)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f0a4fdb86270c4fa8998ce825896be3674fdb6fd1650cee5abc4c8c19f4251c0", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00678bf40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00678bf20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0042c1f4f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 14:20:04.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-130" for this suite. 02/13/23 14:20:04.402
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":237,"skipped":4460,"failed":0}
------------------------------
• [SLOW TEST] [45.973 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:19:18.436
    Feb 13 14:19:18.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename init-container 02/13/23 14:19:18.437
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:19:18.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:19:18.469
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 02/13/23 14:19:18.473
    Feb 13 14:19:18.474: INFO: PodSpec: initContainers in spec.initContainers
    W0213 14:19:18.489440      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:20:04.397: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-05cf82a8-351f-411f-b1fc-30e9211cd01d", GenerateName:"", Namespace:"init-container-130", SelfLink:"", UID:"c93f4a14-809c-48ab-a0e4-8def6d6f31b3", ResourceVersion:"25276", Generation:0, CreationTimestamp:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"474517721"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005316030), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.February, 13, 14, 20, 4, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005316060), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-cgwvc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00678bec0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cgwvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0042c1e28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-5500-0ccfa5-pool-bf9f-o7jrw", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0066e9b20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0042c1ea0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0042c1ec0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0042c1ec8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0042c1ecc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc004570f10), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.11", PodIP:"10.244.0.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.0.45"}}, StartTime:time.Date(2023, time.February, 13, 14, 19, 18, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0066e9c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0066e9c70)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f0a4fdb86270c4fa8998ce825896be3674fdb6fd1650cee5abc4c8c19f4251c0", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00678bf40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00678bf20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0042c1f4f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 14:20:04.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-130" for this suite. 02/13/23 14:20:04.402
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:04.41
Feb 13 14:20:04.410: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:20:04.412
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:04.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:04.433
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:20:04.45
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:20:05.04
STEP: Deploying the webhook pod 02/13/23 14:20:05.052
W0213 14:20:05.065478      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:20:05.065
Feb 13 14:20:05.076: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:20:07.097
STEP: Verifying the service has paired with the endpoint 02/13/23 14:20:07.119
Feb 13 14:20:08.121: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 02/13/23 14:20:08.125
STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.154
STEP: Updating a validating webhook configuration's rules to not include the create operation 02/13/23 14:20:08.174
STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.186
STEP: Patching a validating webhook configuration's rules to include the create operation 02/13/23 14:20:08.198
STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.209
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:20:08.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7193" for this suite. 02/13/23 14:20:08.23
STEP: Destroying namespace "webhook-7193-markers" for this suite. 02/13/23 14:20:08.236
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":238,"skipped":4461,"failed":0}
------------------------------
• [3.881 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:04.41
    Feb 13 14:20:04.410: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:20:04.412
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:04.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:04.433
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:20:04.45
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:20:05.04
    STEP: Deploying the webhook pod 02/13/23 14:20:05.052
    W0213 14:20:05.065478      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:20:05.065
    Feb 13 14:20:05.076: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:20:07.097
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:20:07.119
    Feb 13 14:20:08.121: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 02/13/23 14:20:08.125
    STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.154
    STEP: Updating a validating webhook configuration's rules to not include the create operation 02/13/23 14:20:08.174
    STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.186
    STEP: Patching a validating webhook configuration's rules to include the create operation 02/13/23 14:20:08.198
    STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:08.209
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:20:08.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7193" for this suite. 02/13/23 14:20:08.23
    STEP: Destroying namespace "webhook-7193-markers" for this suite. 02/13/23 14:20:08.236
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:08.291
Feb 13 14:20:08.291: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename watch 02/13/23 14:20:08.292
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:08.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:08.334
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 02/13/23 14:20:08.342
STEP: starting a background goroutine to produce watch events 02/13/23 14:20:08.349
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 02/13/23 14:20:08.349
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Feb 13 14:20:11.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4668" for this suite. 02/13/23 14:20:11.149
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":239,"skipped":4467,"failed":0}
------------------------------
• [2.915 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:08.291
    Feb 13 14:20:08.291: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename watch 02/13/23 14:20:08.292
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:08.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:08.334
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 02/13/23 14:20:08.342
    STEP: starting a background goroutine to produce watch events 02/13/23 14:20:08.349
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 02/13/23 14:20:08.349
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Feb 13 14:20:11.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4668" for this suite. 02/13/23 14:20:11.149
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:11.208
Feb 13 14:20:11.208: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:20:11.209
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:11.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:11.238
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 02/13/23 14:20:11.242
STEP: Creating a ResourceQuota 02/13/23 14:20:16.25
STEP: Ensuring resource quota status is calculated 02/13/23 14:20:16.267
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:20:18.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3459" for this suite. 02/13/23 14:20:18.278
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":240,"skipped":4470,"failed":0}
------------------------------
• [SLOW TEST] [7.078 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:11.208
    Feb 13 14:20:11.208: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:20:11.209
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:11.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:11.238
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 02/13/23 14:20:11.242
    STEP: Creating a ResourceQuota 02/13/23 14:20:16.25
    STEP: Ensuring resource quota status is calculated 02/13/23 14:20:16.267
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:20:18.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3459" for this suite. 02/13/23 14:20:18.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:18.288
Feb 13 14:20:18.288: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:20:18.29
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:18.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:18.315
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:20:18.332
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:20:18.591
STEP: Deploying the webhook pod 02/13/23 14:20:18.601
W0213 14:20:18.617842      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:20:18.618
Feb 13 14:20:18.630: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:20:20.645
STEP: Verifying the service has paired with the endpoint 02/13/23 14:20:20.668
Feb 13 14:20:21.669: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 02/13/23 14:20:21.753
STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:21.806
STEP: Deleting the collection of validation webhooks 02/13/23 14:20:21.865
STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:21.906
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:20:21.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6318" for this suite. 02/13/23 14:20:21.921
STEP: Destroying namespace "webhook-6318-markers" for this suite. 02/13/23 14:20:21.931
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":241,"skipped":4478,"failed":0}
------------------------------
• [3.686 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:18.288
    Feb 13 14:20:18.288: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:20:18.29
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:18.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:18.315
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:20:18.332
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:20:18.591
    STEP: Deploying the webhook pod 02/13/23 14:20:18.601
    W0213 14:20:18.617842      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:20:18.618
    Feb 13 14:20:18.630: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:20:20.645
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:20:20.668
    Feb 13 14:20:21.669: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 02/13/23 14:20:21.753
    STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:21.806
    STEP: Deleting the collection of validation webhooks 02/13/23 14:20:21.865
    STEP: Creating a configMap that does not comply to the validation webhook rules 02/13/23 14:20:21.906
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:20:21.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6318" for this suite. 02/13/23 14:20:21.921
    STEP: Destroying namespace "webhook-6318-markers" for this suite. 02/13/23 14:20:21.931
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:21.979
Feb 13 14:20:21.979: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:20:21.981
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:21.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:21.997
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 02/13/23 14:20:22.001
W0213 14:20:22.010928      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:20:22.011: INFO: Waiting up to 5m0s for pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1" in namespace "projected-3303" to be "running and ready"
Feb 13 14:20:22.014: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.566631ms
Feb 13 14:20:22.014: INFO: The phase of Pod labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:20:24.021: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010158413s
Feb 13 14:20:24.021: INFO: The phase of Pod labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1 is Running (Ready = true)
Feb 13 14:20:24.021: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1" satisfied condition "running and ready"
Feb 13 14:20:24.554: INFO: Successfully updated pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:20:28.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3303" for this suite. 02/13/23 14:20:28.592
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":242,"skipped":4479,"failed":0}
------------------------------
• [SLOW TEST] [6.623 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:21.979
    Feb 13 14:20:21.979: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:20:21.981
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:21.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:21.997
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 02/13/23 14:20:22.001
    W0213 14:20:22.010928      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:20:22.011: INFO: Waiting up to 5m0s for pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1" in namespace "projected-3303" to be "running and ready"
    Feb 13 14:20:22.014: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.566631ms
    Feb 13 14:20:22.014: INFO: The phase of Pod labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:20:24.021: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010158413s
    Feb 13 14:20:24.021: INFO: The phase of Pod labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1 is Running (Ready = true)
    Feb 13 14:20:24.021: INFO: Pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1" satisfied condition "running and ready"
    Feb 13 14:20:24.554: INFO: Successfully updated pod "labelsupdate520cf40b-be0d-41f9-8eca-6c6325343ff1"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:20:28.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3303" for this suite. 02/13/23 14:20:28.592
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:28.603
Feb 13 14:20:28.603: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 14:20:28.604
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:28.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:28.622
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 02/13/23 14:20:28.626
W0213 14:20:28.635181      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:20:28.635: INFO: Waiting up to 5m0s for pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b" in namespace "emptydir-3796" to be "Succeeded or Failed"
Feb 13 14:20:28.638: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320181ms
Feb 13 14:20:30.644: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008711279s
Feb 13 14:20:32.644: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009299938s
STEP: Saw pod success 02/13/23 14:20:32.644
Feb 13 14:20:32.645: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b" satisfied condition "Succeeded or Failed"
Feb 13 14:20:32.650: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b container test-container: <nil>
STEP: delete the pod 02/13/23 14:20:32.661
Feb 13 14:20:32.675: INFO: Waiting for pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b to disappear
Feb 13 14:20:32.679: INFO: Pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 14:20:32.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3796" for this suite. 02/13/23 14:20:32.685
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":243,"skipped":4482,"failed":0}
------------------------------
• [4.088 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:28.603
    Feb 13 14:20:28.603: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 14:20:28.604
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:28.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:28.622
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 02/13/23 14:20:28.626
    W0213 14:20:28.635181      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:20:28.635: INFO: Waiting up to 5m0s for pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b" in namespace "emptydir-3796" to be "Succeeded or Failed"
    Feb 13 14:20:28.638: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320181ms
    Feb 13 14:20:30.644: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008711279s
    Feb 13 14:20:32.644: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009299938s
    STEP: Saw pod success 02/13/23 14:20:32.644
    Feb 13 14:20:32.645: INFO: Pod "pod-e0f85d07-3426-4b84-a699-2010e5e0f21b" satisfied condition "Succeeded or Failed"
    Feb 13 14:20:32.650: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b container test-container: <nil>
    STEP: delete the pod 02/13/23 14:20:32.661
    Feb 13 14:20:32.675: INFO: Waiting for pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b to disappear
    Feb 13 14:20:32.679: INFO: Pod pod-e0f85d07-3426-4b84-a699-2010e5e0f21b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:20:32.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3796" for this suite. 02/13/23 14:20:32.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:32.699
Feb 13 14:20:32.699: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:20:32.702
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:32.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:32.726
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-caf22e2d-0a0c-4af5-b863-3ceedb12edb0 02/13/23 14:20:32.733
STEP: Creating secret with name s-test-opt-upd-38860ef6-b9ff-44e2-8060-7270428f941a 02/13/23 14:20:32.738
STEP: Creating the pod 02/13/23 14:20:32.743
W0213 14:20:32.753748      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:20:32.754: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f" in namespace "projected-1847" to be "running and ready"
Feb 13 14:20:32.765: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.578795ms
Feb 13 14:20:32.765: INFO: The phase of Pod pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:20:34.772: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f": Phase="Running", Reason="", readiness=true. Elapsed: 2.017801893s
Feb 13 14:20:34.772: INFO: The phase of Pod pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f is Running (Ready = true)
Feb 13 14:20:34.772: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-caf22e2d-0a0c-4af5-b863-3ceedb12edb0 02/13/23 14:20:34.81
STEP: Updating secret s-test-opt-upd-38860ef6-b9ff-44e2-8060-7270428f941a 02/13/23 14:20:34.818
STEP: Creating secret with name s-test-opt-create-98fc6de6-eb5a-4c85-a0d9-bc4c94525b82 02/13/23 14:20:34.825
STEP: waiting to observe update in volume 02/13/23 14:20:34.832
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Feb 13 14:20:36.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1847" for this suite. 02/13/23 14:20:36.88
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":244,"skipped":4493,"failed":0}
------------------------------
• [4.187 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:32.699
    Feb 13 14:20:32.699: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:20:32.702
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:32.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:32.726
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-caf22e2d-0a0c-4af5-b863-3ceedb12edb0 02/13/23 14:20:32.733
    STEP: Creating secret with name s-test-opt-upd-38860ef6-b9ff-44e2-8060-7270428f941a 02/13/23 14:20:32.738
    STEP: Creating the pod 02/13/23 14:20:32.743
    W0213 14:20:32.753748      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:20:32.754: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f" in namespace "projected-1847" to be "running and ready"
    Feb 13 14:20:32.765: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.578795ms
    Feb 13 14:20:32.765: INFO: The phase of Pod pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:20:34.772: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f": Phase="Running", Reason="", readiness=true. Elapsed: 2.017801893s
    Feb 13 14:20:34.772: INFO: The phase of Pod pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f is Running (Ready = true)
    Feb 13 14:20:34.772: INFO: Pod "pod-projected-secrets-aab16e85-8913-4c80-a1d2-53594410043f" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-caf22e2d-0a0c-4af5-b863-3ceedb12edb0 02/13/23 14:20:34.81
    STEP: Updating secret s-test-opt-upd-38860ef6-b9ff-44e2-8060-7270428f941a 02/13/23 14:20:34.818
    STEP: Creating secret with name s-test-opt-create-98fc6de6-eb5a-4c85-a0d9-bc4c94525b82 02/13/23 14:20:34.825
    STEP: waiting to observe update in volume 02/13/23 14:20:34.832
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Feb 13 14:20:36.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1847" for this suite. 02/13/23 14:20:36.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:36.891
Feb 13 14:20:36.891: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename watch 02/13/23 14:20:36.892
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:36.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:36.911
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 02/13/23 14:20:36.914
STEP: creating a new configmap 02/13/23 14:20:36.915
STEP: modifying the configmap once 02/13/23 14:20:36.92
STEP: changing the label value of the configmap 02/13/23 14:20:36.928
STEP: Expecting to observe a delete notification for the watched object 02/13/23 14:20:36.937
Feb 13 14:20:36.937: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25692 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:20:36.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25693 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:20:36.938: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25694 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 02/13/23 14:20:36.938
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 02/13/23 14:20:36.946
STEP: changing the label value of the configmap back 02/13/23 14:20:46.947
STEP: modifying the configmap a third time 02/13/23 14:20:46.958
STEP: deleting the configmap 02/13/23 14:20:46.968
STEP: Expecting to observe an add notification for the watched object when the label value was restored 02/13/23 14:20:46.974
Feb 13 14:20:46.974: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25745 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:20:46.974: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25746 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:20:46.975: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25747 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Feb 13 14:20:46.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1349" for this suite. 02/13/23 14:20:46.979
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":245,"skipped":4519,"failed":0}
------------------------------
• [SLOW TEST] [10.094 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:36.891
    Feb 13 14:20:36.891: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename watch 02/13/23 14:20:36.892
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:36.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:36.911
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 02/13/23 14:20:36.914
    STEP: creating a new configmap 02/13/23 14:20:36.915
    STEP: modifying the configmap once 02/13/23 14:20:36.92
    STEP: changing the label value of the configmap 02/13/23 14:20:36.928
    STEP: Expecting to observe a delete notification for the watched object 02/13/23 14:20:36.937
    Feb 13 14:20:36.937: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25692 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:20:36.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25693 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:20:36.938: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25694 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 02/13/23 14:20:36.938
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 02/13/23 14:20:36.946
    STEP: changing the label value of the configmap back 02/13/23 14:20:46.947
    STEP: modifying the configmap a third time 02/13/23 14:20:46.958
    STEP: deleting the configmap 02/13/23 14:20:46.968
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 02/13/23 14:20:46.974
    Feb 13 14:20:46.974: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25745 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:20:46.974: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25746 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:20:46.975: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1349  2b14e02d-59da-4ede-b7de-dd3bbafda0e6 25747 0 2023-02-13 14:20:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-02-13 14:20:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Feb 13 14:20:46.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1349" for this suite. 02/13/23 14:20:46.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:46.995
Feb 13 14:20:46.995: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:20:46.996
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:47.013
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:47.016
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 02/13/23 14:20:47.02
Feb 13 14:20:47.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 create -f -'
Feb 13 14:20:47.290: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:20:47.290: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 14:20:47.29
Feb 13 14:20:47.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 14:20:47.405: INFO: stderr: ""
Feb 13 14:20:47.405: INFO: stdout: "update-demo-nautilus-8w8mk update-demo-nautilus-bdqch "
Feb 13 14:20:47.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 14:20:47.515: INFO: stderr: ""
Feb 13 14:20:47.515: INFO: stdout: ""
Feb 13 14:20:47.515: INFO: update-demo-nautilus-8w8mk is created but not running
Feb 13 14:20:52.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Feb 13 14:20:52.607: INFO: stderr: ""
Feb 13 14:20:52.607: INFO: stdout: "update-demo-nautilus-8w8mk update-demo-nautilus-bdqch "
Feb 13 14:20:52.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 14:20:52.703: INFO: stderr: ""
Feb 13 14:20:52.703: INFO: stdout: "true"
Feb 13 14:20:52.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 14:20:52.807: INFO: stderr: ""
Feb 13 14:20:52.808: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 14:20:52.808: INFO: validating pod update-demo-nautilus-8w8mk
Feb 13 14:20:52.850: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:20:52.850: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:20:52.850: INFO: update-demo-nautilus-8w8mk is verified up and running
Feb 13 14:20:52.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-bdqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Feb 13 14:20:52.962: INFO: stderr: ""
Feb 13 14:20:52.962: INFO: stdout: "true"
Feb 13 14:20:52.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-bdqch -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Feb 13 14:20:53.066: INFO: stderr: ""
Feb 13 14:20:53.066: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Feb 13 14:20:53.066: INFO: validating pod update-demo-nautilus-bdqch
Feb 13 14:20:53.077: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:20:53.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:20:53.077: INFO: update-demo-nautilus-bdqch is verified up and running
STEP: using delete to clean up resources 02/13/23 14:20:53.077
Feb 13 14:20:53.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 delete --grace-period=0 --force -f -'
Feb 13 14:20:53.179: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 14:20:53.180: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 14:20:53.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get rc,svc -l name=update-demo --no-headers'
Feb 13 14:20:53.324: INFO: stderr: "No resources found in kubectl-3330 namespace.\n"
Feb 13 14:20:53.324: INFO: stdout: ""
Feb 13 14:20:53.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 14:20:53.430: INFO: stderr: ""
Feb 13 14:20:53.430: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:20:53.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3330" for this suite. 02/13/23 14:20:53.437
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":246,"skipped":4531,"failed":0}
------------------------------
• [SLOW TEST] [6.455 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:46.995
    Feb 13 14:20:46.995: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:20:46.996
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:47.013
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:47.016
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 02/13/23 14:20:47.02
    Feb 13 14:20:47.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 create -f -'
    Feb 13 14:20:47.290: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:20:47.290: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 02/13/23 14:20:47.29
    Feb 13 14:20:47.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 14:20:47.405: INFO: stderr: ""
    Feb 13 14:20:47.405: INFO: stdout: "update-demo-nautilus-8w8mk update-demo-nautilus-bdqch "
    Feb 13 14:20:47.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 14:20:47.515: INFO: stderr: ""
    Feb 13 14:20:47.515: INFO: stdout: ""
    Feb 13 14:20:47.515: INFO: update-demo-nautilus-8w8mk is created but not running
    Feb 13 14:20:52.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Feb 13 14:20:52.607: INFO: stderr: ""
    Feb 13 14:20:52.607: INFO: stdout: "update-demo-nautilus-8w8mk update-demo-nautilus-bdqch "
    Feb 13 14:20:52.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 14:20:52.703: INFO: stderr: ""
    Feb 13 14:20:52.703: INFO: stdout: "true"
    Feb 13 14:20:52.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-8w8mk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 14:20:52.807: INFO: stderr: ""
    Feb 13 14:20:52.808: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 14:20:52.808: INFO: validating pod update-demo-nautilus-8w8mk
    Feb 13 14:20:52.850: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 14:20:52.850: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 14:20:52.850: INFO: update-demo-nautilus-8w8mk is verified up and running
    Feb 13 14:20:52.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-bdqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Feb 13 14:20:52.962: INFO: stderr: ""
    Feb 13 14:20:52.962: INFO: stdout: "true"
    Feb 13 14:20:52.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods update-demo-nautilus-bdqch -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Feb 13 14:20:53.066: INFO: stderr: ""
    Feb 13 14:20:53.066: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Feb 13 14:20:53.066: INFO: validating pod update-demo-nautilus-bdqch
    Feb 13 14:20:53.077: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Feb 13 14:20:53.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Feb 13 14:20:53.077: INFO: update-demo-nautilus-bdqch is verified up and running
    STEP: using delete to clean up resources 02/13/23 14:20:53.077
    Feb 13 14:20:53.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 delete --grace-period=0 --force -f -'
    Feb 13 14:20:53.179: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 14:20:53.180: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Feb 13 14:20:53.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get rc,svc -l name=update-demo --no-headers'
    Feb 13 14:20:53.324: INFO: stderr: "No resources found in kubectl-3330 namespace.\n"
    Feb 13 14:20:53.324: INFO: stdout: ""
    Feb 13 14:20:53.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-3330 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Feb 13 14:20:53.430: INFO: stderr: ""
    Feb 13 14:20:53.430: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:20:53.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3330" for this suite. 02/13/23 14:20:53.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:20:53.452
Feb 13 14:20:53.453: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 14:20:53.454
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:53.475
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:53.482
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d in namespace container-probe-6416 02/13/23 14:20:53.489
W0213 14:20:53.501175      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:20:53.501: INFO: Waiting up to 5m0s for pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d" in namespace "container-probe-6416" to be "not pending"
Feb 13 14:20:53.505: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.35144ms
Feb 13 14:20:55.512: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011482545s
Feb 13 14:20:55.512: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d" satisfied condition "not pending"
Feb 13 14:20:55.512: INFO: Started pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d in namespace container-probe-6416
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:20:55.512
Feb 13 14:20:55.518: INFO: Initial restart count of pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d is 0
STEP: deleting the pod 02/13/23 14:24:56.372
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 14:24:56.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6416" for this suite. 02/13/23 14:24:56.396
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":247,"skipped":4556,"failed":0}
------------------------------
• [SLOW TEST] [242.952 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:20:53.452
    Feb 13 14:20:53.453: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 14:20:53.454
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:20:53.475
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:20:53.482
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d in namespace container-probe-6416 02/13/23 14:20:53.489
    W0213 14:20:53.501175      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:20:53.501: INFO: Waiting up to 5m0s for pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d" in namespace "container-probe-6416" to be "not pending"
    Feb 13 14:20:53.505: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.35144ms
    Feb 13 14:20:55.512: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011482545s
    Feb 13 14:20:55.512: INFO: Pod "liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d" satisfied condition "not pending"
    Feb 13 14:20:55.512: INFO: Started pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d in namespace container-probe-6416
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:20:55.512
    Feb 13 14:20:55.518: INFO: Initial restart count of pod liveness-1428de62-36ec-4ea1-b149-60d6ef731d8d is 0
    STEP: deleting the pod 02/13/23 14:24:56.372
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 14:24:56.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6416" for this suite. 02/13/23 14:24:56.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:24:56.407
Feb 13 14:24:56.408: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context-test 02/13/23 14:24:56.411
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:24:56.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:24:56.437
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
W0213 14:24:56.452713      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:24:56.453: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" in namespace "security-context-test-1471" to be "Succeeded or Failed"
Feb 13 14:24:56.459: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507128ms
Feb 13 14:24:58.464: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011391751s
Feb 13 14:25:00.468: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014778917s
Feb 13 14:25:00.468: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" satisfied condition "Succeeded or Failed"
Feb 13 14:25:00.504: INFO: Got logs for pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 14:25:00.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1471" for this suite. 02/13/23 14:25:00.509
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":248,"skipped":4568,"failed":0}
------------------------------
• [4.110 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:24:56.407
    Feb 13 14:24:56.408: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context-test 02/13/23 14:24:56.411
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:24:56.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:24:56.437
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    W0213 14:24:56.452713      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:24:56.453: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" in namespace "security-context-test-1471" to be "Succeeded or Failed"
    Feb 13 14:24:56.459: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507128ms
    Feb 13 14:24:58.464: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011391751s
    Feb 13 14:25:00.468: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014778917s
    Feb 13 14:25:00.468: INFO: Pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723" satisfied condition "Succeeded or Failed"
    Feb 13 14:25:00.504: INFO: Got logs for pod "busybox-privileged-false-2fcf3619-7967-4065-90be-c21353490723": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 14:25:00.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1471" for this suite. 02/13/23 14:25:00.509
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:25:00.518
Feb 13 14:25:00.518: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:25:00.52
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:00.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:00.543
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-1644 02/13/23 14:25:00.547
W0213 14:25:00.557822      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:00.558: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1644" to be "running and ready"
Feb 13 14:25:00.562: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.994624ms
Feb 13 14:25:00.562: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:25:02.568: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.010458398s
Feb 13 14:25:02.568: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Feb 13 14:25:02.568: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Feb 13 14:25:02.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Feb 13 14:25:02.803: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Feb 13 14:25:02.803: INFO: stdout: "iptables"
Feb 13 14:25:02.803: INFO: proxyMode: iptables
Feb 13 14:25:02.819: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Feb 13 14:25:02.826: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-1644 02/13/23 14:25:02.826
STEP: creating replication controller affinity-nodeport-timeout in namespace services-1644 02/13/23 14:25:02.849
W0213 14:25:02.860325      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport-timeout" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport-timeout" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport-timeout" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport-timeout" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:25:02.861814      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1644, replica count: 3
I0213 14:25:05.913017      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:25:05.930: INFO: Creating new exec pod
W0213 14:25:05.940564      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:05.941: INFO: Waiting up to 5m0s for pod "execpod-affinity82mlf" in namespace "services-1644" to be "running"
Feb 13 14:25:05.944: INFO: Pod "execpod-affinity82mlf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782603ms
Feb 13 14:25:07.953: INFO: Pod "execpod-affinity82mlf": Phase="Running", Reason="", readiness=true. Elapsed: 2.011905627s
Feb 13 14:25:07.953: INFO: Pod "execpod-affinity82mlf" satisfied condition "running"
Feb 13 14:25:08.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Feb 13 14:25:09.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Feb 13 14:25:09.259: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:25:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.3.30 80'
Feb 13 14:25:09.529: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.103.3.30 80\nConnection to 10.103.3.30 80 port [tcp/http] succeeded!\n"
Feb 13 14:25:09.529: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:25:09.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 31612'
Feb 13 14:25:09.813: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 31612\nConnection to 192.168.1.12 31612 port [tcp/*] succeeded!\n"
Feb 13 14:25:09.813: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:25:09.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 31612'
Feb 13 14:25:10.075: INFO: stderr: "+ echo+ nc -v -t -w 2 192.168.1.11 31612\n hostName\nConnection to 192.168.1.11 31612 port [tcp/*] succeeded!\n"
Feb 13 14:25:10.075: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:25:10.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:31612/ ; done'
Feb 13 14:25:10.484: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
Feb 13 14:25:10.484: INFO: stdout: "\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx"
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
Feb 13 14:25:10.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
Feb 13 14:25:10.762: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
Feb 13 14:25:10.762: INFO: stdout: "affinity-nodeport-timeout-9swsx"
Feb 13 14:25:30.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
Feb 13 14:25:31.019: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
Feb 13 14:25:31.019: INFO: stdout: "affinity-nodeport-timeout-9swsx"
Feb 13 14:25:51.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
Feb 13 14:25:51.270: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
Feb 13 14:25:51.271: INFO: stdout: "affinity-nodeport-timeout-lgdzp"
Feb 13 14:25:51.271: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1644, will wait for the garbage collector to delete the pods 02/13/23 14:25:51.288
Feb 13 14:25:51.349: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.264603ms
Feb 13 14:25:51.450: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.964101ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:25:53.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1644" for this suite. 02/13/23 14:25:53.673
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":249,"skipped":4569,"failed":0}
------------------------------
• [SLOW TEST] [53.160 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:25:00.518
    Feb 13 14:25:00.518: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:25:00.52
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:00.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:00.543
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-1644 02/13/23 14:25:00.547
    W0213 14:25:00.557822      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:00.558: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1644" to be "running and ready"
    Feb 13 14:25:00.562: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.994624ms
    Feb 13 14:25:00.562: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:25:02.568: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.010458398s
    Feb 13 14:25:02.568: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Feb 13 14:25:02.568: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Feb 13 14:25:02.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Feb 13 14:25:02.803: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Feb 13 14:25:02.803: INFO: stdout: "iptables"
    Feb 13 14:25:02.803: INFO: proxyMode: iptables
    Feb 13 14:25:02.819: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Feb 13 14:25:02.826: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-1644 02/13/23 14:25:02.826
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-1644 02/13/23 14:25:02.849
    W0213 14:25:02.860325      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport-timeout" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport-timeout" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport-timeout" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport-timeout" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:25:02.861814      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1644, replica count: 3
    I0213 14:25:05.913017      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:25:05.930: INFO: Creating new exec pod
    W0213 14:25:05.940564      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:05.941: INFO: Waiting up to 5m0s for pod "execpod-affinity82mlf" in namespace "services-1644" to be "running"
    Feb 13 14:25:05.944: INFO: Pod "execpod-affinity82mlf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782603ms
    Feb 13 14:25:07.953: INFO: Pod "execpod-affinity82mlf": Phase="Running", Reason="", readiness=true. Elapsed: 2.011905627s
    Feb 13 14:25:07.953: INFO: Pod "execpod-affinity82mlf" satisfied condition "running"
    Feb 13 14:25:08.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Feb 13 14:25:09.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Feb 13 14:25:09.259: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:25:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.3.30 80'
    Feb 13 14:25:09.529: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.103.3.30 80\nConnection to 10.103.3.30 80 port [tcp/http] succeeded!\n"
    Feb 13 14:25:09.529: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:25:09.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.12 31612'
    Feb 13 14:25:09.813: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.12 31612\nConnection to 192.168.1.12 31612 port [tcp/*] succeeded!\n"
    Feb 13 14:25:09.813: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:25:09.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.11 31612'
    Feb 13 14:25:10.075: INFO: stderr: "+ echo+ nc -v -t -w 2 192.168.1.11 31612\n hostName\nConnection to 192.168.1.11 31612 port [tcp/*] succeeded!\n"
    Feb 13 14:25:10.075: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:25:10.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.12:31612/ ; done'
    Feb 13 14:25:10.484: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
    Feb 13 14:25:10.484: INFO: stdout: "\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx\naffinity-nodeport-timeout-9swsx"
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Received response from host: affinity-nodeport-timeout-9swsx
    Feb 13 14:25:10.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
    Feb 13 14:25:10.762: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
    Feb 13 14:25:10.762: INFO: stdout: "affinity-nodeport-timeout-9swsx"
    Feb 13 14:25:30.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
    Feb 13 14:25:31.019: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
    Feb 13 14:25:31.019: INFO: stdout: "affinity-nodeport-timeout-9swsx"
    Feb 13 14:25:51.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-1644 exec execpod-affinity82mlf -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.12:31612/'
    Feb 13 14:25:51.270: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.12:31612/\n"
    Feb 13 14:25:51.271: INFO: stdout: "affinity-nodeport-timeout-lgdzp"
    Feb 13 14:25:51.271: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1644, will wait for the garbage collector to delete the pods 02/13/23 14:25:51.288
    Feb 13 14:25:51.349: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.264603ms
    Feb 13 14:25:51.450: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.964101ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:25:53.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1644" for this suite. 02/13/23 14:25:53.673
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:25:53.681
Feb 13 14:25:53.681: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:25:53.682
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:53.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:53.698
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
W0213 14:25:53.716040      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.716: INFO: created pod pod-service-account-defaultsa
Feb 13 14:25:53.716: INFO: pod pod-service-account-defaultsa service account token volume mount: true
W0213 14:25:53.723432      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.723: INFO: created pod pod-service-account-mountsa
Feb 13 14:25:53.723: INFO: pod pod-service-account-mountsa service account token volume mount: true
W0213 14:25:53.732595      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.733: INFO: created pod pod-service-account-nomountsa
Feb 13 14:25:53.733: INFO: pod pod-service-account-nomountsa service account token volume mount: false
W0213 14:25:53.739150      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.739: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 13 14:25:53.739: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
W0213 14:25:53.749209      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.749: INFO: created pod pod-service-account-mountsa-mountspec
Feb 13 14:25:53.749: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
W0213 14:25:53.768169      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.768: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 13 14:25:53.768: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
W0213 14:25:53.780909      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.781: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 13 14:25:53.781: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
W0213 14:25:53.797327      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.797: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 13 14:25:53.799: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
W0213 14:25:53.805974      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.806: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 13 14:25:53.806: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 14:25:53.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4231" for this suite. 02/13/23 14:25:53.812
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":250,"skipped":4593,"failed":0}
------------------------------
• [0.136 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:25:53.681
    Feb 13 14:25:53.681: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:25:53.682
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:53.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:53.698
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    W0213 14:25:53.716040      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.716: INFO: created pod pod-service-account-defaultsa
    Feb 13 14:25:53.716: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    W0213 14:25:53.723432      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.723: INFO: created pod pod-service-account-mountsa
    Feb 13 14:25:53.723: INFO: pod pod-service-account-mountsa service account token volume mount: true
    W0213 14:25:53.732595      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.733: INFO: created pod pod-service-account-nomountsa
    Feb 13 14:25:53.733: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    W0213 14:25:53.739150      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.739: INFO: created pod pod-service-account-defaultsa-mountspec
    Feb 13 14:25:53.739: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    W0213 14:25:53.749209      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.749: INFO: created pod pod-service-account-mountsa-mountspec
    Feb 13 14:25:53.749: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    W0213 14:25:53.768169      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.768: INFO: created pod pod-service-account-nomountsa-mountspec
    Feb 13 14:25:53.768: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    W0213 14:25:53.780909      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.781: INFO: created pod pod-service-account-defaultsa-nomountspec
    Feb 13 14:25:53.781: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    W0213 14:25:53.797327      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.797: INFO: created pod pod-service-account-mountsa-nomountspec
    Feb 13 14:25:53.799: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    W0213 14:25:53.805974      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.806: INFO: created pod pod-service-account-nomountsa-nomountspec
    Feb 13 14:25:53.806: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 14:25:53.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4231" for this suite. 02/13/23 14:25:53.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:25:53.82
Feb 13 14:25:53.820: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:25:53.822
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:53.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:53.839
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-5739 02/13/23 14:25:53.843
STEP: creating a selector 02/13/23 14:25:53.844
STEP: Creating the service pods in kubernetes 02/13/23 14:25:53.844
Feb 13 14:25:53.844: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
W0213 14:25:53.863981      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:25:53.873461      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:25:53.882198      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:25:53.882: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5739" to be "running and ready"
Feb 13 14:25:53.885: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.987133ms
Feb 13 14:25:53.885: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:25:55.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.0108812s
Feb 13 14:25:55.893: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:25:57.892: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.009680505s
Feb 13 14:25:57.892: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:25:59.892: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.010092853s
Feb 13 14:25:59.892: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:26:01.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.0107264s
Feb 13 14:26:01.893: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:26:03.891: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.008671095s
Feb 13 14:26:03.891: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:26:05.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.011296758s
Feb 13 14:26:05.893: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Feb 13 14:26:05.893: INFO: Pod "netserver-0" satisfied condition "running and ready"
Feb 13 14:26:05.901: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5739" to be "running and ready"
Feb 13 14:26:05.907: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.616757ms
Feb 13 14:26:05.907: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Feb 13 14:26:05.907: INFO: Pod "netserver-1" satisfied condition "running and ready"
Feb 13 14:26:05.913: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5739" to be "running and ready"
Feb 13 14:26:05.919: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.357252ms
Feb 13 14:26:05.919: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Feb 13 14:26:05.919: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 02/13/23 14:26:05.924
W0213 14:26:05.935739      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:26:05.948013      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:05.948: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5739" to be "running"
Feb 13 14:26:05.954: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.875579ms
Feb 13 14:26:07.961: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013733949s
Feb 13 14:26:07.961: INFO: Pod "test-container-pod" satisfied condition "running"
Feb 13 14:26:07.967: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5739" to be "running"
Feb 13 14:26:07.973: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.317727ms
Feb 13 14:26:07.973: INFO: Pod "host-test-container-pod" satisfied condition "running"
Feb 13 14:26:07.978: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Feb 13 14:26:07.978: INFO: Going to poll 10.244.1.153 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:26:07.983: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.153 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:26:07.983: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:26:07.985: INFO: ExecWithOptions: Clientset creation
Feb 13 14:26:07.985: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.153+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:26:09.139: INFO: Found all 1 expected endpoints: [netserver-0]
Feb 13 14:26:09.140: INFO: Going to poll 10.244.0.56 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:26:09.148: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.56 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:26:09.148: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:26:09.149: INFO: ExecWithOptions: Clientset creation
Feb 13 14:26:09.149: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.56+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:26:10.321: INFO: Found all 1 expected endpoints: [netserver-1]
Feb 13 14:26:10.321: INFO: Going to poll 10.244.2.214 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:26:10.327: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.214 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:26:10.327: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:26:10.329: INFO: ExecWithOptions: Clientset creation
Feb 13 14:26:10.330: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.2.214+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:26:11.545: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Feb 13 14:26:11.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5739" for this suite. 02/13/23 14:26:11.553
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":251,"skipped":4603,"failed":0}
------------------------------
• [SLOW TEST] [17.741 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:25:53.82
    Feb 13 14:25:53.820: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:25:53.822
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:25:53.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:25:53.839
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-5739 02/13/23 14:25:53.843
    STEP: creating a selector 02/13/23 14:25:53.844
    STEP: Creating the service pods in kubernetes 02/13/23 14:25:53.844
    Feb 13 14:25:53.844: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    W0213 14:25:53.863981      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:25:53.873461      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:25:53.882198      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:25:53.882: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5739" to be "running and ready"
    Feb 13 14:25:53.885: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.987133ms
    Feb 13 14:25:53.885: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:25:55.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.0108812s
    Feb 13 14:25:55.893: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:25:57.892: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.009680505s
    Feb 13 14:25:57.892: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:25:59.892: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.010092853s
    Feb 13 14:25:59.892: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:26:01.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.0107264s
    Feb 13 14:26:01.893: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:26:03.891: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.008671095s
    Feb 13 14:26:03.891: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:26:05.893: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.011296758s
    Feb 13 14:26:05.893: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Feb 13 14:26:05.893: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Feb 13 14:26:05.901: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5739" to be "running and ready"
    Feb 13 14:26:05.907: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.616757ms
    Feb 13 14:26:05.907: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Feb 13 14:26:05.907: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Feb 13 14:26:05.913: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5739" to be "running and ready"
    Feb 13 14:26:05.919: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.357252ms
    Feb 13 14:26:05.919: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Feb 13 14:26:05.919: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 02/13/23 14:26:05.924
    W0213 14:26:05.935739      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:26:05.948013      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:05.948: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5739" to be "running"
    Feb 13 14:26:05.954: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.875579ms
    Feb 13 14:26:07.961: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013733949s
    Feb 13 14:26:07.961: INFO: Pod "test-container-pod" satisfied condition "running"
    Feb 13 14:26:07.967: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5739" to be "running"
    Feb 13 14:26:07.973: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.317727ms
    Feb 13 14:26:07.973: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Feb 13 14:26:07.978: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Feb 13 14:26:07.978: INFO: Going to poll 10.244.1.153 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:26:07.983: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.153 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:26:07.983: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:26:07.985: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:26:07.985: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.153+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:26:09.139: INFO: Found all 1 expected endpoints: [netserver-0]
    Feb 13 14:26:09.140: INFO: Going to poll 10.244.0.56 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:26:09.148: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.56 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:26:09.148: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:26:09.149: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:26:09.149: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.56+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:26:10.321: INFO: Found all 1 expected endpoints: [netserver-1]
    Feb 13 14:26:10.321: INFO: Going to poll 10.244.2.214 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:26:10.327: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.214 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5739 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:26:10.327: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:26:10.329: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:26:10.330: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5739/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.2.214+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:26:11.545: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Feb 13 14:26:11.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5739" for this suite. 02/13/23 14:26:11.553
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:11.578
Feb 13 14:26:11.579: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:26:11.58
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:11.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:11.603
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 02/13/23 14:26:11.609
STEP: Creating a ResourceQuota 02/13/23 14:26:16.622
STEP: Ensuring resource quota status is calculated 02/13/23 14:26:16.63
STEP: Creating a Service 02/13/23 14:26:18.636
STEP: Creating a NodePort Service 02/13/23 14:26:18.666
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 02/13/23 14:26:18.693
STEP: Ensuring resource quota status captures service creation 02/13/23 14:26:18.722
STEP: Deleting Services 02/13/23 14:26:20.732
STEP: Ensuring resource quota status released usage 02/13/23 14:26:20.779
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:26:22.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3580" for this suite. 02/13/23 14:26:22.791
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":252,"skipped":4648,"failed":0}
------------------------------
• [SLOW TEST] [11.220 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:11.578
    Feb 13 14:26:11.579: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:26:11.58
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:11.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:11.603
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 02/13/23 14:26:11.609
    STEP: Creating a ResourceQuota 02/13/23 14:26:16.622
    STEP: Ensuring resource quota status is calculated 02/13/23 14:26:16.63
    STEP: Creating a Service 02/13/23 14:26:18.636
    STEP: Creating a NodePort Service 02/13/23 14:26:18.666
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 02/13/23 14:26:18.693
    STEP: Ensuring resource quota status captures service creation 02/13/23 14:26:18.722
    STEP: Deleting Services 02/13/23 14:26:20.732
    STEP: Ensuring resource quota status released usage 02/13/23 14:26:20.779
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:26:22.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3580" for this suite. 02/13/23 14:26:22.791
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:22.799
Feb 13 14:26:22.799: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:26:22.801
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:22.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:22.823
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:26:22.828
W0213 14:26:22.836683      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:22.837: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc" in namespace "projected-1489" to be "Succeeded or Failed"
Feb 13 14:26:22.840: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167772ms
Feb 13 14:26:24.846: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009890106s
Feb 13 14:26:26.845: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008845402s
STEP: Saw pod success 02/13/23 14:26:26.846
Feb 13 14:26:26.846: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc" satisfied condition "Succeeded or Failed"
Feb 13 14:26:26.855: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc container client-container: <nil>
STEP: delete the pod 02/13/23 14:26:26.866
Feb 13 14:26:26.878: INFO: Waiting for pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc to disappear
Feb 13 14:26:26.880: INFO: Pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:26:26.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1489" for this suite. 02/13/23 14:26:26.886
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":253,"skipped":4648,"failed":0}
------------------------------
• [4.094 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:22.799
    Feb 13 14:26:22.799: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:26:22.801
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:22.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:22.823
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:26:22.828
    W0213 14:26:22.836683      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:22.837: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc" in namespace "projected-1489" to be "Succeeded or Failed"
    Feb 13 14:26:22.840: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167772ms
    Feb 13 14:26:24.846: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009890106s
    Feb 13 14:26:26.845: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008845402s
    STEP: Saw pod success 02/13/23 14:26:26.846
    Feb 13 14:26:26.846: INFO: Pod "downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc" satisfied condition "Succeeded or Failed"
    Feb 13 14:26:26.855: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc container client-container: <nil>
    STEP: delete the pod 02/13/23 14:26:26.866
    Feb 13 14:26:26.878: INFO: Waiting for pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc to disappear
    Feb 13 14:26:26.880: INFO: Pod downwardapi-volume-8784f48e-f75a-4bfa-8875-50672bd21ffc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:26:26.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1489" for this suite. 02/13/23 14:26:26.886
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:26.894
Feb 13 14:26:26.895: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:26:26.897
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:26.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:26.917
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
W0213 14:26:26.933752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:26.934: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" in namespace "kubelet-test-8910" to be "running and ready"
Feb 13 14:26:26.938: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.122426ms
Feb 13 14:26:26.938: INFO: The phase of Pod busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:26:28.946: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01191849s
Feb 13 14:26:28.946: INFO: The phase of Pod busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c is Running (Ready = true)
Feb 13 14:26:28.946: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Feb 13 14:26:28.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8910" for this suite. 02/13/23 14:26:28.996
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":254,"skipped":4650,"failed":0}
------------------------------
• [2.110 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:26.894
    Feb 13 14:26:26.895: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:26:26.897
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:26.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:26.917
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    W0213 14:26:26.933752      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:26.934: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" in namespace "kubelet-test-8910" to be "running and ready"
    Feb 13 14:26:26.938: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.122426ms
    Feb 13 14:26:26.938: INFO: The phase of Pod busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:26:28.946: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01191849s
    Feb 13 14:26:28.946: INFO: The phase of Pod busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c is Running (Ready = true)
    Feb 13 14:26:28.946: INFO: Pod "busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Feb 13 14:26:28.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8910" for this suite. 02/13/23 14:26:28.996
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:29.027
Feb 13 14:26:29.027: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 14:26:29.029
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:29.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:29.056
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 02/13/23 14:26:29.06
W0213 14:26:29.065919      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:29.068: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 13 14:26:34.073: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 02/13/23 14:26:34.073
STEP: getting scale subresource 02/13/23 14:26:34.073
STEP: updating a scale subresource 02/13/23 14:26:34.079
STEP: verifying the replicaset Spec.Replicas was modified 02/13/23 14:26:34.086
STEP: Patch a scale subresource 02/13/23 14:26:34.089
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 14:26:34.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9770" for this suite. 02/13/23 14:26:34.11
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":255,"skipped":4671,"failed":0}
------------------------------
• [SLOW TEST] [5.094 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:29.027
    Feb 13 14:26:29.027: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 14:26:29.029
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:29.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:29.056
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 02/13/23 14:26:29.06
    W0213 14:26:29.065919      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:29.068: INFO: Pod name sample-pod: Found 0 pods out of 1
    Feb 13 14:26:34.073: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 02/13/23 14:26:34.073
    STEP: getting scale subresource 02/13/23 14:26:34.073
    STEP: updating a scale subresource 02/13/23 14:26:34.079
    STEP: verifying the replicaset Spec.Replicas was modified 02/13/23 14:26:34.086
    STEP: Patch a scale subresource 02/13/23 14:26:34.089
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 14:26:34.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9770" for this suite. 02/13/23 14:26:34.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:34.123
Feb 13 14:26:34.123: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:26:34.124
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.15
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 02/13/23 14:26:34.163
STEP: watching for the Service to be added 02/13/23 14:26:34.181
Feb 13 14:26:34.183: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Feb 13 14:26:34.184: INFO: Service test-service-cpv5d created
STEP: Getting /status 02/13/23 14:26:34.184
Feb 13 14:26:34.192: INFO: Service test-service-cpv5d has LoadBalancer: {[]}
STEP: patching the ServiceStatus 02/13/23 14:26:34.193
STEP: watching for the Service to be patched 02/13/23 14:26:34.208
Feb 13 14:26:34.212: INFO: observed Service test-service-cpv5d in namespace services-2487 with annotations: map[] & LoadBalancer: {[]}
Feb 13 14:26:34.212: INFO: Found Service test-service-cpv5d in namespace services-2487 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Feb 13 14:26:34.212: INFO: Service test-service-cpv5d has service status patched
STEP: updating the ServiceStatus 02/13/23 14:26:34.212
Feb 13 14:26:34.222: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 02/13/23 14:26:34.222
Feb 13 14:26:34.225: INFO: Observed Service test-service-cpv5d in namespace services-2487 with annotations: map[] & Conditions: {[]}
Feb 13 14:26:34.225: INFO: Observed event: &Service{ObjectMeta:{test-service-cpv5d  services-2487  4b13d250-e237-46b1-9774-79c70ec6f436 26930 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.101.191.113,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.101.191.113],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Feb 13 14:26:34.226: INFO: Found Service test-service-cpv5d in namespace services-2487 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Feb 13 14:26:34.226: INFO: Service test-service-cpv5d has service status updated
STEP: patching the service 02/13/23 14:26:34.226
STEP: watching for the Service to be patched 02/13/23 14:26:34.239
Feb 13 14:26:34.242: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
Feb 13 14:26:34.243: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
Feb 13 14:26:34.243: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
Feb 13 14:26:34.243: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service:patched test-service-static:true]
Feb 13 14:26:34.244: INFO: Service test-service-cpv5d patched
STEP: deleting the service 02/13/23 14:26:34.244
STEP: watching for the Service to be deleted 02/13/23 14:26:34.258
Feb 13 14:26:34.261: INFO: Observed event: ADDED
Feb 13 14:26:34.261: INFO: Observed event: MODIFIED
Feb 13 14:26:34.261: INFO: Observed event: MODIFIED
Feb 13 14:26:34.262: INFO: Observed event: MODIFIED
Feb 13 14:26:34.262: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Feb 13 14:26:34.262: INFO: Service test-service-cpv5d deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:26:34.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2487" for this suite. 02/13/23 14:26:34.265
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":256,"skipped":4681,"failed":0}
------------------------------
• [0.147 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:34.123
    Feb 13 14:26:34.123: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:26:34.124
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.15
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 02/13/23 14:26:34.163
    STEP: watching for the Service to be added 02/13/23 14:26:34.181
    Feb 13 14:26:34.183: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Feb 13 14:26:34.184: INFO: Service test-service-cpv5d created
    STEP: Getting /status 02/13/23 14:26:34.184
    Feb 13 14:26:34.192: INFO: Service test-service-cpv5d has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 02/13/23 14:26:34.193
    STEP: watching for the Service to be patched 02/13/23 14:26:34.208
    Feb 13 14:26:34.212: INFO: observed Service test-service-cpv5d in namespace services-2487 with annotations: map[] & LoadBalancer: {[]}
    Feb 13 14:26:34.212: INFO: Found Service test-service-cpv5d in namespace services-2487 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Feb 13 14:26:34.212: INFO: Service test-service-cpv5d has service status patched
    STEP: updating the ServiceStatus 02/13/23 14:26:34.212
    Feb 13 14:26:34.222: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 02/13/23 14:26:34.222
    Feb 13 14:26:34.225: INFO: Observed Service test-service-cpv5d in namespace services-2487 with annotations: map[] & Conditions: {[]}
    Feb 13 14:26:34.225: INFO: Observed event: &Service{ObjectMeta:{test-service-cpv5d  services-2487  4b13d250-e237-46b1-9774-79c70ec6f436 26930 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.101.191.113,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.101.191.113],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Feb 13 14:26:34.226: INFO: Found Service test-service-cpv5d in namespace services-2487 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Feb 13 14:26:34.226: INFO: Service test-service-cpv5d has service status updated
    STEP: patching the service 02/13/23 14:26:34.226
    STEP: watching for the Service to be patched 02/13/23 14:26:34.239
    Feb 13 14:26:34.242: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
    Feb 13 14:26:34.243: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
    Feb 13 14:26:34.243: INFO: observed Service test-service-cpv5d in namespace services-2487 with labels: map[test-service-static:true]
    Feb 13 14:26:34.243: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service:patched test-service-static:true]
    Feb 13 14:26:34.244: INFO: Service test-service-cpv5d patched
    STEP: deleting the service 02/13/23 14:26:34.244
    STEP: watching for the Service to be deleted 02/13/23 14:26:34.258
    Feb 13 14:26:34.261: INFO: Observed event: ADDED
    Feb 13 14:26:34.261: INFO: Observed event: MODIFIED
    Feb 13 14:26:34.261: INFO: Observed event: MODIFIED
    Feb 13 14:26:34.262: INFO: Observed event: MODIFIED
    Feb 13 14:26:34.262: INFO: Found Service test-service-cpv5d in namespace services-2487 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Feb 13 14:26:34.262: INFO: Service test-service-cpv5d deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:26:34.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2487" for this suite. 02/13/23 14:26:34.265
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:34.279
Feb 13 14:26:34.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename podtemplate 02/13/23 14:26:34.28
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.312
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 02/13/23 14:26:34.317
W0213 14:26:34.326090      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:34.326: INFO: created test-podtemplate-1
W0213 14:26:34.333496      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:34.333: INFO: created test-podtemplate-2
W0213 14:26:34.339158      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:34.339: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 02/13/23 14:26:34.339
STEP: delete collection of pod templates 02/13/23 14:26:34.343
Feb 13 14:26:34.344: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 02/13/23 14:26:34.356
Feb 13 14:26:34.356: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Feb 13 14:26:34.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5221" for this suite. 02/13/23 14:26:34.365
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":257,"skipped":4707,"failed":0}
------------------------------
• [0.092 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:34.279
    Feb 13 14:26:34.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename podtemplate 02/13/23 14:26:34.28
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.312
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 02/13/23 14:26:34.317
    W0213 14:26:34.326090      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:34.326: INFO: created test-podtemplate-1
    W0213 14:26:34.333496      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:34.333: INFO: created test-podtemplate-2
    W0213 14:26:34.339158      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:34.339: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 02/13/23 14:26:34.339
    STEP: delete collection of pod templates 02/13/23 14:26:34.343
    Feb 13 14:26:34.344: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 02/13/23 14:26:34.356
    Feb 13 14:26:34.356: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Feb 13 14:26:34.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5221" for this suite. 02/13/23 14:26:34.365
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:34.373
Feb 13 14:26:34.374: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename watch 02/13/23 14:26:34.376
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.399
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 02/13/23 14:26:34.404
STEP: creating a new configmap 02/13/23 14:26:34.406
STEP: modifying the configmap once 02/13/23 14:26:34.412
STEP: closing the watch once it receives two notifications 02/13/23 14:26:34.421
Feb 13 14:26:34.422: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26950 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:26:34.423: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26951 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 02/13/23 14:26:34.424
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 02/13/23 14:26:34.435
STEP: deleting the configmap 02/13/23 14:26:34.438
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 02/13/23 14:26:34.445
Feb 13 14:26:34.445: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26952 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 13 14:26:34.446: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26953 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Feb 13 14:26:34.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6720" for this suite. 02/13/23 14:26:34.453
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":258,"skipped":4716,"failed":0}
------------------------------
• [0.086 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:34.373
    Feb 13 14:26:34.374: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename watch 02/13/23 14:26:34.376
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.399
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 02/13/23 14:26:34.404
    STEP: creating a new configmap 02/13/23 14:26:34.406
    STEP: modifying the configmap once 02/13/23 14:26:34.412
    STEP: closing the watch once it receives two notifications 02/13/23 14:26:34.421
    Feb 13 14:26:34.422: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26950 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:26:34.423: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26951 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 02/13/23 14:26:34.424
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 02/13/23 14:26:34.435
    STEP: deleting the configmap 02/13/23 14:26:34.438
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 02/13/23 14:26:34.445
    Feb 13 14:26:34.445: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26952 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Feb 13 14:26:34.446: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6720  f3197ea8-6428-4440-a237-eeb3b677abbe 26953 0 2023-02-13 14:26:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-02-13 14:26:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Feb 13 14:26:34.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6720" for this suite. 02/13/23 14:26:34.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:26:34.462
Feb 13 14:26:34.462: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-pred 02/13/23 14:26:34.464
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.48
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Feb 13 14:26:34.484: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:26:34.490: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:26:34.495: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
Feb 13 14:26:34.506: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container civo-ccm ready: true, restart count 0
Feb 13 14:26:34.506: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:26:34.506: INFO: 	Container csi-attacher ready: true, restart count 0
Feb 13 14:26:34.506: INFO: 	Container csi-provisioner ready: true, restart count 0
Feb 13 14:26:34.506: INFO: 	Container csi-resizer ready: true, restart count 0
Feb 13 14:26:34.506: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:26:34.506: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:26:34.506: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:26:34.506: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container coredns ready: true, restart count 0
Feb 13 14:26:34.506: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:26:34.506: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:26:34.506: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.506: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:26:34.506: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
Feb 13 14:26:34.512: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:26:34.513: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:26:34.513: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:26:34.513: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:26:34.513: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:26:34.513: INFO: test-rs-lw9xp from replicaset-9770 started at 2023-02-13 14:26:29 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container httpd ready: true, restart count 0
Feb 13 14:26:34.513: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:26:34.513: INFO: pod-service-account-defaultsa from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.513: INFO: 	Container token-test ready: false, restart count 0
Feb 13 14:26:34.514: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.514: INFO: 	Container token-test ready: false, restart count 0
Feb 13 14:26:34.514: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.514: INFO: 	Container token-test ready: false, restart count 0
Feb 13 14:26:34.514: INFO: 
Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
Feb 13 14:26:34.520: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container civo-csi-plugin ready: true, restart count 0
Feb 13 14:26:34.520: INFO: 	Container csi-driver-registrar ready: true, restart count 0
Feb 13 14:26:34.520: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container konnectivity-agent ready: true, restart count 0
Feb 13 14:26:34.520: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 13 14:26:34.520: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 14:26:34.520: INFO: busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c from kubelet-test-8910 started at 2023-02-13 14:26:26 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c ready: true, restart count 0
Feb 13 14:26:34.520: INFO: test-rs-8rvq8 from replicaset-9770 started at 2023-02-13 14:26:34 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.520: INFO: 	Container httpd ready: false, restart count 0
Feb 13 14:26:34.520: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
Feb 13 14:26:34.521: INFO: 	Container e2e ready: true, restart count 0
Feb 13 14:26:34.521: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 14:26:34.521: INFO: pod-service-account-mountsa from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.521: INFO: 	Container token-test ready: false, restart count 0
Feb 13 14:26:34.521: INFO: pod-service-account-mountsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
Feb 13 14:26:34.521: INFO: 	Container token-test ready: false, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 14:26:34.521
Feb 13 14:26:34.529: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9041" to be "running"
Feb 13 14:26:34.531: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716516ms
Feb 13 14:26:36.540: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.010930578s
Feb 13 14:26:36.540: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 14:26:36.547
STEP: Trying to apply a random label on the found node. 02/13/23 14:26:36.571
STEP: verifying the node has the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 95 02/13/23 14:26:36.589
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 02/13/23 14:26:36.594
W0213 14:26:36.603065      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:36.603: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9041" to be "not pending"
Feb 13 14:26:36.609: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.368849ms
Feb 13 14:26:38.615: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012065072s
Feb 13 14:26:38.615: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.1.11 on the node which pod4 resides and expect not scheduled 02/13/23 14:26:38.616
W0213 14:26:38.626708      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:26:38.627: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9041" to be "not pending"
Feb 13 14:26:38.633: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970512ms
Feb 13 14:26:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01380594s
Feb 13 14:26:42.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013865085s
Feb 13 14:26:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01315058s
Feb 13 14:26:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013276557s
Feb 13 14:26:48.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016338809s
Feb 13 14:26:50.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014844571s
Feb 13 14:26:52.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.013076756s
Feb 13 14:26:54.637: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010627493s
Feb 13 14:26:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.012904656s
Feb 13 14:26:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012934588s
Feb 13 14:27:00.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014611282s
Feb 13 14:27:02.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014769362s
Feb 13 14:27:04.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.012621895s
Feb 13 14:27:06.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013025347s
Feb 13 14:27:08.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011589989s
Feb 13 14:27:10.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015968826s
Feb 13 14:27:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013643034s
Feb 13 14:27:14.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.012194249s
Feb 13 14:27:16.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011357438s
Feb 13 14:27:18.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.011891149s
Feb 13 14:27:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013438768s
Feb 13 14:27:22.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012294359s
Feb 13 14:27:24.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.01266794s
Feb 13 14:27:26.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.011718592s
Feb 13 14:27:28.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014916428s
Feb 13 14:27:30.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.015135835s
Feb 13 14:27:32.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013170477s
Feb 13 14:27:34.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.012703654s
Feb 13 14:27:36.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013189971s
Feb 13 14:27:38.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013311018s
Feb 13 14:27:40.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015461611s
Feb 13 14:27:42.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.014858629s
Feb 13 14:27:44.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014273668s
Feb 13 14:27:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013099265s
Feb 13 14:27:48.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014011256s
Feb 13 14:27:50.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.012706739s
Feb 13 14:27:52.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013907561s
Feb 13 14:27:54.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014374061s
Feb 13 14:27:56.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015242471s
Feb 13 14:27:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013257075s
Feb 13 14:28:00.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015936188s
Feb 13 14:28:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012491247s
Feb 13 14:28:04.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012677738s
Feb 13 14:28:06.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.012825555s
Feb 13 14:28:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.014294414s
Feb 13 14:28:10.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013306847s
Feb 13 14:28:12.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.012389209s
Feb 13 14:28:14.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.01300549s
Feb 13 14:28:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012838668s
Feb 13 14:28:18.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.014075618s
Feb 13 14:28:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.013420165s
Feb 13 14:28:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013628386s
Feb 13 14:28:24.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.011507137s
Feb 13 14:28:26.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015009435s
Feb 13 14:28:28.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.014091622s
Feb 13 14:28:30.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013177422s
Feb 13 14:28:32.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011533211s
Feb 13 14:28:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.01448689s
Feb 13 14:28:36.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.011685396s
Feb 13 14:28:38.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.012538692s
Feb 13 14:28:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.013651719s
Feb 13 14:28:42.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.01248187s
Feb 13 14:28:44.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014387371s
Feb 13 14:28:46.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.014279904s
Feb 13 14:28:48.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.012485903s
Feb 13 14:28:50.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.012931234s
Feb 13 14:28:52.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.013957487s
Feb 13 14:28:54.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.01287411s
Feb 13 14:28:56.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.014149984s
Feb 13 14:28:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.013508373s
Feb 13 14:29:00.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.014588035s
Feb 13 14:29:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.01288789s
Feb 13 14:29:04.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.011436169s
Feb 13 14:29:06.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.012817411s
Feb 13 14:29:08.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.012494227s
Feb 13 14:29:10.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.014328233s
Feb 13 14:29:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.01324556s
Feb 13 14:29:14.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013461738s
Feb 13 14:29:16.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.013352728s
Feb 13 14:29:18.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.013506867s
Feb 13 14:29:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.01361528s
Feb 13 14:29:22.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015628634s
Feb 13 14:29:24.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.013963385s
Feb 13 14:29:26.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.012160259s
Feb 13 14:29:28.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014274734s
Feb 13 14:29:30.644: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017440651s
Feb 13 14:29:32.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.011530352s
Feb 13 14:29:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.014857141s
Feb 13 14:29:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.012439349s
Feb 13 14:29:38.644: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.017434585s
Feb 13 14:29:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.013299508s
Feb 13 14:29:42.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.013513363s
Feb 13 14:29:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.013076281s
Feb 13 14:29:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.013579148s
Feb 13 14:29:48.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01292158s
Feb 13 14:29:50.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014601657s
Feb 13 14:29:52.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.012184599s
Feb 13 14:29:54.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.012347757s
Feb 13 14:29:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.013107591s
Feb 13 14:29:58.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.012633262s
Feb 13 14:30:00.637: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.010285592s
Feb 13 14:30:02.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.015195265s
Feb 13 14:30:04.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.014382401s
Feb 13 14:30:06.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013953735s
Feb 13 14:30:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.014612725s
Feb 13 14:30:10.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.013786896s
Feb 13 14:30:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.01357343s
Feb 13 14:30:14.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014596651s
Feb 13 14:30:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.012714954s
Feb 13 14:30:18.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.014520511s
Feb 13 14:30:20.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.015172835s
Feb 13 14:30:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.013575333s
Feb 13 14:30:24.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.011870978s
Feb 13 14:30:26.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.013385705s
Feb 13 14:30:28.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013496161s
Feb 13 14:30:30.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.015510351s
Feb 13 14:30:32.645: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.018741568s
Feb 13 14:30:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013975548s
Feb 13 14:30:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.012493686s
Feb 13 14:30:38.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.015365626s
Feb 13 14:30:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.013269776s
Feb 13 14:30:42.645: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.018302194s
Feb 13 14:30:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.013275414s
Feb 13 14:30:46.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.013996081s
Feb 13 14:30:48.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014366508s
Feb 13 14:30:50.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.011787208s
Feb 13 14:30:52.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.01271045s
Feb 13 14:30:54.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.011870805s
Feb 13 14:30:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013453392s
Feb 13 14:30:58.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.014264122s
Feb 13 14:31:00.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013345181s
Feb 13 14:31:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.011985782s
Feb 13 14:31:04.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014319568s
Feb 13 14:31:06.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.013129574s
Feb 13 14:31:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.014692751s
Feb 13 14:31:10.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014437277s
Feb 13 14:31:12.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.012628838s
Feb 13 14:31:14.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.014575306s
Feb 13 14:31:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.011946746s
Feb 13 14:31:18.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.012714173s
Feb 13 14:31:20.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.012114803s
Feb 13 14:31:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.013298335s
Feb 13 14:31:24.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.01221906s
Feb 13 14:31:26.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.012984024s
Feb 13 14:31:28.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.012314718s
Feb 13 14:31:30.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.012602714s
Feb 13 14:31:32.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.013035396s
Feb 13 14:31:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.014111207s
Feb 13 14:31:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.012453482s
Feb 13 14:31:38.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014136033s
Feb 13 14:31:38.648: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021537322s
STEP: removing the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:31:38.649
STEP: verifying the node doesn't have the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 02/13/23 14:31:38.665
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:31:38.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9041" for this suite. 02/13/23 14:31:38.677
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":259,"skipped":4723,"failed":0}
------------------------------
• [SLOW TEST] [304.222 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:26:34.462
    Feb 13 14:26:34.462: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-pred 02/13/23 14:26:34.464
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:26:34.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:26:34.48
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Feb 13 14:26:34.484: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Feb 13 14:26:34.490: INFO: Waiting for terminating namespaces to be deleted...
    Feb 13 14:26:34.495: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-myudo before test
    Feb 13 14:26:34.506: INFO: civo-ccm-69cdbdd6c5-5h8vx from kube-system started at 2023-02-13 13:01:29 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container civo-ccm ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: civo-csi-controller-0 from kube-system started at 2023-02-13 13:01:34 +0000 UTC (4 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: 	Container csi-attacher ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: 	Container csi-provisioner ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: 	Container csi-resizer ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: civo-csi-node-ggrnh from kube-system started at 2023-02-13 13:01:34 +0000 UTC (2 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: coredns-584d5df445-c4zbq from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: coredns-584d5df445-fgktn from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container coredns ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: konnectivity-agent-xsjnx from kube-system started at 2023-02-13 13:01:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: kube-flannel-gwjn2 from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: kube-proxy-mffzd from kube-system started at 2023-02-13 13:01:22 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.506: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:26:34.506: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-o7jrw before test
    Feb 13 14:26:34.512: INFO: civo-csi-node-kr4tf from kube-system started at 2023-02-13 13:46:42 +0000 UTC (2 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: konnectivity-agent-hbzh6 from kube-system started at 2023-02-13 13:46:44 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: kube-flannel-7phdp from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: kube-proxy-8rwqk from kube-system started at 2023-02-13 13:01:37 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: test-rs-lw9xp from replicaset-9770 started at 2023-02-13 14:26:29 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container httpd ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: sonobuoy from sonobuoy started at 2023-02-13 13:32:52 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Feb 13 14:26:34.513: INFO: pod-service-account-defaultsa from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.513: INFO: 	Container token-test ready: false, restart count 0
    Feb 13 14:26:34.514: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.514: INFO: 	Container token-test ready: false, restart count 0
    Feb 13 14:26:34.514: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.514: INFO: 	Container token-test ready: false, restart count 0
    Feb 13 14:26:34.514: INFO: 
    Logging pods the apiserver thinks is on node conformance-5500-0ccfa5-pool-bf9f-vfwrl before test
    Feb 13 14:26:34.520: INFO: civo-csi-node-kzhfv from kube-system started at 2023-02-13 13:02:16 +0000 UTC (2 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container civo-csi-plugin ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: 	Container csi-driver-registrar ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: konnectivity-agent-tzdhw from kube-system started at 2023-02-13 13:02:16 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: kube-flannel-vdl8c from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container kube-flannel ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: kube-proxy-v8znv from kube-system started at 2023-02-13 13:01:24 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container kube-proxy ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c from kubelet-test-8910 started at 2023-02-13 14:26:26 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container busybox-readonly-fsbf042e3b-e18d-47bd-a866-fd107d18436c ready: true, restart count 0
    Feb 13 14:26:34.520: INFO: test-rs-8rvq8 from replicaset-9770 started at 2023-02-13 14:26:34 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.520: INFO: 	Container httpd ready: false, restart count 0
    Feb 13 14:26:34.520: INFO: sonobuoy-e2e-job-43a812b6f8b849b0 from sonobuoy started at 2023-02-13 13:32:56 +0000 UTC (2 container statuses recorded)
    Feb 13 14:26:34.521: INFO: 	Container e2e ready: true, restart count 0
    Feb 13 14:26:34.521: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Feb 13 14:26:34.521: INFO: pod-service-account-mountsa from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.521: INFO: 	Container token-test ready: false, restart count 0
    Feb 13 14:26:34.521: INFO: pod-service-account-mountsa-mountspec from svcaccounts-4231 started at 2023-02-13 14:25:53 +0000 UTC (1 container statuses recorded)
    Feb 13 14:26:34.521: INFO: 	Container token-test ready: false, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 02/13/23 14:26:34.521
    Feb 13 14:26:34.529: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9041" to be "running"
    Feb 13 14:26:34.531: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716516ms
    Feb 13 14:26:36.540: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.010930578s
    Feb 13 14:26:36.540: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 02/13/23 14:26:36.547
    STEP: Trying to apply a random label on the found node. 02/13/23 14:26:36.571
    STEP: verifying the node has the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 95 02/13/23 14:26:36.589
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 02/13/23 14:26:36.594
    W0213 14:26:36.603065      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:36.603: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9041" to be "not pending"
    Feb 13 14:26:36.609: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.368849ms
    Feb 13 14:26:38.615: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012065072s
    Feb 13 14:26:38.615: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.1.11 on the node which pod4 resides and expect not scheduled 02/13/23 14:26:38.616
    W0213 14:26:38.626708      19 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:26:38.627: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9041" to be "not pending"
    Feb 13 14:26:38.633: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970512ms
    Feb 13 14:26:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01380594s
    Feb 13 14:26:42.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013865085s
    Feb 13 14:26:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01315058s
    Feb 13 14:26:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013276557s
    Feb 13 14:26:48.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016338809s
    Feb 13 14:26:50.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014844571s
    Feb 13 14:26:52.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.013076756s
    Feb 13 14:26:54.637: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010627493s
    Feb 13 14:26:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.012904656s
    Feb 13 14:26:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012934588s
    Feb 13 14:27:00.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014611282s
    Feb 13 14:27:02.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014769362s
    Feb 13 14:27:04.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.012621895s
    Feb 13 14:27:06.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013025347s
    Feb 13 14:27:08.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011589989s
    Feb 13 14:27:10.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015968826s
    Feb 13 14:27:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013643034s
    Feb 13 14:27:14.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.012194249s
    Feb 13 14:27:16.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011357438s
    Feb 13 14:27:18.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.011891149s
    Feb 13 14:27:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013438768s
    Feb 13 14:27:22.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012294359s
    Feb 13 14:27:24.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.01266794s
    Feb 13 14:27:26.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.011718592s
    Feb 13 14:27:28.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014916428s
    Feb 13 14:27:30.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.015135835s
    Feb 13 14:27:32.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013170477s
    Feb 13 14:27:34.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.012703654s
    Feb 13 14:27:36.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013189971s
    Feb 13 14:27:38.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013311018s
    Feb 13 14:27:40.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015461611s
    Feb 13 14:27:42.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.014858629s
    Feb 13 14:27:44.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014273668s
    Feb 13 14:27:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013099265s
    Feb 13 14:27:48.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014011256s
    Feb 13 14:27:50.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.012706739s
    Feb 13 14:27:52.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013907561s
    Feb 13 14:27:54.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014374061s
    Feb 13 14:27:56.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015242471s
    Feb 13 14:27:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013257075s
    Feb 13 14:28:00.643: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015936188s
    Feb 13 14:28:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012491247s
    Feb 13 14:28:04.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012677738s
    Feb 13 14:28:06.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.012825555s
    Feb 13 14:28:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.014294414s
    Feb 13 14:28:10.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013306847s
    Feb 13 14:28:12.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.012389209s
    Feb 13 14:28:14.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.01300549s
    Feb 13 14:28:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012838668s
    Feb 13 14:28:18.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.014075618s
    Feb 13 14:28:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.013420165s
    Feb 13 14:28:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013628386s
    Feb 13 14:28:24.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.011507137s
    Feb 13 14:28:26.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015009435s
    Feb 13 14:28:28.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.014091622s
    Feb 13 14:28:30.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013177422s
    Feb 13 14:28:32.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011533211s
    Feb 13 14:28:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.01448689s
    Feb 13 14:28:36.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.011685396s
    Feb 13 14:28:38.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.012538692s
    Feb 13 14:28:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.013651719s
    Feb 13 14:28:42.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.01248187s
    Feb 13 14:28:44.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014387371s
    Feb 13 14:28:46.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.014279904s
    Feb 13 14:28:48.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.012485903s
    Feb 13 14:28:50.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.012931234s
    Feb 13 14:28:52.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.013957487s
    Feb 13 14:28:54.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.01287411s
    Feb 13 14:28:56.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.014149984s
    Feb 13 14:28:58.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.013508373s
    Feb 13 14:29:00.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.014588035s
    Feb 13 14:29:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.01288789s
    Feb 13 14:29:04.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.011436169s
    Feb 13 14:29:06.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.012817411s
    Feb 13 14:29:08.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.012494227s
    Feb 13 14:29:10.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.014328233s
    Feb 13 14:29:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.01324556s
    Feb 13 14:29:14.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013461738s
    Feb 13 14:29:16.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.013352728s
    Feb 13 14:29:18.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.013506867s
    Feb 13 14:29:20.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.01361528s
    Feb 13 14:29:22.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015628634s
    Feb 13 14:29:24.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.013963385s
    Feb 13 14:29:26.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.012160259s
    Feb 13 14:29:28.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014274734s
    Feb 13 14:29:30.644: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017440651s
    Feb 13 14:29:32.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.011530352s
    Feb 13 14:29:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.014857141s
    Feb 13 14:29:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.012439349s
    Feb 13 14:29:38.644: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.017434585s
    Feb 13 14:29:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.013299508s
    Feb 13 14:29:42.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.013513363s
    Feb 13 14:29:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.013076281s
    Feb 13 14:29:46.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.013579148s
    Feb 13 14:29:48.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01292158s
    Feb 13 14:29:50.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014601657s
    Feb 13 14:29:52.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.012184599s
    Feb 13 14:29:54.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.012347757s
    Feb 13 14:29:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.013107591s
    Feb 13 14:29:58.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.012633262s
    Feb 13 14:30:00.637: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.010285592s
    Feb 13 14:30:02.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.015195265s
    Feb 13 14:30:04.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.014382401s
    Feb 13 14:30:06.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013953735s
    Feb 13 14:30:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.014612725s
    Feb 13 14:30:10.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.013786896s
    Feb 13 14:30:12.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.01357343s
    Feb 13 14:30:14.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014596651s
    Feb 13 14:30:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.012714954s
    Feb 13 14:30:18.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.014520511s
    Feb 13 14:30:20.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.015172835s
    Feb 13 14:30:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.013575333s
    Feb 13 14:30:24.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.011870978s
    Feb 13 14:30:26.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.013385705s
    Feb 13 14:30:28.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013496161s
    Feb 13 14:30:30.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.015510351s
    Feb 13 14:30:32.645: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.018741568s
    Feb 13 14:30:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013975548s
    Feb 13 14:30:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.012493686s
    Feb 13 14:30:38.642: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.015365626s
    Feb 13 14:30:40.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.013269776s
    Feb 13 14:30:42.645: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.018302194s
    Feb 13 14:30:44.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.013275414s
    Feb 13 14:30:46.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.013996081s
    Feb 13 14:30:48.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014366508s
    Feb 13 14:30:50.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.011787208s
    Feb 13 14:30:52.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.01271045s
    Feb 13 14:30:54.638: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.011870805s
    Feb 13 14:30:56.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013453392s
    Feb 13 14:30:58.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.014264122s
    Feb 13 14:31:00.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013345181s
    Feb 13 14:31:02.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.011985782s
    Feb 13 14:31:04.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014319568s
    Feb 13 14:31:06.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.013129574s
    Feb 13 14:31:08.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.014692751s
    Feb 13 14:31:10.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014437277s
    Feb 13 14:31:12.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.012628838s
    Feb 13 14:31:14.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.014575306s
    Feb 13 14:31:16.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.011946746s
    Feb 13 14:31:18.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.012714173s
    Feb 13 14:31:20.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.012114803s
    Feb 13 14:31:22.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.013298335s
    Feb 13 14:31:24.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.01221906s
    Feb 13 14:31:26.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.012984024s
    Feb 13 14:31:28.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.012314718s
    Feb 13 14:31:30.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.012602714s
    Feb 13 14:31:32.640: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.013035396s
    Feb 13 14:31:34.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.014111207s
    Feb 13 14:31:36.639: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.012453482s
    Feb 13 14:31:38.641: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014136033s
    Feb 13 14:31:38.648: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021537322s
    STEP: removing the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 off the node conformance-5500-0ccfa5-pool-bf9f-o7jrw 02/13/23 14:31:38.649
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-60785de7-15d5-4ec9-969b-ab759d5f2d21 02/13/23 14:31:38.665
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:31:38.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9041" for this suite. 02/13/23 14:31:38.677
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:31:38.688
Feb 13 14:31:38.689: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename discovery 02/13/23 14:31:38.691
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:38.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:38.713
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 02/13/23 14:31:38.717
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Feb 13 14:31:39.193: INFO: Checking APIGroup: apiregistration.k8s.io
Feb 13 14:31:39.195: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Feb 13 14:31:39.195: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Feb 13 14:31:39.195: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Feb 13 14:31:39.195: INFO: Checking APIGroup: apps
Feb 13 14:31:39.197: INFO: PreferredVersion.GroupVersion: apps/v1
Feb 13 14:31:39.197: INFO: Versions found [{apps/v1 v1}]
Feb 13 14:31:39.197: INFO: apps/v1 matches apps/v1
Feb 13 14:31:39.197: INFO: Checking APIGroup: events.k8s.io
Feb 13 14:31:39.199: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Feb 13 14:31:39.199: INFO: Versions found [{events.k8s.io/v1 v1}]
Feb 13 14:31:39.199: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Feb 13 14:31:39.199: INFO: Checking APIGroup: authentication.k8s.io
Feb 13 14:31:39.201: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Feb 13 14:31:39.201: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Feb 13 14:31:39.201: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Feb 13 14:31:39.201: INFO: Checking APIGroup: authorization.k8s.io
Feb 13 14:31:39.203: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Feb 13 14:31:39.203: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Feb 13 14:31:39.203: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Feb 13 14:31:39.203: INFO: Checking APIGroup: autoscaling
Feb 13 14:31:39.205: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Feb 13 14:31:39.205: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Feb 13 14:31:39.205: INFO: autoscaling/v2 matches autoscaling/v2
Feb 13 14:31:39.205: INFO: Checking APIGroup: batch
Feb 13 14:31:39.207: INFO: PreferredVersion.GroupVersion: batch/v1
Feb 13 14:31:39.207: INFO: Versions found [{batch/v1 v1}]
Feb 13 14:31:39.208: INFO: batch/v1 matches batch/v1
Feb 13 14:31:39.208: INFO: Checking APIGroup: certificates.k8s.io
Feb 13 14:31:39.210: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Feb 13 14:31:39.210: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Feb 13 14:31:39.210: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Feb 13 14:31:39.210: INFO: Checking APIGroup: networking.k8s.io
Feb 13 14:31:39.212: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Feb 13 14:31:39.212: INFO: Versions found [{networking.k8s.io/v1 v1}]
Feb 13 14:31:39.212: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Feb 13 14:31:39.212: INFO: Checking APIGroup: policy
Feb 13 14:31:39.215: INFO: PreferredVersion.GroupVersion: policy/v1
Feb 13 14:31:39.215: INFO: Versions found [{policy/v1 v1}]
Feb 13 14:31:39.215: INFO: policy/v1 matches policy/v1
Feb 13 14:31:39.215: INFO: Checking APIGroup: rbac.authorization.k8s.io
Feb 13 14:31:39.217: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Feb 13 14:31:39.217: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Feb 13 14:31:39.217: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Feb 13 14:31:39.217: INFO: Checking APIGroup: storage.k8s.io
Feb 13 14:31:39.219: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Feb 13 14:31:39.219: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Feb 13 14:31:39.219: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Feb 13 14:31:39.219: INFO: Checking APIGroup: admissionregistration.k8s.io
Feb 13 14:31:39.221: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Feb 13 14:31:39.221: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Feb 13 14:31:39.221: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Feb 13 14:31:39.221: INFO: Checking APIGroup: apiextensions.k8s.io
Feb 13 14:31:39.223: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Feb 13 14:31:39.223: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Feb 13 14:31:39.223: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Feb 13 14:31:39.223: INFO: Checking APIGroup: scheduling.k8s.io
Feb 13 14:31:39.225: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Feb 13 14:31:39.225: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Feb 13 14:31:39.225: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Feb 13 14:31:39.225: INFO: Checking APIGroup: coordination.k8s.io
Feb 13 14:31:39.227: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Feb 13 14:31:39.227: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Feb 13 14:31:39.227: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Feb 13 14:31:39.227: INFO: Checking APIGroup: node.k8s.io
Feb 13 14:31:39.229: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Feb 13 14:31:39.229: INFO: Versions found [{node.k8s.io/v1 v1}]
Feb 13 14:31:39.229: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Feb 13 14:31:39.229: INFO: Checking APIGroup: discovery.k8s.io
Feb 13 14:31:39.231: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Feb 13 14:31:39.231: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Feb 13 14:31:39.231: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Feb 13 14:31:39.231: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Feb 13 14:31:39.233: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Feb 13 14:31:39.233: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Feb 13 14:31:39.233: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Feb 13 14:31:39.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-8351" for this suite. 02/13/23 14:31:39.239
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":260,"skipped":4740,"failed":0}
------------------------------
• [0.558 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:31:38.688
    Feb 13 14:31:38.689: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename discovery 02/13/23 14:31:38.691
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:38.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:38.713
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 02/13/23 14:31:38.717
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Feb 13 14:31:39.193: INFO: Checking APIGroup: apiregistration.k8s.io
    Feb 13 14:31:39.195: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Feb 13 14:31:39.195: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Feb 13 14:31:39.195: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Feb 13 14:31:39.195: INFO: Checking APIGroup: apps
    Feb 13 14:31:39.197: INFO: PreferredVersion.GroupVersion: apps/v1
    Feb 13 14:31:39.197: INFO: Versions found [{apps/v1 v1}]
    Feb 13 14:31:39.197: INFO: apps/v1 matches apps/v1
    Feb 13 14:31:39.197: INFO: Checking APIGroup: events.k8s.io
    Feb 13 14:31:39.199: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Feb 13 14:31:39.199: INFO: Versions found [{events.k8s.io/v1 v1}]
    Feb 13 14:31:39.199: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Feb 13 14:31:39.199: INFO: Checking APIGroup: authentication.k8s.io
    Feb 13 14:31:39.201: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Feb 13 14:31:39.201: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Feb 13 14:31:39.201: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Feb 13 14:31:39.201: INFO: Checking APIGroup: authorization.k8s.io
    Feb 13 14:31:39.203: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Feb 13 14:31:39.203: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Feb 13 14:31:39.203: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Feb 13 14:31:39.203: INFO: Checking APIGroup: autoscaling
    Feb 13 14:31:39.205: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Feb 13 14:31:39.205: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Feb 13 14:31:39.205: INFO: autoscaling/v2 matches autoscaling/v2
    Feb 13 14:31:39.205: INFO: Checking APIGroup: batch
    Feb 13 14:31:39.207: INFO: PreferredVersion.GroupVersion: batch/v1
    Feb 13 14:31:39.207: INFO: Versions found [{batch/v1 v1}]
    Feb 13 14:31:39.208: INFO: batch/v1 matches batch/v1
    Feb 13 14:31:39.208: INFO: Checking APIGroup: certificates.k8s.io
    Feb 13 14:31:39.210: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Feb 13 14:31:39.210: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Feb 13 14:31:39.210: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Feb 13 14:31:39.210: INFO: Checking APIGroup: networking.k8s.io
    Feb 13 14:31:39.212: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Feb 13 14:31:39.212: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Feb 13 14:31:39.212: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Feb 13 14:31:39.212: INFO: Checking APIGroup: policy
    Feb 13 14:31:39.215: INFO: PreferredVersion.GroupVersion: policy/v1
    Feb 13 14:31:39.215: INFO: Versions found [{policy/v1 v1}]
    Feb 13 14:31:39.215: INFO: policy/v1 matches policy/v1
    Feb 13 14:31:39.215: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Feb 13 14:31:39.217: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Feb 13 14:31:39.217: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Feb 13 14:31:39.217: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Feb 13 14:31:39.217: INFO: Checking APIGroup: storage.k8s.io
    Feb 13 14:31:39.219: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Feb 13 14:31:39.219: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Feb 13 14:31:39.219: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Feb 13 14:31:39.219: INFO: Checking APIGroup: admissionregistration.k8s.io
    Feb 13 14:31:39.221: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Feb 13 14:31:39.221: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Feb 13 14:31:39.221: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Feb 13 14:31:39.221: INFO: Checking APIGroup: apiextensions.k8s.io
    Feb 13 14:31:39.223: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Feb 13 14:31:39.223: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Feb 13 14:31:39.223: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Feb 13 14:31:39.223: INFO: Checking APIGroup: scheduling.k8s.io
    Feb 13 14:31:39.225: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Feb 13 14:31:39.225: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Feb 13 14:31:39.225: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Feb 13 14:31:39.225: INFO: Checking APIGroup: coordination.k8s.io
    Feb 13 14:31:39.227: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Feb 13 14:31:39.227: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Feb 13 14:31:39.227: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Feb 13 14:31:39.227: INFO: Checking APIGroup: node.k8s.io
    Feb 13 14:31:39.229: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Feb 13 14:31:39.229: INFO: Versions found [{node.k8s.io/v1 v1}]
    Feb 13 14:31:39.229: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Feb 13 14:31:39.229: INFO: Checking APIGroup: discovery.k8s.io
    Feb 13 14:31:39.231: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Feb 13 14:31:39.231: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Feb 13 14:31:39.231: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Feb 13 14:31:39.231: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Feb 13 14:31:39.233: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Feb 13 14:31:39.233: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Feb 13 14:31:39.233: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Feb 13 14:31:39.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-8351" for this suite. 02/13/23 14:31:39.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:31:39.252
Feb 13 14:31:39.253: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:31:39.255
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:39.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:39.282
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-b77f6e59-ffcf-48f6-a0f8-9e4d5f94a0e4 02/13/23 14:31:39.292
STEP: Creating configMap with name cm-test-opt-upd-fe85f34b-ff38-4da9-ae32-154b6146fe81 02/13/23 14:31:39.298
STEP: Creating the pod 02/13/23 14:31:39.303
W0213 14:31:39.313263      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:31:39.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742" in namespace "configmap-6808" to be "running and ready"
Feb 13 14:31:39.317: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742": Phase="Pending", Reason="", readiness=false. Elapsed: 3.742423ms
Feb 13 14:31:39.317: INFO: The phase of Pod pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:31:41.324: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742": Phase="Running", Reason="", readiness=true. Elapsed: 2.011109725s
Feb 13 14:31:41.324: INFO: The phase of Pod pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742 is Running (Ready = true)
Feb 13 14:31:41.324: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-b77f6e59-ffcf-48f6-a0f8-9e4d5f94a0e4 02/13/23 14:31:41.389
STEP: Updating configmap cm-test-opt-upd-fe85f34b-ff38-4da9-ae32-154b6146fe81 02/13/23 14:31:41.397
STEP: Creating configMap with name cm-test-opt-create-49581875-ff5a-4db2-bff3-8567cc152569 02/13/23 14:31:41.404
STEP: waiting to observe update in volume 02/13/23 14:31:41.411
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:31:43.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6808" for this suite. 02/13/23 14:31:43.459
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":261,"skipped":4751,"failed":0}
------------------------------
• [4.214 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:31:39.252
    Feb 13 14:31:39.253: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:31:39.255
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:39.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:39.282
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-b77f6e59-ffcf-48f6-a0f8-9e4d5f94a0e4 02/13/23 14:31:39.292
    STEP: Creating configMap with name cm-test-opt-upd-fe85f34b-ff38-4da9-ae32-154b6146fe81 02/13/23 14:31:39.298
    STEP: Creating the pod 02/13/23 14:31:39.303
    W0213 14:31:39.313263      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:31:39.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742" in namespace "configmap-6808" to be "running and ready"
    Feb 13 14:31:39.317: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742": Phase="Pending", Reason="", readiness=false. Elapsed: 3.742423ms
    Feb 13 14:31:39.317: INFO: The phase of Pod pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:31:41.324: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742": Phase="Running", Reason="", readiness=true. Elapsed: 2.011109725s
    Feb 13 14:31:41.324: INFO: The phase of Pod pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742 is Running (Ready = true)
    Feb 13 14:31:41.324: INFO: Pod "pod-configmaps-6ac2423f-8450-4b8b-aa79-a5c624f3e742" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-b77f6e59-ffcf-48f6-a0f8-9e4d5f94a0e4 02/13/23 14:31:41.389
    STEP: Updating configmap cm-test-opt-upd-fe85f34b-ff38-4da9-ae32-154b6146fe81 02/13/23 14:31:41.397
    STEP: Creating configMap with name cm-test-opt-create-49581875-ff5a-4db2-bff3-8567cc152569 02/13/23 14:31:41.404
    STEP: waiting to observe update in volume 02/13/23 14:31:41.411
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:31:43.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6808" for this suite. 02/13/23 14:31:43.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:31:43.474
Feb 13 14:31:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:31:43.476
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:43.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:43.503
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  02/13/23 14:31:43.509
W0213 14:31:43.523552      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:31:43.524: INFO: Waiting up to 5m0s for pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf" in namespace "svcaccounts-258" to be "Succeeded or Failed"
Feb 13 14:31:43.533: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.691719ms
Feb 13 14:31:45.541: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016978997s
Feb 13 14:31:47.541: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017569984s
STEP: Saw pod success 02/13/23 14:31:47.542
Feb 13 14:31:47.542: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf" satisfied condition "Succeeded or Failed"
Feb 13 14:31:47.548: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:31:47.588
Feb 13 14:31:47.601: INFO: Waiting for pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf to disappear
Feb 13 14:31:47.603: INFO: Pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 14:31:47.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-258" for this suite. 02/13/23 14:31:47.607
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":262,"skipped":4770,"failed":0}
------------------------------
• [4.139 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:31:43.474
    Feb 13 14:31:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:31:43.476
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:43.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:43.503
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  02/13/23 14:31:43.509
    W0213 14:31:43.523552      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:31:43.524: INFO: Waiting up to 5m0s for pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf" in namespace "svcaccounts-258" to be "Succeeded or Failed"
    Feb 13 14:31:43.533: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.691719ms
    Feb 13 14:31:45.541: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016978997s
    Feb 13 14:31:47.541: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017569984s
    STEP: Saw pod success 02/13/23 14:31:47.542
    Feb 13 14:31:47.542: INFO: Pod "test-pod-aef5a058-34f7-46cc-876f-9c838a663caf" satisfied condition "Succeeded or Failed"
    Feb 13 14:31:47.548: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:31:47.588
    Feb 13 14:31:47.601: INFO: Waiting for pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf to disappear
    Feb 13 14:31:47.603: INFO: Pod test-pod-aef5a058-34f7-46cc-876f-9c838a663caf no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 14:31:47.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-258" for this suite. 02/13/23 14:31:47.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:31:47.615
Feb 13 14:31:47.616: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:31:47.617
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:47.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:47.634
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 02/13/23 14:31:47.637
W0213 14:31:47.648393      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:31:47.648: INFO: Waiting up to 5m0s for pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f" in namespace "downward-api-793" to be "Succeeded or Failed"
Feb 13 14:31:47.656: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268486ms
Feb 13 14:31:49.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015064063s
Feb 13 14:31:51.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015003214s
STEP: Saw pod success 02/13/23 14:31:51.663
Feb 13 14:31:51.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f" satisfied condition "Succeeded or Failed"
Feb 13 14:31:51.668: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f container dapi-container: <nil>
STEP: delete the pod 02/13/23 14:31:51.677
Feb 13 14:31:51.689: INFO: Waiting for pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f to disappear
Feb 13 14:31:51.691: INFO: Pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Feb 13 14:31:51.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-793" for this suite. 02/13/23 14:31:51.695
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":263,"skipped":4786,"failed":0}
------------------------------
• [4.085 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:31:47.615
    Feb 13 14:31:47.616: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:31:47.617
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:47.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:47.634
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 02/13/23 14:31:47.637
    W0213 14:31:47.648393      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:31:47.648: INFO: Waiting up to 5m0s for pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f" in namespace "downward-api-793" to be "Succeeded or Failed"
    Feb 13 14:31:47.656: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268486ms
    Feb 13 14:31:49.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015064063s
    Feb 13 14:31:51.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015003214s
    STEP: Saw pod success 02/13/23 14:31:51.663
    Feb 13 14:31:51.663: INFO: Pod "downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f" satisfied condition "Succeeded or Failed"
    Feb 13 14:31:51.668: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f container dapi-container: <nil>
    STEP: delete the pod 02/13/23 14:31:51.677
    Feb 13 14:31:51.689: INFO: Waiting for pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f to disappear
    Feb 13 14:31:51.691: INFO: Pod downward-api-e6cf8bbb-cf0d-4d17-b63b-bb7fb003e96f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Feb 13 14:31:51.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-793" for this suite. 02/13/23 14:31:51.695
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:31:51.702
Feb 13 14:31:51.702: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename subpath 02/13/23 14:31:51.703
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:51.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:51.72
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 02/13/23 14:31:51.724
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-7ml7 02/13/23 14:31:51.733
STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:31:51.733
W0213 14:31:51.743704      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-projected-7ml7" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-projected-7ml7" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-projected-7ml7" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-projected-7ml7" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:31:51.744: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7ml7" in namespace "subpath-8450" to be "Succeeded or Failed"
Feb 13 14:31:51.748: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.228955ms
Feb 13 14:31:53.752: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 2.008229069s
Feb 13 14:31:55.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 4.013434109s
Feb 13 14:31:57.756: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 6.011687647s
Feb 13 14:31:59.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 8.010797675s
Feb 13 14:32:01.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 10.0114322s
Feb 13 14:32:03.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 12.011074018s
Feb 13 14:32:05.753: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 14.009278503s
Feb 13 14:32:07.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 16.010710142s
Feb 13 14:32:09.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 18.013130512s
Feb 13 14:32:11.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 20.010622046s
Feb 13 14:32:13.754: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=false. Elapsed: 22.009954658s
Feb 13 14:32:15.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012914614s
STEP: Saw pod success 02/13/23 14:32:15.757
Feb 13 14:32:15.758: INFO: Pod "pod-subpath-test-projected-7ml7" satisfied condition "Succeeded or Failed"
Feb 13 14:32:15.764: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-projected-7ml7 container test-container-subpath-projected-7ml7: <nil>
STEP: delete the pod 02/13/23 14:32:15.777
Feb 13 14:32:15.791: INFO: Waiting for pod pod-subpath-test-projected-7ml7 to disappear
Feb 13 14:32:15.798: INFO: Pod pod-subpath-test-projected-7ml7 no longer exists
STEP: Deleting pod pod-subpath-test-projected-7ml7 02/13/23 14:32:15.798
Feb 13 14:32:15.799: INFO: Deleting pod "pod-subpath-test-projected-7ml7" in namespace "subpath-8450"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Feb 13 14:32:15.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8450" for this suite. 02/13/23 14:32:15.812
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":264,"skipped":4790,"failed":0}
------------------------------
• [SLOW TEST] [24.117 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:31:51.702
    Feb 13 14:31:51.702: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename subpath 02/13/23 14:31:51.703
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:31:51.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:31:51.72
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 02/13/23 14:31:51.724
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-7ml7 02/13/23 14:31:51.733
    STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:31:51.733
    W0213 14:31:51.743704      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-projected-7ml7" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-projected-7ml7" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-projected-7ml7" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-projected-7ml7" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:31:51.744: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7ml7" in namespace "subpath-8450" to be "Succeeded or Failed"
    Feb 13 14:31:51.748: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.228955ms
    Feb 13 14:31:53.752: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 2.008229069s
    Feb 13 14:31:55.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 4.013434109s
    Feb 13 14:31:57.756: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 6.011687647s
    Feb 13 14:31:59.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 8.010797675s
    Feb 13 14:32:01.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 10.0114322s
    Feb 13 14:32:03.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 12.011074018s
    Feb 13 14:32:05.753: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 14.009278503s
    Feb 13 14:32:07.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 16.010710142s
    Feb 13 14:32:09.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 18.013130512s
    Feb 13 14:32:11.755: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=true. Elapsed: 20.010622046s
    Feb 13 14:32:13.754: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Running", Reason="", readiness=false. Elapsed: 22.009954658s
    Feb 13 14:32:15.757: INFO: Pod "pod-subpath-test-projected-7ml7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012914614s
    STEP: Saw pod success 02/13/23 14:32:15.757
    Feb 13 14:32:15.758: INFO: Pod "pod-subpath-test-projected-7ml7" satisfied condition "Succeeded or Failed"
    Feb 13 14:32:15.764: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-projected-7ml7 container test-container-subpath-projected-7ml7: <nil>
    STEP: delete the pod 02/13/23 14:32:15.777
    Feb 13 14:32:15.791: INFO: Waiting for pod pod-subpath-test-projected-7ml7 to disappear
    Feb 13 14:32:15.798: INFO: Pod pod-subpath-test-projected-7ml7 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-7ml7 02/13/23 14:32:15.798
    Feb 13 14:32:15.799: INFO: Deleting pod "pod-subpath-test-projected-7ml7" in namespace "subpath-8450"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Feb 13 14:32:15.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8450" for this suite. 02/13/23 14:32:15.812
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:32:15.825
Feb 13 14:32:15.826: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename cronjob 02/13/23 14:32:15.828
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:32:15.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:32:15.848
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 02/13/23 14:32:15.853
W0213 14:32:15.865955      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring more than one job is running at a time 02/13/23 14:32:15.866
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 02/13/23 14:34:01.875
STEP: Removing cronjob 02/13/23 14:34:01.883
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Feb 13 14:34:01.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5411" for this suite. 02/13/23 14:34:01.913
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":265,"skipped":4792,"failed":0}
------------------------------
• [SLOW TEST] [106.100 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:32:15.825
    Feb 13 14:32:15.826: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename cronjob 02/13/23 14:32:15.828
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:32:15.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:32:15.848
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 02/13/23 14:32:15.853
    W0213 14:32:15.865955      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring more than one job is running at a time 02/13/23 14:32:15.866
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 02/13/23 14:34:01.875
    STEP: Removing cronjob 02/13/23 14:34:01.883
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Feb 13 14:34:01.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5411" for this suite. 02/13/23 14:34:01.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:01.932
Feb 13 14:34:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:34:01.935
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:01.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:01.967
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Feb 13 14:34:01.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8200" for this suite. 02/13/23 14:34:01.995
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":266,"skipped":4802,"failed":0}
------------------------------
• [0.070 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:01.932
    Feb 13 14:34:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:34:01.935
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:01.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:01.967
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Feb 13 14:34:01.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8200" for this suite. 02/13/23 14:34:01.995
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:02.009
Feb 13 14:34:02.009: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:34:02.011
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:02.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:02.036
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 02/13/23 14:34:02.04
STEP: Creating a ResourceQuota 02/13/23 14:34:07.046
STEP: Ensuring resource quota status is calculated 02/13/23 14:34:07.054
STEP: Creating a ReplicaSet 02/13/23 14:34:09.062
W0213 14:34:09.081770      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rs" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rs" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rs" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rs" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota status captures replicaset creation 02/13/23 14:34:09.082
STEP: Deleting a ReplicaSet 02/13/23 14:34:11.088
STEP: Ensuring resource quota status released usage 02/13/23 14:34:11.095
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:34:13.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5117" for this suite. 02/13/23 14:34:13.11
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":267,"skipped":4808,"failed":0}
------------------------------
• [SLOW TEST] [11.111 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:02.009
    Feb 13 14:34:02.009: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:34:02.011
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:02.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:02.036
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 02/13/23 14:34:02.04
    STEP: Creating a ResourceQuota 02/13/23 14:34:07.046
    STEP: Ensuring resource quota status is calculated 02/13/23 14:34:07.054
    STEP: Creating a ReplicaSet 02/13/23 14:34:09.062
    W0213 14:34:09.081770      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rs" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rs" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rs" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rs" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota status captures replicaset creation 02/13/23 14:34:09.082
    STEP: Deleting a ReplicaSet 02/13/23 14:34:11.088
    STEP: Ensuring resource quota status released usage 02/13/23 14:34:11.095
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:34:13.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5117" for this suite. 02/13/23 14:34:13.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:13.126
Feb 13 14:34:13.126: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:34:13.128
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:13.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:13.157
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-c2c77e99-7e2a-481a-90e8-f25361604977 02/13/23 14:34:13.162
STEP: Creating a pod to test consume configMaps 02/13/23 14:34:13.17
W0213 14:34:13.178767      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:13.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836" in namespace "configmap-2103" to be "Succeeded or Failed"
Feb 13 14:34:13.187: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Pending", Reason="", readiness=false. Elapsed: 8.102012ms
Feb 13 14:34:15.196: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017252159s
Feb 13 14:34:17.197: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018023995s
STEP: Saw pod success 02/13/23 14:34:17.197
Feb 13 14:34:17.197: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836" satisfied condition "Succeeded or Failed"
Feb 13 14:34:17.205: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:34:17.235
Feb 13 14:34:17.250: INFO: Waiting for pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 to disappear
Feb 13 14:34:17.254: INFO: Pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:34:17.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2103" for this suite. 02/13/23 14:34:17.259
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":268,"skipped":4830,"failed":0}
------------------------------
• [4.141 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:13.126
    Feb 13 14:34:13.126: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:34:13.128
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:13.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:13.157
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-c2c77e99-7e2a-481a-90e8-f25361604977 02/13/23 14:34:13.162
    STEP: Creating a pod to test consume configMaps 02/13/23 14:34:13.17
    W0213 14:34:13.178767      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:13.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836" in namespace "configmap-2103" to be "Succeeded or Failed"
    Feb 13 14:34:13.187: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Pending", Reason="", readiness=false. Elapsed: 8.102012ms
    Feb 13 14:34:15.196: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017252159s
    Feb 13 14:34:17.197: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018023995s
    STEP: Saw pod success 02/13/23 14:34:17.197
    Feb 13 14:34:17.197: INFO: Pod "pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836" satisfied condition "Succeeded or Failed"
    Feb 13 14:34:17.205: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:34:17.235
    Feb 13 14:34:17.250: INFO: Waiting for pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 to disappear
    Feb 13 14:34:17.254: INFO: Pod pod-configmaps-a543fe6a-4f8f-4c99-8413-8356e73ff836 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:34:17.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2103" for this suite. 02/13/23 14:34:17.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:17.281
Feb 13 14:34:17.282: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context-test 02/13/23 14:34:17.284
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:17.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:17.303
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
W0213 14:34:17.324383      19 warnings.go:70] would violate PodSecurity "restricted:latest": unrestricted capabilities (container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:17.324: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" in namespace "security-context-test-4917" to be "Succeeded or Failed"
Feb 13 14:34:17.328: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.662574ms
Feb 13 14:34:19.336: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011457628s
Feb 13 14:34:21.334: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010280378s
Feb 13 14:34:21.335: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 14:34:21.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4917" for this suite. 02/13/23 14:34:21.352
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":269,"skipped":4854,"failed":0}
------------------------------
• [4.079 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:17.281
    Feb 13 14:34:17.282: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context-test 02/13/23 14:34:17.284
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:17.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:17.303
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    W0213 14:34:17.324383      19 warnings.go:70] would violate PodSecurity "restricted:latest": unrestricted capabilities (container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:17.324: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" in namespace "security-context-test-4917" to be "Succeeded or Failed"
    Feb 13 14:34:17.328: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.662574ms
    Feb 13 14:34:19.336: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011457628s
    Feb 13 14:34:21.334: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010280378s
    Feb 13 14:34:21.335: INFO: Pod "alpine-nnp-false-31d4d1a0-b940-4522-8fb4-4f7ffdce96c0" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 14:34:21.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4917" for this suite. 02/13/23 14:34:21.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:21.362
Feb 13 14:34:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:34:21.363
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:21.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:21.382
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
W0213 14:34:21.393197      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for pod completion 02/13/23 14:34:21.393
Feb 13 14:34:21.393: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b" in namespace "kubelet-test-1490" to be "completed"
Feb 13 14:34:21.397: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031953ms
Feb 13 14:34:23.403: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009288591s
Feb 13 14:34:25.405: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011729332s
Feb 13 14:34:25.406: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Feb 13 14:34:25.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1490" for this suite. 02/13/23 14:34:25.43
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":270,"skipped":4871,"failed":0}
------------------------------
• [4.077 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:21.362
    Feb 13 14:34:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubelet-test 02/13/23 14:34:21.363
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:21.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:21.382
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    W0213 14:34:21.393197      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for pod completion 02/13/23 14:34:21.393
    Feb 13 14:34:21.393: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b" in namespace "kubelet-test-1490" to be "completed"
    Feb 13 14:34:21.397: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031953ms
    Feb 13 14:34:23.403: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009288591s
    Feb 13 14:34:25.405: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011729332s
    Feb 13 14:34:25.406: INFO: Pod "agnhost-host-aliases4f5d62a5-5255-4c79-baf0-2cefb83f0c4b" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Feb 13 14:34:25.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1490" for this suite. 02/13/23 14:34:25.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:25.441
Feb 13 14:34:25.441: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename ingress 02/13/23 14:34:25.442
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:25.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:25.464
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 02/13/23 14:34:25.467
STEP: getting /apis/networking.k8s.io 02/13/23 14:34:25.47
STEP: getting /apis/networking.k8s.iov1 02/13/23 14:34:25.472
STEP: creating 02/13/23 14:34:25.473
STEP: getting 02/13/23 14:34:25.495
STEP: listing 02/13/23 14:34:25.498
STEP: watching 02/13/23 14:34:25.5
Feb 13 14:34:25.500: INFO: starting watch
STEP: cluster-wide listing 02/13/23 14:34:25.501
STEP: cluster-wide watching 02/13/23 14:34:25.504
Feb 13 14:34:25.504: INFO: starting watch
STEP: patching 02/13/23 14:34:25.505
STEP: updating 02/13/23 14:34:25.511
Feb 13 14:34:25.520: INFO: waiting for watch events with expected annotations
Feb 13 14:34:25.520: INFO: saw patched and updated annotations
STEP: patching /status 02/13/23 14:34:25.52
STEP: updating /status 02/13/23 14:34:25.526
STEP: get /status 02/13/23 14:34:25.543
STEP: deleting 02/13/23 14:34:25.548
STEP: deleting a collection 02/13/23 14:34:25.56
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Feb 13 14:34:25.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-775" for this suite. 02/13/23 14:34:25.581
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":271,"skipped":4895,"failed":0}
------------------------------
• [0.148 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:25.441
    Feb 13 14:34:25.441: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename ingress 02/13/23 14:34:25.442
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:25.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:25.464
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 02/13/23 14:34:25.467
    STEP: getting /apis/networking.k8s.io 02/13/23 14:34:25.47
    STEP: getting /apis/networking.k8s.iov1 02/13/23 14:34:25.472
    STEP: creating 02/13/23 14:34:25.473
    STEP: getting 02/13/23 14:34:25.495
    STEP: listing 02/13/23 14:34:25.498
    STEP: watching 02/13/23 14:34:25.5
    Feb 13 14:34:25.500: INFO: starting watch
    STEP: cluster-wide listing 02/13/23 14:34:25.501
    STEP: cluster-wide watching 02/13/23 14:34:25.504
    Feb 13 14:34:25.504: INFO: starting watch
    STEP: patching 02/13/23 14:34:25.505
    STEP: updating 02/13/23 14:34:25.511
    Feb 13 14:34:25.520: INFO: waiting for watch events with expected annotations
    Feb 13 14:34:25.520: INFO: saw patched and updated annotations
    STEP: patching /status 02/13/23 14:34:25.52
    STEP: updating /status 02/13/23 14:34:25.526
    STEP: get /status 02/13/23 14:34:25.543
    STEP: deleting 02/13/23 14:34:25.548
    STEP: deleting a collection 02/13/23 14:34:25.56
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Feb 13 14:34:25.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-775" for this suite. 02/13/23 14:34:25.581
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:25.589
Feb 13 14:34:25.589: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 14:34:25.59
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:25.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:25.611
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 02/13/23 14:34:25.614
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 02/13/23 14:34:25.62
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 02/13/23 14:34:25.62
STEP: creating a pod to probe DNS 02/13/23 14:34:25.62
STEP: submitting the pod to kubernetes 02/13/23 14:34:25.621
W0213 14:34:25.631247      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:25.631: INFO: Waiting up to 15m0s for pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67" in namespace "dns-1095" to be "running"
Feb 13 14:34:25.633: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.276412ms
Feb 13 14:34:27.641: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67": Phase="Running", Reason="", readiness=true. Elapsed: 2.009748072s
Feb 13 14:34:27.641: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67" satisfied condition "running"
STEP: retrieving the pod 02/13/23 14:34:27.641
STEP: looking for the results for each expected name from probers 02/13/23 14:34:27.647
Feb 13 14:34:27.691: INFO: DNS probes using dns-1095/dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67 succeeded

STEP: deleting the pod 02/13/23 14:34:27.691
STEP: deleting the test headless service 02/13/23 14:34:27.715
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 14:34:27.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1095" for this suite. 02/13/23 14:34:27.731
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":272,"skipped":4898,"failed":0}
------------------------------
• [2.158 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:25.589
    Feb 13 14:34:25.589: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 14:34:25.59
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:25.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:25.611
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 02/13/23 14:34:25.614
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     02/13/23 14:34:25.62
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1095.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     02/13/23 14:34:25.62
    STEP: creating a pod to probe DNS 02/13/23 14:34:25.62
    STEP: submitting the pod to kubernetes 02/13/23 14:34:25.621
    W0213 14:34:25.631247      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:25.631: INFO: Waiting up to 15m0s for pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67" in namespace "dns-1095" to be "running"
    Feb 13 14:34:25.633: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.276412ms
    Feb 13 14:34:27.641: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67": Phase="Running", Reason="", readiness=true. Elapsed: 2.009748072s
    Feb 13 14:34:27.641: INFO: Pod "dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 14:34:27.641
    STEP: looking for the results for each expected name from probers 02/13/23 14:34:27.647
    Feb 13 14:34:27.691: INFO: DNS probes using dns-1095/dns-test-0e52aa9c-7777-4cec-902c-ded3f42b5d67 succeeded

    STEP: deleting the pod 02/13/23 14:34:27.691
    STEP: deleting the test headless service 02/13/23 14:34:27.715
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 14:34:27.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1095" for this suite. 02/13/23 14:34:27.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:27.756
Feb 13 14:34:27.756: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 14:34:27.757
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:27.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:27.779
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 02/13/23 14:34:27.783
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1620;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1620;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +notcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_tcp@PTR;sleep 1; done
 02/13/23 14:34:27.813
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1620;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1620;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +notcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_tcp@PTR;sleep 1; done
 02/13/23 14:34:27.813
STEP: creating a pod to probe DNS 02/13/23 14:34:27.813
STEP: submitting the pod to kubernetes 02/13/23 14:34:27.814
W0213 14:34:27.832106      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:27.832: INFO: Waiting up to 15m0s for pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3" in namespace "dns-1620" to be "running"
Feb 13 14:34:27.839: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.39212ms
Feb 13 14:34:29.845: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3": Phase="Running", Reason="", readiness=true. Elapsed: 2.013527678s
Feb 13 14:34:29.845: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3" satisfied condition "running"
STEP: retrieving the pod 02/13/23 14:34:29.845
STEP: looking for the results for each expected name from probers 02/13/23 14:34:29.849
Feb 13 14:34:29.859: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.866: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.873: INFO: Unable to read wheezy_udp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.880: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.887: INFO: Unable to read wheezy_udp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.895: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.903: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.916: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.948: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.954: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.961: INFO: Unable to read jessie_udp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.967: INFO: Unable to read jessie_tcp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.974: INFO: Unable to read jessie_udp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.981: INFO: Unable to read jessie_tcp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.988: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:29.995: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
Feb 13 14:34:30.024: INFO: Lookups using dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1620 wheezy_tcp@dns-test-service.dns-1620 wheezy_udp@dns-test-service.dns-1620.svc wheezy_tcp@dns-test-service.dns-1620.svc wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1620 jessie_tcp@dns-test-service.dns-1620 jessie_udp@dns-test-service.dns-1620.svc jessie_tcp@dns-test-service.dns-1620.svc jessie_udp@_http._tcp.dns-test-service.dns-1620.svc jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc]

Feb 13 14:34:35.183: INFO: DNS probes using dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3 succeeded

STEP: deleting the pod 02/13/23 14:34:35.183
STEP: deleting the test service 02/13/23 14:34:35.209
STEP: deleting the test headless service 02/13/23 14:34:35.233
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 14:34:35.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1620" for this suite. 02/13/23 14:34:35.245
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":273,"skipped":4970,"failed":0}
------------------------------
• [SLOW TEST] [7.494 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:27.756
    Feb 13 14:34:27.756: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 14:34:27.757
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:27.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:27.779
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 02/13/23 14:34:27.783
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1620;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1620;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +notcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_tcp@PTR;sleep 1; done
     02/13/23 14:34:27.813
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1620;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1620;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1620.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1620.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1620.svc;check="$$(dig +notcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.213.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.213.125_tcp@PTR;sleep 1; done
     02/13/23 14:34:27.813
    STEP: creating a pod to probe DNS 02/13/23 14:34:27.813
    STEP: submitting the pod to kubernetes 02/13/23 14:34:27.814
    W0213 14:34:27.832106      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:27.832: INFO: Waiting up to 15m0s for pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3" in namespace "dns-1620" to be "running"
    Feb 13 14:34:27.839: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.39212ms
    Feb 13 14:34:29.845: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3": Phase="Running", Reason="", readiness=true. Elapsed: 2.013527678s
    Feb 13 14:34:29.845: INFO: Pod "dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 14:34:29.845
    STEP: looking for the results for each expected name from probers 02/13/23 14:34:29.849
    Feb 13 14:34:29.859: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.866: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.873: INFO: Unable to read wheezy_udp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.880: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.887: INFO: Unable to read wheezy_udp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.895: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.903: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.916: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.948: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.954: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.961: INFO: Unable to read jessie_udp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.967: INFO: Unable to read jessie_tcp@dns-test-service.dns-1620 from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.974: INFO: Unable to read jessie_udp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.981: INFO: Unable to read jessie_tcp@dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.988: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:29.995: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc from pod dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3: the server could not find the requested resource (get pods dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3)
    Feb 13 14:34:30.024: INFO: Lookups using dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1620 wheezy_tcp@dns-test-service.dns-1620 wheezy_udp@dns-test-service.dns-1620.svc wheezy_tcp@dns-test-service.dns-1620.svc wheezy_udp@_http._tcp.dns-test-service.dns-1620.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1620.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1620 jessie_tcp@dns-test-service.dns-1620 jessie_udp@dns-test-service.dns-1620.svc jessie_tcp@dns-test-service.dns-1620.svc jessie_udp@_http._tcp.dns-test-service.dns-1620.svc jessie_tcp@_http._tcp.dns-test-service.dns-1620.svc]

    Feb 13 14:34:35.183: INFO: DNS probes using dns-1620/dns-test-a5cd5e60-8f46-479f-b819-58d5698e2ce3 succeeded

    STEP: deleting the pod 02/13/23 14:34:35.183
    STEP: deleting the test service 02/13/23 14:34:35.209
    STEP: deleting the test headless service 02/13/23 14:34:35.233
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 14:34:35.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1620" for this suite. 02/13/23 14:34:35.245
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:35.267
Feb 13 14:34:35.267: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 02/13/23 14:34:35.269
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:35.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:35.288
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 02/13/23 14:34:35.292
STEP: Creating hostNetwork=false pod 02/13/23 14:34:35.292
W0213 14:34:35.299478      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:35.299: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5233" to be "running and ready"
Feb 13 14:34:35.305: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.94749ms
Feb 13 14:34:35.305: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:34:37.313: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013806232s
Feb 13 14:34:37.313: INFO: The phase of Pod test-pod is Running (Ready = true)
Feb 13 14:34:37.313: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 02/13/23 14:34:37.319
W0213 14:34:37.330043      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:37.330: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5233" to be "running and ready"
Feb 13 14:34:37.336: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.08886ms
Feb 13 14:34:37.336: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:34:39.343: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013129665s
Feb 13 14:34:39.343: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Feb 13 14:34:39.343: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 02/13/23 14:34:39.349
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 02/13/23 14:34:39.349
Feb 13 14:34:39.350: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:39.350: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:39.351: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:39.351: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Feb 13 14:34:39.520: INFO: Exec stderr: ""
Feb 13 14:34:39.521: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:39.521: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:39.523: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:39.525: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Feb 13 14:34:39.711: INFO: Exec stderr: ""
Feb 13 14:34:39.711: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:39.711: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:39.713: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:39.713: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Feb 13 14:34:39.866: INFO: Exec stderr: ""
Feb 13 14:34:39.866: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:39.868: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:39.868: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Feb 13 14:34:40.002: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 02/13/23 14:34:40.002
Feb 13 14:34:40.003: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.003: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.005: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.005: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Feb 13 14:34:40.153: INFO: Exec stderr: ""
Feb 13 14:34:40.154: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.155: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.156: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.157: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Feb 13 14:34:40.313: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 02/13/23 14:34:40.313
Feb 13 14:34:40.313: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.314: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.314: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Feb 13 14:34:40.485: INFO: Exec stderr: ""
Feb 13 14:34:40.485: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.485: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.485: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.485: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Feb 13 14:34:40.621: INFO: Exec stderr: ""
Feb 13 14:34:40.621: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.621: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.621: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.622: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Feb 13 14:34:40.767: INFO: Exec stderr: ""
Feb 13 14:34:40.767: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:34:40.767: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:34:40.768: INFO: ExecWithOptions: Clientset creation
Feb 13 14:34:40.768: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Feb 13 14:34:40.904: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Feb 13 14:34:40.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5233" for this suite. 02/13/23 14:34:40.91
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":274,"skipped":4981,"failed":0}
------------------------------
• [SLOW TEST] [5.662 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:35.267
    Feb 13 14:34:35.267: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 02/13/23 14:34:35.269
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:35.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:35.288
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 02/13/23 14:34:35.292
    STEP: Creating hostNetwork=false pod 02/13/23 14:34:35.292
    W0213 14:34:35.299478      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:35.299: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5233" to be "running and ready"
    Feb 13 14:34:35.305: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.94749ms
    Feb 13 14:34:35.305: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:34:37.313: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013806232s
    Feb 13 14:34:37.313: INFO: The phase of Pod test-pod is Running (Ready = true)
    Feb 13 14:34:37.313: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 02/13/23 14:34:37.319
    W0213 14:34:37.330043      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:37.330: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5233" to be "running and ready"
    Feb 13 14:34:37.336: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.08886ms
    Feb 13 14:34:37.336: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:34:39.343: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013129665s
    Feb 13 14:34:39.343: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Feb 13 14:34:39.343: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 02/13/23 14:34:39.349
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 02/13/23 14:34:39.349
    Feb 13 14:34:39.350: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:39.350: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:39.351: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:39.351: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Feb 13 14:34:39.520: INFO: Exec stderr: ""
    Feb 13 14:34:39.521: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:39.521: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:39.523: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:39.525: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Feb 13 14:34:39.711: INFO: Exec stderr: ""
    Feb 13 14:34:39.711: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:39.711: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:39.713: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:39.713: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Feb 13 14:34:39.866: INFO: Exec stderr: ""
    Feb 13 14:34:39.866: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:39.868: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:39.868: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Feb 13 14:34:40.002: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 02/13/23 14:34:40.002
    Feb 13 14:34:40.003: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.003: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.005: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.005: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Feb 13 14:34:40.153: INFO: Exec stderr: ""
    Feb 13 14:34:40.154: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.155: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.156: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.157: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Feb 13 14:34:40.313: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 02/13/23 14:34:40.313
    Feb 13 14:34:40.313: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.314: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.314: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Feb 13 14:34:40.485: INFO: Exec stderr: ""
    Feb 13 14:34:40.485: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.485: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.485: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.485: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Feb 13 14:34:40.621: INFO: Exec stderr: ""
    Feb 13 14:34:40.621: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.621: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.621: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.622: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Feb 13 14:34:40.767: INFO: Exec stderr: ""
    Feb 13 14:34:40.767: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5233 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:34:40.767: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:34:40.768: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:34:40.768: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5233/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Feb 13 14:34:40.904: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Feb 13 14:34:40.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-5233" for this suite. 02/13/23 14:34:40.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:40.93
Feb 13 14:34:40.930: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:34:40.931
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:40.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:40.951
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:34:40.957
W0213 14:34:40.966275      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:34:40.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8" in namespace "downward-api-254" to be "Succeeded or Failed"
Feb 13 14:34:40.972: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.932161ms
Feb 13 14:34:42.979: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012975278s
Feb 13 14:34:44.980: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013543651s
STEP: Saw pod success 02/13/23 14:34:44.98
Feb 13 14:34:44.980: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8" satisfied condition "Succeeded or Failed"
Feb 13 14:34:44.985: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 container client-container: <nil>
STEP: delete the pod 02/13/23 14:34:44.997
Feb 13 14:34:45.015: INFO: Waiting for pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 to disappear
Feb 13 14:34:45.020: INFO: Pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 14:34:45.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-254" for this suite. 02/13/23 14:34:45.026
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":275,"skipped":4986,"failed":0}
------------------------------
• [4.101 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:40.93
    Feb 13 14:34:40.930: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:34:40.931
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:40.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:40.951
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:34:40.957
    W0213 14:34:40.966275      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:34:40.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8" in namespace "downward-api-254" to be "Succeeded or Failed"
    Feb 13 14:34:40.972: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.932161ms
    Feb 13 14:34:42.979: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012975278s
    Feb 13 14:34:44.980: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013543651s
    STEP: Saw pod success 02/13/23 14:34:44.98
    Feb 13 14:34:44.980: INFO: Pod "downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8" satisfied condition "Succeeded or Failed"
    Feb 13 14:34:44.985: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:34:44.997
    Feb 13 14:34:45.015: INFO: Waiting for pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 to disappear
    Feb 13 14:34:45.020: INFO: Pod downwardapi-volume-fa8d1117-be19-4c14-9078-f200a2648cf8 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 14:34:45.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-254" for this suite. 02/13/23 14:34:45.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:34:45.032
Feb 13 14:34:45.032: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename cronjob 02/13/23 14:34:45.033
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:45.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:45.052
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 02/13/23 14:34:45.055
W0213 14:34:45.061570      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring a job is scheduled 02/13/23 14:34:45.063
STEP: Ensuring exactly one is scheduled 02/13/23 14:35:01.073
STEP: Ensuring exactly one running job exists by listing jobs explicitly 02/13/23 14:35:01.079
STEP: Ensuring no more jobs are scheduled 02/13/23 14:35:01.084
STEP: Removing cronjob 02/13/23 14:40:01.093
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Feb 13 14:40:01.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6669" for this suite. 02/13/23 14:40:01.108
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":276,"skipped":5006,"failed":0}
------------------------------
• [SLOW TEST] [316.091 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:34:45.032
    Feb 13 14:34:45.032: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename cronjob 02/13/23 14:34:45.033
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:34:45.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:34:45.052
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 02/13/23 14:34:45.055
    W0213 14:34:45.061570      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring a job is scheduled 02/13/23 14:34:45.063
    STEP: Ensuring exactly one is scheduled 02/13/23 14:35:01.073
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 02/13/23 14:35:01.079
    STEP: Ensuring no more jobs are scheduled 02/13/23 14:35:01.084
    STEP: Removing cronjob 02/13/23 14:40:01.093
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Feb 13 14:40:01.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6669" for this suite. 02/13/23 14:40:01.108
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:01.133
Feb 13 14:40:01.137: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:40:01.141
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:01.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:01.182
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 02/13/23 14:40:01.191
STEP: watching for the ServiceAccount to be added 02/13/23 14:40:01.199
STEP: patching the ServiceAccount 02/13/23 14:40:01.202
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 02/13/23 14:40:01.209
STEP: deleting the ServiceAccount 02/13/23 14:40:01.213
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Feb 13 14:40:01.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3038" for this suite. 02/13/23 14:40:01.229
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":277,"skipped":5023,"failed":0}
------------------------------
• [0.105 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:01.133
    Feb 13 14:40:01.137: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svcaccounts 02/13/23 14:40:01.141
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:01.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:01.182
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 02/13/23 14:40:01.191
    STEP: watching for the ServiceAccount to be added 02/13/23 14:40:01.199
    STEP: patching the ServiceAccount 02/13/23 14:40:01.202
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 02/13/23 14:40:01.209
    STEP: deleting the ServiceAccount 02/13/23 14:40:01.213
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Feb 13 14:40:01.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3038" for this suite. 02/13/23 14:40:01.229
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:01.243
Feb 13 14:40:01.243: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:40:01.245
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:01.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:01.272
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-4271/secret-test-74aa9c5e-bc33-406a-b098-9e56f9498b4e 02/13/23 14:40:01.277
STEP: Creating a pod to test consume secrets 02/13/23 14:40:01.282
W0213 14:40:01.293362      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:40:01.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37" in namespace "secrets-4271" to be "Succeeded or Failed"
Feb 13 14:40:01.297: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.762177ms
Feb 13 14:40:03.301: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008059667s
Feb 13 14:40:05.302: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008986939s
STEP: Saw pod success 02/13/23 14:40:05.302
Feb 13 14:40:05.303: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37" satisfied condition "Succeeded or Failed"
Feb 13 14:40:05.307: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 container env-test: <nil>
STEP: delete the pod 02/13/23 14:40:05.346
Feb 13 14:40:05.358: INFO: Waiting for pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 to disappear
Feb 13 14:40:05.361: INFO: Pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:40:05.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4271" for this suite. 02/13/23 14:40:05.366
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":278,"skipped":5023,"failed":0}
------------------------------
• [4.128 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:01.243
    Feb 13 14:40:01.243: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:40:01.245
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:01.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:01.272
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-4271/secret-test-74aa9c5e-bc33-406a-b098-9e56f9498b4e 02/13/23 14:40:01.277
    STEP: Creating a pod to test consume secrets 02/13/23 14:40:01.282
    W0213 14:40:01.293362      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:40:01.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37" in namespace "secrets-4271" to be "Succeeded or Failed"
    Feb 13 14:40:01.297: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.762177ms
    Feb 13 14:40:03.301: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008059667s
    Feb 13 14:40:05.302: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008986939s
    STEP: Saw pod success 02/13/23 14:40:05.302
    Feb 13 14:40:05.303: INFO: Pod "pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37" satisfied condition "Succeeded or Failed"
    Feb 13 14:40:05.307: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 container env-test: <nil>
    STEP: delete the pod 02/13/23 14:40:05.346
    Feb 13 14:40:05.358: INFO: Waiting for pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 to disappear
    Feb 13 14:40:05.361: INFO: Pod pod-configmaps-b858edf9-cbd9-4a88-9f46-0d32a781ec37 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:40:05.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4271" for this suite. 02/13/23 14:40:05.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:05.373
Feb 13 14:40:05.373: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 14:40:05.375
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:05.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:05.393
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Feb 13 14:40:05.399: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:40:05.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5002" for this suite. 02/13/23 14:40:05.998
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":279,"skipped":5043,"failed":0}
------------------------------
• [0.636 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:05.373
    Feb 13 14:40:05.373: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename custom-resource-definition 02/13/23 14:40:05.375
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:05.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:05.393
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Feb 13 14:40:05.399: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:40:05.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5002" for this suite. 02/13/23 14:40:05.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:06.012
Feb 13 14:40:06.012: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 14:40:06.014
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:06.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:06.032
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 02/13/23 14:40:06.038
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local;sleep 1; done
 02/13/23 14:40:06.051
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local;sleep 1; done
 02/13/23 14:40:06.052
STEP: creating a pod to probe DNS 02/13/23 14:40:06.052
STEP: submitting the pod to kubernetes 02/13/23 14:40:06.053
W0213 14:40:06.067810      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:40:06.068: INFO: Waiting up to 15m0s for pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770" in namespace "dns-7160" to be "running"
Feb 13 14:40:06.072: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010437ms
Feb 13 14:40:08.079: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770": Phase="Running", Reason="", readiness=true. Elapsed: 2.010411128s
Feb 13 14:40:08.079: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770" satisfied condition "running"
STEP: retrieving the pod 02/13/23 14:40:08.079
STEP: looking for the results for each expected name from probers 02/13/23 14:40:08.085
Feb 13 14:40:08.099: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.107: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.115: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.123: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.130: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.138: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.152: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.160: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
Feb 13 14:40:08.160: INFO: Lookups using dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local]

Feb 13 14:40:13.223: INFO: DNS probes using dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770 succeeded

STEP: deleting the pod 02/13/23 14:40:13.223
STEP: deleting the test headless service 02/13/23 14:40:13.237
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 14:40:13.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7160" for this suite. 02/13/23 14:40:13.258
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":280,"skipped":5051,"failed":0}
------------------------------
• [SLOW TEST] [7.255 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:06.012
    Feb 13 14:40:06.012: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 14:40:06.014
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:06.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:06.032
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 02/13/23 14:40:06.038
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local;sleep 1; done
     02/13/23 14:40:06.051
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7160.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local;sleep 1; done
     02/13/23 14:40:06.052
    STEP: creating a pod to probe DNS 02/13/23 14:40:06.052
    STEP: submitting the pod to kubernetes 02/13/23 14:40:06.053
    W0213 14:40:06.067810      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:40:06.068: INFO: Waiting up to 15m0s for pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770" in namespace "dns-7160" to be "running"
    Feb 13 14:40:06.072: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010437ms
    Feb 13 14:40:08.079: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770": Phase="Running", Reason="", readiness=true. Elapsed: 2.010411128s
    Feb 13 14:40:08.079: INFO: Pod "dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 14:40:08.079
    STEP: looking for the results for each expected name from probers 02/13/23 14:40:08.085
    Feb 13 14:40:08.099: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.107: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.115: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.123: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.130: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.138: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.152: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.160: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local from pod dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770: the server could not find the requested resource (get pods dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770)
    Feb 13 14:40:08.160: INFO: Lookups using dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7160.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7160.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7160.svc.cluster.local jessie_udp@dns-test-service-2.dns-7160.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7160.svc.cluster.local]

    Feb 13 14:40:13.223: INFO: DNS probes using dns-7160/dns-test-2c3f6b64-626d-46d8-944c-7edf5fbbc770 succeeded

    STEP: deleting the pod 02/13/23 14:40:13.223
    STEP: deleting the test headless service 02/13/23 14:40:13.237
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 14:40:13.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7160" for this suite. 02/13/23 14:40:13.258
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:13.279
Feb 13 14:40:13.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 14:40:13.281
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:13.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:13.304
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-bc9b7c86-2db2-4e9a-9e58-fbbfe88aa20a 02/13/23 14:40:13.307
STEP: Creating a pod to test consume secrets 02/13/23 14:40:13.311
W0213 14:40:13.319891      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:40:13.320: INFO: Waiting up to 5m0s for pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d" in namespace "secrets-9177" to be "Succeeded or Failed"
Feb 13 14:40:13.325: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.000519ms
Feb 13 14:40:15.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011837643s
Feb 13 14:40:17.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010935585s
STEP: Saw pod success 02/13/23 14:40:17.331
Feb 13 14:40:17.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d" satisfied condition "Succeeded or Failed"
Feb 13 14:40:17.334: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d container secret-env-test: <nil>
STEP: delete the pod 02/13/23 14:40:17.344
Feb 13 14:40:17.352: INFO: Waiting for pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d to disappear
Feb 13 14:40:17.355: INFO: Pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Feb 13 14:40:17.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9177" for this suite. 02/13/23 14:40:17.358
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":281,"skipped":5088,"failed":0}
------------------------------
• [4.087 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:13.279
    Feb 13 14:40:13.279: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 14:40:13.281
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:13.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:13.304
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-bc9b7c86-2db2-4e9a-9e58-fbbfe88aa20a 02/13/23 14:40:13.307
    STEP: Creating a pod to test consume secrets 02/13/23 14:40:13.311
    W0213 14:40:13.319891      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:40:13.320: INFO: Waiting up to 5m0s for pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d" in namespace "secrets-9177" to be "Succeeded or Failed"
    Feb 13 14:40:13.325: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.000519ms
    Feb 13 14:40:15.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011837643s
    Feb 13 14:40:17.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010935585s
    STEP: Saw pod success 02/13/23 14:40:17.331
    Feb 13 14:40:17.331: INFO: Pod "pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d" satisfied condition "Succeeded or Failed"
    Feb 13 14:40:17.334: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d container secret-env-test: <nil>
    STEP: delete the pod 02/13/23 14:40:17.344
    Feb 13 14:40:17.352: INFO: Waiting for pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d to disappear
    Feb 13 14:40:17.355: INFO: Pod pod-secrets-6e09c738-8228-467b-ab94-e26af22d652d no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 14:40:17.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9177" for this suite. 02/13/23 14:40:17.358
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:17.37
Feb 13 14:40:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 14:40:17.372
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:17.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:17.389
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 02/13/23 14:40:17.393
W0213 14:40:17.400673      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: delete the rc 02/13/23 14:40:22.405
STEP: wait for all pods to be garbage collected 02/13/23 14:40:22.413
STEP: Gathering metrics 02/13/23 14:40:27.427
W0213 14:40:27.441184      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 14:40:27.441: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 14:40:27.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7103" for this suite. 02/13/23 14:40:27.452
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":282,"skipped":5134,"failed":0}
------------------------------
• [SLOW TEST] [10.092 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:17.37
    Feb 13 14:40:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 14:40:17.372
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:17.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:17.389
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 02/13/23 14:40:17.393
    W0213 14:40:17.400673      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: delete the rc 02/13/23 14:40:22.405
    STEP: wait for all pods to be garbage collected 02/13/23 14:40:22.413
    STEP: Gathering metrics 02/13/23 14:40:27.427
    W0213 14:40:27.441184      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 14:40:27.441: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 14:40:27.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7103" for this suite. 02/13/23 14:40:27.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:27.463
Feb 13 14:40:27.463: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:40:27.464
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:27.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:27.494
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:40:27.511
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:40:27.887
STEP: Deploying the webhook pod 02/13/23 14:40:27.903
W0213 14:40:27.923193      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:40:27.923
Feb 13 14:40:27.933: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 02/13/23 14:40:29.954
STEP: Verifying the service has paired with the endpoint 02/13/23 14:40:29.969
Feb 13 14:40:30.970: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 02/13/23 14:40:30.976
Feb 13 14:40:31.005: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook 02/13/23 14:40:31.136
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:40:31.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4627" for this suite. 02/13/23 14:40:31.192
STEP: Destroying namespace "webhook-4627-markers" for this suite. 02/13/23 14:40:31.199
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":283,"skipped":5141,"failed":0}
------------------------------
• [3.781 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:27.463
    Feb 13 14:40:27.463: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:40:27.464
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:27.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:27.494
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:40:27.511
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:40:27.887
    STEP: Deploying the webhook pod 02/13/23 14:40:27.903
    W0213 14:40:27.923193      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:40:27.923
    Feb 13 14:40:27.933: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 02/13/23 14:40:29.954
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:40:29.969
    Feb 13 14:40:30.970: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 02/13/23 14:40:30.976
    Feb 13 14:40:31.005: INFO: Waiting for webhook configuration to be ready...
    STEP: create a configmap that should be updated by the webhook 02/13/23 14:40:31.136
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:40:31.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4627" for this suite. 02/13/23 14:40:31.192
    STEP: Destroying namespace "webhook-4627-markers" for this suite. 02/13/23 14:40:31.199
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:31.253
Feb 13 14:40:31.253: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 14:40:31.254
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:31.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:31.27
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 02/13/23 14:40:31.273
W0213 14:40:31.277423      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring job reaches completions 02/13/23 14:40:31.277
STEP: Ensuring pods with index for job exist 02/13/23 14:40:41.282
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 14:40:41.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9739" for this suite. 02/13/23 14:40:41.29
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":284,"skipped":5155,"failed":0}
------------------------------
• [SLOW TEST] [10.043 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:31.253
    Feb 13 14:40:31.253: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 14:40:31.254
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:31.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:31.27
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 02/13/23 14:40:31.273
    W0213 14:40:31.277423      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring job reaches completions 02/13/23 14:40:31.277
    STEP: Ensuring pods with index for job exist 02/13/23 14:40:41.282
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 14:40:41.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9739" for this suite. 02/13/23 14:40:41.29
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:41.297
Feb 13 14:40:41.297: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:40:41.298
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:41.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:41.315
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7ef2419f-47c2-4748-a69f-56af95dbff29 02/13/23 14:40:41.322
STEP: Creating the pod 02/13/23 14:40:41.33
W0213 14:40:41.339440      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:40:41.339: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1" in namespace "projected-2323" to be "running and ready"
Feb 13 14:40:41.346: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.408029ms
Feb 13 14:40:41.346: INFO: The phase of Pod pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:40:43.352: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012068662s
Feb 13 14:40:43.352: INFO: The phase of Pod pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1 is Running (Ready = true)
Feb 13 14:40:43.352: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-7ef2419f-47c2-4748-a69f-56af95dbff29 02/13/23 14:40:43.369
STEP: waiting to observe update in volume 02/13/23 14:40:43.377
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 14:40:45.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2323" for this suite. 02/13/23 14:40:45.407
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":285,"skipped":5161,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:41.297
    Feb 13 14:40:41.297: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:40:41.298
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:41.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:41.315
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-7ef2419f-47c2-4748-a69f-56af95dbff29 02/13/23 14:40:41.322
    STEP: Creating the pod 02/13/23 14:40:41.33
    W0213 14:40:41.339440      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:40:41.339: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1" in namespace "projected-2323" to be "running and ready"
    Feb 13 14:40:41.346: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.408029ms
    Feb 13 14:40:41.346: INFO: The phase of Pod pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:40:43.352: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012068662s
    Feb 13 14:40:43.352: INFO: The phase of Pod pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1 is Running (Ready = true)
    Feb 13 14:40:43.352: INFO: Pod "pod-projected-configmaps-1eb67469-c736-4804-af38-14ab198e99c1" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-7ef2419f-47c2-4748-a69f-56af95dbff29 02/13/23 14:40:43.369
    STEP: waiting to observe update in volume 02/13/23 14:40:43.377
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 14:40:45.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2323" for this suite. 02/13/23 14:40:45.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:45.415
Feb 13 14:40:45.415: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:40:45.417
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:45.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:45.439
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:40:45.444
W0213 14:40:45.455722      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:40:45.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939" in namespace "downward-api-5470" to be "Succeeded or Failed"
Feb 13 14:40:45.463: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Pending", Reason="", readiness=false. Elapsed: 7.52085ms
Feb 13 14:40:47.472: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015717682s
Feb 13 14:40:49.469: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012890431s
STEP: Saw pod success 02/13/23 14:40:49.469
Feb 13 14:40:49.470: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939" satisfied condition "Succeeded or Failed"
Feb 13 14:40:49.475: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 container client-container: <nil>
STEP: delete the pod 02/13/23 14:40:49.505
Feb 13 14:40:49.523: INFO: Waiting for pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 to disappear
Feb 13 14:40:49.527: INFO: Pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 14:40:49.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5470" for this suite. 02/13/23 14:40:49.533
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":286,"skipped":5167,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:45.415
    Feb 13 14:40:45.415: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:40:45.417
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:45.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:45.439
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:40:45.444
    W0213 14:40:45.455722      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:40:45.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939" in namespace "downward-api-5470" to be "Succeeded or Failed"
    Feb 13 14:40:45.463: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Pending", Reason="", readiness=false. Elapsed: 7.52085ms
    Feb 13 14:40:47.472: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015717682s
    Feb 13 14:40:49.469: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012890431s
    STEP: Saw pod success 02/13/23 14:40:49.469
    Feb 13 14:40:49.470: INFO: Pod "downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939" satisfied condition "Succeeded or Failed"
    Feb 13 14:40:49.475: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:40:49.505
    Feb 13 14:40:49.523: INFO: Waiting for pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 to disappear
    Feb 13 14:40:49.527: INFO: Pod downwardapi-volume-395aba03-3858-41c9-b978-8bcd34e09939 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 14:40:49.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5470" for this suite. 02/13/23 14:40:49.533
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:40:49.551
Feb 13 14:40:49.552: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:40:49.554
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:49.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:49.589
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 02/13/23 14:40:49.593
Feb 13 14:40:49.594: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: mark a version not serverd 02/13/23 14:40:56.031
STEP: check the unserved version gets removed 02/13/23 14:40:56.066
STEP: check the other version is not changed 02/13/23 14:40:58.726
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:41:03.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2160" for this suite. 02/13/23 14:41:03.53
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":287,"skipped":5185,"failed":0}
------------------------------
• [SLOW TEST] [13.993 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:40:49.551
    Feb 13 14:40:49.552: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:40:49.554
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:40:49.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:40:49.589
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 02/13/23 14:40:49.593
    Feb 13 14:40:49.594: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: mark a version not serverd 02/13/23 14:40:56.031
    STEP: check the unserved version gets removed 02/13/23 14:40:56.066
    STEP: check the other version is not changed 02/13/23 14:40:58.726
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:41:03.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2160" for this suite. 02/13/23 14:41:03.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:41:03.549
Feb 13 14:41:03.550: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:41:03.551
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:03.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:03.578
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:41:03.584
W0213 14:41:03.598140      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:03.598: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b" in namespace "projected-7737" to be "Succeeded or Failed"
Feb 13 14:41:03.604: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.847621ms
Feb 13 14:41:05.612: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01375792s
Feb 13 14:41:07.612: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014380071s
STEP: Saw pod success 02/13/23 14:41:07.613
Feb 13 14:41:07.613: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b" satisfied condition "Succeeded or Failed"
Feb 13 14:41:07.618: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b container client-container: <nil>
STEP: delete the pod 02/13/23 14:41:07.631
Feb 13 14:41:07.650: INFO: Waiting for pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b to disappear
Feb 13 14:41:07.661: INFO: Pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Feb 13 14:41:07.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7737" for this suite. 02/13/23 14:41:07.668
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":288,"skipped":5218,"failed":0}
------------------------------
• [4.130 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:41:03.549
    Feb 13 14:41:03.550: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:41:03.551
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:03.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:03.578
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:41:03.584
    W0213 14:41:03.598140      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:03.598: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b" in namespace "projected-7737" to be "Succeeded or Failed"
    Feb 13 14:41:03.604: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.847621ms
    Feb 13 14:41:05.612: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01375792s
    Feb 13 14:41:07.612: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014380071s
    STEP: Saw pod success 02/13/23 14:41:07.613
    Feb 13 14:41:07.613: INFO: Pod "downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b" satisfied condition "Succeeded or Failed"
    Feb 13 14:41:07.618: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b container client-container: <nil>
    STEP: delete the pod 02/13/23 14:41:07.631
    Feb 13 14:41:07.650: INFO: Waiting for pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b to disappear
    Feb 13 14:41:07.661: INFO: Pod downwardapi-volume-1080428f-4b86-4e07-9938-812006e8a04b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Feb 13 14:41:07.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7737" for this suite. 02/13/23 14:41:07.668
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:41:07.681
Feb 13 14:41:07.681: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename endpointslice 02/13/23 14:41:07.683
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:07.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:07.705
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 02/13/23 14:41:07.709
STEP: getting /apis/discovery.k8s.io 02/13/23 14:41:07.711
STEP: getting /apis/discovery.k8s.iov1 02/13/23 14:41:07.713
STEP: creating 02/13/23 14:41:07.714
STEP: getting 02/13/23 14:41:07.734
STEP: listing 02/13/23 14:41:07.737
STEP: watching 02/13/23 14:41:07.741
Feb 13 14:41:07.741: INFO: starting watch
STEP: cluster-wide listing 02/13/23 14:41:07.743
STEP: cluster-wide watching 02/13/23 14:41:07.746
Feb 13 14:41:07.746: INFO: starting watch
STEP: patching 02/13/23 14:41:07.749
STEP: updating 02/13/23 14:41:07.754
Feb 13 14:41:07.762: INFO: waiting for watch events with expected annotations
Feb 13 14:41:07.762: INFO: saw patched and updated annotations
STEP: deleting 02/13/23 14:41:07.762
STEP: deleting a collection 02/13/23 14:41:07.774
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Feb 13 14:41:07.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7865" for this suite. 02/13/23 14:41:07.787
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":289,"skipped":5233,"failed":0}
------------------------------
• [0.112 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:41:07.681
    Feb 13 14:41:07.681: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename endpointslice 02/13/23 14:41:07.683
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:07.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:07.705
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 02/13/23 14:41:07.709
    STEP: getting /apis/discovery.k8s.io 02/13/23 14:41:07.711
    STEP: getting /apis/discovery.k8s.iov1 02/13/23 14:41:07.713
    STEP: creating 02/13/23 14:41:07.714
    STEP: getting 02/13/23 14:41:07.734
    STEP: listing 02/13/23 14:41:07.737
    STEP: watching 02/13/23 14:41:07.741
    Feb 13 14:41:07.741: INFO: starting watch
    STEP: cluster-wide listing 02/13/23 14:41:07.743
    STEP: cluster-wide watching 02/13/23 14:41:07.746
    Feb 13 14:41:07.746: INFO: starting watch
    STEP: patching 02/13/23 14:41:07.749
    STEP: updating 02/13/23 14:41:07.754
    Feb 13 14:41:07.762: INFO: waiting for watch events with expected annotations
    Feb 13 14:41:07.762: INFO: saw patched and updated annotations
    STEP: deleting 02/13/23 14:41:07.762
    STEP: deleting a collection 02/13/23 14:41:07.774
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Feb 13 14:41:07.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7865" for this suite. 02/13/23 14:41:07.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:41:07.799
Feb 13 14:41:07.799: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 14:41:07.802
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:07.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:07.821
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-b13cb18b-aa3c-4a35-8c26-1820a6a1ff8a 02/13/23 14:41:07.829
STEP: Creating configMap with name cm-test-opt-upd-30c123d5-1bdf-4c43-ab6e-1dc6a4178487 02/13/23 14:41:07.837
STEP: Creating the pod 02/13/23 14:41:07.843
W0213 14:41:07.857732      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:07.858: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075" in namespace "projected-9434" to be "running and ready"
Feb 13 14:41:07.867: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075": Phase="Pending", Reason="", readiness=false. Elapsed: 8.857539ms
Feb 13 14:41:07.867: INFO: The phase of Pod pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:41:09.874: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075": Phase="Running", Reason="", readiness=true. Elapsed: 2.015981673s
Feb 13 14:41:09.874: INFO: The phase of Pod pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075 is Running (Ready = true)
Feb 13 14:41:09.874: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-b13cb18b-aa3c-4a35-8c26-1820a6a1ff8a 02/13/23 14:41:09.908
STEP: Updating configmap cm-test-opt-upd-30c123d5-1bdf-4c43-ab6e-1dc6a4178487 02/13/23 14:41:09.918
STEP: Creating configMap with name cm-test-opt-create-85a5900a-96b6-4050-944b-50a25a77282e 02/13/23 14:41:09.925
STEP: waiting to observe update in volume 02/13/23 14:41:09.931
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 14:41:13.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9434" for this suite. 02/13/23 14:41:13.994
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":290,"skipped":5260,"failed":0}
------------------------------
• [SLOW TEST] [6.202 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:41:07.799
    Feb 13 14:41:07.799: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 14:41:07.802
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:07.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:07.821
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-b13cb18b-aa3c-4a35-8c26-1820a6a1ff8a 02/13/23 14:41:07.829
    STEP: Creating configMap with name cm-test-opt-upd-30c123d5-1bdf-4c43-ab6e-1dc6a4178487 02/13/23 14:41:07.837
    STEP: Creating the pod 02/13/23 14:41:07.843
    W0213 14:41:07.857732      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:07.858: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075" in namespace "projected-9434" to be "running and ready"
    Feb 13 14:41:07.867: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075": Phase="Pending", Reason="", readiness=false. Elapsed: 8.857539ms
    Feb 13 14:41:07.867: INFO: The phase of Pod pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:41:09.874: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075": Phase="Running", Reason="", readiness=true. Elapsed: 2.015981673s
    Feb 13 14:41:09.874: INFO: The phase of Pod pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075 is Running (Ready = true)
    Feb 13 14:41:09.874: INFO: Pod "pod-projected-configmaps-7df00308-582c-4739-b36b-0555aec04075" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-b13cb18b-aa3c-4a35-8c26-1820a6a1ff8a 02/13/23 14:41:09.908
    STEP: Updating configmap cm-test-opt-upd-30c123d5-1bdf-4c43-ab6e-1dc6a4178487 02/13/23 14:41:09.918
    STEP: Creating configMap with name cm-test-opt-create-85a5900a-96b6-4050-944b-50a25a77282e 02/13/23 14:41:09.925
    STEP: waiting to observe update in volume 02/13/23 14:41:09.931
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 14:41:13.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9434" for this suite. 02/13/23 14:41:13.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:41:14.002
Feb 13 14:41:14.002: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename deployment 02/13/23 14:41:14.003
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:14.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:14.031
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 02/13/23 14:41:14.043
W0213 14:41:14.050420      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: waiting for Deployment to be created 02/13/23 14:41:14.051
STEP: waiting for all Replicas to be Ready 02/13/23 14:41:14.053
Feb 13 14:41:14.056: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.057: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.072: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.072: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.093: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.094: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.122: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:14.122: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Feb 13 14:41:15.450: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Feb 13 14:41:15.450: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Feb 13 14:41:15.732: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 02/13/23 14:41:15.732
W0213 14:41:15.742896      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
W0213 14:41:15.742949      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:15.747: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 02/13/23 14:41:15.747
Feb 13 14:41:15.749: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.752: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.762: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.762: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.788: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.788: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:15.796: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:15.797: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:15.807: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:15.807: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:17.493: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:17.493: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:17.519: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
STEP: listing Deployments 02/13/23 14:41:17.519
Feb 13 14:41:17.522: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 02/13/23 14:41:17.522
W0213 14:41:17.532371      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:17.536: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 02/13/23 14:41:17.536
Feb 13 14:41:17.549: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:17.552: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:17.581: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:17.612: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:17.624: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:18.539: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:18.593: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:18.616: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:18.663: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Feb 13 14:41:19.822: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 02/13/23 14:41:19.849
STEP: fetching the DeploymentStatus 02/13/23 14:41:19.857
Feb 13 14:41:19.862: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 3
STEP: deleting the Deployment 02/13/23 14:41:19.864
Feb 13 14:41:19.872: INFO: observed event type MODIFIED
Feb 13 14:41:19.872: INFO: observed event type MODIFIED
Feb 13 14:41:19.872: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
Feb 13 14:41:19.873: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Feb 13 14:41:19.881: INFO: Log out all the ReplicaSets if there is no deployment created
Feb 13 14:41:19.886: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8686  2603f952-d04f-48bb-859f-e7a5ec3bca7d 29915 4 2023-02-13 14:41:15 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1357 0xc003db1358}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1410 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Feb 13 14:41:19.889: INFO: pod: "test-deployment-54cc775c4b-x5pp7":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-x5pp7 test-deployment-54cc775c4b- deployment-8686  86fbe385-7c76-434d-9d50-6c75e2466405 29910 0 2023-02-13 14:41:15 +0000 UTC 2023-02-13 14:41:20 +0000 UTC 0xc003d85708 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 2603f952-d04f-48bb-859f-e7a5ec3bca7d 0xc003d85737 0xc003d85738}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2603f952-d04f-48bb-859f-e7a5ec3bca7d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.224\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xnxtg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xnxtg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.224,StartTime:2023-02-13 14:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://1559853f6996463b72da9ce0e20e8b075d8c45586f209d4c1201801fdb8dccdd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Feb 13 14:41:19.889: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8686  6eeeb58f-c810-4981-b64e-c206a8aadffe 29906 2 2023-02-13 14:41:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1497 0xc003db1498}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1520 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Feb 13 14:41:19.894: INFO: pod: "test-deployment-7c7d8d58c8-chd4d":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-chd4d test-deployment-7c7d8d58c8- deployment-8686  f5bffadb-9a9a-443e-a3b6-8e57bcfbde8a 29905 0 2023-02-13 14:41:18 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 6eeeb58f-c810-4981-b64e-c206a8aadffe 0xc003db19b7 0xc003db19b8}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6eeeb58f-c810-4981-b64e-c206a8aadffe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wwgk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wwgk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.85,StartTime:2023-02-13 14:41:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://59b96330207a18c2d61254531abe4e71943d9e94c35cb2bb8ec2948e7244514b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Feb 13 14:41:19.894: INFO: pod: "test-deployment-7c7d8d58c8-rhx96":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-rhx96 test-deployment-7c7d8d58c8- deployment-8686  9a0a5c64-024d-4183-8c0f-8b7768d1f411 29855 0 2023-02-13 14:41:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 6eeeb58f-c810-4981-b64e-c206a8aadffe 0xc003db1c97 0xc003db1c98}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6eeeb58f-c810-4981-b64e-c206a8aadffe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dlhj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dlhj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.225,StartTime:2023-02-13 14:41:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ae3d064295538a9e33228a5ac8349e0c24363138e76f51c820f01525628bd75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Feb 13 14:41:19.894: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8686  0552aa4e-424e-4f4a-8bfd-cf7406a4083d 29818 3 2023-02-13 14:41:14 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1597 0xc003db1598}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1630 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Feb 13 14:41:19.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8686" for this suite. 02/13/23 14:41:19.909
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":291,"skipped":5271,"failed":0}
------------------------------
• [SLOW TEST] [5.912 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:41:14.002
    Feb 13 14:41:14.002: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename deployment 02/13/23 14:41:14.003
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:14.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:14.031
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 02/13/23 14:41:14.043
    W0213 14:41:14.050420      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: waiting for Deployment to be created 02/13/23 14:41:14.051
    STEP: waiting for all Replicas to be Ready 02/13/23 14:41:14.053
    Feb 13 14:41:14.056: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.057: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.072: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.072: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.093: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.094: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.122: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:14.122: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Feb 13 14:41:15.450: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Feb 13 14:41:15.450: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Feb 13 14:41:15.732: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 02/13/23 14:41:15.732
    W0213 14:41:15.742896      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    W0213 14:41:15.742949      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:15.747: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 02/13/23 14:41:15.747
    Feb 13 14:41:15.749: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.750: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 0
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.751: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.752: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.762: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.762: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.788: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.788: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:15.796: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:15.797: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:15.807: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:15.807: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:17.493: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:17.493: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:17.519: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    STEP: listing Deployments 02/13/23 14:41:17.519
    Feb 13 14:41:17.522: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 02/13/23 14:41:17.522
    W0213 14:41:17.532371      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:17.536: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 02/13/23 14:41:17.536
    Feb 13 14:41:17.549: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:17.552: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:17.581: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:17.612: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:17.624: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:18.539: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:18.593: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:18.616: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:18.663: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Feb 13 14:41:19.822: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 02/13/23 14:41:19.849
    STEP: fetching the DeploymentStatus 02/13/23 14:41:19.857
    Feb 13 14:41:19.862: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 1
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:19.863: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 2
    Feb 13 14:41:19.864: INFO: observed Deployment test-deployment in namespace deployment-8686 with ReadyReplicas 3
    STEP: deleting the Deployment 02/13/23 14:41:19.864
    Feb 13 14:41:19.872: INFO: observed event type MODIFIED
    Feb 13 14:41:19.872: INFO: observed event type MODIFIED
    Feb 13 14:41:19.872: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    Feb 13 14:41:19.873: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Feb 13 14:41:19.881: INFO: Log out all the ReplicaSets if there is no deployment created
    Feb 13 14:41:19.886: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8686  2603f952-d04f-48bb-859f-e7a5ec3bca7d 29915 4 2023-02-13 14:41:15 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1357 0xc003db1358}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1410 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Feb 13 14:41:19.889: INFO: pod: "test-deployment-54cc775c4b-x5pp7":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-x5pp7 test-deployment-54cc775c4b- deployment-8686  86fbe385-7c76-434d-9d50-6c75e2466405 29910 0 2023-02-13 14:41:15 +0000 UTC 2023-02-13 14:41:20 +0000 UTC 0xc003d85708 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 2603f952-d04f-48bb-859f-e7a5ec3bca7d 0xc003d85737 0xc003d85738}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2603f952-d04f-48bb-859f-e7a5ec3bca7d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.224\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xnxtg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xnxtg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.224,StartTime:2023-02-13 14:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://1559853f6996463b72da9ce0e20e8b075d8c45586f209d4c1201801fdb8dccdd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Feb 13 14:41:19.889: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8686  6eeeb58f-c810-4981-b64e-c206a8aadffe 29906 2 2023-02-13 14:41:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1497 0xc003db1498}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1520 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Feb 13 14:41:19.894: INFO: pod: "test-deployment-7c7d8d58c8-chd4d":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-chd4d test-deployment-7c7d8d58c8- deployment-8686  f5bffadb-9a9a-443e-a3b6-8e57bcfbde8a 29905 0 2023-02-13 14:41:18 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 6eeeb58f-c810-4981-b64e-c206a8aadffe 0xc003db19b7 0xc003db19b8}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6eeeb58f-c810-4981-b64e-c206a8aadffe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wwgk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wwgk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-o7jrw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:10.244.0.85,StartTime:2023-02-13 14:41:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://59b96330207a18c2d61254531abe4e71943d9e94c35cb2bb8ec2948e7244514b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Feb 13 14:41:19.894: INFO: pod: "test-deployment-7c7d8d58c8-rhx96":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-rhx96 test-deployment-7c7d8d58c8- deployment-8686  9a0a5c64-024d-4183-8c0f-8b7768d1f411 29855 0 2023-02-13 14:41:17 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 6eeeb58f-c810-4981-b64e-c206a8aadffe 0xc003db1c97 0xc003db1c98}] [] [{kube-controller-manager Update v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6eeeb58f-c810-4981-b64e-c206a8aadffe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-02-13 14:41:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dlhj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dlhj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-5500-0ccfa5-pool-bf9f-vfwrl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-02-13 14:41:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.10,PodIP:10.244.2.225,StartTime:2023-02-13 14:41:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-02-13 14:41:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ae3d064295538a9e33228a5ac8349e0c24363138e76f51c820f01525628bd75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Feb 13 14:41:19.894: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8686  0552aa4e-424e-4f4a-8bfd-cf7406a4083d 29818 3 2023-02-13 14:41:14 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 9935280a-3cae-4840-950d-cd5f4262a27a 0xc003db1597 0xc003db1598}] [] [{kube-controller-manager Update apps/v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9935280a-3cae-4840-950d-cd5f4262a27a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-02-13 14:41:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003db1630 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Feb 13 14:41:19.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8686" for this suite. 02/13/23 14:41:19.909
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:41:19.917
Feb 13 14:41:19.917: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 14:41:19.918
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:19.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:19.932
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1046 02/13/23 14:41:19.935
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 02/13/23 14:41:19.941
W0213 14:41:19.946139      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:19.949: INFO: Found 0 stateful pods, waiting for 3
Feb 13 14:41:29.957: INFO: Found 2 stateful pods, waiting for 3
Feb 13 14:41:39.954: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:41:39.954: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:41:39.954: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:41:39.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:41:40.213: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:41:40.213: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:41:40.213: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 02/13/23 14:41:50.235
W0213 14:41:50.264180      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:41:50.264: INFO: Updating stateful set ss2
STEP: Creating a new revision 02/13/23 14:41:50.265
STEP: Updating Pods in reverse ordinal order 02/13/23 14:42:00.29
Feb 13 14:42:00.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:42:00.555: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:42:00.555: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:42:00.555: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 02/13/23 14:42:20.589
Feb 13 14:42:20.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:42:20.865: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:42:20.865: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:42:20.865: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

W0213 14:42:30.919012      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:42:30.919: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 02/13/23 14:42:40.948
Feb 13 14:42:40.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:42:41.210: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:42:41.210: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:42:41.210: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 14:42:51.251: INFO: Deleting all statefulset in ns statefulset-1046
Feb 13 14:42:51.256: INFO: Scaling statefulset ss2 to 0
W0213 14:42:51.272839      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:43:01.286: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:43:01.291: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 14:43:01.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1046" for this suite. 02/13/23 14:43:01.32
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":292,"skipped":5291,"failed":0}
------------------------------
• [SLOW TEST] [101.409 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:41:19.917
    Feb 13 14:41:19.917: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 14:41:19.918
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:41:19.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:41:19.932
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1046 02/13/23 14:41:19.935
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 02/13/23 14:41:19.941
    W0213 14:41:19.946139      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:19.949: INFO: Found 0 stateful pods, waiting for 3
    Feb 13 14:41:29.957: INFO: Found 2 stateful pods, waiting for 3
    Feb 13 14:41:39.954: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:41:39.954: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:41:39.954: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:41:39.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:41:40.213: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:41:40.213: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:41:40.213: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 02/13/23 14:41:50.235
    W0213 14:41:50.264180      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:41:50.264: INFO: Updating stateful set ss2
    STEP: Creating a new revision 02/13/23 14:41:50.265
    STEP: Updating Pods in reverse ordinal order 02/13/23 14:42:00.29
    Feb 13 14:42:00.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:42:00.555: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:42:00.555: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:42:00.555: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 02/13/23 14:42:20.589
    Feb 13 14:42:20.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:42:20.865: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:42:20.865: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:42:20.865: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    W0213 14:42:30.919012      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:42:30.919: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 02/13/23 14:42:40.948
    Feb 13 14:42:40.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-1046 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:42:41.210: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:42:41.210: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:42:41.210: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 14:42:51.251: INFO: Deleting all statefulset in ns statefulset-1046
    Feb 13 14:42:51.256: INFO: Scaling statefulset ss2 to 0
    W0213 14:42:51.272839      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:43:01.286: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:43:01.291: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 14:43:01.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1046" for this suite. 02/13/23 14:43:01.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:43:01.335
Feb 13 14:43:01.335: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:43:01.336
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:01.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:01.353
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 02/13/23 14:43:01.356
Feb 13 14:43:01.358: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: rename a version 02/13/23 14:43:07.576
STEP: check the new version name is served 02/13/23 14:43:07.596
STEP: check the old version name is removed 02/13/23 14:43:10.238
STEP: check the other version is not changed 02/13/23 14:43:11.598
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:43:16.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9216" for this suite. 02/13/23 14:43:16.459
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":293,"skipped":5312,"failed":0}
------------------------------
• [SLOW TEST] [15.135 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:43:01.335
    Feb 13 14:43:01.335: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:43:01.336
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:01.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:01.353
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 02/13/23 14:43:01.356
    Feb 13 14:43:01.358: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: rename a version 02/13/23 14:43:07.576
    STEP: check the new version name is served 02/13/23 14:43:07.596
    STEP: check the old version name is removed 02/13/23 14:43:10.238
    STEP: check the other version is not changed 02/13/23 14:43:11.598
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:43:16.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9216" for this suite. 02/13/23 14:43:16.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:43:16.47
Feb 13 14:43:16.470: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 14:43:16.471
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:16.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:16.492
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6118.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6118.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 02/13/23 14:43:16.497
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6118.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6118.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 02/13/23 14:43:16.497
STEP: creating a pod to probe /etc/hosts 02/13/23 14:43:16.497
STEP: submitting the pod to kubernetes 02/13/23 14:43:16.497
W0213 14:43:16.506770      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:43:16.507: INFO: Waiting up to 15m0s for pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278" in namespace "dns-6118" to be "running"
Feb 13 14:43:16.515: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278": Phase="Pending", Reason="", readiness=false. Elapsed: 7.72399ms
Feb 13 14:43:18.521: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278": Phase="Running", Reason="", readiness=true. Elapsed: 2.014164484s
Feb 13 14:43:18.521: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278" satisfied condition "running"
STEP: retrieving the pod 02/13/23 14:43:18.521
STEP: looking for the results for each expected name from probers 02/13/23 14:43:18.525
Feb 13 14:43:18.554: INFO: DNS probes using dns-6118/dns-test-9815edfe-020c-4bf3-aa27-6765b7904278 succeeded

STEP: deleting the pod 02/13/23 14:43:18.554
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 14:43:18.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6118" for this suite. 02/13/23 14:43:18.572
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":294,"skipped":5317,"failed":0}
------------------------------
• [2.109 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:43:16.47
    Feb 13 14:43:16.470: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 14:43:16.471
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:16.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:16.492
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6118.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6118.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     02/13/23 14:43:16.497
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6118.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6118.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     02/13/23 14:43:16.497
    STEP: creating a pod to probe /etc/hosts 02/13/23 14:43:16.497
    STEP: submitting the pod to kubernetes 02/13/23 14:43:16.497
    W0213 14:43:16.506770      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:43:16.507: INFO: Waiting up to 15m0s for pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278" in namespace "dns-6118" to be "running"
    Feb 13 14:43:16.515: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278": Phase="Pending", Reason="", readiness=false. Elapsed: 7.72399ms
    Feb 13 14:43:18.521: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278": Phase="Running", Reason="", readiness=true. Elapsed: 2.014164484s
    Feb 13 14:43:18.521: INFO: Pod "dns-test-9815edfe-020c-4bf3-aa27-6765b7904278" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 14:43:18.521
    STEP: looking for the results for each expected name from probers 02/13/23 14:43:18.525
    Feb 13 14:43:18.554: INFO: DNS probes using dns-6118/dns-test-9815edfe-020c-4bf3-aa27-6765b7904278 succeeded

    STEP: deleting the pod 02/13/23 14:43:18.554
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 14:43:18.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6118" for this suite. 02/13/23 14:43:18.572
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:43:18.593
Feb 13 14:43:18.594: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:43:18.595
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:18.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:18.618
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:43:18.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2539" for this suite. 02/13/23 14:43:18.632
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":295,"skipped":5440,"failed":0}
------------------------------
• [0.047 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:43:18.593
    Feb 13 14:43:18.594: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:43:18.595
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:18.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:18.618
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:43:18.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2539" for this suite. 02/13/23 14:43:18.632
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:43:18.648
Feb 13 14:43:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:43:18.65
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:18.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:18.674
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-68a8d119-bbc0-44d3-bc10-4e4ae9b47fe7 02/13/23 14:43:18.682
STEP: Creating a pod to test consume configMaps 02/13/23 14:43:18.694
W0213 14:43:18.702642      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:43:18.703: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e" in namespace "configmap-5499" to be "Succeeded or Failed"
Feb 13 14:43:18.710: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.007841ms
Feb 13 14:43:20.715: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012290065s
Feb 13 14:43:22.717: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013438013s
STEP: Saw pod success 02/13/23 14:43:22.717
Feb 13 14:43:22.717: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e" satisfied condition "Succeeded or Failed"
Feb 13 14:43:22.720: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e container agnhost-container: <nil>
STEP: delete the pod 02/13/23 14:43:22.745
Feb 13 14:43:22.759: INFO: Waiting for pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e to disappear
Feb 13 14:43:22.762: INFO: Pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:43:22.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5499" for this suite. 02/13/23 14:43:22.767
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":296,"skipped":5449,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:43:18.648
    Feb 13 14:43:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:43:18.65
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:18.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:18.674
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-68a8d119-bbc0-44d3-bc10-4e4ae9b47fe7 02/13/23 14:43:18.682
    STEP: Creating a pod to test consume configMaps 02/13/23 14:43:18.694
    W0213 14:43:18.702642      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:43:18.703: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e" in namespace "configmap-5499" to be "Succeeded or Failed"
    Feb 13 14:43:18.710: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.007841ms
    Feb 13 14:43:20.715: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012290065s
    Feb 13 14:43:22.717: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013438013s
    STEP: Saw pod success 02/13/23 14:43:22.717
    Feb 13 14:43:22.717: INFO: Pod "pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e" satisfied condition "Succeeded or Failed"
    Feb 13 14:43:22.720: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 14:43:22.745
    Feb 13 14:43:22.759: INFO: Waiting for pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e to disappear
    Feb 13 14:43:22.762: INFO: Pod pod-configmaps-6c187e07-eec9-482b-b627-0a0c16b2215e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:43:22.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5499" for this suite. 02/13/23 14:43:22.767
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:43:22.783
Feb 13 14:43:22.783: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:43:22.785
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:22.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:22.805
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-4491 02/13/23 14:43:22.809
W0213 14:43:22.817592      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:43:22.818: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4491" to be "running and ready"
Feb 13 14:43:22.825: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.996808ms
Feb 13 14:43:22.825: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:43:24.830: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011661819s
Feb 13 14:43:24.830: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Feb 13 14:43:24.830: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Feb 13 14:43:24.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Feb 13 14:43:25.086: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Feb 13 14:43:25.086: INFO: stdout: "iptables"
Feb 13 14:43:25.086: INFO: proxyMode: iptables
Feb 13 14:43:25.105: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Feb 13 14:43:25.109: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-4491 02/13/23 14:43:25.109
STEP: creating replication controller affinity-clusterip-timeout in namespace services-4491 02/13/23 14:43:25.124
W0213 14:43:25.132098      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip-timeout" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip-timeout" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip-timeout" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip-timeout" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:43:25.132969      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-4491, replica count: 3
I0213 14:43:28.185240      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:43:28.193: INFO: Creating new exec pod
W0213 14:43:28.201167      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:43:28.201: INFO: Waiting up to 5m0s for pod "execpod-affinityrbxpd" in namespace "services-4491" to be "running"
Feb 13 14:43:28.210: INFO: Pod "execpod-affinityrbxpd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.094629ms
Feb 13 14:43:30.216: INFO: Pod "execpod-affinityrbxpd": Phase="Running", Reason="", readiness=true. Elapsed: 2.014623677s
Feb 13 14:43:30.216: INFO: Pod "execpod-affinityrbxpd" satisfied condition "running"
Feb 13 14:43:31.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Feb 13 14:43:31.485: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Feb 13 14:43:31.485: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:43:31.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.67.195 80'
Feb 13 14:43:31.735: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.67.195 80\nConnection to 10.108.67.195 80 port [tcp/http] succeeded!\n"
Feb 13 14:43:31.735: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:43:31.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.67.195:80/ ; done'
Feb 13 14:43:32.084: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
Feb 13 14:43:32.084: INFO: stdout: "\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl"
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
Feb 13 14:43:32.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:43:32.372: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
Feb 13 14:43:32.372: INFO: stdout: "affinity-clusterip-timeout-v2hxl"
Feb 13 14:43:52.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:43:54.657: INFO: rc: 28
Feb 13 14:43:54.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:43:56.919: INFO: rc: 28
Feb 13 14:43:56.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:43:59.180: INFO: rc: 28
Feb 13 14:43:59.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:44:01.463: INFO: rc: 28
Feb 13 14:44:01.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
Feb 13 14:44:01.714: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
Feb 13 14:44:01.715: INFO: stdout: "affinity-clusterip-timeout-75gxj"
Feb 13 14:44:01.715: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-4491, will wait for the garbage collector to delete the pods 02/13/23 14:44:01.738
Feb 13 14:44:01.803: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 9.326777ms
Feb 13 14:44:01.904: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.072893ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:44:04.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4491" for this suite. 02/13/23 14:44:04.141
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":297,"skipped":5514,"failed":0}
------------------------------
• [SLOW TEST] [41.368 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:43:22.783
    Feb 13 14:43:22.783: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:43:22.785
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:43:22.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:43:22.805
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-4491 02/13/23 14:43:22.809
    W0213 14:43:22.817592      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:43:22.818: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4491" to be "running and ready"
    Feb 13 14:43:22.825: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.996808ms
    Feb 13 14:43:22.825: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:43:24.830: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011661819s
    Feb 13 14:43:24.830: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Feb 13 14:43:24.830: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Feb 13 14:43:24.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Feb 13 14:43:25.086: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Feb 13 14:43:25.086: INFO: stdout: "iptables"
    Feb 13 14:43:25.086: INFO: proxyMode: iptables
    Feb 13 14:43:25.105: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Feb 13 14:43:25.109: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-4491 02/13/23 14:43:25.109
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-4491 02/13/23 14:43:25.124
    W0213 14:43:25.132098      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip-timeout" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip-timeout" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip-timeout" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip-timeout" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:43:25.132969      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-4491, replica count: 3
    I0213 14:43:28.185240      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:43:28.193: INFO: Creating new exec pod
    W0213 14:43:28.201167      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:43:28.201: INFO: Waiting up to 5m0s for pod "execpod-affinityrbxpd" in namespace "services-4491" to be "running"
    Feb 13 14:43:28.210: INFO: Pod "execpod-affinityrbxpd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.094629ms
    Feb 13 14:43:30.216: INFO: Pod "execpod-affinityrbxpd": Phase="Running", Reason="", readiness=true. Elapsed: 2.014623677s
    Feb 13 14:43:30.216: INFO: Pod "execpod-affinityrbxpd" satisfied condition "running"
    Feb 13 14:43:31.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Feb 13 14:43:31.485: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Feb 13 14:43:31.485: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:43:31.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.67.195 80'
    Feb 13 14:43:31.735: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.67.195 80\nConnection to 10.108.67.195 80 port [tcp/http] succeeded!\n"
    Feb 13 14:43:31.735: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:43:31.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.67.195:80/ ; done'
    Feb 13 14:43:32.084: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
    Feb 13 14:43:32.084: INFO: stdout: "\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl\naffinity-clusterip-timeout-v2hxl"
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Received response from host: affinity-clusterip-timeout-v2hxl
    Feb 13 14:43:32.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:43:32.372: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
    Feb 13 14:43:32.372: INFO: stdout: "affinity-clusterip-timeout-v2hxl"
    Feb 13 14:43:52.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:43:54.657: INFO: rc: 28
    Feb 13 14:43:54.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:43:56.919: INFO: rc: 28
    Feb 13 14:43:56.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:43:59.180: INFO: rc: 28
    Feb 13 14:43:59.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:44:01.463: INFO: rc: 28
    Feb 13 14:44:01.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-4491 exec execpod-affinityrbxpd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.108.67.195:80/'
    Feb 13 14:44:01.714: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.108.67.195:80/\n"
    Feb 13 14:44:01.715: INFO: stdout: "affinity-clusterip-timeout-75gxj"
    Feb 13 14:44:01.715: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-4491, will wait for the garbage collector to delete the pods 02/13/23 14:44:01.738
    Feb 13 14:44:01.803: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 9.326777ms
    Feb 13 14:44:01.904: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.072893ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:44:04.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4491" for this suite. 02/13/23 14:44:04.141
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:44:04.168
Feb 13 14:44:04.169: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 14:44:04.172
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:44:04.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:44:04.201
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-242 02/13/23 14:44:04.207
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 02/13/23 14:44:04.218
STEP: Creating stateful set ss in namespace statefulset-242 02/13/23 14:44:04.226
W0213 14:44:04.234215      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-242 02/13/23 14:44:04.234
Feb 13 14:44:04.241: INFO: Found 0 stateful pods, waiting for 1
Feb 13 14:44:14.249: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 02/13/23 14:44:14.249
Feb 13 14:44:14.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:44:14.533: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:44:14.533: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:44:14.533: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:44:14.541: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 14:44:24.549: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:44:24.549: INFO: Waiting for statefulset status.replicas updated to 0
W0213 14:44:24.568023      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:44:24.575: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999074s
Feb 13 14:44:25.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993003301s
Feb 13 14:44:26.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.986021601s
Feb 13 14:44:27.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975531966s
Feb 13 14:44:28.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968809581s
Feb 13 14:44:29.610: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.963434702s
Feb 13 14:44:30.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.957059789s
Feb 13 14:44:31.624: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.950286262s
Feb 13 14:44:32.630: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.943247638s
Feb 13 14:44:33.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.69913ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-242 02/13/23 14:44:34.637
Feb 13 14:44:34.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:44:34.915: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:44:34.915: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:44:34.915: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:44:34.920: INFO: Found 1 stateful pods, waiting for 3
Feb 13 14:44:44.929: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:44:44.929: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:44:44.929: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 02/13/23 14:44:44.929
STEP: Scale down will halt with unhealthy stateful pod 02/13/23 14:44:44.929
Feb 13 14:44:44.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:44:45.191: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:44:45.191: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:44:45.191: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:44:45.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:44:45.439: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:44:45.439: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:44:45.439: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:44:45.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 13 14:44:45.679: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 13 14:44:45.679: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 13 14:44:45.679: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 13 14:44:45.679: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:44:45.685: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 13 14:44:55.699: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:44:55.699: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:44:55.699: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
W0213 14:44:55.716319      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:44:55.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999917s
Feb 13 14:44:56.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996105751s
Feb 13 14:44:57.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986600189s
Feb 13 14:44:58.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978229496s
Feb 13 14:44:59.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971857099s
Feb 13 14:45:00.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964521446s
Feb 13 14:45:01.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.957089843s
Feb 13 14:45:02.772: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.950297194s
Feb 13 14:45:03.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.94348082s
Feb 13 14:45:04.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 934.677496ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-242 02/13/23 14:45:05.788
Feb 13 14:45:05.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:45:06.058: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:45:06.058: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:45:06.058: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:45:06.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:45:06.300: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:45:06.300: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:45:06.300: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:45:06.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 13 14:45:06.552: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 13 14:45:06.552: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 13 14:45:06.552: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 13 14:45:06.552: INFO: Scaling statefulset ss to 0
W0213 14:45:06.566918      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Verifying that stateful set ss was scaled down in reverse order 02/13/23 14:45:16.581
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 14:45:16.581: INFO: Deleting all statefulset in ns statefulset-242
Feb 13 14:45:16.586: INFO: Scaling statefulset ss to 0
W0213 14:45:16.602628      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:45:16.608: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:45:16.612: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 14:45:16.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-242" for this suite. 02/13/23 14:45:16.639
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":298,"skipped":5519,"failed":0}
------------------------------
• [SLOW TEST] [72.483 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:44:04.168
    Feb 13 14:44:04.169: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 14:44:04.172
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:44:04.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:44:04.201
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-242 02/13/23 14:44:04.207
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 02/13/23 14:44:04.218
    STEP: Creating stateful set ss in namespace statefulset-242 02/13/23 14:44:04.226
    W0213 14:44:04.234215      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-242 02/13/23 14:44:04.234
    Feb 13 14:44:04.241: INFO: Found 0 stateful pods, waiting for 1
    Feb 13 14:44:14.249: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 02/13/23 14:44:14.249
    Feb 13 14:44:14.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:44:14.533: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:44:14.533: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:44:14.533: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:44:14.541: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Feb 13 14:44:24.549: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:44:24.549: INFO: Waiting for statefulset status.replicas updated to 0
    W0213 14:44:24.568023      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:44:24.575: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999074s
    Feb 13 14:44:25.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993003301s
    Feb 13 14:44:26.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.986021601s
    Feb 13 14:44:27.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975531966s
    Feb 13 14:44:28.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968809581s
    Feb 13 14:44:29.610: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.963434702s
    Feb 13 14:44:30.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.957059789s
    Feb 13 14:44:31.624: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.950286262s
    Feb 13 14:44:32.630: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.943247638s
    Feb 13 14:44:33.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.69913ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-242 02/13/23 14:44:34.637
    Feb 13 14:44:34.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:44:34.915: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:44:34.915: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:44:34.915: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:44:34.920: INFO: Found 1 stateful pods, waiting for 3
    Feb 13 14:44:44.929: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:44:44.929: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Feb 13 14:44:44.929: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 02/13/23 14:44:44.929
    STEP: Scale down will halt with unhealthy stateful pod 02/13/23 14:44:44.929
    Feb 13 14:44:44.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:44:45.191: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:44:45.191: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:44:45.191: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:44:45.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:44:45.439: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:44:45.439: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:44:45.439: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:44:45.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Feb 13 14:44:45.679: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Feb 13 14:44:45.679: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Feb 13 14:44:45.679: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Feb 13 14:44:45.679: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:44:45.685: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Feb 13 14:44:55.699: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:44:55.699: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Feb 13 14:44:55.699: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    W0213 14:44:55.716319      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:44:55.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999917s
    Feb 13 14:44:56.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996105751s
    Feb 13 14:44:57.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986600189s
    Feb 13 14:44:58.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978229496s
    Feb 13 14:44:59.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971857099s
    Feb 13 14:45:00.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964521446s
    Feb 13 14:45:01.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.957089843s
    Feb 13 14:45:02.772: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.950297194s
    Feb 13 14:45:03.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.94348082s
    Feb 13 14:45:04.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 934.677496ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-242 02/13/23 14:45:05.788
    Feb 13 14:45:05.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:45:06.058: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:45:06.058: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:45:06.058: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:45:06.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:45:06.300: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:45:06.300: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:45:06.300: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:45:06.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=statefulset-242 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Feb 13 14:45:06.552: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Feb 13 14:45:06.552: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Feb 13 14:45:06.552: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Feb 13 14:45:06.552: INFO: Scaling statefulset ss to 0
    W0213 14:45:06.566918      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Verifying that stateful set ss was scaled down in reverse order 02/13/23 14:45:16.581
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 14:45:16.581: INFO: Deleting all statefulset in ns statefulset-242
    Feb 13 14:45:16.586: INFO: Scaling statefulset ss to 0
    W0213 14:45:16.602628      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:45:16.608: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:45:16.612: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 14:45:16.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-242" for this suite. 02/13/23 14:45:16.639
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:45:16.65
Feb 13 14:45:16.651: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:45:16.653
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:16.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:16.678
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 02/13/23 14:45:16.681
W0213 14:45:16.691447      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:45:16.691: INFO: Waiting up to 5m0s for pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac" in namespace "downward-api-3390" to be "running and ready"
Feb 13 14:45:16.702: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670513ms
Feb 13 14:45:16.702: INFO: The phase of Pod annotationupdate94dba439-0b85-487d-9078-383fadab81ac is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:45:18.710: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac": Phase="Running", Reason="", readiness=true. Elapsed: 2.018842311s
Feb 13 14:45:18.710: INFO: The phase of Pod annotationupdate94dba439-0b85-487d-9078-383fadab81ac is Running (Ready = true)
Feb 13 14:45:18.710: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac" satisfied condition "running and ready"
Feb 13 14:45:19.274: INFO: Successfully updated pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 14:45:23.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3390" for this suite. 02/13/23 14:45:23.323
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":299,"skipped":5520,"failed":0}
------------------------------
• [SLOW TEST] [6.685 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:45:16.65
    Feb 13 14:45:16.651: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:45:16.653
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:16.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:16.678
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 02/13/23 14:45:16.681
    W0213 14:45:16.691447      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:45:16.691: INFO: Waiting up to 5m0s for pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac" in namespace "downward-api-3390" to be "running and ready"
    Feb 13 14:45:16.702: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670513ms
    Feb 13 14:45:16.702: INFO: The phase of Pod annotationupdate94dba439-0b85-487d-9078-383fadab81ac is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:45:18.710: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac": Phase="Running", Reason="", readiness=true. Elapsed: 2.018842311s
    Feb 13 14:45:18.710: INFO: The phase of Pod annotationupdate94dba439-0b85-487d-9078-383fadab81ac is Running (Ready = true)
    Feb 13 14:45:18.710: INFO: Pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac" satisfied condition "running and ready"
    Feb 13 14:45:19.274: INFO: Successfully updated pod "annotationupdate94dba439-0b85-487d-9078-383fadab81ac"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 14:45:23.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3390" for this suite. 02/13/23 14:45:23.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:45:23.342
Feb 13 14:45:23.343: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 14:45:23.344
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:23.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:23.371
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 02/13/23 14:45:23.377
W0213 14:45:23.390703      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:45:23.391: INFO: Waiting up to 5m0s for pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305" in namespace "emptydir-4182" to be "Succeeded or Failed"
Feb 13 14:45:23.397: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Pending", Reason="", readiness=false. Elapsed: 5.747947ms
Feb 13 14:45:25.403: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011649001s
Feb 13 14:45:27.405: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014167165s
STEP: Saw pod success 02/13/23 14:45:27.405
Feb 13 14:45:27.406: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305" satisfied condition "Succeeded or Failed"
Feb 13 14:45:27.411: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 container test-container: <nil>
STEP: delete the pod 02/13/23 14:45:27.425
Feb 13 14:45:27.438: INFO: Waiting for pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 to disappear
Feb 13 14:45:27.442: INFO: Pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 14:45:27.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4182" for this suite. 02/13/23 14:45:27.447
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":300,"skipped":5534,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:45:23.342
    Feb 13 14:45:23.343: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 14:45:23.344
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:23.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:23.371
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 02/13/23 14:45:23.377
    W0213 14:45:23.390703      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:45:23.391: INFO: Waiting up to 5m0s for pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305" in namespace "emptydir-4182" to be "Succeeded or Failed"
    Feb 13 14:45:23.397: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Pending", Reason="", readiness=false. Elapsed: 5.747947ms
    Feb 13 14:45:25.403: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011649001s
    Feb 13 14:45:27.405: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014167165s
    STEP: Saw pod success 02/13/23 14:45:27.405
    Feb 13 14:45:27.406: INFO: Pod "pod-922fb3ea-7190-43f5-9ade-9d78f3369305" satisfied condition "Succeeded or Failed"
    Feb 13 14:45:27.411: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 container test-container: <nil>
    STEP: delete the pod 02/13/23 14:45:27.425
    Feb 13 14:45:27.438: INFO: Waiting for pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 to disappear
    Feb 13 14:45:27.442: INFO: Pod pod-922fb3ea-7190-43f5-9ade-9d78f3369305 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:45:27.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4182" for this suite. 02/13/23 14:45:27.447
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:45:27.458
Feb 13 14:45:27.458: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:45:27.461
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:27.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:27.482
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
W0213 14:45:27.500505      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:45:27.500: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7177 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Feb 13 14:45:27.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7177" for this suite. 02/13/23 14:45:27.522
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":301,"skipped":5562,"failed":0}
------------------------------
• [0.072 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:45:27.458
    Feb 13 14:45:27.458: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename runtimeclass 02/13/23 14:45:27.461
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:27.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:27.482
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    W0213 14:45:27.500505      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:45:27.500: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7177 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Feb 13 14:45:27.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7177" for this suite. 02/13/23 14:45:27.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:45:27.531
Feb 13 14:45:27.531: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename daemonsets 02/13/23 14:45:27.534
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:27.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:27.554
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Feb 13 14:45:27.581: INFO: Creating daemon "daemon-set" with a node selector
W0213 14:45:27.588764      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Initially, daemon pods should not be running on any nodes. 02/13/23 14:45:27.589
Feb 13 14:45:27.597: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:27.597: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 02/13/23 14:45:27.597
Feb 13 14:45:27.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:27.620: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:28.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:28.627: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:29.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Feb 13 14:45:29.627: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 02/13/23 14:45:29.634
Feb 13 14:45:29.661: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Feb 13 14:45:29.661: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Feb 13 14:45:30.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:30.667: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 02/13/23 14:45:30.667
W0213 14:45:30.680492      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:45:30.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:30.688: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:31.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:31.694: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:32.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:32.695: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:33.708: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:33.708: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:34.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:34.695: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
Feb 13 14:45:35.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Feb 13 14:45:35.696: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:45:35.706
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2837, will wait for the garbage collector to delete the pods 02/13/23 14:45:35.706
Feb 13 14:45:35.770: INFO: Deleting DaemonSet.extensions daemon-set took: 8.568073ms
Feb 13 14:45:35.871: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.995409ms
Feb 13 14:45:38.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Feb 13 14:45:38.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Feb 13 14:45:38.483: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31434"},"items":null}

Feb 13 14:45:38.488: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31434"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:45:38.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2837" for this suite. 02/13/23 14:45:38.524
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":302,"skipped":5568,"failed":0}
------------------------------
• [SLOW TEST] [10.999 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:45:27.531
    Feb 13 14:45:27.531: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename daemonsets 02/13/23 14:45:27.534
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:27.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:27.554
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Feb 13 14:45:27.581: INFO: Creating daemon "daemon-set" with a node selector
    W0213 14:45:27.588764      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Initially, daemon pods should not be running on any nodes. 02/13/23 14:45:27.589
    Feb 13 14:45:27.597: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:27.597: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 02/13/23 14:45:27.597
    Feb 13 14:45:27.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:27.620: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:28.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:28.627: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:29.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Feb 13 14:45:29.627: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 02/13/23 14:45:29.634
    Feb 13 14:45:29.661: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Feb 13 14:45:29.661: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Feb 13 14:45:30.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:30.667: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 02/13/23 14:45:30.667
    W0213 14:45:30.680492      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:45:30.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:30.688: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:31.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:31.694: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:32.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:32.695: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:33.708: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:33.708: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:34.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:34.695: INFO: Node conformance-5500-0ccfa5-pool-bf9f-vfwrl is running 0 daemon pod, expected 1
    Feb 13 14:45:35.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Feb 13 14:45:35.696: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 02/13/23 14:45:35.706
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2837, will wait for the garbage collector to delete the pods 02/13/23 14:45:35.706
    Feb 13 14:45:35.770: INFO: Deleting DaemonSet.extensions daemon-set took: 8.568073ms
    Feb 13 14:45:35.871: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.995409ms
    Feb 13 14:45:38.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Feb 13 14:45:38.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Feb 13 14:45:38.483: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31434"},"items":null}

    Feb 13 14:45:38.488: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31434"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:45:38.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2837" for this suite. 02/13/23 14:45:38.524
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:45:38.531
Feb 13 14:45:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename cronjob 02/13/23 14:45:38.532
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:38.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:38.552
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 02/13/23 14:45:38.554
W0213 14:45:38.561034      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring no jobs are scheduled 02/13/23 14:45:38.561
STEP: Ensuring no job exists by listing jobs explicitly 02/13/23 14:50:38.575
STEP: Removing cronjob 02/13/23 14:50:38.583
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Feb 13 14:50:38.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7445" for this suite. 02/13/23 14:50:38.603
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":303,"skipped":5572,"failed":0}
------------------------------
• [SLOW TEST] [300.080 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:45:38.531
    Feb 13 14:45:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename cronjob 02/13/23 14:45:38.532
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:45:38.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:45:38.552
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 02/13/23 14:45:38.554
    W0213 14:45:38.561034      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring no jobs are scheduled 02/13/23 14:45:38.561
    STEP: Ensuring no job exists by listing jobs explicitly 02/13/23 14:50:38.575
    STEP: Removing cronjob 02/13/23 14:50:38.583
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Feb 13 14:50:38.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7445" for this suite. 02/13/23 14:50:38.603
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:50:38.623
Feb 13 14:50:38.623: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:50:38.626
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:38.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:38.653
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 02/13/23 14:50:38.658
STEP: Ensuring ResourceQuota status is calculated 02/13/23 14:50:38.668
STEP: Creating a ResourceQuota with not terminating scope 02/13/23 14:50:40.675
STEP: Ensuring ResourceQuota status is calculated 02/13/23 14:50:40.687
STEP: Creating a long running pod 02/13/23 14:50:42.697
W0213 14:50:42.724382      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota with not terminating scope captures the pod usage 02/13/23 14:50:42.724
STEP: Ensuring resource quota with terminating scope ignored the pod usage 02/13/23 14:50:44.73
STEP: Deleting the pod 02/13/23 14:50:46.736
STEP: Ensuring resource quota status released the pod usage 02/13/23 14:50:46.756
STEP: Creating a terminating pod 02/13/23 14:50:48.762
W0213 14:50:48.780167      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota with terminating scope captures the pod usage 02/13/23 14:50:48.78
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 02/13/23 14:50:50.788
STEP: Deleting the pod 02/13/23 14:50:52.796
STEP: Ensuring resource quota status released the pod usage 02/13/23 14:50:52.815
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:50:54.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9049" for this suite. 02/13/23 14:50:54.831
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":304,"skipped":5593,"failed":0}
------------------------------
• [SLOW TEST] [16.218 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:50:38.623
    Feb 13 14:50:38.623: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:50:38.626
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:38.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:38.653
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 02/13/23 14:50:38.658
    STEP: Ensuring ResourceQuota status is calculated 02/13/23 14:50:38.668
    STEP: Creating a ResourceQuota with not terminating scope 02/13/23 14:50:40.675
    STEP: Ensuring ResourceQuota status is calculated 02/13/23 14:50:40.687
    STEP: Creating a long running pod 02/13/23 14:50:42.697
    W0213 14:50:42.724382      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 02/13/23 14:50:42.724
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 02/13/23 14:50:44.73
    STEP: Deleting the pod 02/13/23 14:50:46.736
    STEP: Ensuring resource quota status released the pod usage 02/13/23 14:50:46.756
    STEP: Creating a terminating pod 02/13/23 14:50:48.762
    W0213 14:50:48.780167      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota with terminating scope captures the pod usage 02/13/23 14:50:48.78
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 02/13/23 14:50:50.788
    STEP: Deleting the pod 02/13/23 14:50:52.796
    STEP: Ensuring resource quota status released the pod usage 02/13/23 14:50:52.815
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:50:54.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9049" for this suite. 02/13/23 14:50:54.831
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:50:54.847
Feb 13 14:50:54.847: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 14:50:54.849
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:54.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:54.877
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 02/13/23 14:50:54.882
W0213 14:50:54.892303      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:50:54.892: INFO: Waiting up to 5m0s for pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0" in namespace "emptydir-9564" to be "Succeeded or Failed"
Feb 13 14:50:54.901: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.563013ms
Feb 13 14:50:56.907: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014548089s
Feb 13 14:50:58.906: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013608337s
STEP: Saw pod success 02/13/23 14:50:58.906
Feb 13 14:50:58.906: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0" satisfied condition "Succeeded or Failed"
Feb 13 14:50:58.910: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 container test-container: <nil>
STEP: delete the pod 02/13/23 14:50:58.941
Feb 13 14:50:58.956: INFO: Waiting for pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 to disappear
Feb 13 14:50:58.960: INFO: Pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 14:50:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9564" for this suite. 02/13/23 14:50:58.967
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":305,"skipped":5604,"failed":0}
------------------------------
• [4.128 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:50:54.847
    Feb 13 14:50:54.847: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 14:50:54.849
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:54.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:54.877
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 02/13/23 14:50:54.882
    W0213 14:50:54.892303      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:50:54.892: INFO: Waiting up to 5m0s for pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0" in namespace "emptydir-9564" to be "Succeeded or Failed"
    Feb 13 14:50:54.901: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.563013ms
    Feb 13 14:50:56.907: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014548089s
    Feb 13 14:50:58.906: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013608337s
    STEP: Saw pod success 02/13/23 14:50:58.906
    Feb 13 14:50:58.906: INFO: Pod "pod-e379971d-06e1-481a-9840-c9a7b34f16f0" satisfied condition "Succeeded or Failed"
    Feb 13 14:50:58.910: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 container test-container: <nil>
    STEP: delete the pod 02/13/23 14:50:58.941
    Feb 13 14:50:58.956: INFO: Waiting for pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 to disappear
    Feb 13 14:50:58.960: INFO: Pod pod-e379971d-06e1-481a-9840-c9a7b34f16f0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:50:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9564" for this suite. 02/13/23 14:50:58.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:50:58.982
Feb 13 14:50:58.982: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 14:50:58.984
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:59.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:59.012
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 02/13/23 14:50:59.017
W0213 14:50:59.029753      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:50:59.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23" in namespace "downward-api-8569" to be "Succeeded or Failed"
Feb 13 14:50:59.036: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Pending", Reason="", readiness=false. Elapsed: 6.478126ms
Feb 13 14:51:01.045: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015138164s
Feb 13 14:51:03.042: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012702078s
STEP: Saw pod success 02/13/23 14:51:03.042
Feb 13 14:51:03.042: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23" satisfied condition "Succeeded or Failed"
Feb 13 14:51:03.047: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 container client-container: <nil>
STEP: delete the pod 02/13/23 14:51:03.06
Feb 13 14:51:03.074: INFO: Waiting for pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 to disappear
Feb 13 14:51:03.077: INFO: Pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Feb 13 14:51:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8569" for this suite. 02/13/23 14:51:03.083
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":306,"skipped":5611,"failed":0}
------------------------------
• [4.108 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:50:58.982
    Feb 13 14:50:58.982: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 14:50:58.984
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:50:59.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:50:59.012
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 02/13/23 14:50:59.017
    W0213 14:50:59.029753      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:50:59.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23" in namespace "downward-api-8569" to be "Succeeded or Failed"
    Feb 13 14:50:59.036: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Pending", Reason="", readiness=false. Elapsed: 6.478126ms
    Feb 13 14:51:01.045: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015138164s
    Feb 13 14:51:03.042: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012702078s
    STEP: Saw pod success 02/13/23 14:51:03.042
    Feb 13 14:51:03.042: INFO: Pod "downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23" satisfied condition "Succeeded or Failed"
    Feb 13 14:51:03.047: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 container client-container: <nil>
    STEP: delete the pod 02/13/23 14:51:03.06
    Feb 13 14:51:03.074: INFO: Waiting for pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 to disappear
    Feb 13 14:51:03.077: INFO: Pod downwardapi-volume-0853482c-c3a9-4b8a-b3bf-c2d553059a23 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Feb 13 14:51:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8569" for this suite. 02/13/23 14:51:03.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:51:03.097
Feb 13 14:51:03.097: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename security-context 02/13/23 14:51:03.098
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:03.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:03.121
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 02/13/23 14:51:03.126
W0213 14:51:03.135096      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:51:03.135: INFO: Waiting up to 5m0s for pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c" in namespace "security-context-6627" to be "Succeeded or Failed"
Feb 13 14:51:03.139: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63209ms
Feb 13 14:51:05.146: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010511518s
Feb 13 14:51:07.151: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015618784s
STEP: Saw pod success 02/13/23 14:51:07.151
Feb 13 14:51:07.152: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c" satisfied condition "Succeeded or Failed"
Feb 13 14:51:07.155: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c container test-container: <nil>
STEP: delete the pod 02/13/23 14:51:07.166
Feb 13 14:51:07.181: INFO: Waiting for pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c to disappear
Feb 13 14:51:07.185: INFO: Pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Feb 13 14:51:07.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-6627" for this suite. 02/13/23 14:51:07.189
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":307,"skipped":5616,"failed":0}
------------------------------
• [4.101 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:51:03.097
    Feb 13 14:51:03.097: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename security-context 02/13/23 14:51:03.098
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:03.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:03.121
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 02/13/23 14:51:03.126
    W0213 14:51:03.135096      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:51:03.135: INFO: Waiting up to 5m0s for pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c" in namespace "security-context-6627" to be "Succeeded or Failed"
    Feb 13 14:51:03.139: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63209ms
    Feb 13 14:51:05.146: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010511518s
    Feb 13 14:51:07.151: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015618784s
    STEP: Saw pod success 02/13/23 14:51:07.151
    Feb 13 14:51:07.152: INFO: Pod "security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c" satisfied condition "Succeeded or Failed"
    Feb 13 14:51:07.155: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c container test-container: <nil>
    STEP: delete the pod 02/13/23 14:51:07.166
    Feb 13 14:51:07.181: INFO: Waiting for pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c to disappear
    Feb 13 14:51:07.185: INFO: Pod security-context-794f06e5-8d9d-4b17-9b5d-cd9bb951b95c no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Feb 13 14:51:07.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-6627" for this suite. 02/13/23 14:51:07.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:51:07.209
Feb 13 14:51:07.209: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 14:51:07.211
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:07.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:07.232
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 02/13/23 14:51:07.237
W0213 14:51:07.255613      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:51:07.256: INFO: Waiting up to 5m0s for pod "pod-d8554349-17ac-4210-9962-1868f406f09e" in namespace "emptydir-1266" to be "Succeeded or Failed"
Feb 13 14:51:07.260: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346462ms
Feb 13 14:51:09.266: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010275439s
Feb 13 14:51:11.271: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014854609s
STEP: Saw pod success 02/13/23 14:51:11.271
Feb 13 14:51:11.271: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e" satisfied condition "Succeeded or Failed"
Feb 13 14:51:11.278: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-d8554349-17ac-4210-9962-1868f406f09e container test-container: <nil>
STEP: delete the pod 02/13/23 14:51:11.291
Feb 13 14:51:11.311: INFO: Waiting for pod pod-d8554349-17ac-4210-9962-1868f406f09e to disappear
Feb 13 14:51:11.316: INFO: Pod pod-d8554349-17ac-4210-9962-1868f406f09e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 14:51:11.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1266" for this suite. 02/13/23 14:51:11.322
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":308,"skipped":5638,"failed":0}
------------------------------
• [4.122 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:51:07.209
    Feb 13 14:51:07.209: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 14:51:07.211
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:07.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:07.232
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 02/13/23 14:51:07.237
    W0213 14:51:07.255613      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:51:07.256: INFO: Waiting up to 5m0s for pod "pod-d8554349-17ac-4210-9962-1868f406f09e" in namespace "emptydir-1266" to be "Succeeded or Failed"
    Feb 13 14:51:07.260: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346462ms
    Feb 13 14:51:09.266: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010275439s
    Feb 13 14:51:11.271: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014854609s
    STEP: Saw pod success 02/13/23 14:51:11.271
    Feb 13 14:51:11.271: INFO: Pod "pod-d8554349-17ac-4210-9962-1868f406f09e" satisfied condition "Succeeded or Failed"
    Feb 13 14:51:11.278: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-d8554349-17ac-4210-9962-1868f406f09e container test-container: <nil>
    STEP: delete the pod 02/13/23 14:51:11.291
    Feb 13 14:51:11.311: INFO: Waiting for pod pod-d8554349-17ac-4210-9962-1868f406f09e to disappear
    Feb 13 14:51:11.316: INFO: Pod pod-d8554349-17ac-4210-9962-1868f406f09e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 14:51:11.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1266" for this suite. 02/13/23 14:51:11.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:51:11.338
Feb 13 14:51:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:51:11.341
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:11.359
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:11.364
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 02/13/23 14:51:11.369
Feb 13 14:51:11.371: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:51:13.504: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 14:51:22.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7005" for this suite. 02/13/23 14:51:22.664
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":309,"skipped":5646,"failed":0}
------------------------------
• [SLOW TEST] [11.336 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:51:11.338
    Feb 13 14:51:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename crd-publish-openapi 02/13/23 14:51:11.341
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:11.359
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:11.364
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 02/13/23 14:51:11.369
    Feb 13 14:51:11.371: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:51:13.504: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 14:51:22.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7005" for this suite. 02/13/23 14:51:22.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:51:22.682
Feb 13 14:51:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 14:51:22.684
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:22.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:22.71
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-2b061dfc-aef2-44b9-858b-c0d0d422d296 02/13/23 14:51:22.719
STEP: Creating the pod 02/13/23 14:51:22.725
W0213 14:51:22.738194      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:51:22.738: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66" in namespace "configmap-1992" to be "running and ready"
Feb 13 14:51:22.745: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66": Phase="Pending", Reason="", readiness=false. Elapsed: 6.914299ms
Feb 13 14:51:22.745: INFO: The phase of Pod pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:51:24.750: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66": Phase="Running", Reason="", readiness=true. Elapsed: 2.012153614s
Feb 13 14:51:24.751: INFO: The phase of Pod pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66 is Running (Ready = true)
Feb 13 14:51:24.751: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-2b061dfc-aef2-44b9-858b-c0d0d422d296 02/13/23 14:51:24.764
STEP: waiting to observe update in volume 02/13/23 14:51:24.77
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 14:52:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1992" for this suite. 02/13/23 14:52:55.463
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":310,"skipped":5685,"failed":0}
------------------------------
• [SLOW TEST] [92.790 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:51:22.682
    Feb 13 14:51:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 14:51:22.684
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:51:22.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:51:22.71
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-2b061dfc-aef2-44b9-858b-c0d0d422d296 02/13/23 14:51:22.719
    STEP: Creating the pod 02/13/23 14:51:22.725
    W0213 14:51:22.738194      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:51:22.738: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66" in namespace "configmap-1992" to be "running and ready"
    Feb 13 14:51:22.745: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66": Phase="Pending", Reason="", readiness=false. Elapsed: 6.914299ms
    Feb 13 14:51:22.745: INFO: The phase of Pod pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:51:24.750: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66": Phase="Running", Reason="", readiness=true. Elapsed: 2.012153614s
    Feb 13 14:51:24.751: INFO: The phase of Pod pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66 is Running (Ready = true)
    Feb 13 14:51:24.751: INFO: Pod "pod-configmaps-bf094fb2-2642-4894-8745-a7d533fdae66" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-2b061dfc-aef2-44b9-858b-c0d0d422d296 02/13/23 14:51:24.764
    STEP: waiting to observe update in volume 02/13/23 14:51:24.77
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 14:52:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1992" for this suite. 02/13/23 14:52:55.463
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:52:55.477
Feb 13 14:52:55.477: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename init-container 02/13/23 14:52:55.48
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:52:55.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:52:55.509
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 02/13/23 14:52:55.514
Feb 13 14:52:55.515: INFO: PodSpec: initContainers in spec.initContainers
W0213 14:52:55.526342      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 14:52:58.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6812" for this suite. 02/13/23 14:52:58.77
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":311,"skipped":5685,"failed":0}
------------------------------
• [3.303 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:52:55.477
    Feb 13 14:52:55.477: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename init-container 02/13/23 14:52:55.48
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:52:55.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:52:55.509
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 02/13/23 14:52:55.514
    Feb 13 14:52:55.515: INFO: PodSpec: initContainers in spec.initContainers
    W0213 14:52:55.526342      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 14:52:58.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6812" for this suite. 02/13/23 14:52:58.77
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:52:58.78
Feb 13 14:52:58.780: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename proxy 02/13/23 14:52:58.781
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:52:58.794
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:52:58.797
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 02/13/23 14:52:58.822
STEP: creating replication controller proxy-service-cgt97 in namespace proxy-9783 02/13/23 14:52:58.823
W0213 14:52:58.834933      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "proxy-service-cgt97" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "proxy-service-cgt97" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "proxy-service-cgt97" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "proxy-service-cgt97" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:52:58.835966      19 runners.go:193] Created replication controller with name: proxy-service-cgt97, namespace: proxy-9783, replica count: 1
I0213 14:52:59.888185      19 runners.go:193] proxy-service-cgt97 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 14:53:00.889061      19 runners.go:193] proxy-service-cgt97 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:53:00.893: INFO: setup took 2.092368095s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 02/13/23 14:53:00.893
Feb 13 14:53:00.929: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 32.875576ms)
Feb 13 14:53:00.934: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 39.756804ms)
Feb 13 14:53:00.934: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 39.339307ms)
Feb 13 14:53:00.938: INFO: (0) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 42.260383ms)
Feb 13 14:53:00.938: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 40.237618ms)
Feb 13 14:53:00.940: INFO: (0) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 42.741009ms)
Feb 13 14:53:00.942: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 45.385423ms)
Feb 13 14:53:00.942: INFO: (0) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 44.511997ms)
Feb 13 14:53:00.944: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 48.606449ms)
Feb 13 14:53:00.945: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 48.284919ms)
Feb 13 14:53:00.945: INFO: (0) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 48.320141ms)
Feb 13 14:53:00.946: INFO: (0) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 50.563076ms)
Feb 13 14:53:00.946: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 51.121571ms)
Feb 13 14:53:00.949: INFO: (0) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 51.657293ms)
Feb 13 14:53:00.949: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 54.854287ms)
Feb 13 14:53:00.950: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 53.392067ms)
Feb 13 14:53:00.960: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 9.00659ms)
Feb 13 14:53:00.963: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.243352ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.108783ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 13.441941ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.672757ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 14.297615ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.085204ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 13.992476ms)
Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 13.627871ms)
Feb 13 14:53:00.965: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.214704ms)
Feb 13 14:53:00.966: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.474704ms)
Feb 13 14:53:00.966: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.471078ms)
Feb 13 14:53:00.967: INFO: (1) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.129022ms)
Feb 13 14:53:00.967: INFO: (1) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 16.227521ms)
Feb 13 14:53:00.969: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.270029ms)
Feb 13 14:53:00.969: INFO: (1) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.920189ms)
Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.215211ms)
Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.139101ms)
Feb 13 14:53:00.984: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 13.511226ms)
Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 13.247363ms)
Feb 13 14:53:00.984: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 14.270901ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.139176ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.819448ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 13.238167ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 15.733854ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.565593ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.954619ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.276138ms)
Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.044189ms)
Feb 13 14:53:00.987: INFO: (2) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.760284ms)
Feb 13 14:53:00.987: INFO: (2) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.491604ms)
Feb 13 14:53:00.988: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.845584ms)
Feb 13 14:53:00.996: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 7.708267ms)
Feb 13 14:53:01.000: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.266257ms)
Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.408185ms)
Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.086931ms)
Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.931595ms)
Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 13.967588ms)
Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.851804ms)
Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.611521ms)
Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.772956ms)
Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 14.580391ms)
Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.803556ms)
Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 15.48855ms)
Feb 13 14:53:01.005: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.661829ms)
Feb 13 14:53:01.006: INFO: (3) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 16.36925ms)
Feb 13 14:53:01.006: INFO: (3) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.513112ms)
Feb 13 14:53:01.007: INFO: (3) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.698246ms)
Feb 13 14:53:01.020: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.697996ms)
Feb 13 14:53:01.021: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.881842ms)
Feb 13 14:53:01.024: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.918621ms)
Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.371788ms)
Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.919324ms)
Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.997378ms)
Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.313762ms)
Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.496814ms)
Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 18.858722ms)
Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.07647ms)
Feb 13 14:53:01.027: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 19.402852ms)
Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.792157ms)
Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.166195ms)
Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 18.945169ms)
Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 20.285365ms)
Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 20.578169ms)
Feb 13 14:53:01.042: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.870062ms)
Feb 13 14:53:01.042: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 11.878689ms)
Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 12.639712ms)
Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 12.188593ms)
Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.262531ms)
Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 12.680691ms)
Feb 13 14:53:01.044: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.086967ms)
Feb 13 14:53:01.045: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 15.338207ms)
Feb 13 14:53:01.046: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 15.775201ms)
Feb 13 14:53:01.046: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.17586ms)
Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.352795ms)
Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 16.673443ms)
Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 17.411042ms)
Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.795333ms)
Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 16.917315ms)
Feb 13 14:53:01.048: INFO: (5) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.567775ms)
Feb 13 14:53:01.058: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 10.362976ms)
Feb 13 14:53:01.062: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.156613ms)
Feb 13 14:53:01.063: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.438547ms)
Feb 13 14:53:01.065: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.020198ms)
Feb 13 14:53:01.065: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.673353ms)
Feb 13 14:53:01.066: INFO: (6) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 17.316021ms)
Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.456794ms)
Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.08782ms)
Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 18.743459ms)
Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 19.919274ms)
Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 19.490809ms)
Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 19.958165ms)
Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 20.049275ms)
Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.246341ms)
Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 20.558267ms)
Feb 13 14:53:01.070: INFO: (6) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 21.8824ms)
Feb 13 14:53:01.088: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.775816ms)
Feb 13 14:53:01.089: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.654758ms)
Feb 13 14:53:01.089: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.815139ms)
Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 20.362274ms)
Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 20.173088ms)
Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.729721ms)
Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 19.634651ms)
Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 20.522255ms)
Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 21.35976ms)
Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 20.781803ms)
Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 21.257909ms)
Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 21.733422ms)
Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 23.356041ms)
Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 22.329534ms)
Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 22.535868ms)
Feb 13 14:53:01.095: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 23.204633ms)
Feb 13 14:53:01.106: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 11.671231ms)
Feb 13 14:53:01.107: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.804477ms)
Feb 13 14:53:01.107: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.343284ms)
Feb 13 14:53:01.111: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.325019ms)
Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 16.409274ms)
Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.939966ms)
Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 17.064929ms)
Feb 13 14:53:01.113: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.80877ms)
Feb 13 14:53:01.113: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.03486ms)
Feb 13 14:53:01.114: INFO: (8) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.332797ms)
Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 19.521461ms)
Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.701166ms)
Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.84895ms)
Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.453687ms)
Feb 13 14:53:01.116: INFO: (8) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 20.37839ms)
Feb 13 14:53:01.116: INFO: (8) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.736106ms)
Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.884729ms)
Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 15.442993ms)
Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 15.458139ms)
Feb 13 14:53:01.133: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 16.29078ms)
Feb 13 14:53:01.133: INFO: (9) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.290592ms)
Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 16.684585ms)
Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.963549ms)
Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.851158ms)
Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.894582ms)
Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 17.979446ms)
Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.900862ms)
Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.771184ms)
Feb 13 14:53:01.136: INFO: (9) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.0729ms)
Feb 13 14:53:01.138: INFO: (9) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 21.188735ms)
Feb 13 14:53:01.141: INFO: (9) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.530566ms)
Feb 13 14:53:01.141: INFO: (9) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 23.696923ms)
Feb 13 14:53:01.157: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.386765ms)
Feb 13 14:53:01.157: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.170646ms)
Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.709771ms)
Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 17.55764ms)
Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.762807ms)
Feb 13 14:53:01.159: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.725961ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.663395ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 18.823216ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.5433ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.365216ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 19.688419ms)
Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 19.171709ms)
Feb 13 14:53:01.161: INFO: (10) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 19.371371ms)
Feb 13 14:53:01.161: INFO: (10) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 19.700447ms)
Feb 13 14:53:01.163: INFO: (10) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 21.848525ms)
Feb 13 14:53:01.164: INFO: (10) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 22.228267ms)
Feb 13 14:53:01.180: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.21219ms)
Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.566387ms)
Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 17.525326ms)
Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.594088ms)
Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.690341ms)
Feb 13 14:53:01.182: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.407477ms)
Feb 13 14:53:01.183: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 18.874223ms)
Feb 13 14:53:01.183: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.791076ms)
Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.979695ms)
Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.88417ms)
Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 19.847043ms)
Feb 13 14:53:01.185: INFO: (11) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 20.50296ms)
Feb 13 14:53:01.186: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 21.806723ms)
Feb 13 14:53:01.187: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 22.551722ms)
Feb 13 14:53:01.188: INFO: (11) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 23.794685ms)
Feb 13 14:53:01.188: INFO: (11) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.803277ms)
Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.638039ms)
Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.811778ms)
Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 12.489885ms)
Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 12.985476ms)
Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.121938ms)
Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.955609ms)
Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.000271ms)
Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.442438ms)
Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 14.554271ms)
Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.405919ms)
Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.247872ms)
Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.60671ms)
Feb 13 14:53:01.204: INFO: (12) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 15.629693ms)
Feb 13 14:53:01.205: INFO: (12) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 15.608417ms)
Feb 13 14:53:01.205: INFO: (12) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.241954ms)
Feb 13 14:53:01.206: INFO: (12) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.220514ms)
Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 10.704503ms)
Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 10.11043ms)
Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 10.0404ms)
Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 10.580348ms)
Feb 13 14:53:01.219: INFO: (13) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 13.214211ms)
Feb 13 14:53:01.220: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.123743ms)
Feb 13 14:53:01.220: INFO: (13) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 13.443666ms)
Feb 13 14:53:01.221: INFO: (13) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 14.182394ms)
Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 15.026506ms)
Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.987383ms)
Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 15.258094ms)
Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 16.14009ms)
Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.087333ms)
Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.187341ms)
Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 16.407438ms)
Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.603759ms)
Feb 13 14:53:01.230: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 6.632132ms)
Feb 13 14:53:01.237: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 11.797236ms)
Feb 13 14:53:01.237: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 11.940828ms)
Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 12.801094ms)
Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.098379ms)
Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.235126ms)
Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 13.370638ms)
Feb 13 14:53:01.239: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 15.001786ms)
Feb 13 14:53:01.239: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.312993ms)
Feb 13 14:53:01.240: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.135733ms)
Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 15.944452ms)
Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 16.289049ms)
Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.56796ms)
Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 18.320913ms)
Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 18.5051ms)
Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 18.61894ms)
Feb 13 14:53:01.254: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 10.737623ms)
Feb 13 14:53:01.257: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.098621ms)
Feb 13 14:53:01.257: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.686334ms)
Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.479125ms)
Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.582071ms)
Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.593138ms)
Feb 13 14:53:01.262: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.141787ms)
Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.792869ms)
Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 18.196344ms)
Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 19.556093ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 19.808442ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 19.504487ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 19.169049ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.871638ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 19.009761ms)
Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.153377ms)
Feb 13 14:53:01.273: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 8.660076ms)
Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.944828ms)
Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 13.301096ms)
Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 13.367127ms)
Feb 13 14:53:01.280: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.137344ms)
Feb 13 14:53:01.280: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.062362ms)
Feb 13 14:53:01.281: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 14.949846ms)
Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.469813ms)
Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.470668ms)
Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.322523ms)
Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.645371ms)
Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.347854ms)
Feb 13 14:53:01.283: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.453049ms)
Feb 13 14:53:01.284: INFO: (16) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 18.540086ms)
Feb 13 14:53:01.285: INFO: (16) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.876603ms)
Feb 13 14:53:01.286: INFO: (16) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.328594ms)
Feb 13 14:53:01.298: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.024755ms)
Feb 13 14:53:01.300: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.893475ms)
Feb 13 14:53:01.301: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.568809ms)
Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.737156ms)
Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 15.276606ms)
Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 15.13061ms)
Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 15.812875ms)
Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.063345ms)
Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.832797ms)
Feb 13 14:53:01.304: INFO: (17) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.268723ms)
Feb 13 14:53:01.305: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 17.817516ms)
Feb 13 14:53:01.308: INFO: (17) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 20.741105ms)
Feb 13 14:53:01.314: INFO: (17) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 27.362701ms)
Feb 13 14:53:01.314: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 27.235143ms)
Feb 13 14:53:01.315: INFO: (17) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 27.634334ms)
Feb 13 14:53:01.316: INFO: (17) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 28.693217ms)
Feb 13 14:53:01.349: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 32.122943ms)
Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 39.187309ms)
Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 39.448467ms)
Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 39.104961ms)
Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 40.52547ms)
Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 52.356611ms)
Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 53.23774ms)
Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 53.289239ms)
Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 53.154483ms)
Feb 13 14:53:01.371: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 53.182186ms)
Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 79.738312ms)
Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 80.022089ms)
Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 80.571677ms)
Feb 13 14:53:01.398: INFO: (18) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 81.45324ms)
Feb 13 14:53:01.398: INFO: (18) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 80.796173ms)
Feb 13 14:53:01.405: INFO: (18) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 87.723526ms)
Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 21.087134ms)
Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 22.325287ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 22.481382ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 22.429426ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 23.004592ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 22.732615ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 23.010977ms)
Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 21.621067ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 22.379248ms)
Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 22.506738ms)
Feb 13 14:53:01.429: INFO: (19) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.675296ms)
Feb 13 14:53:01.430: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 24.866328ms)
Feb 13 14:53:01.431: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 25.600145ms)
Feb 13 14:53:01.432: INFO: (19) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 27.010642ms)
Feb 13 14:53:01.433: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 27.376658ms)
Feb 13 14:53:01.433: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 27.619229ms)
STEP: deleting ReplicationController proxy-service-cgt97 in namespace proxy-9783, will wait for the garbage collector to delete the pods 02/13/23 14:53:01.433
Feb 13 14:53:01.497: INFO: Deleting ReplicationController proxy-service-cgt97 took: 10.456573ms
Feb 13 14:53:01.598: INFO: Terminating ReplicationController proxy-service-cgt97 pods took: 100.54479ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Feb 13 14:53:04.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9783" for this suite. 02/13/23 14:53:04.106
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":312,"skipped":5685,"failed":0}
------------------------------
• [SLOW TEST] [5.335 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:52:58.78
    Feb 13 14:52:58.780: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename proxy 02/13/23 14:52:58.781
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:52:58.794
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:52:58.797
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 02/13/23 14:52:58.822
    STEP: creating replication controller proxy-service-cgt97 in namespace proxy-9783 02/13/23 14:52:58.823
    W0213 14:52:58.834933      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "proxy-service-cgt97" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "proxy-service-cgt97" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "proxy-service-cgt97" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "proxy-service-cgt97" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:52:58.835966      19 runners.go:193] Created replication controller with name: proxy-service-cgt97, namespace: proxy-9783, replica count: 1
    I0213 14:52:59.888185      19 runners.go:193] proxy-service-cgt97 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0213 14:53:00.889061      19 runners.go:193] proxy-service-cgt97 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:53:00.893: INFO: setup took 2.092368095s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 02/13/23 14:53:00.893
    Feb 13 14:53:00.929: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 32.875576ms)
    Feb 13 14:53:00.934: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 39.756804ms)
    Feb 13 14:53:00.934: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 39.339307ms)
    Feb 13 14:53:00.938: INFO: (0) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 42.260383ms)
    Feb 13 14:53:00.938: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 40.237618ms)
    Feb 13 14:53:00.940: INFO: (0) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 42.741009ms)
    Feb 13 14:53:00.942: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 45.385423ms)
    Feb 13 14:53:00.942: INFO: (0) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 44.511997ms)
    Feb 13 14:53:00.944: INFO: (0) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 48.606449ms)
    Feb 13 14:53:00.945: INFO: (0) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 48.284919ms)
    Feb 13 14:53:00.945: INFO: (0) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 48.320141ms)
    Feb 13 14:53:00.946: INFO: (0) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 50.563076ms)
    Feb 13 14:53:00.946: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 51.121571ms)
    Feb 13 14:53:00.949: INFO: (0) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 51.657293ms)
    Feb 13 14:53:00.949: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 54.854287ms)
    Feb 13 14:53:00.950: INFO: (0) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 53.392067ms)
    Feb 13 14:53:00.960: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 9.00659ms)
    Feb 13 14:53:00.963: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.243352ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.108783ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 13.441941ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.672757ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 14.297615ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.085204ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 13.992476ms)
    Feb 13 14:53:00.964: INFO: (1) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 13.627871ms)
    Feb 13 14:53:00.965: INFO: (1) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.214704ms)
    Feb 13 14:53:00.966: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.474704ms)
    Feb 13 14:53:00.966: INFO: (1) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.471078ms)
    Feb 13 14:53:00.967: INFO: (1) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.129022ms)
    Feb 13 14:53:00.967: INFO: (1) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 16.227521ms)
    Feb 13 14:53:00.969: INFO: (1) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.270029ms)
    Feb 13 14:53:00.969: INFO: (1) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.920189ms)
    Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.215211ms)
    Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.139101ms)
    Feb 13 14:53:00.984: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 13.511226ms)
    Feb 13 14:53:00.983: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 13.247363ms)
    Feb 13 14:53:00.984: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 14.270901ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.139176ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.819448ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 13.238167ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 15.733854ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.565593ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.954619ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.276138ms)
    Feb 13 14:53:00.985: INFO: (2) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.044189ms)
    Feb 13 14:53:00.987: INFO: (2) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.760284ms)
    Feb 13 14:53:00.987: INFO: (2) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.491604ms)
    Feb 13 14:53:00.988: INFO: (2) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.845584ms)
    Feb 13 14:53:00.996: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 7.708267ms)
    Feb 13 14:53:01.000: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.266257ms)
    Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.408185ms)
    Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.086931ms)
    Feb 13 14:53:01.001: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.931595ms)
    Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 13.967588ms)
    Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.851804ms)
    Feb 13 14:53:01.003: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.611521ms)
    Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.772956ms)
    Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 14.580391ms)
    Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.803556ms)
    Feb 13 14:53:01.004: INFO: (3) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 15.48855ms)
    Feb 13 14:53:01.005: INFO: (3) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.661829ms)
    Feb 13 14:53:01.006: INFO: (3) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 16.36925ms)
    Feb 13 14:53:01.006: INFO: (3) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.513112ms)
    Feb 13 14:53:01.007: INFO: (3) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.698246ms)
    Feb 13 14:53:01.020: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.697996ms)
    Feb 13 14:53:01.021: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.881842ms)
    Feb 13 14:53:01.024: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.918621ms)
    Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.371788ms)
    Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.919324ms)
    Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.997378ms)
    Feb 13 14:53:01.025: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.313762ms)
    Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.496814ms)
    Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 18.858722ms)
    Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.07647ms)
    Feb 13 14:53:01.027: INFO: (4) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 19.402852ms)
    Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.792157ms)
    Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.166195ms)
    Feb 13 14:53:01.026: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 18.945169ms)
    Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 20.285365ms)
    Feb 13 14:53:01.028: INFO: (4) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 20.578169ms)
    Feb 13 14:53:01.042: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.870062ms)
    Feb 13 14:53:01.042: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 11.878689ms)
    Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 12.639712ms)
    Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 12.188593ms)
    Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.262531ms)
    Feb 13 14:53:01.043: INFO: (5) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 12.680691ms)
    Feb 13 14:53:01.044: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 13.086967ms)
    Feb 13 14:53:01.045: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 15.338207ms)
    Feb 13 14:53:01.046: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 15.775201ms)
    Feb 13 14:53:01.046: INFO: (5) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.17586ms)
    Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.352795ms)
    Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 16.673443ms)
    Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 17.411042ms)
    Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.795333ms)
    Feb 13 14:53:01.047: INFO: (5) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 16.917315ms)
    Feb 13 14:53:01.048: INFO: (5) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.567775ms)
    Feb 13 14:53:01.058: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 10.362976ms)
    Feb 13 14:53:01.062: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.156613ms)
    Feb 13 14:53:01.063: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 14.438547ms)
    Feb 13 14:53:01.065: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.020198ms)
    Feb 13 14:53:01.065: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.673353ms)
    Feb 13 14:53:01.066: INFO: (6) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 17.316021ms)
    Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.456794ms)
    Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.08782ms)
    Feb 13 14:53:01.067: INFO: (6) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 18.743459ms)
    Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 19.919274ms)
    Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 19.490809ms)
    Feb 13 14:53:01.068: INFO: (6) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 19.958165ms)
    Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 20.049275ms)
    Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.246341ms)
    Feb 13 14:53:01.069: INFO: (6) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 20.558267ms)
    Feb 13 14:53:01.070: INFO: (6) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 21.8824ms)
    Feb 13 14:53:01.088: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.775816ms)
    Feb 13 14:53:01.089: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.654758ms)
    Feb 13 14:53:01.089: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.815139ms)
    Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 20.362274ms)
    Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 20.173088ms)
    Feb 13 14:53:01.091: INFO: (7) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.729721ms)
    Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 19.634651ms)
    Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 20.522255ms)
    Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 21.35976ms)
    Feb 13 14:53:01.092: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 20.781803ms)
    Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 21.257909ms)
    Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 21.733422ms)
    Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 23.356041ms)
    Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 22.329534ms)
    Feb 13 14:53:01.094: INFO: (7) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 22.535868ms)
    Feb 13 14:53:01.095: INFO: (7) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 23.204633ms)
    Feb 13 14:53:01.106: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 11.671231ms)
    Feb 13 14:53:01.107: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.804477ms)
    Feb 13 14:53:01.107: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.343284ms)
    Feb 13 14:53:01.111: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.325019ms)
    Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 16.409274ms)
    Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.939966ms)
    Feb 13 14:53:01.112: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 17.064929ms)
    Feb 13 14:53:01.113: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.80877ms)
    Feb 13 14:53:01.113: INFO: (8) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.03486ms)
    Feb 13 14:53:01.114: INFO: (8) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 18.332797ms)
    Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 19.521461ms)
    Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.701166ms)
    Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.84895ms)
    Feb 13 14:53:01.115: INFO: (8) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.453687ms)
    Feb 13 14:53:01.116: INFO: (8) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 20.37839ms)
    Feb 13 14:53:01.116: INFO: (8) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 20.736106ms)
    Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.884729ms)
    Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 15.442993ms)
    Feb 13 14:53:01.132: INFO: (9) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 15.458139ms)
    Feb 13 14:53:01.133: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 16.29078ms)
    Feb 13 14:53:01.133: INFO: (9) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.290592ms)
    Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 16.684585ms)
    Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.963549ms)
    Feb 13 14:53:01.134: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.851158ms)
    Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.894582ms)
    Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 17.979446ms)
    Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.900862ms)
    Feb 13 14:53:01.135: INFO: (9) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 17.771184ms)
    Feb 13 14:53:01.136: INFO: (9) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.0729ms)
    Feb 13 14:53:01.138: INFO: (9) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 21.188735ms)
    Feb 13 14:53:01.141: INFO: (9) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.530566ms)
    Feb 13 14:53:01.141: INFO: (9) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 23.696923ms)
    Feb 13 14:53:01.157: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.386765ms)
    Feb 13 14:53:01.157: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.170646ms)
    Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.709771ms)
    Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 17.55764ms)
    Feb 13 14:53:01.158: INFO: (10) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.762807ms)
    Feb 13 14:53:01.159: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.725961ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.663395ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 18.823216ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.5433ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.365216ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 19.688419ms)
    Feb 13 14:53:01.160: INFO: (10) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 19.171709ms)
    Feb 13 14:53:01.161: INFO: (10) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 19.371371ms)
    Feb 13 14:53:01.161: INFO: (10) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 19.700447ms)
    Feb 13 14:53:01.163: INFO: (10) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 21.848525ms)
    Feb 13 14:53:01.164: INFO: (10) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 22.228267ms)
    Feb 13 14:53:01.180: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.21219ms)
    Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.566387ms)
    Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 17.525326ms)
    Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 17.594088ms)
    Feb 13 14:53:01.181: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 17.690341ms)
    Feb 13 14:53:01.182: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.407477ms)
    Feb 13 14:53:01.183: INFO: (11) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 18.874223ms)
    Feb 13 14:53:01.183: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 18.791076ms)
    Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.979695ms)
    Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 19.88417ms)
    Feb 13 14:53:01.184: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 19.847043ms)
    Feb 13 14:53:01.185: INFO: (11) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 20.50296ms)
    Feb 13 14:53:01.186: INFO: (11) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 21.806723ms)
    Feb 13 14:53:01.187: INFO: (11) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 22.551722ms)
    Feb 13 14:53:01.188: INFO: (11) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 23.794685ms)
    Feb 13 14:53:01.188: INFO: (11) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.803277ms)
    Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.638039ms)
    Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 12.811778ms)
    Feb 13 14:53:01.201: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 12.489885ms)
    Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 12.985476ms)
    Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 13.121938ms)
    Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.955609ms)
    Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.000271ms)
    Feb 13 14:53:01.202: INFO: (12) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.442438ms)
    Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 14.554271ms)
    Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.405919ms)
    Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.247872ms)
    Feb 13 14:53:01.203: INFO: (12) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.60671ms)
    Feb 13 14:53:01.204: INFO: (12) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 15.629693ms)
    Feb 13 14:53:01.205: INFO: (12) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 15.608417ms)
    Feb 13 14:53:01.205: INFO: (12) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 16.241954ms)
    Feb 13 14:53:01.206: INFO: (12) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 17.220514ms)
    Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 10.704503ms)
    Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 10.11043ms)
    Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 10.0404ms)
    Feb 13 14:53:01.217: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 10.580348ms)
    Feb 13 14:53:01.219: INFO: (13) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 13.214211ms)
    Feb 13 14:53:01.220: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.123743ms)
    Feb 13 14:53:01.220: INFO: (13) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 13.443666ms)
    Feb 13 14:53:01.221: INFO: (13) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 14.182394ms)
    Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 15.026506ms)
    Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.987383ms)
    Feb 13 14:53:01.222: INFO: (13) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 15.258094ms)
    Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 16.14009ms)
    Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 16.087333ms)
    Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 16.187341ms)
    Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 16.407438ms)
    Feb 13 14:53:01.223: INFO: (13) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.603759ms)
    Feb 13 14:53:01.230: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 6.632132ms)
    Feb 13 14:53:01.237: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 11.797236ms)
    Feb 13 14:53:01.237: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 11.940828ms)
    Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 12.801094ms)
    Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 14.098379ms)
    Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 14.235126ms)
    Feb 13 14:53:01.238: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 13.370638ms)
    Feb 13 14:53:01.239: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 15.001786ms)
    Feb 13 14:53:01.239: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 15.312993ms)
    Feb 13 14:53:01.240: INFO: (14) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.135733ms)
    Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 15.944452ms)
    Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 16.289049ms)
    Feb 13 14:53:01.241: INFO: (14) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.56796ms)
    Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 18.320913ms)
    Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 18.5051ms)
    Feb 13 14:53:01.243: INFO: (14) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 18.61894ms)
    Feb 13 14:53:01.254: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 10.737623ms)
    Feb 13 14:53:01.257: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.098621ms)
    Feb 13 14:53:01.257: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 12.686334ms)
    Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 13.479125ms)
    Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 14.582071ms)
    Feb 13 14:53:01.258: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 13.593138ms)
    Feb 13 14:53:01.262: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 18.141787ms)
    Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 17.792869ms)
    Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 18.196344ms)
    Feb 13 14:53:01.263: INFO: (15) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 19.556093ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 19.808442ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 19.504487ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 19.169049ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 19.871638ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 19.009761ms)
    Feb 13 14:53:01.264: INFO: (15) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.153377ms)
    Feb 13 14:53:01.273: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 8.660076ms)
    Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 12.944828ms)
    Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 13.301096ms)
    Feb 13 14:53:01.278: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 13.367127ms)
    Feb 13 14:53:01.280: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 14.137344ms)
    Feb 13 14:53:01.280: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 14.062362ms)
    Feb 13 14:53:01.281: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 14.949846ms)
    Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 16.469813ms)
    Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.470668ms)
    Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 16.322523ms)
    Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.645371ms)
    Feb 13 14:53:01.282: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 16.347854ms)
    Feb 13 14:53:01.283: INFO: (16) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 17.453049ms)
    Feb 13 14:53:01.284: INFO: (16) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 18.540086ms)
    Feb 13 14:53:01.285: INFO: (16) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 19.876603ms)
    Feb 13 14:53:01.286: INFO: (16) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 20.328594ms)
    Feb 13 14:53:01.298: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 11.024755ms)
    Feb 13 14:53:01.300: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 12.893475ms)
    Feb 13 14:53:01.301: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.568809ms)
    Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 14.737156ms)
    Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 15.276606ms)
    Feb 13 14:53:01.302: INFO: (17) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 15.13061ms)
    Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 15.812875ms)
    Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 16.063345ms)
    Feb 13 14:53:01.303: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 16.832797ms)
    Feb 13 14:53:01.304: INFO: (17) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 17.268723ms)
    Feb 13 14:53:01.305: INFO: (17) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 17.817516ms)
    Feb 13 14:53:01.308: INFO: (17) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 20.741105ms)
    Feb 13 14:53:01.314: INFO: (17) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 27.362701ms)
    Feb 13 14:53:01.314: INFO: (17) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 27.235143ms)
    Feb 13 14:53:01.315: INFO: (17) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 27.634334ms)
    Feb 13 14:53:01.316: INFO: (17) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 28.693217ms)
    Feb 13 14:53:01.349: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 32.122943ms)
    Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 39.187309ms)
    Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 39.448467ms)
    Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 39.104961ms)
    Feb 13 14:53:01.356: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 40.52547ms)
    Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 52.356611ms)
    Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 53.23774ms)
    Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 53.289239ms)
    Feb 13 14:53:01.370: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 53.154483ms)
    Feb 13 14:53:01.371: INFO: (18) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 53.182186ms)
    Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 79.738312ms)
    Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 80.022089ms)
    Feb 13 14:53:01.397: INFO: (18) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 80.571677ms)
    Feb 13 14:53:01.398: INFO: (18) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 81.45324ms)
    Feb 13 14:53:01.398: INFO: (18) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 80.796173ms)
    Feb 13 14:53:01.405: INFO: (18) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 87.723526ms)
    Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 21.087134ms)
    Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname2/proxy/: tls qux (200; 22.325287ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/https:proxy-service-cgt97:tlsportname1/proxy/: tls baz (200; 22.481382ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:462/proxy/: tls qux (200; 22.429426ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 23.004592ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">test<... (200; 22.732615ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname2/proxy/: bar (200; 23.010977ms)
    Feb 13 14:53:01.427: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8/proxy/rewriteme">test</a> (200; 21.621067ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/services/proxy-service-cgt97:portname1/proxy/: foo (200; 22.379248ms)
    Feb 13 14:53:01.428: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:443/proxy/tlsrewritem... (200; 22.506738ms)
    Feb 13 14:53:01.429: INFO: (19) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname1/proxy/: foo (200; 23.675296ms)
    Feb 13 14:53:01.430: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/: <a href="/api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:1080/proxy/rewriteme">... (200; 24.866328ms)
    Feb 13 14:53:01.431: INFO: (19) /api/v1/namespaces/proxy-9783/pods/https:proxy-service-cgt97-4lvq8:460/proxy/: tls baz (200; 25.600145ms)
    Feb 13 14:53:01.432: INFO: (19) /api/v1/namespaces/proxy-9783/services/http:proxy-service-cgt97:portname2/proxy/: bar (200; 27.010642ms)
    Feb 13 14:53:01.433: INFO: (19) /api/v1/namespaces/proxy-9783/pods/http:proxy-service-cgt97-4lvq8:162/proxy/: bar (200; 27.376658ms)
    Feb 13 14:53:01.433: INFO: (19) /api/v1/namespaces/proxy-9783/pods/proxy-service-cgt97-4lvq8:160/proxy/: foo (200; 27.619229ms)
    STEP: deleting ReplicationController proxy-service-cgt97 in namespace proxy-9783, will wait for the garbage collector to delete the pods 02/13/23 14:53:01.433
    Feb 13 14:53:01.497: INFO: Deleting ReplicationController proxy-service-cgt97 took: 10.456573ms
    Feb 13 14:53:01.598: INFO: Terminating ReplicationController proxy-service-cgt97 pods took: 100.54479ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Feb 13 14:53:04.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9783" for this suite. 02/13/23 14:53:04.106
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:53:04.12
Feb 13 14:53:04.120: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 14:53:04.12
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:04.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:04.14
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6535 02/13/23 14:53:04.143
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6535 02/13/23 14:53:04.148
W0213 14:53:04.154839      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:53:04.158: INFO: Found 0 stateful pods, waiting for 1
Feb 13 14:53:14.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 02/13/23 14:53:14.177
STEP: updating a scale subresource 02/13/23 14:53:14.182
STEP: verifying the statefulset Spec.Replicas was modified 02/13/23 14:53:14.191
STEP: Patch a scale subresource 02/13/23 14:53:14.195
STEP: verifying the statefulset Spec.Replicas was modified 02/13/23 14:53:14.203
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 14:53:14.208: INFO: Deleting all statefulset in ns statefulset-6535
Feb 13 14:53:14.221: INFO: Scaling statefulset ss to 0
W0213 14:53:14.233059      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:53:24.245: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:53:24.250: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 14:53:24.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6535" for this suite. 02/13/23 14:53:24.277
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":313,"skipped":5692,"failed":0}
------------------------------
• [SLOW TEST] [20.163 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:53:04.12
    Feb 13 14:53:04.120: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 14:53:04.12
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:04.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:04.14
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6535 02/13/23 14:53:04.143
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6535 02/13/23 14:53:04.148
    W0213 14:53:04.154839      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:53:04.158: INFO: Found 0 stateful pods, waiting for 1
    Feb 13 14:53:14.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 02/13/23 14:53:14.177
    STEP: updating a scale subresource 02/13/23 14:53:14.182
    STEP: verifying the statefulset Spec.Replicas was modified 02/13/23 14:53:14.191
    STEP: Patch a scale subresource 02/13/23 14:53:14.195
    STEP: verifying the statefulset Spec.Replicas was modified 02/13/23 14:53:14.203
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 14:53:14.208: INFO: Deleting all statefulset in ns statefulset-6535
    Feb 13 14:53:14.221: INFO: Scaling statefulset ss to 0
    W0213 14:53:14.233059      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:53:24.245: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 14:53:24.250: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 14:53:24.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6535" for this suite. 02/13/23 14:53:24.277
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:53:24.285
Feb 13 14:53:24.285: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:53:24.287
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:24.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:24.306
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9634 02/13/23 14:53:24.311
STEP: creating a selector 02/13/23 14:53:24.311
STEP: Creating the service pods in kubernetes 02/13/23 14:53:24.312
Feb 13 14:53:24.312: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
W0213 14:53:24.327366      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:53:24.341011      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:53:24.357777      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:53:24.358: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9634" to be "running and ready"
Feb 13 14:53:24.361: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.912714ms
Feb 13 14:53:24.361: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 14:53:26.368: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010302552s
Feb 13 14:53:26.368: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:53:28.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011452695s
Feb 13 14:53:28.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:53:30.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011537577s
Feb 13 14:53:30.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:53:32.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011152965s
Feb 13 14:53:32.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:53:34.368: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01016856s
Feb 13 14:53:34.368: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Feb 13 14:53:36.366: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008697698s
Feb 13 14:53:36.366: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Feb 13 14:53:36.366: INFO: Pod "netserver-0" satisfied condition "running and ready"
Feb 13 14:53:36.371: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9634" to be "running and ready"
Feb 13 14:53:36.375: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.977781ms
Feb 13 14:53:36.375: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Feb 13 14:53:36.375: INFO: Pod "netserver-1" satisfied condition "running and ready"
Feb 13 14:53:36.379: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9634" to be "running and ready"
Feb 13 14:53:36.383: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.045505ms
Feb 13 14:53:36.383: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Feb 13 14:53:36.383: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 02/13/23 14:53:36.387
W0213 14:53:36.395378      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 14:53:36.404865      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:53:36.405: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9634" to be "running"
Feb 13 14:53:36.408: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08294ms
Feb 13 14:53:38.415: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009970776s
Feb 13 14:53:38.415: INFO: Pod "test-container-pod" satisfied condition "running"
Feb 13 14:53:38.421: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9634" to be "running"
Feb 13 14:53:38.426: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.582673ms
Feb 13 14:53:38.426: INFO: Pod "host-test-container-pod" satisfied condition "running"
Feb 13 14:53:38.431: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Feb 13 14:53:38.431: INFO: Going to poll 10.244.1.159 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:53:38.436: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.159:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:53:38.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:53:38.438: INFO: ExecWithOptions: Clientset creation
Feb 13 14:53:38.438: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.159%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:53:38.609: INFO: Found all 1 expected endpoints: [netserver-0]
Feb 13 14:53:38.609: INFO: Going to poll 10.244.0.103 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:53:38.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.103:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:53:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:53:38.615: INFO: ExecWithOptions: Clientset creation
Feb 13 14:53:38.615: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.103%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:53:38.755: INFO: Found all 1 expected endpoints: [netserver-1]
Feb 13 14:53:38.755: INFO: Going to poll 10.244.2.235 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Feb 13 14:53:38.760: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.235:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Feb 13 14:53:38.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
Feb 13 14:53:38.762: INFO: ExecWithOptions: Clientset creation
Feb 13 14:53:38.762: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.2.235%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Feb 13 14:53:38.916: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Feb 13 14:53:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9634" for this suite. 02/13/23 14:53:38.924
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":314,"skipped":5696,"failed":0}
------------------------------
• [SLOW TEST] [14.648 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:53:24.285
    Feb 13 14:53:24.285: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename pod-network-test 02/13/23 14:53:24.287
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:24.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:24.306
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9634 02/13/23 14:53:24.311
    STEP: creating a selector 02/13/23 14:53:24.311
    STEP: Creating the service pods in kubernetes 02/13/23 14:53:24.312
    Feb 13 14:53:24.312: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    W0213 14:53:24.327366      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:53:24.341011      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:53:24.357777      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:53:24.358: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9634" to be "running and ready"
    Feb 13 14:53:24.361: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.912714ms
    Feb 13 14:53:24.361: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 14:53:26.368: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010302552s
    Feb 13 14:53:26.368: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:53:28.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011452695s
    Feb 13 14:53:28.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:53:30.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011537577s
    Feb 13 14:53:30.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:53:32.369: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011152965s
    Feb 13 14:53:32.369: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:53:34.368: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01016856s
    Feb 13 14:53:34.368: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Feb 13 14:53:36.366: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008697698s
    Feb 13 14:53:36.366: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Feb 13 14:53:36.366: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Feb 13 14:53:36.371: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9634" to be "running and ready"
    Feb 13 14:53:36.375: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.977781ms
    Feb 13 14:53:36.375: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Feb 13 14:53:36.375: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Feb 13 14:53:36.379: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9634" to be "running and ready"
    Feb 13 14:53:36.383: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.045505ms
    Feb 13 14:53:36.383: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Feb 13 14:53:36.383: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 02/13/23 14:53:36.387
    W0213 14:53:36.395378      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 14:53:36.404865      19 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:53:36.405: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9634" to be "running"
    Feb 13 14:53:36.408: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08294ms
    Feb 13 14:53:38.415: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009970776s
    Feb 13 14:53:38.415: INFO: Pod "test-container-pod" satisfied condition "running"
    Feb 13 14:53:38.421: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9634" to be "running"
    Feb 13 14:53:38.426: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.582673ms
    Feb 13 14:53:38.426: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Feb 13 14:53:38.431: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Feb 13 14:53:38.431: INFO: Going to poll 10.244.1.159 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:53:38.436: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.159:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:53:38.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:53:38.438: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:53:38.438: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.159%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:53:38.609: INFO: Found all 1 expected endpoints: [netserver-0]
    Feb 13 14:53:38.609: INFO: Going to poll 10.244.0.103 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:53:38.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.103:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:53:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:53:38.615: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:53:38.615: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.103%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:53:38.755: INFO: Found all 1 expected endpoints: [netserver-1]
    Feb 13 14:53:38.755: INFO: Going to poll 10.244.2.235 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Feb 13 14:53:38.760: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.235:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9634 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Feb 13 14:53:38.760: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    Feb 13 14:53:38.762: INFO: ExecWithOptions: Clientset creation
    Feb 13 14:53:38.762: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9634/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.2.235%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Feb 13 14:53:38.916: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Feb 13 14:53:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9634" for this suite. 02/13/23 14:53:38.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:53:38.949
Feb 13 14:53:38.949: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 14:53:38.95
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:38.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:38.979
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 02/13/23 14:53:38.985
Feb 13 14:53:38.986: INFO: namespace kubectl-8761
Feb 13 14:53:38.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 create -f -'
Feb 13 14:53:39.661: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 14:53:39.661: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 02/13/23 14:53:39.661
Feb 13 14:53:40.668: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:53:40.668: INFO: Found 0 / 1
Feb 13 14:53:41.668: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:53:41.668: INFO: Found 1 / 1
Feb 13 14:53:41.668: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 14:53:41.677: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 13 14:53:41.677: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 14:53:41.677: INFO: wait on agnhost-primary startup in kubectl-8761 
Feb 13 14:53:41.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 logs agnhost-primary-vbczs agnhost-primary'
Feb 13 14:53:41.816: INFO: stderr: ""
Feb 13 14:53:41.816: INFO: stdout: "Paused\n"
STEP: exposing RC 02/13/23 14:53:41.816
Feb 13 14:53:41.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Feb 13 14:53:41.930: INFO: stderr: ""
Feb 13 14:53:41.930: INFO: stdout: "service/rm2 exposed\n"
Feb 13 14:53:41.933: INFO: Service rm2 in namespace kubectl-8761 found.
STEP: exposing service 02/13/23 14:53:43.941
Feb 13 14:53:43.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Feb 13 14:53:44.052: INFO: stderr: ""
Feb 13 14:53:44.052: INFO: stdout: "service/rm3 exposed\n"
Feb 13 14:53:44.057: INFO: Service rm3 in namespace kubectl-8761 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 14:53:46.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8761" for this suite. 02/13/23 14:53:46.075
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":315,"skipped":5757,"failed":0}
------------------------------
• [SLOW TEST] [7.137 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:53:38.949
    Feb 13 14:53:38.949: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 14:53:38.95
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:38.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:38.979
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 02/13/23 14:53:38.985
    Feb 13 14:53:38.986: INFO: namespace kubectl-8761
    Feb 13 14:53:38.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 create -f -'
    Feb 13 14:53:39.661: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 14:53:39.661: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 02/13/23 14:53:39.661
    Feb 13 14:53:40.668: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:53:40.668: INFO: Found 0 / 1
    Feb 13 14:53:41.668: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:53:41.668: INFO: Found 1 / 1
    Feb 13 14:53:41.668: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Feb 13 14:53:41.677: INFO: Selector matched 1 pods for map[app:agnhost]
    Feb 13 14:53:41.677: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Feb 13 14:53:41.677: INFO: wait on agnhost-primary startup in kubectl-8761 
    Feb 13 14:53:41.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 logs agnhost-primary-vbczs agnhost-primary'
    Feb 13 14:53:41.816: INFO: stderr: ""
    Feb 13 14:53:41.816: INFO: stdout: "Paused\n"
    STEP: exposing RC 02/13/23 14:53:41.816
    Feb 13 14:53:41.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Feb 13 14:53:41.930: INFO: stderr: ""
    Feb 13 14:53:41.930: INFO: stdout: "service/rm2 exposed\n"
    Feb 13 14:53:41.933: INFO: Service rm2 in namespace kubectl-8761 found.
    STEP: exposing service 02/13/23 14:53:43.941
    Feb 13 14:53:43.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-8761 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Feb 13 14:53:44.052: INFO: stderr: ""
    Feb 13 14:53:44.052: INFO: stdout: "service/rm3 exposed\n"
    Feb 13 14:53:44.057: INFO: Service rm3 in namespace kubectl-8761 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 14:53:46.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8761" for this suite. 02/13/23 14:53:46.075
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:53:46.091
Feb 13 14:53:46.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename taint-multiple-pods 02/13/23 14:53:46.095
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:46.12
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:46.126
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Feb 13 14:53:46.131: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 14:54:46.160: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Feb 13 14:54:46.163: INFO: Starting informer...
STEP: Starting pods... 02/13/23 14:54:46.164
W0213 14:54:46.173288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:54:46.386: INFO: Pod1 is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
W0213 14:54:46.392918      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:54:46.600: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-3376" to be "running"
Feb 13 14:54:46.605: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.053943ms
Feb 13 14:54:48.611: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011197233s
Feb 13 14:54:48.611: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Feb 13 14:54:48.611: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-3376" to be "running"
Feb 13 14:54:48.616: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.8102ms
Feb 13 14:54:48.616: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Feb 13 14:54:48.616: INFO: Pod2 is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
STEP: Trying to apply a taint on the Node 02/13/23 14:54:48.616
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 14:54:48.638
STEP: Waiting for Pod1 and Pod2 to be deleted 02/13/23 14:54:48.647
Feb 13 14:54:54.471: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb 13 14:55:14.535: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 14:55:14.554
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Feb 13 14:55:14.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-3376" for this suite. 02/13/23 14:55:14.564
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":316,"skipped":5759,"failed":0}
------------------------------
• [SLOW TEST] [88.494 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:53:46.091
    Feb 13 14:53:46.091: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename taint-multiple-pods 02/13/23 14:53:46.095
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:53:46.12
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:53:46.126
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Feb 13 14:53:46.131: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 14:54:46.160: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Feb 13 14:54:46.163: INFO: Starting informer...
    STEP: Starting pods... 02/13/23 14:54:46.164
    W0213 14:54:46.173288      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:54:46.386: INFO: Pod1 is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
    W0213 14:54:46.392918      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:54:46.600: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-3376" to be "running"
    Feb 13 14:54:46.605: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.053943ms
    Feb 13 14:54:48.611: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011197233s
    Feb 13 14:54:48.611: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Feb 13 14:54:48.611: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-3376" to be "running"
    Feb 13 14:54:48.616: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.8102ms
    Feb 13 14:54:48.616: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Feb 13 14:54:48.616: INFO: Pod2 is running on conformance-5500-0ccfa5-pool-bf9f-o7jrw. Tainting Node
    STEP: Trying to apply a taint on the Node 02/13/23 14:54:48.616
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 14:54:48.638
    STEP: Waiting for Pod1 and Pod2 to be deleted 02/13/23 14:54:48.647
    Feb 13 14:54:54.471: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Feb 13 14:55:14.535: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 02/13/23 14:55:14.554
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 14:55:14.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-3376" for this suite. 02/13/23 14:55:14.564
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:55:14.588
Feb 13 14:55:14.588: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 14:55:14.59
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:14.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:14.625
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 02/13/23 14:55:14.629
W0213 14:55:14.637704      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the Deployment to create new ReplicaSet 02/13/23 14:55:14.638
STEP: delete the deployment 02/13/23 14:55:14.643
STEP: wait for all rs to be garbage collected 02/13/23 14:55:14.652
STEP: expected 0 rs, got 1 rs 02/13/23 14:55:14.668
STEP: expected 0 pods, got 2 pods 02/13/23 14:55:14.678
STEP: Gathering metrics 02/13/23 14:55:15.193
W0213 14:55:15.201629      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Feb 13 14:55:15.201: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 14:55:15.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2852" for this suite. 02/13/23 14:55:15.206
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":317,"skipped":5764,"failed":0}
------------------------------
• [0.628 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:55:14.588
    Feb 13 14:55:14.588: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 14:55:14.59
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:14.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:14.625
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 02/13/23 14:55:14.629
    W0213 14:55:14.637704      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the Deployment to create new ReplicaSet 02/13/23 14:55:14.638
    STEP: delete the deployment 02/13/23 14:55:14.643
    STEP: wait for all rs to be garbage collected 02/13/23 14:55:14.652
    STEP: expected 0 rs, got 1 rs 02/13/23 14:55:14.668
    STEP: expected 0 pods, got 2 pods 02/13/23 14:55:14.678
    STEP: Gathering metrics 02/13/23 14:55:15.193
    W0213 14:55:15.201629      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Feb 13 14:55:15.201: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 14:55:15.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2852" for this suite. 02/13/23 14:55:15.206
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:55:15.223
Feb 13 14:55:15.223: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename subpath 02/13/23 14:55:15.231
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:15.257
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:15.26
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 02/13/23 14:55:15.264
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-4rsr 02/13/23 14:55:15.274
STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:55:15.274
W0213 14:55:15.283927      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-secret-4rsr" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-secret-4rsr" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-secret-4rsr" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-secret-4rsr" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:55:15.284: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4rsr" in namespace "subpath-3338" to be "Succeeded or Failed"
Feb 13 14:55:15.288: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.88012ms
Feb 13 14:55:17.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013799353s
Feb 13 14:55:19.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 4.013133254s
Feb 13 14:55:21.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 6.013704594s
Feb 13 14:55:23.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 8.011584389s
Feb 13 14:55:25.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 10.010894087s
Feb 13 14:55:27.294: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 12.010611993s
Feb 13 14:55:29.298: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 14.014010083s
Feb 13 14:55:31.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 16.012069196s
Feb 13 14:55:33.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 18.011078851s
Feb 13 14:55:35.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 20.012525244s
Feb 13 14:55:37.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 22.013756489s
Feb 13 14:55:39.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=false. Elapsed: 24.01229987s
Feb 13 14:55:41.294: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010359905s
STEP: Saw pod success 02/13/23 14:55:41.294
Feb 13 14:55:41.294: INFO: Pod "pod-subpath-test-secret-4rsr" satisfied condition "Succeeded or Failed"
Feb 13 14:55:41.298: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-secret-4rsr container test-container-subpath-secret-4rsr: <nil>
STEP: delete the pod 02/13/23 14:55:41.324
Feb 13 14:55:41.337: INFO: Waiting for pod pod-subpath-test-secret-4rsr to disappear
Feb 13 14:55:41.340: INFO: Pod pod-subpath-test-secret-4rsr no longer exists
STEP: Deleting pod pod-subpath-test-secret-4rsr 02/13/23 14:55:41.34
Feb 13 14:55:41.341: INFO: Deleting pod "pod-subpath-test-secret-4rsr" in namespace "subpath-3338"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Feb 13 14:55:41.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3338" for this suite. 02/13/23 14:55:41.348
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":318,"skipped":5785,"failed":0}
------------------------------
• [SLOW TEST] [26.131 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:55:15.223
    Feb 13 14:55:15.223: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename subpath 02/13/23 14:55:15.231
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:15.257
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:15.26
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 02/13/23 14:55:15.264
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-4rsr 02/13/23 14:55:15.274
    STEP: Creating a pod to test atomic-volume-subpath 02/13/23 14:55:15.274
    W0213 14:55:15.283927      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-secret-4rsr" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-secret-4rsr" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-secret-4rsr" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-secret-4rsr" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:55:15.284: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4rsr" in namespace "subpath-3338" to be "Succeeded or Failed"
    Feb 13 14:55:15.288: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.88012ms
    Feb 13 14:55:17.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013799353s
    Feb 13 14:55:19.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 4.013133254s
    Feb 13 14:55:21.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 6.013704594s
    Feb 13 14:55:23.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 8.011584389s
    Feb 13 14:55:25.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 10.010894087s
    Feb 13 14:55:27.294: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 12.010611993s
    Feb 13 14:55:29.298: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 14.014010083s
    Feb 13 14:55:31.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 16.012069196s
    Feb 13 14:55:33.295: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 18.011078851s
    Feb 13 14:55:35.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 20.012525244s
    Feb 13 14:55:37.297: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=true. Elapsed: 22.013756489s
    Feb 13 14:55:39.296: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Running", Reason="", readiness=false. Elapsed: 24.01229987s
    Feb 13 14:55:41.294: INFO: Pod "pod-subpath-test-secret-4rsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010359905s
    STEP: Saw pod success 02/13/23 14:55:41.294
    Feb 13 14:55:41.294: INFO: Pod "pod-subpath-test-secret-4rsr" satisfied condition "Succeeded or Failed"
    Feb 13 14:55:41.298: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-secret-4rsr container test-container-subpath-secret-4rsr: <nil>
    STEP: delete the pod 02/13/23 14:55:41.324
    Feb 13 14:55:41.337: INFO: Waiting for pod pod-subpath-test-secret-4rsr to disappear
    Feb 13 14:55:41.340: INFO: Pod pod-subpath-test-secret-4rsr no longer exists
    STEP: Deleting pod pod-subpath-test-secret-4rsr 02/13/23 14:55:41.34
    Feb 13 14:55:41.341: INFO: Deleting pod "pod-subpath-test-secret-4rsr" in namespace "subpath-3338"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Feb 13 14:55:41.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3338" for this suite. 02/13/23 14:55:41.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:55:41.357
Feb 13 14:55:41.357: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 14:55:41.358
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.383
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 02/13/23 14:55:41.395
STEP: Getting a ResourceQuota 02/13/23 14:55:41.404
STEP: Listing all ResourceQuotas with LabelSelector 02/13/23 14:55:41.407
STEP: Patching the ResourceQuota 02/13/23 14:55:41.412
STEP: Deleting a Collection of ResourceQuotas 02/13/23 14:55:41.419
STEP: Verifying the deleted ResourceQuota 02/13/23 14:55:41.429
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 14:55:41.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4783" for this suite. 02/13/23 14:55:41.436
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":319,"skipped":5830,"failed":0}
------------------------------
• [0.086 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:55:41.357
    Feb 13 14:55:41.357: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 14:55:41.358
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.383
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 02/13/23 14:55:41.395
    STEP: Getting a ResourceQuota 02/13/23 14:55:41.404
    STEP: Listing all ResourceQuotas with LabelSelector 02/13/23 14:55:41.407
    STEP: Patching the ResourceQuota 02/13/23 14:55:41.412
    STEP: Deleting a Collection of ResourceQuotas 02/13/23 14:55:41.419
    STEP: Verifying the deleted ResourceQuota 02/13/23 14:55:41.429
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 14:55:41.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4783" for this suite. 02/13/23 14:55:41.436
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:55:41.449
Feb 13 14:55:41.449: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename endpointslice 02/13/23 14:55:41.45
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.469
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Feb 13 14:55:41.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2133" for this suite. 02/13/23 14:55:41.526
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":320,"skipped":5856,"failed":0}
------------------------------
• [0.082 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:55:41.449
    Feb 13 14:55:41.449: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename endpointslice 02/13/23 14:55:41.45
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.469
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Feb 13 14:55:41.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2133" for this suite. 02/13/23 14:55:41.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:55:41.545
Feb 13 14:55:41.545: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 14:55:41.547
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.574
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 in namespace container-probe-3603 02/13/23 14:55:41.578
W0213 14:55:41.585956      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:55:41.586: INFO: Waiting up to 5m0s for pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9" in namespace "container-probe-3603" to be "not pending"
Feb 13 14:55:41.593: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.574528ms
Feb 13 14:55:43.601: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9": Phase="Running", Reason="", readiness=true. Elapsed: 2.015625997s
Feb 13 14:55:43.602: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9" satisfied condition "not pending"
Feb 13 14:55:43.602: INFO: Started pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 in namespace container-probe-3603
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:55:43.602
Feb 13 14:55:43.610: INFO: Initial restart count of pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 is 0
STEP: deleting the pod 02/13/23 14:59:44.447
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 14:59:44.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3603" for this suite. 02/13/23 14:59:44.47
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":321,"skipped":5868,"failed":0}
------------------------------
• [SLOW TEST] [242.933 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:55:41.545
    Feb 13 14:55:41.545: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 14:55:41.547
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:55:41.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:55:41.574
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 in namespace container-probe-3603 02/13/23 14:55:41.578
    W0213 14:55:41.585956      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:55:41.586: INFO: Waiting up to 5m0s for pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9" in namespace "container-probe-3603" to be "not pending"
    Feb 13 14:55:41.593: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.574528ms
    Feb 13 14:55:43.601: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9": Phase="Running", Reason="", readiness=true. Elapsed: 2.015625997s
    Feb 13 14:55:43.602: INFO: Pod "busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9" satisfied condition "not pending"
    Feb 13 14:55:43.602: INFO: Started pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 in namespace container-probe-3603
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 14:55:43.602
    Feb 13 14:55:43.610: INFO: Initial restart count of pod busybox-1fbc4292-5450-492d-9ee9-3a490b1e2fc9 is 0
    STEP: deleting the pod 02/13/23 14:59:44.447
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 14:59:44.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3603" for this suite. 02/13/23 14:59:44.47
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:59:44.481
Feb 13 14:59:44.481: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 14:59:44.484
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:59:44.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:59:44.516
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-6516 02/13/23 14:59:44.521
STEP: creating service affinity-clusterip in namespace services-6516 02/13/23 14:59:44.521
STEP: creating replication controller affinity-clusterip in namespace services-6516 02/13/23 14:59:44.539
W0213 14:59:44.549356      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 14:59:44.549552      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6516, replica count: 3
I0213 14:59:47.600902      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:59:47.612: INFO: Creating new exec pod
W0213 14:59:47.623690      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 14:59:47.624: INFO: Waiting up to 5m0s for pod "execpod-affinityzhmmf" in namespace "services-6516" to be "running"
Feb 13 14:59:47.629: INFO: Pod "execpod-affinityzhmmf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.423577ms
Feb 13 14:59:49.634: INFO: Pod "execpod-affinityzhmmf": Phase="Running", Reason="", readiness=true. Elapsed: 2.009497696s
Feb 13 14:59:49.634: INFO: Pod "execpod-affinityzhmmf" satisfied condition "running"
Feb 13 14:59:50.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Feb 13 14:59:50.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Feb 13 14:59:50.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:59:50.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.105.76.108 80'
Feb 13 14:59:51.182: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.105.76.108 80\nConnection to 10.105.76.108 80 port [tcp/http] succeeded!\n"
Feb 13 14:59:51.183: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 14:59:51.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.105.76.108:80/ ; done'
Feb 13 14:59:51.517: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n"
Feb 13 14:59:51.517: INFO: stdout: "\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq"
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.518: INFO: Received response from host: affinity-clusterip-gsmhq
Feb 13 14:59:51.518: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-6516, will wait for the garbage collector to delete the pods 02/13/23 14:59:51.541
Feb 13 14:59:51.607: INFO: Deleting ReplicationController affinity-clusterip took: 12.125597ms
Feb 13 14:59:51.708: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.812294ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 14:59:53.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6516" for this suite. 02/13/23 14:59:53.557
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":322,"skipped":5872,"failed":0}
------------------------------
• [SLOW TEST] [9.082 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:59:44.481
    Feb 13 14:59:44.481: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 14:59:44.484
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:59:44.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:59:44.516
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-6516 02/13/23 14:59:44.521
    STEP: creating service affinity-clusterip in namespace services-6516 02/13/23 14:59:44.521
    STEP: creating replication controller affinity-clusterip in namespace services-6516 02/13/23 14:59:44.539
    W0213 14:59:44.549356      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 14:59:44.549552      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6516, replica count: 3
    I0213 14:59:47.600902      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 14:59:47.612: INFO: Creating new exec pod
    W0213 14:59:47.623690      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 14:59:47.624: INFO: Waiting up to 5m0s for pod "execpod-affinityzhmmf" in namespace "services-6516" to be "running"
    Feb 13 14:59:47.629: INFO: Pod "execpod-affinityzhmmf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.423577ms
    Feb 13 14:59:49.634: INFO: Pod "execpod-affinityzhmmf": Phase="Running", Reason="", readiness=true. Elapsed: 2.009497696s
    Feb 13 14:59:49.634: INFO: Pod "execpod-affinityzhmmf" satisfied condition "running"
    Feb 13 14:59:50.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Feb 13 14:59:50.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Feb 13 14:59:50.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:59:50.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.105.76.108 80'
    Feb 13 14:59:51.182: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.105.76.108 80\nConnection to 10.105.76.108 80 port [tcp/http] succeeded!\n"
    Feb 13 14:59:51.183: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 14:59:51.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-6516 exec execpod-affinityzhmmf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.105.76.108:80/ ; done'
    Feb 13 14:59:51.517: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.76.108:80/\n"
    Feb 13 14:59:51.517: INFO: stdout: "\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq\naffinity-clusterip-gsmhq"
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.517: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.518: INFO: Received response from host: affinity-clusterip-gsmhq
    Feb 13 14:59:51.518: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-6516, will wait for the garbage collector to delete the pods 02/13/23 14:59:51.541
    Feb 13 14:59:51.607: INFO: Deleting ReplicationController affinity-clusterip took: 12.125597ms
    Feb 13 14:59:51.708: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.812294ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 14:59:53.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6516" for this suite. 02/13/23 14:59:53.557
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 14:59:53.566
Feb 13 14:59:53.567: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 14:59:53.569
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:59:53.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:59:53.585
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 14:59:53.601
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:59:54.11
STEP: Deploying the webhook pod 02/13/23 14:59:54.12
W0213 14:59:54.141250      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 14:59:54.141
Feb 13 14:59:54.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 14:59:56.165
STEP: Verifying the service has paired with the endpoint 02/13/23 14:59:56.184
Feb 13 14:59:57.184: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Feb 13 14:59:57.192: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1662-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:59:57.713
STEP: Creating a custom resource that should be mutated by the webhook 02/13/23 14:59:57.747
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 15:00:00.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1040" for this suite. 02/13/23 15:00:00.384
STEP: Destroying namespace "webhook-1040-markers" for this suite. 02/13/23 15:00:00.393
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":323,"skipped":5873,"failed":0}
------------------------------
• [SLOW TEST] [6.880 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 14:59:53.566
    Feb 13 14:59:53.567: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 14:59:53.569
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 14:59:53.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 14:59:53.585
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 14:59:53.601
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 14:59:54.11
    STEP: Deploying the webhook pod 02/13/23 14:59:54.12
    W0213 14:59:54.141250      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 14:59:54.141
    Feb 13 14:59:54.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 14:59:56.165
    STEP: Verifying the service has paired with the endpoint 02/13/23 14:59:56.184
    Feb 13 14:59:57.184: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Feb 13 14:59:57.192: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1662-crds.webhook.example.com via the AdmissionRegistration API 02/13/23 14:59:57.713
    STEP: Creating a custom resource that should be mutated by the webhook 02/13/23 14:59:57.747
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 15:00:00.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1040" for this suite. 02/13/23 15:00:00.384
    STEP: Destroying namespace "webhook-1040-markers" for this suite. 02/13/23 15:00:00.393
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:00:00.452
Feb 13 15:00:00.452: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 15:00:00.453
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:00.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:00.468
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 15:00:00.491
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:00:00.866
STEP: Deploying the webhook pod 02/13/23 15:00:00.874
W0213 15:00:00.889647      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 15:00:00.89
Feb 13 15:00:00.899: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 15:00:02.918
STEP: Verifying the service has paired with the endpoint 02/13/23 15:00:02.935
Feb 13 15:00:03.936: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 02/13/23 15:00:03.943
STEP: create a pod 02/13/23 15:00:03.985
W0213 15:00:03.994594      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:00:03.994: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-3641" to be "running"
Feb 13 15:00:04.005: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.060418ms
Feb 13 15:00:06.012: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017174267s
Feb 13 15:00:06.012: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 02/13/23 15:00:06.012
Feb 13 15:00:06.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=webhook-3641 attach --namespace=webhook-3641 to-be-attached-pod -i -c=container1'
Feb 13 15:00:06.144: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 15:00:06.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3641" for this suite. 02/13/23 15:00:06.155
STEP: Destroying namespace "webhook-3641-markers" for this suite. 02/13/23 15:00:06.161
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":324,"skipped":5895,"failed":0}
------------------------------
• [SLOW TEST] [5.757 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:00:00.452
    Feb 13 15:00:00.452: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 15:00:00.453
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:00.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:00.468
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 15:00:00.491
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:00:00.866
    STEP: Deploying the webhook pod 02/13/23 15:00:00.874
    W0213 15:00:00.889647      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 15:00:00.89
    Feb 13 15:00:00.899: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 15:00:02.918
    STEP: Verifying the service has paired with the endpoint 02/13/23 15:00:02.935
    Feb 13 15:00:03.936: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 02/13/23 15:00:03.943
    STEP: create a pod 02/13/23 15:00:03.985
    W0213 15:00:03.994594      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:00:03.994: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-3641" to be "running"
    Feb 13 15:00:04.005: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.060418ms
    Feb 13 15:00:06.012: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017174267s
    Feb 13 15:00:06.012: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 02/13/23 15:00:06.012
    Feb 13 15:00:06.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=webhook-3641 attach --namespace=webhook-3641 to-be-attached-pod -i -c=container1'
    Feb 13 15:00:06.144: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 15:00:06.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3641" for this suite. 02/13/23 15:00:06.155
    STEP: Destroying namespace "webhook-3641-markers" for this suite. 02/13/23 15:00:06.161
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:00:06.215
Feb 13 15:00:06.216: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 15:00:06.217
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:06.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:06.242
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 02/13/23 15:00:06.245
STEP: Creating a ResourceQuota 02/13/23 15:00:11.252
STEP: Ensuring resource quota status is calculated 02/13/23 15:00:11.26
STEP: Creating a Pod that fits quota 02/13/23 15:00:13.268
W0213 15:00:13.298538      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring ResourceQuota status captures the pod usage 02/13/23 15:00:13.298
STEP: Not allowing a pod to be created that exceeds remaining quota 02/13/23 15:00:15.306
W0213 15:00:15.312144      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 02/13/23 15:00:15.312
W0213 15:00:15.317863      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring a pod cannot update its resource requirements 02/13/23 15:00:15.317
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 02/13/23 15:00:15.324
STEP: Deleting the pod 02/13/23 15:00:17.332
STEP: Ensuring resource quota status released the pod usage 02/13/23 15:00:17.355
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 15:00:19.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2012" for this suite. 02/13/23 15:00:19.373
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":325,"skipped":5901,"failed":0}
------------------------------
• [SLOW TEST] [13.169 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:00:06.215
    Feb 13 15:00:06.216: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 15:00:06.217
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:06.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:06.242
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 02/13/23 15:00:06.245
    STEP: Creating a ResourceQuota 02/13/23 15:00:11.252
    STEP: Ensuring resource quota status is calculated 02/13/23 15:00:11.26
    STEP: Creating a Pod that fits quota 02/13/23 15:00:13.268
    W0213 15:00:13.298538      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring ResourceQuota status captures the pod usage 02/13/23 15:00:13.298
    STEP: Not allowing a pod to be created that exceeds remaining quota 02/13/23 15:00:15.306
    W0213 15:00:15.312144      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 02/13/23 15:00:15.312
    W0213 15:00:15.317863      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring a pod cannot update its resource requirements 02/13/23 15:00:15.317
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 02/13/23 15:00:15.324
    STEP: Deleting the pod 02/13/23 15:00:17.332
    STEP: Ensuring resource quota status released the pod usage 02/13/23 15:00:17.355
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 15:00:19.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2012" for this suite. 02/13/23 15:00:19.373
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:00:19.398
Feb 13 15:00:19.398: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename lease-test 02/13/23 15:00:19.4
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:19.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:19.432
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Feb 13 15:00:19.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3196" for this suite. 02/13/23 15:00:19.505
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":326,"skipped":5928,"failed":0}
------------------------------
• [0.114 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:00:19.398
    Feb 13 15:00:19.398: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename lease-test 02/13/23 15:00:19.4
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:19.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:19.432
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Feb 13 15:00:19.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-3196" for this suite. 02/13/23 15:00:19.505
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:00:19.519
Feb 13 15:00:19.520: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 15:00:19.521
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:19.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:19.535
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-0681e6bb-fad6-4d98-90ff-a0b6adc553b2 02/13/23 15:00:19.538
STEP: Creating a pod to test consume configMaps 02/13/23 15:00:19.544
W0213 15:00:19.550502      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:00:19.550: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9" in namespace "configmap-2204" to be "Succeeded or Failed"
Feb 13 15:00:19.556: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.135941ms
Feb 13 15:00:21.565: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014289284s
Feb 13 15:00:23.564: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014184036s
STEP: Saw pod success 02/13/23 15:00:23.564
Feb 13 15:00:23.565: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9" satisfied condition "Succeeded or Failed"
Feb 13 15:00:23.572: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 container agnhost-container: <nil>
STEP: delete the pod 02/13/23 15:00:23.61
Feb 13 15:00:23.626: INFO: Waiting for pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 to disappear
Feb 13 15:00:23.629: INFO: Pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 15:00:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2204" for this suite. 02/13/23 15:00:23.636
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":327,"skipped":5965,"failed":0}
------------------------------
• [4.128 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:00:19.519
    Feb 13 15:00:19.520: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 15:00:19.521
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:19.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:19.535
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-0681e6bb-fad6-4d98-90ff-a0b6adc553b2 02/13/23 15:00:19.538
    STEP: Creating a pod to test consume configMaps 02/13/23 15:00:19.544
    W0213 15:00:19.550502      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:00:19.550: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9" in namespace "configmap-2204" to be "Succeeded or Failed"
    Feb 13 15:00:19.556: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.135941ms
    Feb 13 15:00:21.565: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014289284s
    Feb 13 15:00:23.564: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014184036s
    STEP: Saw pod success 02/13/23 15:00:23.564
    Feb 13 15:00:23.565: INFO: Pod "pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9" satisfied condition "Succeeded or Failed"
    Feb 13 15:00:23.572: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 15:00:23.61
    Feb 13 15:00:23.626: INFO: Waiting for pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 to disappear
    Feb 13 15:00:23.629: INFO: Pod pod-configmaps-d7265e63-c6ab-46b2-92d1-7497bf919df9 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 15:00:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2204" for this suite. 02/13/23 15:00:23.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:00:23.664
Feb 13 15:00:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption 02/13/23 15:00:23.665
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:23.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:23.702
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Feb 13 15:00:23.726: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 15:01:23.753: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:01:23.755
Feb 13 15:01:23.756: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename sched-preemption-path 02/13/23 15:01:23.756
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:23.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:23.772
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Feb 13 15:01:23.794: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Feb 13 15:01:23.798: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Feb 13 15:01:23.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3942" for this suite. 02/13/23 15:01:23.821
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Feb 13 15:01:23.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-743" for this suite. 02/13/23 15:01:23.84
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":328,"skipped":6018,"failed":0}
------------------------------
• [SLOW TEST] [60.220 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:00:23.664
    Feb 13 15:00:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption 02/13/23 15:00:23.665
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:00:23.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:00:23.702
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Feb 13 15:00:23.726: INFO: Waiting up to 1m0s for all nodes to be ready
    Feb 13 15:01:23.753: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:01:23.755
    Feb 13 15:01:23.756: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename sched-preemption-path 02/13/23 15:01:23.756
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:23.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:23.772
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Feb 13 15:01:23.794: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Feb 13 15:01:23.798: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Feb 13 15:01:23.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-3942" for this suite. 02/13/23 15:01:23.821
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 15:01:23.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-743" for this suite. 02/13/23 15:01:23.84
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:01:23.892
Feb 13 15:01:23.893: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replicaset 02/13/23 15:01:23.894
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:23.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:23.912
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 02/13/23 15:01:23.915
W0213 15:01:23.920284      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Verify that the required pods have come up 02/13/23 15:01:23.92
Feb 13 15:01:23.923: INFO: Pod name sample-pod: Found 0 pods out of 3
Feb 13 15:01:28.928: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 02/13/23 15:01:28.928
Feb 13 15:01:28.932: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 02/13/23 15:01:28.932
STEP: DeleteCollection of the ReplicaSets 02/13/23 15:01:28.939
STEP: After DeleteCollection verify that ReplicaSets have been deleted 02/13/23 15:01:28.948
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Feb 13 15:01:28.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4184" for this suite. 02/13/23 15:01:28.963
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":329,"skipped":6024,"failed":0}
------------------------------
• [SLOW TEST] [5.085 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:01:23.892
    Feb 13 15:01:23.893: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replicaset 02/13/23 15:01:23.894
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:23.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:23.912
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 02/13/23 15:01:23.915
    W0213 15:01:23.920284      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Verify that the required pods have come up 02/13/23 15:01:23.92
    Feb 13 15:01:23.923: INFO: Pod name sample-pod: Found 0 pods out of 3
    Feb 13 15:01:28.928: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 02/13/23 15:01:28.928
    Feb 13 15:01:28.932: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 02/13/23 15:01:28.932
    STEP: DeleteCollection of the ReplicaSets 02/13/23 15:01:28.939
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 02/13/23 15:01:28.948
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Feb 13 15:01:28.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4184" for this suite. 02/13/23 15:01:28.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:01:28.982
Feb 13 15:01:28.982: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename subpath 02/13/23 15:01:28.983
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:29.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:29.016
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 02/13/23 15:01:29.057
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-vdjp 02/13/23 15:01:29.07
STEP: Creating a pod to test atomic-volume-subpath 02/13/23 15:01:29.07
W0213 15:01:29.081142      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-vdjp" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-vdjp" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-vdjp" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-vdjp" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:01:29.081: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vdjp" in namespace "subpath-9424" to be "Succeeded or Failed"
Feb 13 15:01:29.086: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812296ms
Feb 13 15:01:31.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010950377s
Feb 13 15:01:33.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 4.01046082s
Feb 13 15:01:35.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 6.012259241s
Feb 13 15:01:37.095: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 8.01369468s
Feb 13 15:01:39.094: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 10.012912878s
Feb 13 15:01:41.094: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 12.01296817s
Feb 13 15:01:43.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 14.011339181s
Feb 13 15:01:45.097: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 16.015699325s
Feb 13 15:01:47.095: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 18.014043928s
Feb 13 15:01:49.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 20.012217415s
Feb 13 15:01:51.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.011196434s
Feb 13 15:01:53.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.011878589s
STEP: Saw pod success 02/13/23 15:01:53.093
Feb 13 15:01:53.093: INFO: Pod "pod-subpath-test-configmap-vdjp" satisfied condition "Succeeded or Failed"
Feb 13 15:01:53.100: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-configmap-vdjp container test-container-subpath-configmap-vdjp: <nil>
STEP: delete the pod 02/13/23 15:01:53.113
Feb 13 15:01:53.125: INFO: Waiting for pod pod-subpath-test-configmap-vdjp to disappear
Feb 13 15:01:53.129: INFO: Pod pod-subpath-test-configmap-vdjp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vdjp 02/13/23 15:01:53.129
Feb 13 15:01:53.129: INFO: Deleting pod "pod-subpath-test-configmap-vdjp" in namespace "subpath-9424"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Feb 13 15:01:53.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9424" for this suite. 02/13/23 15:01:53.139
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":330,"skipped":6033,"failed":0}
------------------------------
• [SLOW TEST] [24.166 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:01:28.982
    Feb 13 15:01:28.982: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename subpath 02/13/23 15:01:28.983
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:29.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:29.016
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 02/13/23 15:01:29.057
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-vdjp 02/13/23 15:01:29.07
    STEP: Creating a pod to test atomic-volume-subpath 02/13/23 15:01:29.07
    W0213 15:01:29.081142      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-vdjp" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-vdjp" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-vdjp" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-vdjp" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:01:29.081: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vdjp" in namespace "subpath-9424" to be "Succeeded or Failed"
    Feb 13 15:01:29.086: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812296ms
    Feb 13 15:01:31.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010950377s
    Feb 13 15:01:33.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 4.01046082s
    Feb 13 15:01:35.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 6.012259241s
    Feb 13 15:01:37.095: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 8.01369468s
    Feb 13 15:01:39.094: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 10.012912878s
    Feb 13 15:01:41.094: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 12.01296817s
    Feb 13 15:01:43.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 14.011339181s
    Feb 13 15:01:45.097: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 16.015699325s
    Feb 13 15:01:47.095: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 18.014043928s
    Feb 13 15:01:49.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=true. Elapsed: 20.012217415s
    Feb 13 15:01:51.092: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.011196434s
    Feb 13 15:01:53.093: INFO: Pod "pod-subpath-test-configmap-vdjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.011878589s
    STEP: Saw pod success 02/13/23 15:01:53.093
    Feb 13 15:01:53.093: INFO: Pod "pod-subpath-test-configmap-vdjp" satisfied condition "Succeeded or Failed"
    Feb 13 15:01:53.100: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-subpath-test-configmap-vdjp container test-container-subpath-configmap-vdjp: <nil>
    STEP: delete the pod 02/13/23 15:01:53.113
    Feb 13 15:01:53.125: INFO: Waiting for pod pod-subpath-test-configmap-vdjp to disappear
    Feb 13 15:01:53.129: INFO: Pod pod-subpath-test-configmap-vdjp no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-vdjp 02/13/23 15:01:53.129
    Feb 13 15:01:53.129: INFO: Deleting pod "pod-subpath-test-configmap-vdjp" in namespace "subpath-9424"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Feb 13 15:01:53.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9424" for this suite. 02/13/23 15:01:53.139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:01:53.157
Feb 13 15:01:53.157: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 15:01:53.159
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:53.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:53.174
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-9932 02/13/23 15:01:53.177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[] 02/13/23 15:01:53.187
Feb 13 15:01:53.198: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9932 02/13/23 15:01:53.198
W0213 15:01:53.205271      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:01:53.205: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9932" to be "running and ready"
Feb 13 15:01:53.209: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.241335ms
Feb 13 15:01:53.210: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 15:01:55.217: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011149013s
Feb 13 15:01:55.217: INFO: The phase of Pod pod1 is Running (Ready = true)
Feb 13 15:01:55.217: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod1:[80]] 02/13/23 15:01:55.222
Feb 13 15:01:55.238: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 02/13/23 15:01:55.238
Feb 13 15:01:55.238: INFO: Creating new exec pod
W0213 15:01:55.246479      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:01:55.246: INFO: Waiting up to 5m0s for pod "execpodd4v2n" in namespace "services-9932" to be "running"
Feb 13 15:01:55.251: INFO: Pod "execpodd4v2n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.627803ms
Feb 13 15:01:57.256: INFO: Pod "execpodd4v2n": Phase="Running", Reason="", readiness=true. Elapsed: 2.00947853s
Feb 13 15:01:57.256: INFO: Pod "execpodd4v2n" satisfied condition "running"
Feb 13 15:01:58.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:00.546: INFO: rc: 1
Feb 13 15:02:00.546: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 endpoint-test2 80
nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 13 15:02:01.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:03.809: INFO: rc: 1
Feb 13 15:02:03.809: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 endpoint-test2 80
nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 13 15:02:04.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:06.825: INFO: rc: 1
Feb 13 15:02:06.825: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 endpoint-test2 80
nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Feb 13 15:02:07.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:07.819: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Feb 13 15:02:07.819: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 15:02:07.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
Feb 13 15:02:08.097: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n"
Feb 13 15:02:08.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-9932 02/13/23 15:02:08.098
W0213 15:02:08.109419      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:08.109: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9932" to be "running and ready"
Feb 13 15:02:08.115: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015291ms
Feb 13 15:02:08.115: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Feb 13 15:02:10.120: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010640841s
Feb 13 15:02:10.120: INFO: The phase of Pod pod2 is Running (Ready = true)
Feb 13 15:02:10.120: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod1:[80] pod2:[80]] 02/13/23 15:02:10.124
Feb 13 15:02:10.135: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 02/13/23 15:02:10.135
Feb 13 15:02:11.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:11.415: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Feb 13 15:02:11.415: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 15:02:11.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
Feb 13 15:02:11.682: INFO: stderr: "+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Feb 13 15:02:11.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9932 02/13/23 15:02:11.682
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod2:[80]] 02/13/23 15:02:11.696
Feb 13 15:02:12.722: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 02/13/23 15:02:12.723
Feb 13 15:02:13.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Feb 13 15:02:14.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Feb 13 15:02:14.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Feb 13 15:02:14.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
Feb 13 15:02:14.217: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n"
Feb 13 15:02:14.217: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-9932 02/13/23 15:02:14.217
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[] 02/13/23 15:02:14.233
Feb 13 15:02:14.254: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 15:02:14.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9932" for this suite. 02/13/23 15:02:14.296
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":331,"skipped":6057,"failed":0}
------------------------------
• [SLOW TEST] [21.145 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:01:53.157
    Feb 13 15:01:53.157: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 15:01:53.159
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:01:53.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:01:53.174
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-9932 02/13/23 15:01:53.177
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[] 02/13/23 15:01:53.187
    Feb 13 15:01:53.198: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9932 02/13/23 15:01:53.198
    W0213 15:01:53.205271      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:01:53.205: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9932" to be "running and ready"
    Feb 13 15:01:53.209: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.241335ms
    Feb 13 15:01:53.210: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 15:01:55.217: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011149013s
    Feb 13 15:01:55.217: INFO: The phase of Pod pod1 is Running (Ready = true)
    Feb 13 15:01:55.217: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod1:[80]] 02/13/23 15:01:55.222
    Feb 13 15:01:55.238: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 02/13/23 15:01:55.238
    Feb 13 15:01:55.238: INFO: Creating new exec pod
    W0213 15:01:55.246479      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:01:55.246: INFO: Waiting up to 5m0s for pod "execpodd4v2n" in namespace "services-9932" to be "running"
    Feb 13 15:01:55.251: INFO: Pod "execpodd4v2n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.627803ms
    Feb 13 15:01:57.256: INFO: Pod "execpodd4v2n": Phase="Running", Reason="", readiness=true. Elapsed: 2.00947853s
    Feb 13 15:01:57.256: INFO: Pod "execpodd4v2n" satisfied condition "running"
    Feb 13 15:01:58.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:00.546: INFO: rc: 1
    Feb 13 15:02:00.546: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 endpoint-test2 80
    nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Feb 13 15:02:01.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:03.809: INFO: rc: 1
    Feb 13 15:02:03.809: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 endpoint-test2 80
    nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Feb 13 15:02:04.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:06.825: INFO: rc: 1
    Feb 13 15:02:06.825: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
    Command stdout:

    stderr:
    + echo hostName
    + nc -v -t -w 2 endpoint-test2 80
    nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Feb 13 15:02:07.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:07.819: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Feb 13 15:02:07.819: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 15:02:07.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
    Feb 13 15:02:08.097: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n"
    Feb 13 15:02:08.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-9932 02/13/23 15:02:08.098
    W0213 15:02:08.109419      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:08.109: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9932" to be "running and ready"
    Feb 13 15:02:08.115: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015291ms
    Feb 13 15:02:08.115: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 15:02:10.120: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010640841s
    Feb 13 15:02:10.120: INFO: The phase of Pod pod2 is Running (Ready = true)
    Feb 13 15:02:10.120: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod1:[80] pod2:[80]] 02/13/23 15:02:10.124
    Feb 13 15:02:10.135: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 02/13/23 15:02:10.135
    Feb 13 15:02:11.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:11.415: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Feb 13 15:02:11.415: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 15:02:11.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
    Feb 13 15:02:11.682: INFO: stderr: "+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Feb 13 15:02:11.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-9932 02/13/23 15:02:11.682
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[pod2:[80]] 02/13/23 15:02:11.696
    Feb 13 15:02:12.722: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 02/13/23 15:02:12.723
    Feb 13 15:02:13.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Feb 13 15:02:14.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Feb 13 15:02:14.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Feb 13 15:02:14.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=services-9932 exec execpodd4v2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.214.22 80'
    Feb 13 15:02:14.217: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.214.22 80\nConnection to 10.96.214.22 80 port [tcp/http] succeeded!\n"
    Feb 13 15:02:14.217: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-9932 02/13/23 15:02:14.217
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9932 to expose endpoints map[] 02/13/23 15:02:14.233
    Feb 13 15:02:14.254: INFO: successfully validated that service endpoint-test2 in namespace services-9932 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 15:02:14.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9932" for this suite. 02/13/23 15:02:14.296
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:02:14.302
Feb 13 15:02:14.302: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 15:02:14.303
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:14.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:14.325
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 02/13/23 15:02:14.334
W0213 15:02:14.342014      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:14.342: INFO: Waiting up to 5m0s for pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728" in namespace "emptydir-3910" to be "Succeeded or Failed"
Feb 13 15:02:14.348: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Pending", Reason="", readiness=false. Elapsed: 5.908421ms
Feb 13 15:02:16.356: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013941157s
Feb 13 15:02:18.354: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012596737s
STEP: Saw pod success 02/13/23 15:02:18.354
Feb 13 15:02:18.355: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728" satisfied condition "Succeeded or Failed"
Feb 13 15:02:18.360: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 container test-container: <nil>
STEP: delete the pod 02/13/23 15:02:18.398
Feb 13 15:02:18.411: INFO: Waiting for pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 to disappear
Feb 13 15:02:18.414: INFO: Pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 15:02:18.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3910" for this suite. 02/13/23 15:02:18.419
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":332,"skipped":6074,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:02:14.302
    Feb 13 15:02:14.302: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 15:02:14.303
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:14.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:14.325
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 02/13/23 15:02:14.334
    W0213 15:02:14.342014      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:14.342: INFO: Waiting up to 5m0s for pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728" in namespace "emptydir-3910" to be "Succeeded or Failed"
    Feb 13 15:02:14.348: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Pending", Reason="", readiness=false. Elapsed: 5.908421ms
    Feb 13 15:02:16.356: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013941157s
    Feb 13 15:02:18.354: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012596737s
    STEP: Saw pod success 02/13/23 15:02:18.354
    Feb 13 15:02:18.355: INFO: Pod "pod-5cc7af37-954d-4179-9a89-72e6a3eaa728" satisfied condition "Succeeded or Failed"
    Feb 13 15:02:18.360: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-vfwrl pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 container test-container: <nil>
    STEP: delete the pod 02/13/23 15:02:18.398
    Feb 13 15:02:18.411: INFO: Waiting for pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 to disappear
    Feb 13 15:02:18.414: INFO: Pod pod-5cc7af37-954d-4179-9a89-72e6a3eaa728 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 15:02:18.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3910" for this suite. 02/13/23 15:02:18.419
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:02:18.436
Feb 13 15:02:18.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 15:02:18.438
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:18.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:18.454
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2009/configmap-test-6cda07c3-eb6f-4c62-b9ba-c5163a1d56c9 02/13/23 15:02:18.459
STEP: Creating a pod to test consume configMaps 02/13/23 15:02:18.465
W0213 15:02:18.474577      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:18.474: INFO: Waiting up to 5m0s for pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595" in namespace "configmap-2009" to be "Succeeded or Failed"
Feb 13 15:02:18.481: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Pending", Reason="", readiness=false. Elapsed: 6.611491ms
Feb 13 15:02:20.486: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011751553s
Feb 13 15:02:22.488: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01375875s
STEP: Saw pod success 02/13/23 15:02:22.488
Feb 13 15:02:22.488: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595" satisfied condition "Succeeded or Failed"
Feb 13 15:02:22.493: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 container env-test: <nil>
STEP: delete the pod 02/13/23 15:02:22.504
Feb 13 15:02:22.513: INFO: Waiting for pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 to disappear
Feb 13 15:02:22.516: INFO: Pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 15:02:22.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2009" for this suite. 02/13/23 15:02:22.52
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":333,"skipped":6117,"failed":0}
------------------------------
• [4.092 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:02:18.436
    Feb 13 15:02:18.436: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 15:02:18.438
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:18.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:18.454
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2009/configmap-test-6cda07c3-eb6f-4c62-b9ba-c5163a1d56c9 02/13/23 15:02:18.459
    STEP: Creating a pod to test consume configMaps 02/13/23 15:02:18.465
    W0213 15:02:18.474577      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:18.474: INFO: Waiting up to 5m0s for pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595" in namespace "configmap-2009" to be "Succeeded or Failed"
    Feb 13 15:02:18.481: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Pending", Reason="", readiness=false. Elapsed: 6.611491ms
    Feb 13 15:02:20.486: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011751553s
    Feb 13 15:02:22.488: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01375875s
    STEP: Saw pod success 02/13/23 15:02:22.488
    Feb 13 15:02:22.488: INFO: Pod "pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595" satisfied condition "Succeeded or Failed"
    Feb 13 15:02:22.493: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 container env-test: <nil>
    STEP: delete the pod 02/13/23 15:02:22.504
    Feb 13 15:02:22.513: INFO: Waiting for pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 to disappear
    Feb 13 15:02:22.516: INFO: Pod pod-configmaps-c64409d5-66fa-4fe0-8e5b-901c0638d595 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 15:02:22.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2009" for this suite. 02/13/23 15:02:22.52
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:02:22.535
Feb 13 15:02:22.536: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename resourcequota 02/13/23 15:02:22.537
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:22.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:22.555
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 02/13/23 15:02:22.561
STEP: Ensuring ResourceQuota status is calculated 02/13/23 15:02:22.565
STEP: Creating a ResourceQuota with not best effort scope 02/13/23 15:02:24.572
STEP: Ensuring ResourceQuota status is calculated 02/13/23 15:02:24.581
STEP: Creating a best-effort pod 02/13/23 15:02:26.587
W0213 15:02:26.602289      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota with best effort scope captures the pod usage 02/13/23 15:02:26.602
STEP: Ensuring resource quota with not best effort ignored the pod usage 02/13/23 15:02:28.608
STEP: Deleting the pod 02/13/23 15:02:30.615
STEP: Ensuring resource quota status released the pod usage 02/13/23 15:02:30.637
STEP: Creating a not best-effort pod 02/13/23 15:02:32.644
W0213 15:02:32.662274      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring resource quota with not best effort scope captures the pod usage 02/13/23 15:02:32.662
STEP: Ensuring resource quota with best effort scope ignored the pod usage 02/13/23 15:02:34.669
STEP: Deleting the pod 02/13/23 15:02:36.675
STEP: Ensuring resource quota status released the pod usage 02/13/23 15:02:36.693
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Feb 13 15:02:38.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4793" for this suite. 02/13/23 15:02:38.707
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":334,"skipped":6118,"failed":0}
------------------------------
• [SLOW TEST] [16.188 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:02:22.535
    Feb 13 15:02:22.536: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename resourcequota 02/13/23 15:02:22.537
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:22.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:22.555
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 02/13/23 15:02:22.561
    STEP: Ensuring ResourceQuota status is calculated 02/13/23 15:02:22.565
    STEP: Creating a ResourceQuota with not best effort scope 02/13/23 15:02:24.572
    STEP: Ensuring ResourceQuota status is calculated 02/13/23 15:02:24.581
    STEP: Creating a best-effort pod 02/13/23 15:02:26.587
    W0213 15:02:26.602289      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota with best effort scope captures the pod usage 02/13/23 15:02:26.602
    STEP: Ensuring resource quota with not best effort ignored the pod usage 02/13/23 15:02:28.608
    STEP: Deleting the pod 02/13/23 15:02:30.615
    STEP: Ensuring resource quota status released the pod usage 02/13/23 15:02:30.637
    STEP: Creating a not best-effort pod 02/13/23 15:02:32.644
    W0213 15:02:32.662274      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 02/13/23 15:02:32.662
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 02/13/23 15:02:34.669
    STEP: Deleting the pod 02/13/23 15:02:36.675
    STEP: Ensuring resource quota status released the pod usage 02/13/23 15:02:36.693
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Feb 13 15:02:38.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4793" for this suite. 02/13/23 15:02:38.707
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:02:38.729
Feb 13 15:02:38.729: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename dns 02/13/23 15:02:38.731
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:38.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:38.76
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 02/13/23 15:02:38.765
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:38.772
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:38.773
STEP: creating a pod to probe DNS 02/13/23 15:02:38.774
STEP: submitting the pod to kubernetes 02/13/23 15:02:38.774
W0213 15:02:38.786451      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:38.786: INFO: Waiting up to 15m0s for pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd" in namespace "dns-9476" to be "running"
Feb 13 15:02:38.792: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.111688ms
Feb 13 15:02:40.799: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01267911s
Feb 13 15:02:40.799: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd" satisfied condition "running"
STEP: retrieving the pod 02/13/23 15:02:40.799
STEP: looking for the results for each expected name from probers 02/13/23 15:02:40.805
Feb 13 15:02:40.843: INFO: DNS probes using dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd succeeded

STEP: deleting the pod 02/13/23 15:02:40.843
STEP: changing the externalName to bar.example.com 02/13/23 15:02:40.86
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:40.87
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:40.87
STEP: creating a second pod to probe DNS 02/13/23 15:02:40.87
STEP: submitting the pod to kubernetes 02/13/23 15:02:40.871
W0213 15:02:40.880313      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:40.881: INFO: Waiting up to 15m0s for pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53" in namespace "dns-9476" to be "running"
Feb 13 15:02:40.885: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.985513ms
Feb 13 15:02:42.891: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.010096376s
Feb 13 15:02:42.891: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53" satisfied condition "running"
STEP: retrieving the pod 02/13/23 15:02:42.892
STEP: looking for the results for each expected name from probers 02/13/23 15:02:42.896
Feb 13 15:02:42.908: INFO: File wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 13 15:02:42.916: INFO: File jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 13 15:02:42.916: INFO: Lookups using dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 failed for: [wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local]

Feb 13 15:02:47.935: INFO: File jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains '' instead of 'bar.example.com.'
Feb 13 15:02:47.935: INFO: Lookups using dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 failed for: [jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local]

Feb 13 15:02:52.936: INFO: DNS probes using dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 succeeded

STEP: deleting the pod 02/13/23 15:02:52.937
STEP: changing the service to type=ClusterIP 02/13/23 15:02:52.956
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:52.973
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
 02/13/23 15:02:52.974
STEP: creating a third pod to probe DNS 02/13/23 15:02:52.974
STEP: submitting the pod to kubernetes 02/13/23 15:02:52.978
W0213 15:02:52.988276      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:52.989: INFO: Waiting up to 15m0s for pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501" in namespace "dns-9476" to be "running"
Feb 13 15:02:52.994: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628663ms
Feb 13 15:02:55.002: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501": Phase="Running", Reason="", readiness=true. Elapsed: 2.012016326s
Feb 13 15:02:55.002: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501" satisfied condition "running"
STEP: retrieving the pod 02/13/23 15:02:55.002
STEP: looking for the results for each expected name from probers 02/13/23 15:02:55.008
Feb 13 15:02:55.032: INFO: DNS probes using dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501 succeeded

STEP: deleting the pod 02/13/23 15:02:55.032
STEP: deleting the test externalName service 02/13/23 15:02:55.051
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Feb 13 15:02:55.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9476" for this suite. 02/13/23 15:02:55.073
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":335,"skipped":6119,"failed":0}
------------------------------
• [SLOW TEST] [16.356 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:02:38.729
    Feb 13 15:02:38.729: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename dns 02/13/23 15:02:38.731
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:38.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:38.76
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 02/13/23 15:02:38.765
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:38.772
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:38.773
    STEP: creating a pod to probe DNS 02/13/23 15:02:38.774
    STEP: submitting the pod to kubernetes 02/13/23 15:02:38.774
    W0213 15:02:38.786451      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:38.786: INFO: Waiting up to 15m0s for pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd" in namespace "dns-9476" to be "running"
    Feb 13 15:02:38.792: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.111688ms
    Feb 13 15:02:40.799: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01267911s
    Feb 13 15:02:40.799: INFO: Pod "dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 15:02:40.799
    STEP: looking for the results for each expected name from probers 02/13/23 15:02:40.805
    Feb 13 15:02:40.843: INFO: DNS probes using dns-test-f85a7ab7-3114-4adc-91f9-859b1cbd7abd succeeded

    STEP: deleting the pod 02/13/23 15:02:40.843
    STEP: changing the externalName to bar.example.com 02/13/23 15:02:40.86
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:40.87
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:40.87
    STEP: creating a second pod to probe DNS 02/13/23 15:02:40.87
    STEP: submitting the pod to kubernetes 02/13/23 15:02:40.871
    W0213 15:02:40.880313      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:40.881: INFO: Waiting up to 15m0s for pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53" in namespace "dns-9476" to be "running"
    Feb 13 15:02:40.885: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.985513ms
    Feb 13 15:02:42.891: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.010096376s
    Feb 13 15:02:42.891: INFO: Pod "dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 15:02:42.892
    STEP: looking for the results for each expected name from probers 02/13/23 15:02:42.896
    Feb 13 15:02:42.908: INFO: File wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Feb 13 15:02:42.916: INFO: File jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Feb 13 15:02:42.916: INFO: Lookups using dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 failed for: [wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local]

    Feb 13 15:02:47.935: INFO: File jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local from pod  dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 contains '' instead of 'bar.example.com.'
    Feb 13 15:02:47.935: INFO: Lookups using dns-9476/dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 failed for: [jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local]

    Feb 13 15:02:52.936: INFO: DNS probes using dns-test-29b0dbce-7be9-4a4e-a926-f6c610285b53 succeeded

    STEP: deleting the pod 02/13/23 15:02:52.937
    STEP: changing the service to type=ClusterIP 02/13/23 15:02:52.956
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:52.973
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9476.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9476.svc.cluster.local; sleep 1; done
     02/13/23 15:02:52.974
    STEP: creating a third pod to probe DNS 02/13/23 15:02:52.974
    STEP: submitting the pod to kubernetes 02/13/23 15:02:52.978
    W0213 15:02:52.988276      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:52.989: INFO: Waiting up to 15m0s for pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501" in namespace "dns-9476" to be "running"
    Feb 13 15:02:52.994: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628663ms
    Feb 13 15:02:55.002: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501": Phase="Running", Reason="", readiness=true. Elapsed: 2.012016326s
    Feb 13 15:02:55.002: INFO: Pod "dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501" satisfied condition "running"
    STEP: retrieving the pod 02/13/23 15:02:55.002
    STEP: looking for the results for each expected name from probers 02/13/23 15:02:55.008
    Feb 13 15:02:55.032: INFO: DNS probes using dns-test-4c987e82-7d1d-459b-9b1c-86d056d77501 succeeded

    STEP: deleting the pod 02/13/23 15:02:55.032
    STEP: deleting the test externalName service 02/13/23 15:02:55.051
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Feb 13 15:02:55.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9476" for this suite. 02/13/23 15:02:55.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:02:55.098
Feb 13 15:02:55.098: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename statefulset 02/13/23 15:02:55.099
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:55.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:55.129
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3524 02/13/23 15:02:55.133
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-3524 02/13/23 15:02:55.144
W0213 15:02:55.149385      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:02:55.151: INFO: Found 0 stateful pods, waiting for 1
Feb 13 15:03:05.161: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 02/13/23 15:03:05.174
W0213 15:03:05.182865      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Getting /status 02/13/23 15:03:05.183
Feb 13 15:03:05.187: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 02/13/23 15:03:05.187
Feb 13 15:03:05.198: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 02/13/23 15:03:05.198
Feb 13 15:03:05.200: INFO: Observed &StatefulSet event: ADDED
Feb 13 15:03:05.201: INFO: Found Statefulset ss in namespace statefulset-3524 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Feb 13 15:03:05.201: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 02/13/23 15:03:05.201
Feb 13 15:03:05.201: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Feb 13 15:03:05.208: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 02/13/23 15:03:05.208
Feb 13 15:03:05.210: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Feb 13 15:03:05.210: INFO: Deleting all statefulset in ns statefulset-3524
Feb 13 15:03:05.213: INFO: Scaling statefulset ss to 0
W0213 15:03:05.223183      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:03:15.233: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 15:03:15.236: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Feb 13 15:03:15.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3524" for this suite. 02/13/23 15:03:15.264
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":336,"skipped":6148,"failed":0}
------------------------------
• [SLOW TEST] [20.173 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:02:55.098
    Feb 13 15:02:55.098: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename statefulset 02/13/23 15:02:55.099
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:02:55.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:02:55.129
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3524 02/13/23 15:02:55.133
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-3524 02/13/23 15:02:55.144
    W0213 15:02:55.149385      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:02:55.151: INFO: Found 0 stateful pods, waiting for 1
    Feb 13 15:03:05.161: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 02/13/23 15:03:05.174
    W0213 15:03:05.182865      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Getting /status 02/13/23 15:03:05.183
    Feb 13 15:03:05.187: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 02/13/23 15:03:05.187
    Feb 13 15:03:05.198: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 02/13/23 15:03:05.198
    Feb 13 15:03:05.200: INFO: Observed &StatefulSet event: ADDED
    Feb 13 15:03:05.201: INFO: Found Statefulset ss in namespace statefulset-3524 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Feb 13 15:03:05.201: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 02/13/23 15:03:05.201
    Feb 13 15:03:05.201: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Feb 13 15:03:05.208: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 02/13/23 15:03:05.208
    Feb 13 15:03:05.210: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Feb 13 15:03:05.210: INFO: Deleting all statefulset in ns statefulset-3524
    Feb 13 15:03:05.213: INFO: Scaling statefulset ss to 0
    W0213 15:03:05.223183      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:03:15.233: INFO: Waiting for statefulset status.replicas updated to 0
    Feb 13 15:03:15.236: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Feb 13 15:03:15.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3524" for this suite. 02/13/23 15:03:15.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:15.274
Feb 13 15:03:15.275: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 15:03:15.276
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:15.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:15.299
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 15:03:15.324
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:03:15.719
STEP: Deploying the webhook pod 02/13/23 15:03:15.731
W0213 15:03:15.751967      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 15:03:15.752
Feb 13 15:03:15.765: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 13 15:03:17.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:03:19.787: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:03:21.785: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:03:23.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:03:25.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 02/13/23 15:03:27.785
STEP: Verifying the service has paired with the endpoint 02/13/23 15:03:27.804
Feb 13 15:03:28.805: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 02/13/23 15:03:28.812
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 02/13/23 15:03:28.817
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 02/13/23 15:03:28.817
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 02/13/23 15:03:28.817
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 02/13/23 15:03:28.822
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 02/13/23 15:03:28.822
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 02/13/23 15:03:28.826
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 15:03:28.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5951" for this suite. 02/13/23 15:03:28.835
STEP: Destroying namespace "webhook-5951-markers" for this suite. 02/13/23 15:03:28.847
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":337,"skipped":6158,"failed":0}
------------------------------
• [SLOW TEST] [13.627 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:15.274
    Feb 13 15:03:15.275: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 15:03:15.276
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:15.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:15.299
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 15:03:15.324
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:03:15.719
    STEP: Deploying the webhook pod 02/13/23 15:03:15.731
    W0213 15:03:15.751967      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 15:03:15.752
    Feb 13 15:03:15.765: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Feb 13 15:03:17.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 15:03:19.787: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 15:03:21.785: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 15:03:23.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Feb 13 15:03:25.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.February, 13, 15, 3, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 02/13/23 15:03:27.785
    STEP: Verifying the service has paired with the endpoint 02/13/23 15:03:27.804
    Feb 13 15:03:28.805: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 02/13/23 15:03:28.812
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 02/13/23 15:03:28.817
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 02/13/23 15:03:28.817
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 02/13/23 15:03:28.817
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 02/13/23 15:03:28.822
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 02/13/23 15:03:28.822
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 02/13/23 15:03:28.826
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 15:03:28.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5951" for this suite. 02/13/23 15:03:28.835
    STEP: Destroying namespace "webhook-5951-markers" for this suite. 02/13/23 15:03:28.847
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:28.906
Feb 13 15:03:28.907: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 15:03:28.908
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:28.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:28.931
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-e931291a-5b78-404b-846a-849e4fee0ccd 02/13/23 15:03:28.934
STEP: Creating secret with name secret-projected-all-test-volume-3cb4992e-f89e-4d35-97dd-c4bc6bb41849 02/13/23 15:03:28.939
STEP: Creating a pod to test Check all projections for projected volume plugin 02/13/23 15:03:28.947
W0213 15:03:28.956830      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-all-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-all-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-all-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-all-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:03:28.957: INFO: Waiting up to 5m0s for pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36" in namespace "projected-8562" to be "Succeeded or Failed"
Feb 13 15:03:28.960: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.98391ms
Feb 13 15:03:30.966: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009595419s
Feb 13 15:03:32.967: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010681681s
STEP: Saw pod success 02/13/23 15:03:32.967
Feb 13 15:03:32.968: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36" satisfied condition "Succeeded or Failed"
Feb 13 15:03:32.972: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 container projected-all-volume-test: <nil>
STEP: delete the pod 02/13/23 15:03:32.983
Feb 13 15:03:32.998: INFO: Waiting for pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 to disappear
Feb 13 15:03:33.002: INFO: Pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Feb 13 15:03:33.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8562" for this suite. 02/13/23 15:03:33.007
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":338,"skipped":6163,"failed":0}
------------------------------
• [4.110 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:28.906
    Feb 13 15:03:28.907: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 15:03:28.908
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:28.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:28.931
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-e931291a-5b78-404b-846a-849e4fee0ccd 02/13/23 15:03:28.934
    STEP: Creating secret with name secret-projected-all-test-volume-3cb4992e-f89e-4d35-97dd-c4bc6bb41849 02/13/23 15:03:28.939
    STEP: Creating a pod to test Check all projections for projected volume plugin 02/13/23 15:03:28.947
    W0213 15:03:28.956830      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-all-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-all-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-all-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-all-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:03:28.957: INFO: Waiting up to 5m0s for pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36" in namespace "projected-8562" to be "Succeeded or Failed"
    Feb 13 15:03:28.960: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.98391ms
    Feb 13 15:03:30.966: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009595419s
    Feb 13 15:03:32.967: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010681681s
    STEP: Saw pod success 02/13/23 15:03:32.967
    Feb 13 15:03:32.968: INFO: Pod "projected-volume-d7762710-c528-4814-b570-938124d6ae36" satisfied condition "Succeeded or Failed"
    Feb 13 15:03:32.972: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 container projected-all-volume-test: <nil>
    STEP: delete the pod 02/13/23 15:03:32.983
    Feb 13 15:03:32.998: INFO: Waiting for pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 to disappear
    Feb 13 15:03:33.002: INFO: Pod projected-volume-d7762710-c528-4814-b570-938124d6ae36 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Feb 13 15:03:33.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8562" for this suite. 02/13/23 15:03:33.007
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:33.029
Feb 13 15:03:33.029: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename endpointslice 02/13/23 15:03:33.03
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:33.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:33.052
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Feb 13 15:03:33.061: INFO: Endpoints addresses: [192.168.1.13] , ports: [6443]
Feb 13 15:03:33.061: INFO: EndpointSlices addresses: [192.168.1.13] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Feb 13 15:03:33.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4758" for this suite. 02/13/23 15:03:33.064
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":339,"skipped":6232,"failed":0}
------------------------------
• [0.042 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:33.029
    Feb 13 15:03:33.029: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename endpointslice 02/13/23 15:03:33.03
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:33.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:33.052
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Feb 13 15:03:33.061: INFO: Endpoints addresses: [192.168.1.13] , ports: [6443]
    Feb 13 15:03:33.061: INFO: EndpointSlices addresses: [192.168.1.13] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Feb 13 15:03:33.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4758" for this suite. 02/13/23 15:03:33.064
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:33.071
Feb 13 15:03:33.072: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 15:03:33.073
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:33.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:33.088
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 02/13/23 15:03:33.091
W0213 15:03:33.099909      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:03:33.100: INFO: Waiting up to 5m0s for pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1" in namespace "downward-api-7665" to be "Succeeded or Failed"
Feb 13 15:03:33.103: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.709906ms
Feb 13 15:03:35.109: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009348511s
Feb 13 15:03:37.109: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00970928s
STEP: Saw pod success 02/13/23 15:03:37.109
Feb 13 15:03:37.110: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1" satisfied condition "Succeeded or Failed"
Feb 13 15:03:37.113: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 container dapi-container: <nil>
STEP: delete the pod 02/13/23 15:03:37.125
Feb 13 15:03:37.141: INFO: Waiting for pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 to disappear
Feb 13 15:03:37.146: INFO: Pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Feb 13 15:03:37.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7665" for this suite. 02/13/23 15:03:37.15
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":340,"skipped":6232,"failed":0}
------------------------------
• [4.087 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:33.071
    Feb 13 15:03:33.072: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 15:03:33.073
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:33.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:33.088
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 02/13/23 15:03:33.091
    W0213 15:03:33.099909      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:03:33.100: INFO: Waiting up to 5m0s for pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1" in namespace "downward-api-7665" to be "Succeeded or Failed"
    Feb 13 15:03:33.103: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.709906ms
    Feb 13 15:03:35.109: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009348511s
    Feb 13 15:03:37.109: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00970928s
    STEP: Saw pod success 02/13/23 15:03:37.109
    Feb 13 15:03:37.110: INFO: Pod "downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1" satisfied condition "Succeeded or Failed"
    Feb 13 15:03:37.113: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 container dapi-container: <nil>
    STEP: delete the pod 02/13/23 15:03:37.125
    Feb 13 15:03:37.141: INFO: Waiting for pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 to disappear
    Feb 13 15:03:37.146: INFO: Pod downward-api-f912208e-81f1-4747-9a1d-c0e6b9f7d9f1 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Feb 13 15:03:37.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7665" for this suite. 02/13/23 15:03:37.15
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:37.161
Feb 13 15:03:37.161: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 15:03:37.162
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:37.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:37.182
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 15:03:37.2
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:03:37.565
STEP: Deploying the webhook pod 02/13/23 15:03:37.571
W0213 15:03:37.586879      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 15:03:37.587
Feb 13 15:03:37.596: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 15:03:39.612
STEP: Verifying the service has paired with the endpoint 02/13/23 15:03:39.626
Feb 13 15:03:40.626: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 02/13/23 15:03:40.632
STEP: Updating a mutating webhook configuration's rules to not include the create operation 02/13/23 15:03:40.682
STEP: Creating a configMap that should not be mutated 02/13/23 15:03:40.694
STEP: Patching a mutating webhook configuration's rules to include the create operation 02/13/23 15:03:40.71
STEP: Creating a configMap that should be mutated 02/13/23 15:03:40.724
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 15:03:40.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7891" for this suite. 02/13/23 15:03:40.768
STEP: Destroying namespace "webhook-7891-markers" for this suite. 02/13/23 15:03:40.775
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":341,"skipped":6233,"failed":0}
------------------------------
• [3.678 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:37.161
    Feb 13 15:03:37.161: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 15:03:37.162
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:37.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:37.182
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 15:03:37.2
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:03:37.565
    STEP: Deploying the webhook pod 02/13/23 15:03:37.571
    W0213 15:03:37.586879      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 15:03:37.587
    Feb 13 15:03:37.596: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 15:03:39.612
    STEP: Verifying the service has paired with the endpoint 02/13/23 15:03:39.626
    Feb 13 15:03:40.626: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 02/13/23 15:03:40.632
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 02/13/23 15:03:40.682
    STEP: Creating a configMap that should not be mutated 02/13/23 15:03:40.694
    STEP: Patching a mutating webhook configuration's rules to include the create operation 02/13/23 15:03:40.71
    STEP: Creating a configMap that should be mutated 02/13/23 15:03:40.724
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 15:03:40.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7891" for this suite. 02/13/23 15:03:40.768
    STEP: Destroying namespace "webhook-7891-markers" for this suite. 02/13/23 15:03:40.775
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:40.839
Feb 13 15:03:40.839: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename runtimeclass 02/13/23 15:03:40.84
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:40.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:40.863
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 02/13/23 15:03:40.869
STEP: getting /apis/node.k8s.io 02/13/23 15:03:40.873
STEP: getting /apis/node.k8s.io/v1 02/13/23 15:03:40.876
STEP: creating 02/13/23 15:03:40.878
STEP: watching 02/13/23 15:03:40.9
Feb 13 15:03:40.901: INFO: starting watch
STEP: getting 02/13/23 15:03:40.908
STEP: listing 02/13/23 15:03:40.912
STEP: patching 02/13/23 15:03:40.916
STEP: updating 02/13/23 15:03:40.923
Feb 13 15:03:40.928: INFO: waiting for watch events with expected annotations
STEP: deleting 02/13/23 15:03:40.929
STEP: deleting a collection 02/13/23 15:03:40.94
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Feb 13 15:03:40.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-11" for this suite. 02/13/23 15:03:40.955
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":342,"skipped":6240,"failed":0}
------------------------------
• [0.123 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:40.839
    Feb 13 15:03:40.839: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename runtimeclass 02/13/23 15:03:40.84
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:40.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:40.863
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 02/13/23 15:03:40.869
    STEP: getting /apis/node.k8s.io 02/13/23 15:03:40.873
    STEP: getting /apis/node.k8s.io/v1 02/13/23 15:03:40.876
    STEP: creating 02/13/23 15:03:40.878
    STEP: watching 02/13/23 15:03:40.9
    Feb 13 15:03:40.901: INFO: starting watch
    STEP: getting 02/13/23 15:03:40.908
    STEP: listing 02/13/23 15:03:40.912
    STEP: patching 02/13/23 15:03:40.916
    STEP: updating 02/13/23 15:03:40.923
    Feb 13 15:03:40.928: INFO: waiting for watch events with expected annotations
    STEP: deleting 02/13/23 15:03:40.929
    STEP: deleting a collection 02/13/23 15:03:40.94
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Feb 13 15:03:40.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-11" for this suite. 02/13/23 15:03:40.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:03:40.967
Feb 13 15:03:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 15:03:40.969
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:40.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:40.987
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 02/13/23 15:03:40.99
W0213 15:03:41.000122      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring active pods == parallelism 02/13/23 15:03:41
STEP: delete a job 02/13/23 15:03:43.007
STEP: deleting Job.batch foo in namespace job-9279, will wait for the garbage collector to delete the pods 02/13/23 15:03:43.007
Feb 13 15:03:43.070: INFO: Deleting Job.batch foo took: 7.21752ms
Feb 13 15:03:43.171: INFO: Terminating Job.batch foo pods took: 100.712255ms
STEP: Ensuring job was deleted 02/13/23 15:04:15.672
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 15:04:15.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9279" for this suite. 02/13/23 15:04:15.683
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":343,"skipped":6264,"failed":0}
------------------------------
• [SLOW TEST] [34.726 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:03:40.967
    Feb 13 15:03:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 15:03:40.969
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:03:40.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:03:40.987
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 02/13/23 15:03:40.99
    W0213 15:03:41.000122      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring active pods == parallelism 02/13/23 15:03:41
    STEP: delete a job 02/13/23 15:03:43.007
    STEP: deleting Job.batch foo in namespace job-9279, will wait for the garbage collector to delete the pods 02/13/23 15:03:43.007
    Feb 13 15:03:43.070: INFO: Deleting Job.batch foo took: 7.21752ms
    Feb 13 15:03:43.171: INFO: Terminating Job.batch foo pods took: 100.712255ms
    STEP: Ensuring job was deleted 02/13/23 15:04:15.672
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 15:04:15.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9279" for this suite. 02/13/23 15:04:15.683
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:15.697
Feb 13 15:04:15.698: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename namespaces 02/13/23 15:04:15.702
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:15.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:15.731
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 02/13/23 15:04:15.735
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:15.751
STEP: Creating a pod in the namespace 02/13/23 15:04:15.757
W0213 15:04:15.769487      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Waiting for the pod to have running status 02/13/23 15:04:15.77
Feb 13 15:04:15.770: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6027" to be "running"
Feb 13 15:04:15.774: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978795ms
Feb 13 15:04:17.779: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009130006s
Feb 13 15:04:17.779: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 02/13/23 15:04:17.779
STEP: Waiting for the namespace to be removed. 02/13/23 15:04:17.785
STEP: Recreating the namespace 02/13/23 15:04:28.79
STEP: Verifying there are no pods in the namespace 02/13/23 15:04:28.803
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Feb 13 15:04:28.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8987" for this suite. 02/13/23 15:04:28.813
STEP: Destroying namespace "nsdeletetest-6027" for this suite. 02/13/23 15:04:28.819
Feb 13 15:04:28.822: INFO: Namespace nsdeletetest-6027 was already deleted
STEP: Destroying namespace "nsdeletetest-5682" for this suite. 02/13/23 15:04:28.822
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":344,"skipped":6265,"failed":0}
------------------------------
• [SLOW TEST] [13.131 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:15.697
    Feb 13 15:04:15.698: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename namespaces 02/13/23 15:04:15.702
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:15.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:15.731
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 02/13/23 15:04:15.735
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:15.751
    STEP: Creating a pod in the namespace 02/13/23 15:04:15.757
    W0213 15:04:15.769487      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Waiting for the pod to have running status 02/13/23 15:04:15.77
    Feb 13 15:04:15.770: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6027" to be "running"
    Feb 13 15:04:15.774: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978795ms
    Feb 13 15:04:17.779: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009130006s
    Feb 13 15:04:17.779: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 02/13/23 15:04:17.779
    STEP: Waiting for the namespace to be removed. 02/13/23 15:04:17.785
    STEP: Recreating the namespace 02/13/23 15:04:28.79
    STEP: Verifying there are no pods in the namespace 02/13/23 15:04:28.803
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Feb 13 15:04:28.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8987" for this suite. 02/13/23 15:04:28.813
    STEP: Destroying namespace "nsdeletetest-6027" for this suite. 02/13/23 15:04:28.819
    Feb 13 15:04:28.822: INFO: Namespace nsdeletetest-6027 was already deleted
    STEP: Destroying namespace "nsdeletetest-5682" for this suite. 02/13/23 15:04:28.822
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:28.831
Feb 13 15:04:28.831: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename projected 02/13/23 15:04:28.832
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:28.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:28.85
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-ead2231b-f049-4140-be53-dca7643686b8 02/13/23 15:04:28.854
STEP: Creating a pod to test consume configMaps 02/13/23 15:04:28.862
W0213 15:04:28.873326      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:04:28.873: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e" in namespace "projected-5888" to be "Succeeded or Failed"
Feb 13 15:04:28.878: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.096556ms
Feb 13 15:04:30.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Running", Reason="", readiness=false. Elapsed: 2.011484205s
Feb 13 15:04:32.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011322023s
STEP: Saw pod success 02/13/23 15:04:32.885
Feb 13 15:04:32.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e" satisfied condition "Succeeded or Failed"
Feb 13 15:04:32.888: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e container agnhost-container: <nil>
STEP: delete the pod 02/13/23 15:04:32.9
Feb 13 15:04:32.916: INFO: Waiting for pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e to disappear
Feb 13 15:04:32.921: INFO: Pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Feb 13 15:04:32.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5888" for this suite. 02/13/23 15:04:32.927
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":345,"skipped":6294,"failed":0}
------------------------------
• [4.106 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:28.831
    Feb 13 15:04:28.831: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename projected 02/13/23 15:04:28.832
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:28.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:28.85
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-ead2231b-f049-4140-be53-dca7643686b8 02/13/23 15:04:28.854
    STEP: Creating a pod to test consume configMaps 02/13/23 15:04:28.862
    W0213 15:04:28.873326      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:04:28.873: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e" in namespace "projected-5888" to be "Succeeded or Failed"
    Feb 13 15:04:28.878: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.096556ms
    Feb 13 15:04:30.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Running", Reason="", readiness=false. Elapsed: 2.011484205s
    Feb 13 15:04:32.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011322023s
    STEP: Saw pod success 02/13/23 15:04:32.885
    Feb 13 15:04:32.885: INFO: Pod "pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e" satisfied condition "Succeeded or Failed"
    Feb 13 15:04:32.888: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e container agnhost-container: <nil>
    STEP: delete the pod 02/13/23 15:04:32.9
    Feb 13 15:04:32.916: INFO: Waiting for pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e to disappear
    Feb 13 15:04:32.921: INFO: Pod pod-projected-configmaps-50c08b1e-47f6-4553-b5d0-10df5e590b5e no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Feb 13 15:04:32.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5888" for this suite. 02/13/23 15:04:32.927
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:32.938
Feb 13 15:04:32.938: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename init-container 02/13/23 15:04:32.939
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:32.959
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:32.964
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 02/13/23 15:04:32.968
Feb 13 15:04:32.968: INFO: PodSpec: initContainers in spec.initContainers
W0213 15:04:32.979854      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Feb 13 15:04:37.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-943" for this suite. 02/13/23 15:04:37.607
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":346,"skipped":6295,"failed":0}
------------------------------
• [4.679 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:32.938
    Feb 13 15:04:32.938: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename init-container 02/13/23 15:04:32.939
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:32.959
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:32.964
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 02/13/23 15:04:32.968
    Feb 13 15:04:32.968: INFO: PodSpec: initContainers in spec.initContainers
    W0213 15:04:32.979854      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Feb 13 15:04:37.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-943" for this suite. 02/13/23 15:04:37.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:37.624
Feb 13 15:04:37.624: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename emptydir 02/13/23 15:04:37.625
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:37.644
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:37.65
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 02/13/23 15:04:37.656
W0213 15:04:37.666380      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:04:37.666: INFO: Waiting up to 5m0s for pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5" in namespace "emptydir-4142" to be "Succeeded or Failed"
Feb 13 15:04:37.669: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87051ms
Feb 13 15:04:39.673: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007301981s
Feb 13 15:04:41.679: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012481209s
STEP: Saw pod success 02/13/23 15:04:41.679
Feb 13 15:04:41.680: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5" satisfied condition "Succeeded or Failed"
Feb 13 15:04:41.690: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 container test-container: <nil>
STEP: delete the pod 02/13/23 15:04:41.704
Feb 13 15:04:41.720: INFO: Waiting for pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 to disappear
Feb 13 15:04:41.725: INFO: Pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Feb 13 15:04:41.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4142" for this suite. 02/13/23 15:04:41.731
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":347,"skipped":6341,"failed":0}
------------------------------
• [4.116 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:37.624
    Feb 13 15:04:37.624: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename emptydir 02/13/23 15:04:37.625
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:37.644
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:37.65
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 02/13/23 15:04:37.656
    W0213 15:04:37.666380      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:04:37.666: INFO: Waiting up to 5m0s for pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5" in namespace "emptydir-4142" to be "Succeeded or Failed"
    Feb 13 15:04:37.669: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87051ms
    Feb 13 15:04:39.673: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007301981s
    Feb 13 15:04:41.679: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012481209s
    STEP: Saw pod success 02/13/23 15:04:41.679
    Feb 13 15:04:41.680: INFO: Pod "pod-76fd43af-64e6-47b3-9091-624c9a036ad5" satisfied condition "Succeeded or Failed"
    Feb 13 15:04:41.690: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 container test-container: <nil>
    STEP: delete the pod 02/13/23 15:04:41.704
    Feb 13 15:04:41.720: INFO: Waiting for pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 to disappear
    Feb 13 15:04:41.725: INFO: Pod pod-76fd43af-64e6-47b3-9091-624c9a036ad5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Feb 13 15:04:41.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4142" for this suite. 02/13/23 15:04:41.731
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:41.75
Feb 13 15:04:41.750: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename var-expansion 02/13/23 15:04:41.753
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:41.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:41.783
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
W0213 15:04:41.801439      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:04:41.801: INFO: Waiting up to 2m0s for pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" in namespace "var-expansion-4733" to be "container 0 failed with reason CreateContainerConfigError"
Feb 13 15:04:41.805: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595": Phase="Pending", Reason="", readiness=false. Elapsed: 4.264507ms
Feb 13 15:04:43.814: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012705122s
Feb 13 15:04:43.814: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Feb 13 15:04:43.814: INFO: Deleting pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" in namespace "var-expansion-4733"
Feb 13 15:04:43.828: INFO: Wait up to 5m0s for pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Feb 13 15:04:45.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4733" for this suite. 02/13/23 15:04:45.848
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":348,"skipped":6379,"failed":0}
------------------------------
• [4.106 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:41.75
    Feb 13 15:04:41.750: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename var-expansion 02/13/23 15:04:41.753
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:41.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:41.783
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    W0213 15:04:41.801439      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:04:41.801: INFO: Waiting up to 2m0s for pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" in namespace "var-expansion-4733" to be "container 0 failed with reason CreateContainerConfigError"
    Feb 13 15:04:41.805: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595": Phase="Pending", Reason="", readiness=false. Elapsed: 4.264507ms
    Feb 13 15:04:43.814: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012705122s
    Feb 13 15:04:43.814: INFO: Pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Feb 13 15:04:43.814: INFO: Deleting pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" in namespace "var-expansion-4733"
    Feb 13 15:04:43.828: INFO: Wait up to 5m0s for pod "var-expansion-6869ce98-3ecb-4e82-8aca-abfcf1f40595" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Feb 13 15:04:45.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4733" for this suite. 02/13/23 15:04:45.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:45.857
Feb 13 15:04:45.857: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 15:04:45.858
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:45.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:45.884
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-1d0c390d-0eb8-4db3-a4a5-e5d9e648e682 02/13/23 15:04:45.894
STEP: Creating secret with name s-test-opt-upd-d50a960c-8fbb-46b0-907a-87e8ac44e1f3 02/13/23 15:04:45.903
STEP: Creating the pod 02/13/23 15:04:45.912
W0213 15:04:45.924619      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:04:45.925: INFO: Waiting up to 5m0s for pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac" in namespace "secrets-6571" to be "running and ready"
Feb 13 15:04:45.932: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac": Phase="Pending", Reason="", readiness=false. Elapsed: 7.101164ms
Feb 13 15:04:45.932: INFO: The phase of Pod pod-secrets-9c84a823-4750-4950-86d9-5887922137ac is Pending, waiting for it to be Running (with Ready = true)
Feb 13 15:04:47.938: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac": Phase="Running", Reason="", readiness=true. Elapsed: 2.013419541s
Feb 13 15:04:47.938: INFO: The phase of Pod pod-secrets-9c84a823-4750-4950-86d9-5887922137ac is Running (Ready = true)
Feb 13 15:04:47.938: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-1d0c390d-0eb8-4db3-a4a5-e5d9e648e682 02/13/23 15:04:47.976
STEP: Updating secret s-test-opt-upd-d50a960c-8fbb-46b0-907a-87e8ac44e1f3 02/13/23 15:04:47.985
STEP: Creating secret with name s-test-opt-create-de637687-9e38-44ae-8314-278171430d9a 02/13/23 15:04:47.991
STEP: waiting to observe update in volume 02/13/23 15:04:47.997
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Feb 13 15:04:52.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6571" for this suite. 02/13/23 15:04:52.051
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":349,"skipped":6397,"failed":0}
------------------------------
• [SLOW TEST] [6.201 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:45.857
    Feb 13 15:04:45.857: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 15:04:45.858
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:45.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:45.884
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-1d0c390d-0eb8-4db3-a4a5-e5d9e648e682 02/13/23 15:04:45.894
    STEP: Creating secret with name s-test-opt-upd-d50a960c-8fbb-46b0-907a-87e8ac44e1f3 02/13/23 15:04:45.903
    STEP: Creating the pod 02/13/23 15:04:45.912
    W0213 15:04:45.924619      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:04:45.925: INFO: Waiting up to 5m0s for pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac" in namespace "secrets-6571" to be "running and ready"
    Feb 13 15:04:45.932: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac": Phase="Pending", Reason="", readiness=false. Elapsed: 7.101164ms
    Feb 13 15:04:45.932: INFO: The phase of Pod pod-secrets-9c84a823-4750-4950-86d9-5887922137ac is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 15:04:47.938: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac": Phase="Running", Reason="", readiness=true. Elapsed: 2.013419541s
    Feb 13 15:04:47.938: INFO: The phase of Pod pod-secrets-9c84a823-4750-4950-86d9-5887922137ac is Running (Ready = true)
    Feb 13 15:04:47.938: INFO: Pod "pod-secrets-9c84a823-4750-4950-86d9-5887922137ac" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-1d0c390d-0eb8-4db3-a4a5-e5d9e648e682 02/13/23 15:04:47.976
    STEP: Updating secret s-test-opt-upd-d50a960c-8fbb-46b0-907a-87e8ac44e1f3 02/13/23 15:04:47.985
    STEP: Creating secret with name s-test-opt-create-de637687-9e38-44ae-8314-278171430d9a 02/13/23 15:04:47.991
    STEP: waiting to observe update in volume 02/13/23 15:04:47.997
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 15:04:52.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6571" for this suite. 02/13/23 15:04:52.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:04:52.061
Feb 13 15:04:52.061: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-probe 02/13/23 15:04:52.062
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:52.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:52.085
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e in namespace container-probe-8388 02/13/23 15:04:52.09
W0213 15:04:52.100922      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:04:52.101: INFO: Waiting up to 5m0s for pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e" in namespace "container-probe-8388" to be "not pending"
Feb 13 15:04:52.114: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.514782ms
Feb 13 15:04:54.121: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.020243379s
Feb 13 15:04:54.121: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e" satisfied condition "not pending"
Feb 13 15:04:54.121: INFO: Started pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e in namespace container-probe-8388
STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 15:04:54.121
Feb 13 15:04:54.127: INFO: Initial restart count of pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e is 0
Feb 13 15:05:14.192: INFO: Restart count of pod container-probe-8388/liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e is now 1 (20.064787166s elapsed)
STEP: deleting the pod 02/13/23 15:05:14.192
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Feb 13 15:05:14.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8388" for this suite. 02/13/23 15:05:14.209
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":350,"skipped":6428,"failed":0}
------------------------------
• [SLOW TEST] [22.155 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:04:52.061
    Feb 13 15:04:52.061: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-probe 02/13/23 15:04:52.062
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:04:52.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:04:52.085
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e in namespace container-probe-8388 02/13/23 15:04:52.09
    W0213 15:04:52.100922      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:04:52.101: INFO: Waiting up to 5m0s for pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e" in namespace "container-probe-8388" to be "not pending"
    Feb 13 15:04:52.114: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.514782ms
    Feb 13 15:04:54.121: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.020243379s
    Feb 13 15:04:54.121: INFO: Pod "liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e" satisfied condition "not pending"
    Feb 13 15:04:54.121: INFO: Started pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e in namespace container-probe-8388
    STEP: checking the pod's current state and verifying that restartCount is present 02/13/23 15:04:54.121
    Feb 13 15:04:54.127: INFO: Initial restart count of pod liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e is 0
    Feb 13 15:05:14.192: INFO: Restart count of pod container-probe-8388/liveness-4c5fd825-6ead-407e-8cdf-ac01aea9ca1e is now 1 (20.064787166s elapsed)
    STEP: deleting the pod 02/13/23 15:05:14.192
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Feb 13 15:05:14.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8388" for this suite. 02/13/23 15:05:14.209
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:14.227
Feb 13 15:05:14.227: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename kubectl 02/13/23 15:05:14.229
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:14.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:14.245
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 02/13/23 15:05:14.248
Feb 13 15:05:14.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 create -f -'
Feb 13 15:05:15.113: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"pause\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"pause\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"pause\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"pause\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
Feb 13 15:05:15.114: INFO: stdout: "pod/pause created\n"
Feb 13 15:05:15.114: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 13 15:05:15.114: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7665" to be "running and ready"
Feb 13 15:05:15.121: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.961058ms
Feb 13 15:05:15.121: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'conformance-5500-0ccfa5-pool-bf9f-o7jrw' to be 'Running' but was 'Pending'
Feb 13 15:05:17.125: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011431362s
Feb 13 15:05:17.125: INFO: Pod "pause" satisfied condition "running and ready"
Feb 13 15:05:17.125: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 02/13/23 15:05:17.125
Feb 13 15:05:17.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 label pods pause testing-label=testing-label-value'
Feb 13 15:05:17.252: INFO: stderr: ""
Feb 13 15:05:17.253: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 02/13/23 15:05:17.253
Feb 13 15:05:17.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pod pause -L testing-label'
Feb 13 15:05:17.358: INFO: stderr: ""
Feb 13 15:05:17.358: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 02/13/23 15:05:17.358
Feb 13 15:05:17.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 label pods pause testing-label-'
Feb 13 15:05:17.458: INFO: stderr: ""
Feb 13 15:05:17.458: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 02/13/23 15:05:17.458
Feb 13 15:05:17.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pod pause -L testing-label'
Feb 13 15:05:17.539: INFO: stderr: ""
Feb 13 15:05:17.539: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 02/13/23 15:05:17.54
Feb 13 15:05:17.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 delete --grace-period=0 --force -f -'
Feb 13 15:05:17.675: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 15:05:17.675: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 13 15:05:17.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get rc,svc -l name=pause --no-headers'
Feb 13 15:05:17.796: INFO: stderr: "No resources found in kubectl-7665 namespace.\n"
Feb 13 15:05:17.796: INFO: stdout: ""
Feb 13 15:05:17.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 15:05:17.908: INFO: stderr: ""
Feb 13 15:05:17.908: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Feb 13 15:05:17.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7665" for this suite. 02/13/23 15:05:17.917
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":351,"skipped":6453,"failed":0}
------------------------------
• [3.699 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:14.227
    Feb 13 15:05:14.227: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename kubectl 02/13/23 15:05:14.229
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:14.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:14.245
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 02/13/23 15:05:14.248
    Feb 13 15:05:14.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 create -f -'
    Feb 13 15:05:15.113: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"pause\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"pause\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"pause\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"pause\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
    Feb 13 15:05:15.114: INFO: stdout: "pod/pause created\n"
    Feb 13 15:05:15.114: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Feb 13 15:05:15.114: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7665" to be "running and ready"
    Feb 13 15:05:15.121: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.961058ms
    Feb 13 15:05:15.121: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'conformance-5500-0ccfa5-pool-bf9f-o7jrw' to be 'Running' but was 'Pending'
    Feb 13 15:05:17.125: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011431362s
    Feb 13 15:05:17.125: INFO: Pod "pause" satisfied condition "running and ready"
    Feb 13 15:05:17.125: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 02/13/23 15:05:17.125
    Feb 13 15:05:17.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 label pods pause testing-label=testing-label-value'
    Feb 13 15:05:17.252: INFO: stderr: ""
    Feb 13 15:05:17.253: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 02/13/23 15:05:17.253
    Feb 13 15:05:17.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pod pause -L testing-label'
    Feb 13 15:05:17.358: INFO: stderr: ""
    Feb 13 15:05:17.358: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 02/13/23 15:05:17.358
    Feb 13 15:05:17.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 label pods pause testing-label-'
    Feb 13 15:05:17.458: INFO: stderr: ""
    Feb 13 15:05:17.458: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 02/13/23 15:05:17.458
    Feb 13 15:05:17.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pod pause -L testing-label'
    Feb 13 15:05:17.539: INFO: stderr: ""
    Feb 13 15:05:17.539: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 02/13/23 15:05:17.54
    Feb 13 15:05:17.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 delete --grace-period=0 --force -f -'
    Feb 13 15:05:17.675: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Feb 13 15:05:17.675: INFO: stdout: "pod \"pause\" force deleted\n"
    Feb 13 15:05:17.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get rc,svc -l name=pause --no-headers'
    Feb 13 15:05:17.796: INFO: stderr: "No resources found in kubectl-7665 namespace.\n"
    Feb 13 15:05:17.796: INFO: stdout: ""
    Feb 13 15:05:17.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-219335588 --namespace=kubectl-7665 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Feb 13 15:05:17.908: INFO: stderr: ""
    Feb 13 15:05:17.908: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Feb 13 15:05:17.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7665" for this suite. 02/13/23 15:05:17.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:17.928
Feb 13 15:05:17.928: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename events 02/13/23 15:05:17.929
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:17.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:17.951
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 02/13/23 15:05:17.954
STEP: listing all events in all namespaces 02/13/23 15:05:17.96
STEP: patching the test event 02/13/23 15:05:17.964
STEP: fetching the test event 02/13/23 15:05:17.971
STEP: updating the test event 02/13/23 15:05:17.974
STEP: getting the test event 02/13/23 15:05:17.986
STEP: deleting the test event 02/13/23 15:05:17.99
STEP: listing all events in all namespaces 02/13/23 15:05:17.997
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Feb 13 15:05:18.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8424" for this suite. 02/13/23 15:05:18.005
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":352,"skipped":6473,"failed":0}
------------------------------
• [0.084 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:17.928
    Feb 13 15:05:17.928: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename events 02/13/23 15:05:17.929
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:17.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:17.951
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 02/13/23 15:05:17.954
    STEP: listing all events in all namespaces 02/13/23 15:05:17.96
    STEP: patching the test event 02/13/23 15:05:17.964
    STEP: fetching the test event 02/13/23 15:05:17.971
    STEP: updating the test event 02/13/23 15:05:17.974
    STEP: getting the test event 02/13/23 15:05:17.986
    STEP: deleting the test event 02/13/23 15:05:17.99
    STEP: listing all events in all namespaces 02/13/23 15:05:17.997
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Feb 13 15:05:18.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8424" for this suite. 02/13/23 15:05:18.005
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:18.015
Feb 13 15:05:18.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename container-runtime 02/13/23 15:05:18.017
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:18.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:18.039
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 02/13/23 15:05:18.043
W0213 15:05:18.053933      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: wait for the container to reach Succeeded 02/13/23 15:05:18.054
STEP: get the container status 02/13/23 15:05:22.082
STEP: the container should be terminated 02/13/23 15:05:22.087
STEP: the termination message should be set 02/13/23 15:05:22.087
Feb 13 15:05:22.087: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 02/13/23 15:05:22.087
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Feb 13 15:05:22.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1850" for this suite. 02/13/23 15:05:22.109
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":353,"skipped":6495,"failed":0}
------------------------------
• [4.099 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:18.015
    Feb 13 15:05:18.016: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename container-runtime 02/13/23 15:05:18.017
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:18.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:18.039
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 02/13/23 15:05:18.043
    W0213 15:05:18.053933      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: wait for the container to reach Succeeded 02/13/23 15:05:18.054
    STEP: get the container status 02/13/23 15:05:22.082
    STEP: the container should be terminated 02/13/23 15:05:22.087
    STEP: the termination message should be set 02/13/23 15:05:22.087
    Feb 13 15:05:22.087: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 02/13/23 15:05:22.087
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Feb 13 15:05:22.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1850" for this suite. 02/13/23 15:05:22.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:22.118
Feb 13 15:05:22.118: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename configmap 02/13/23 15:05:22.119
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:22.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:22.136
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Feb 13 15:05:22.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7077" for this suite. 02/13/23 15:05:22.181
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":354,"skipped":6529,"failed":0}
------------------------------
• [0.069 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:22.118
    Feb 13 15:05:22.118: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename configmap 02/13/23 15:05:22.119
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:22.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:22.136
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Feb 13 15:05:22.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7077" for this suite. 02/13/23 15:05:22.181
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:22.188
Feb 13 15:05:22.188: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename downward-api 02/13/23 15:05:22.189
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:22.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:22.207
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 02/13/23 15:05:22.21
W0213 15:05:22.219292      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:05:22.219: INFO: Waiting up to 5m0s for pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc" in namespace "downward-api-8758" to be "Succeeded or Failed"
Feb 13 15:05:22.226: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.006692ms
Feb 13 15:05:24.232: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012922098s
Feb 13 15:05:26.231: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011571152s
STEP: Saw pod success 02/13/23 15:05:26.231
Feb 13 15:05:26.231: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc" satisfied condition "Succeeded or Failed"
Feb 13 15:05:26.235: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc container dapi-container: <nil>
STEP: delete the pod 02/13/23 15:05:26.26
Feb 13 15:05:26.272: INFO: Waiting for pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc to disappear
Feb 13 15:05:26.275: INFO: Pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Feb 13 15:05:26.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8758" for this suite. 02/13/23 15:05:26.278
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":355,"skipped":6557,"failed":0}
------------------------------
• [4.095 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:22.188
    Feb 13 15:05:22.188: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename downward-api 02/13/23 15:05:22.189
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:22.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:22.207
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 02/13/23 15:05:22.21
    W0213 15:05:22.219292      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:05:22.219: INFO: Waiting up to 5m0s for pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc" in namespace "downward-api-8758" to be "Succeeded or Failed"
    Feb 13 15:05:22.226: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.006692ms
    Feb 13 15:05:24.232: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012922098s
    Feb 13 15:05:26.231: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011571152s
    STEP: Saw pod success 02/13/23 15:05:26.231
    Feb 13 15:05:26.231: INFO: Pod "downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc" satisfied condition "Succeeded or Failed"
    Feb 13 15:05:26.235: INFO: Trying to get logs from node conformance-5500-0ccfa5-pool-bf9f-o7jrw pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc container dapi-container: <nil>
    STEP: delete the pod 02/13/23 15:05:26.26
    Feb 13 15:05:26.272: INFO: Waiting for pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc to disappear
    Feb 13 15:05:26.275: INFO: Pod downward-api-9ee386c3-2e75-4cde-8482-fe5d51a824fc no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Feb 13 15:05:26.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8758" for this suite. 02/13/23 15:05:26.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:26.288
Feb 13 15:05:26.288: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename job 02/13/23 15:05:26.289
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:26.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:26.309
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 02/13/23 15:05:26.313
W0213 15:05:26.319944      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Ensuring active pods == parallelism 02/13/23 15:05:26.32
STEP: Orphaning one of the Job's Pods 02/13/23 15:05:28.327
Feb 13 15:05:28.850: INFO: Successfully updated pod "adopt-release-k89t6"
STEP: Checking that the Job readopts the Pod 02/13/23 15:05:28.85
Feb 13 15:05:28.851: INFO: Waiting up to 15m0s for pod "adopt-release-k89t6" in namespace "job-3123" to be "adopted"
Feb 13 15:05:28.857: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 5.981291ms
Feb 13 15:05:30.861: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010228495s
Feb 13 15:05:30.861: INFO: Pod "adopt-release-k89t6" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 02/13/23 15:05:30.861
Feb 13 15:05:31.372: INFO: Successfully updated pod "adopt-release-k89t6"
STEP: Checking that the Job releases the Pod 02/13/23 15:05:31.372
Feb 13 15:05:31.373: INFO: Waiting up to 15m0s for pod "adopt-release-k89t6" in namespace "job-3123" to be "released"
Feb 13 15:05:31.376: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 3.0487ms
Feb 13 15:05:33.382: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008845065s
Feb 13 15:05:33.382: INFO: Pod "adopt-release-k89t6" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Feb 13 15:05:33.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3123" for this suite. 02/13/23 15:05:33.387
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":356,"skipped":6590,"failed":0}
------------------------------
• [SLOW TEST] [7.110 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:26.288
    Feb 13 15:05:26.288: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename job 02/13/23 15:05:26.289
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:26.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:26.309
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 02/13/23 15:05:26.313
    W0213 15:05:26.319944      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Ensuring active pods == parallelism 02/13/23 15:05:26.32
    STEP: Orphaning one of the Job's Pods 02/13/23 15:05:28.327
    Feb 13 15:05:28.850: INFO: Successfully updated pod "adopt-release-k89t6"
    STEP: Checking that the Job readopts the Pod 02/13/23 15:05:28.85
    Feb 13 15:05:28.851: INFO: Waiting up to 15m0s for pod "adopt-release-k89t6" in namespace "job-3123" to be "adopted"
    Feb 13 15:05:28.857: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 5.981291ms
    Feb 13 15:05:30.861: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010228495s
    Feb 13 15:05:30.861: INFO: Pod "adopt-release-k89t6" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 02/13/23 15:05:30.861
    Feb 13 15:05:31.372: INFO: Successfully updated pod "adopt-release-k89t6"
    STEP: Checking that the Job releases the Pod 02/13/23 15:05:31.372
    Feb 13 15:05:31.373: INFO: Waiting up to 15m0s for pod "adopt-release-k89t6" in namespace "job-3123" to be "released"
    Feb 13 15:05:31.376: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 3.0487ms
    Feb 13 15:05:33.382: INFO: Pod "adopt-release-k89t6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008845065s
    Feb 13 15:05:33.382: INFO: Pod "adopt-release-k89t6" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Feb 13 15:05:33.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3123" for this suite. 02/13/23 15:05:33.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:33.412
Feb 13 15:05:33.412: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename svc-latency 02/13/23 15:05:33.414
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:33.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:33.444
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Feb 13 15:05:33.447: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8502 02/13/23 15:05:33.449
W0213 15:05:33.459367      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "svc-latency-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "svc-latency-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "svc-latency-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "svc-latency-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
I0213 15:05:33.459932      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8502, replica count: 1
I0213 15:05:34.510717      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 15:05:35.511865      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 15:05:35.633: INFO: Created: latency-svc-h4dlj
Feb 13 15:05:35.641: INFO: Got endpoints: latency-svc-h4dlj [29.031505ms]
Feb 13 15:05:35.663: INFO: Created: latency-svc-2nnbk
Feb 13 15:05:35.669: INFO: Got endpoints: latency-svc-2nnbk [27.642905ms]
Feb 13 15:05:35.681: INFO: Created: latency-svc-mxwkl
Feb 13 15:05:35.688: INFO: Got endpoints: latency-svc-mxwkl [45.496ms]
Feb 13 15:05:35.854: INFO: Created: latency-svc-4b6rw
Feb 13 15:05:35.861: INFO: Created: latency-svc-78rxg
Feb 13 15:05:35.862: INFO: Created: latency-svc-22xsb
Feb 13 15:05:35.862: INFO: Created: latency-svc-zv4tr
Feb 13 15:05:35.863: INFO: Created: latency-svc-xjqpv
Feb 13 15:05:35.863: INFO: Created: latency-svc-9plb2
Feb 13 15:05:35.863: INFO: Created: latency-svc-8jj4x
Feb 13 15:05:35.863: INFO: Created: latency-svc-skgzz
Feb 13 15:05:35.862: INFO: Created: latency-svc-4b5hk
Feb 13 15:05:35.863: INFO: Created: latency-svc-kznn2
Feb 13 15:05:35.862: INFO: Created: latency-svc-t2mxp
Feb 13 15:05:35.862: INFO: Created: latency-svc-l9dwp
Feb 13 15:05:35.864: INFO: Created: latency-svc-557pg
Feb 13 15:05:35.865: INFO: Created: latency-svc-kv5rk
Feb 13 15:05:35.865: INFO: Created: latency-svc-d8zn2
Feb 13 15:05:35.866: INFO: Got endpoints: latency-svc-4b6rw [196.322ms]
Feb 13 15:05:35.885: INFO: Got endpoints: latency-svc-22xsb [242.530232ms]
Feb 13 15:05:35.891: INFO: Got endpoints: latency-svc-9plb2 [248.441739ms]
Feb 13 15:05:35.891: INFO: Got endpoints: latency-svc-l9dwp [248.58626ms]
Feb 13 15:05:35.892: INFO: Got endpoints: latency-svc-zv4tr [203.681913ms]
Feb 13 15:05:35.892: INFO: Got endpoints: latency-svc-t2mxp [247.981788ms]
Feb 13 15:05:35.897: INFO: Got endpoints: latency-svc-d8zn2 [254.299013ms]
Feb 13 15:05:35.905: INFO: Created: latency-svc-nx4cz
Feb 13 15:05:35.912: INFO: Created: latency-svc-kxtdz
Feb 13 15:05:35.913: INFO: Got endpoints: latency-svc-8jj4x [269.755143ms]
Feb 13 15:05:35.921: INFO: Got endpoints: latency-svc-skgzz [277.316082ms]
Feb 13 15:05:35.921: INFO: Got endpoints: latency-svc-xjqpv [276.942755ms]
Feb 13 15:05:35.922: INFO: Got endpoints: latency-svc-kznn2 [278.473299ms]
Feb 13 15:05:35.922: INFO: Got endpoints: latency-svc-557pg [277.348647ms]
Feb 13 15:05:35.928: INFO: Got endpoints: latency-svc-kv5rk [284.561937ms]
Feb 13 15:05:35.944: INFO: Got endpoints: latency-svc-4b5hk [299.632786ms]
Feb 13 15:05:35.944: INFO: Got endpoints: latency-svc-78rxg [299.882778ms]
Feb 13 15:05:35.949: INFO: Got endpoints: latency-svc-nx4cz [82.526238ms]
Feb 13 15:05:35.956: INFO: Got endpoints: latency-svc-kxtdz [70.533256ms]
Feb 13 15:05:35.964: INFO: Created: latency-svc-vwx5z
Feb 13 15:05:35.982: INFO: Created: latency-svc-qhprw
Feb 13 15:05:35.995: INFO: Got endpoints: latency-svc-vwx5z [103.617283ms]
Feb 13 15:05:35.996: INFO: Created: latency-svc-9cdw9
Feb 13 15:05:36.007: INFO: Got endpoints: latency-svc-qhprw [114.764071ms]
Feb 13 15:05:36.008: INFO: Got endpoints: latency-svc-9cdw9 [116.398626ms]
Feb 13 15:05:36.017: INFO: Created: latency-svc-lqzjz
Feb 13 15:05:36.037: INFO: Created: latency-svc-4qtvd
Feb 13 15:05:36.039: INFO: Got endpoints: latency-svc-lqzjz [146.882244ms]
Feb 13 15:05:36.043: INFO: Created: latency-svc-v2xvm
Feb 13 15:05:36.052: INFO: Got endpoints: latency-svc-4qtvd [154.801935ms]
Feb 13 15:05:36.070: INFO: Got endpoints: latency-svc-v2xvm [156.893616ms]
Feb 13 15:05:36.079: INFO: Created: latency-svc-cn48m
Feb 13 15:05:36.094: INFO: Created: latency-svc-dr8cn
Feb 13 15:05:36.113: INFO: Got endpoints: latency-svc-cn48m [192.028937ms]
Feb 13 15:05:36.115: INFO: Got endpoints: latency-svc-dr8cn [193.27519ms]
Feb 13 15:05:36.258: INFO: Created: latency-svc-scnj4
Feb 13 15:05:36.268: INFO: Created: latency-svc-vxsbm
Feb 13 15:05:36.270: INFO: Created: latency-svc-fjq6d
Feb 13 15:05:36.272: INFO: Created: latency-svc-n94d9
Feb 13 15:05:36.273: INFO: Created: latency-svc-kc722
Feb 13 15:05:36.274: INFO: Created: latency-svc-vcpgn
Feb 13 15:05:36.275: INFO: Created: latency-svc-nh9rp
Feb 13 15:05:36.275: INFO: Got endpoints: latency-svc-scnj4 [353.721288ms]
Feb 13 15:05:36.276: INFO: Created: latency-svc-fnlrc
Feb 13 15:05:36.277: INFO: Created: latency-svc-dx4r9
Feb 13 15:05:36.281: INFO: Created: latency-svc-z49rr
Feb 13 15:05:36.281: INFO: Created: latency-svc-dwc2b
Feb 13 15:05:36.281: INFO: Created: latency-svc-b4r2v
Feb 13 15:05:36.282: INFO: Created: latency-svc-vqkcn
Feb 13 15:05:36.282: INFO: Created: latency-svc-vzbmx
Feb 13 15:05:36.282: INFO: Created: latency-svc-4jt9d
Feb 13 15:05:36.290: INFO: Got endpoints: latency-svc-nh9rp [368.148143ms]
Feb 13 15:05:36.290: INFO: Got endpoints: latency-svc-dx4r9 [361.615465ms]
Feb 13 15:05:36.291: INFO: Got endpoints: latency-svc-n94d9 [175.51146ms]
Feb 13 15:05:36.298: INFO: Got endpoints: latency-svc-4jt9d [184.724892ms]
Feb 13 15:05:36.302: INFO: Got endpoints: latency-svc-b4r2v [357.793684ms]
Feb 13 15:05:36.302: INFO: Created: latency-svc-kz5n7
Feb 13 15:05:36.303: INFO: Got endpoints: latency-svc-vqkcn [353.871442ms]
Feb 13 15:05:36.304: INFO: Got endpoints: latency-svc-kc722 [348.012343ms]
Feb 13 15:05:36.307: INFO: Got endpoints: latency-svc-vxsbm [362.295494ms]
Feb 13 15:05:36.323: INFO: Created: latency-svc-n9scz
Feb 13 15:05:36.326: INFO: Got endpoints: latency-svc-vcpgn [331.228689ms]
Feb 13 15:05:36.326: INFO: Got endpoints: latency-svc-fnlrc [319.67479ms]
Feb 13 15:05:36.331: INFO: Got endpoints: latency-svc-z49rr [279.329946ms]
Feb 13 15:05:36.332: INFO: Got endpoints: latency-svc-dwc2b [323.476722ms]
Feb 13 15:05:36.332: INFO: Got endpoints: latency-svc-vzbmx [293.114697ms]
Feb 13 15:05:36.340: INFO: Created: latency-svc-d7z7j
Feb 13 15:05:36.349: INFO: Created: latency-svc-gd88j
Feb 13 15:05:36.359: INFO: Created: latency-svc-tqwlq
Feb 13 15:05:36.363: INFO: Got endpoints: latency-svc-fjq6d [293.81846ms]
Feb 13 15:05:36.368: INFO: Created: latency-svc-cxxnm
Feb 13 15:05:36.379: INFO: Created: latency-svc-fslw9
Feb 13 15:05:36.396: INFO: Created: latency-svc-hp7g4
Feb 13 15:05:36.403: INFO: Created: latency-svc-97zph
Feb 13 15:05:36.412: INFO: Created: latency-svc-qv9hw
Feb 13 15:05:36.420: INFO: Got endpoints: latency-svc-kz5n7 [144.947689ms]
Feb 13 15:05:36.427: INFO: Created: latency-svc-dh6fd
Feb 13 15:05:36.435: INFO: Created: latency-svc-hg4fx
Feb 13 15:05:36.448: INFO: Created: latency-svc-84rlk
Feb 13 15:05:36.464: INFO: Created: latency-svc-6zv9g
Feb 13 15:05:36.469: INFO: Got endpoints: latency-svc-n9scz [178.562957ms]
Feb 13 15:05:36.473: INFO: Created: latency-svc-2pcdp
Feb 13 15:05:36.483: INFO: Created: latency-svc-vrd5j
Feb 13 15:05:36.503: INFO: Created: latency-svc-z8w99
Feb 13 15:05:36.513: INFO: Got endpoints: latency-svc-d7z7j [223.253548ms]
Feb 13 15:05:36.532: INFO: Created: latency-svc-nb2k9
Feb 13 15:05:36.564: INFO: Got endpoints: latency-svc-gd88j [273.288418ms]
Feb 13 15:05:36.587: INFO: Created: latency-svc-7cts7
Feb 13 15:05:36.611: INFO: Got endpoints: latency-svc-tqwlq [312.665905ms]
Feb 13 15:05:36.629: INFO: Created: latency-svc-9xqks
Feb 13 15:05:36.664: INFO: Got endpoints: latency-svc-cxxnm [361.611214ms]
Feb 13 15:05:36.683: INFO: Created: latency-svc-7dv7b
Feb 13 15:05:36.717: INFO: Got endpoints: latency-svc-fslw9 [414.090626ms]
Feb 13 15:05:36.736: INFO: Created: latency-svc-n8qtz
Feb 13 15:05:36.765: INFO: Got endpoints: latency-svc-hp7g4 [460.734777ms]
Feb 13 15:05:36.794: INFO: Created: latency-svc-z229n
Feb 13 15:05:36.814: INFO: Got endpoints: latency-svc-97zph [507.544165ms]
Feb 13 15:05:36.840: INFO: Created: latency-svc-bdnqg
Feb 13 15:05:36.861: INFO: Got endpoints: latency-svc-qv9hw [534.282524ms]
Feb 13 15:05:36.878: INFO: Created: latency-svc-xfn2n
Feb 13 15:05:36.912: INFO: Got endpoints: latency-svc-dh6fd [585.292058ms]
Feb 13 15:05:36.936: INFO: Created: latency-svc-bpk5j
Feb 13 15:05:36.962: INFO: Got endpoints: latency-svc-hg4fx [629.977652ms]
Feb 13 15:05:36.980: INFO: Created: latency-svc-sgv76
Feb 13 15:05:37.011: INFO: Got endpoints: latency-svc-84rlk [678.028088ms]
Feb 13 15:05:37.032: INFO: Created: latency-svc-77cwc
Feb 13 15:05:37.061: INFO: Got endpoints: latency-svc-6zv9g [729.366543ms]
Feb 13 15:05:37.079: INFO: Created: latency-svc-xjd2x
Feb 13 15:05:37.113: INFO: Got endpoints: latency-svc-2pcdp [749.028988ms]
Feb 13 15:05:37.132: INFO: Created: latency-svc-7wj2j
Feb 13 15:05:37.163: INFO: Got endpoints: latency-svc-vrd5j [742.447795ms]
Feb 13 15:05:37.184: INFO: Created: latency-svc-46qjv
Feb 13 15:05:37.211: INFO: Got endpoints: latency-svc-z8w99 [741.795949ms]
Feb 13 15:05:37.231: INFO: Created: latency-svc-298w6
Feb 13 15:05:37.270: INFO: Got endpoints: latency-svc-nb2k9 [756.128305ms]
Feb 13 15:05:37.287: INFO: Created: latency-svc-7xxgm
Feb 13 15:05:37.314: INFO: Got endpoints: latency-svc-7cts7 [749.240274ms]
Feb 13 15:05:37.330: INFO: Created: latency-svc-shzsg
Feb 13 15:05:37.363: INFO: Got endpoints: latency-svc-9xqks [752.538467ms]
Feb 13 15:05:37.379: INFO: Created: latency-svc-mmwdg
Feb 13 15:05:37.415: INFO: Got endpoints: latency-svc-7dv7b [750.807236ms]
Feb 13 15:05:37.434: INFO: Created: latency-svc-hsjtf
Feb 13 15:05:37.468: INFO: Got endpoints: latency-svc-n8qtz [751.003292ms]
Feb 13 15:05:37.485: INFO: Created: latency-svc-n7fb8
Feb 13 15:05:37.513: INFO: Got endpoints: latency-svc-z229n [748.522543ms]
Feb 13 15:05:37.534: INFO: Created: latency-svc-jhhvx
Feb 13 15:05:37.563: INFO: Got endpoints: latency-svc-bdnqg [747.824291ms]
Feb 13 15:05:37.588: INFO: Created: latency-svc-dhx84
Feb 13 15:05:37.612: INFO: Got endpoints: latency-svc-xfn2n [750.25007ms]
Feb 13 15:05:37.628: INFO: Created: latency-svc-tgkf9
Feb 13 15:05:37.663: INFO: Got endpoints: latency-svc-bpk5j [751.572351ms]
Feb 13 15:05:37.685: INFO: Created: latency-svc-cgzzr
Feb 13 15:05:37.713: INFO: Got endpoints: latency-svc-sgv76 [750.063753ms]
Feb 13 15:05:37.730: INFO: Created: latency-svc-dsccf
Feb 13 15:05:37.762: INFO: Got endpoints: latency-svc-77cwc [750.793945ms]
Feb 13 15:05:37.780: INFO: Created: latency-svc-vrgtv
Feb 13 15:05:37.810: INFO: Got endpoints: latency-svc-xjd2x [748.869196ms]
Feb 13 15:05:37.828: INFO: Created: latency-svc-fssx5
Feb 13 15:05:37.863: INFO: Got endpoints: latency-svc-7wj2j [750.529937ms]
Feb 13 15:05:37.881: INFO: Created: latency-svc-pvc4f
Feb 13 15:05:37.911: INFO: Got endpoints: latency-svc-46qjv [747.802665ms]
Feb 13 15:05:37.927: INFO: Created: latency-svc-52b6c
Feb 13 15:05:37.965: INFO: Got endpoints: latency-svc-298w6 [753.740018ms]
Feb 13 15:05:37.980: INFO: Created: latency-svc-m8s45
Feb 13 15:05:38.014: INFO: Got endpoints: latency-svc-7xxgm [744.587986ms]
Feb 13 15:05:38.033: INFO: Created: latency-svc-lzs2x
Feb 13 15:05:38.062: INFO: Got endpoints: latency-svc-shzsg [748.235261ms]
Feb 13 15:05:38.084: INFO: Created: latency-svc-g7js7
Feb 13 15:05:38.117: INFO: Got endpoints: latency-svc-mmwdg [753.246246ms]
Feb 13 15:05:38.134: INFO: Created: latency-svc-wqftk
Feb 13 15:05:38.161: INFO: Got endpoints: latency-svc-hsjtf [746.566088ms]
Feb 13 15:05:38.178: INFO: Created: latency-svc-4mwgm
Feb 13 15:05:38.212: INFO: Got endpoints: latency-svc-n7fb8 [743.307497ms]
Feb 13 15:05:38.253: INFO: Created: latency-svc-9nmmg
Feb 13 15:05:38.273: INFO: Got endpoints: latency-svc-jhhvx [759.713262ms]
Feb 13 15:05:38.296: INFO: Created: latency-svc-2m4kl
Feb 13 15:05:38.323: INFO: Got endpoints: latency-svc-dhx84 [759.733942ms]
Feb 13 15:05:38.366: INFO: Got endpoints: latency-svc-tgkf9 [753.8532ms]
Feb 13 15:05:38.366: INFO: Created: latency-svc-mqst4
Feb 13 15:05:38.401: INFO: Created: latency-svc-hzvjc
Feb 13 15:05:38.414: INFO: Got endpoints: latency-svc-cgzzr [750.761004ms]
Feb 13 15:05:38.433: INFO: Created: latency-svc-mbpm8
Feb 13 15:05:38.465: INFO: Got endpoints: latency-svc-dsccf [752.403088ms]
Feb 13 15:05:38.496: INFO: Created: latency-svc-5mcb2
Feb 13 15:05:38.516: INFO: Got endpoints: latency-svc-vrgtv [754.385127ms]
Feb 13 15:05:38.537: INFO: Created: latency-svc-qkxl9
Feb 13 15:05:38.564: INFO: Got endpoints: latency-svc-fssx5 [753.326079ms]
Feb 13 15:05:38.592: INFO: Created: latency-svc-ck44v
Feb 13 15:05:38.613: INFO: Got endpoints: latency-svc-pvc4f [749.433259ms]
Feb 13 15:05:38.636: INFO: Created: latency-svc-8mwjk
Feb 13 15:05:38.664: INFO: Got endpoints: latency-svc-52b6c [752.881188ms]
Feb 13 15:05:38.679: INFO: Created: latency-svc-hzb8m
Feb 13 15:05:38.710: INFO: Got endpoints: latency-svc-m8s45 [745.272729ms]
Feb 13 15:05:38.725: INFO: Created: latency-svc-xwm6c
Feb 13 15:05:38.764: INFO: Got endpoints: latency-svc-lzs2x [749.012765ms]
Feb 13 15:05:38.781: INFO: Created: latency-svc-qqc7s
Feb 13 15:05:38.812: INFO: Got endpoints: latency-svc-g7js7 [749.866524ms]
Feb 13 15:05:38.827: INFO: Created: latency-svc-2rswn
Feb 13 15:05:38.867: INFO: Got endpoints: latency-svc-wqftk [749.989467ms]
Feb 13 15:05:38.888: INFO: Created: latency-svc-f84nr
Feb 13 15:05:38.917: INFO: Got endpoints: latency-svc-4mwgm [755.128998ms]
Feb 13 15:05:38.935: INFO: Created: latency-svc-v2xwb
Feb 13 15:05:38.962: INFO: Got endpoints: latency-svc-9nmmg [749.881346ms]
Feb 13 15:05:38.985: INFO: Created: latency-svc-d2b7h
Feb 13 15:05:39.017: INFO: Got endpoints: latency-svc-2m4kl [743.554066ms]
Feb 13 15:05:39.036: INFO: Created: latency-svc-fb5lr
Feb 13 15:05:39.064: INFO: Got endpoints: latency-svc-mqst4 [741.785554ms]
Feb 13 15:05:39.082: INFO: Created: latency-svc-vn2lj
Feb 13 15:05:39.113: INFO: Got endpoints: latency-svc-hzvjc [747.20129ms]
Feb 13 15:05:39.137: INFO: Created: latency-svc-ww54s
Feb 13 15:05:39.164: INFO: Got endpoints: latency-svc-mbpm8 [749.724837ms]
Feb 13 15:05:39.181: INFO: Created: latency-svc-nflb5
Feb 13 15:05:39.212: INFO: Got endpoints: latency-svc-5mcb2 [746.167102ms]
Feb 13 15:05:39.232: INFO: Created: latency-svc-rwv7g
Feb 13 15:05:39.264: INFO: Got endpoints: latency-svc-qkxl9 [747.510762ms]
Feb 13 15:05:39.282: INFO: Created: latency-svc-c2sms
Feb 13 15:05:39.311: INFO: Got endpoints: latency-svc-ck44v [746.911691ms]
Feb 13 15:05:39.328: INFO: Created: latency-svc-qxq2q
Feb 13 15:05:39.363: INFO: Got endpoints: latency-svc-8mwjk [750.713816ms]
Feb 13 15:05:39.379: INFO: Created: latency-svc-4hd6h
Feb 13 15:05:39.415: INFO: Got endpoints: latency-svc-hzb8m [750.915352ms]
Feb 13 15:05:39.433: INFO: Created: latency-svc-4v5xm
Feb 13 15:05:39.461: INFO: Got endpoints: latency-svc-xwm6c [750.700154ms]
Feb 13 15:05:39.485: INFO: Created: latency-svc-bj8vm
Feb 13 15:05:39.512: INFO: Got endpoints: latency-svc-qqc7s [747.734497ms]
Feb 13 15:05:39.534: INFO: Created: latency-svc-n9mhk
Feb 13 15:05:39.561: INFO: Got endpoints: latency-svc-2rswn [748.767939ms]
Feb 13 15:05:39.574: INFO: Created: latency-svc-87m8z
Feb 13 15:05:39.611: INFO: Got endpoints: latency-svc-f84nr [743.995416ms]
Feb 13 15:05:39.629: INFO: Created: latency-svc-brhq2
Feb 13 15:05:39.662: INFO: Got endpoints: latency-svc-v2xwb [745.1026ms]
Feb 13 15:05:39.682: INFO: Created: latency-svc-zbh9h
Feb 13 15:05:39.716: INFO: Got endpoints: latency-svc-d2b7h [753.273647ms]
Feb 13 15:05:39.741: INFO: Created: latency-svc-m2xcz
Feb 13 15:05:39.765: INFO: Got endpoints: latency-svc-fb5lr [748.23325ms]
Feb 13 15:05:39.781: INFO: Created: latency-svc-gt4l5
Feb 13 15:05:39.815: INFO: Got endpoints: latency-svc-vn2lj [750.233106ms]
Feb 13 15:05:39.843: INFO: Created: latency-svc-hf5rw
Feb 13 15:05:39.865: INFO: Got endpoints: latency-svc-ww54s [752.021648ms]
Feb 13 15:05:39.882: INFO: Created: latency-svc-f66lz
Feb 13 15:05:39.916: INFO: Got endpoints: latency-svc-nflb5 [751.863669ms]
Feb 13 15:05:39.934: INFO: Created: latency-svc-tzsgk
Feb 13 15:05:39.964: INFO: Got endpoints: latency-svc-rwv7g [752.031465ms]
Feb 13 15:05:39.977: INFO: Created: latency-svc-9w57s
Feb 13 15:05:40.011: INFO: Got endpoints: latency-svc-c2sms [746.926999ms]
Feb 13 15:05:40.037: INFO: Created: latency-svc-g65ps
Feb 13 15:05:40.062: INFO: Got endpoints: latency-svc-qxq2q [750.846192ms]
Feb 13 15:05:40.081: INFO: Created: latency-svc-pb62f
Feb 13 15:05:40.114: INFO: Got endpoints: latency-svc-4hd6h [750.021792ms]
Feb 13 15:05:40.141: INFO: Created: latency-svc-9d6sv
Feb 13 15:05:40.163: INFO: Got endpoints: latency-svc-4v5xm [747.857428ms]
Feb 13 15:05:40.182: INFO: Created: latency-svc-jflhn
Feb 13 15:05:40.211: INFO: Got endpoints: latency-svc-bj8vm [749.845873ms]
Feb 13 15:05:40.227: INFO: Created: latency-svc-zq729
Feb 13 15:05:40.260: INFO: Got endpoints: latency-svc-n9mhk [748.705841ms]
Feb 13 15:05:40.282: INFO: Created: latency-svc-x82v9
Feb 13 15:05:40.312: INFO: Got endpoints: latency-svc-87m8z [750.8092ms]
Feb 13 15:05:40.330: INFO: Created: latency-svc-9sccq
Feb 13 15:05:40.361: INFO: Got endpoints: latency-svc-brhq2 [749.805959ms]
Feb 13 15:05:40.381: INFO: Created: latency-svc-mj7rg
Feb 13 15:05:40.414: INFO: Got endpoints: latency-svc-zbh9h [752.030642ms]
Feb 13 15:05:40.431: INFO: Created: latency-svc-tmjwr
Feb 13 15:05:40.467: INFO: Got endpoints: latency-svc-m2xcz [750.332391ms]
Feb 13 15:05:40.489: INFO: Created: latency-svc-qpjdk
Feb 13 15:05:40.513: INFO: Got endpoints: latency-svc-gt4l5 [748.16869ms]
Feb 13 15:05:40.535: INFO: Created: latency-svc-xh2cp
Feb 13 15:05:40.562: INFO: Got endpoints: latency-svc-hf5rw [746.784868ms]
Feb 13 15:05:40.598: INFO: Created: latency-svc-qfvm6
Feb 13 15:05:40.609: INFO: Got endpoints: latency-svc-f66lz [744.279267ms]
Feb 13 15:05:40.630: INFO: Created: latency-svc-lqshj
Feb 13 15:05:40.664: INFO: Got endpoints: latency-svc-tzsgk [748.25799ms]
Feb 13 15:05:40.685: INFO: Created: latency-svc-spcdr
Feb 13 15:05:40.716: INFO: Got endpoints: latency-svc-9w57s [752.238626ms]
Feb 13 15:05:40.737: INFO: Created: latency-svc-vcw9x
Feb 13 15:05:40.761: INFO: Got endpoints: latency-svc-g65ps [750.253525ms]
Feb 13 15:05:40.782: INFO: Created: latency-svc-x7dn4
Feb 13 15:05:40.811: INFO: Got endpoints: latency-svc-pb62f [748.645111ms]
Feb 13 15:05:40.832: INFO: Created: latency-svc-66j5s
Feb 13 15:05:40.861: INFO: Got endpoints: latency-svc-9d6sv [747.47273ms]
Feb 13 15:05:40.884: INFO: Created: latency-svc-fgz9l
Feb 13 15:05:40.919: INFO: Got endpoints: latency-svc-jflhn [755.707816ms]
Feb 13 15:05:40.937: INFO: Created: latency-svc-d5kml
Feb 13 15:05:40.961: INFO: Got endpoints: latency-svc-zq729 [749.177085ms]
Feb 13 15:05:40.979: INFO: Created: latency-svc-fqmn6
Feb 13 15:05:41.010: INFO: Got endpoints: latency-svc-x82v9 [749.392029ms]
Feb 13 15:05:41.034: INFO: Created: latency-svc-qm79b
Feb 13 15:05:41.063: INFO: Got endpoints: latency-svc-9sccq [751.232647ms]
Feb 13 15:05:41.083: INFO: Created: latency-svc-dbd89
Feb 13 15:05:41.110: INFO: Got endpoints: latency-svc-mj7rg [749.239585ms]
Feb 13 15:05:41.131: INFO: Created: latency-svc-v6f64
Feb 13 15:05:41.161: INFO: Got endpoints: latency-svc-tmjwr [746.526149ms]
Feb 13 15:05:41.178: INFO: Created: latency-svc-6h8h8
Feb 13 15:05:41.213: INFO: Got endpoints: latency-svc-qpjdk [746.836473ms]
Feb 13 15:05:41.236: INFO: Created: latency-svc-zf8lz
Feb 13 15:05:41.261: INFO: Got endpoints: latency-svc-xh2cp [747.386831ms]
Feb 13 15:05:41.285: INFO: Created: latency-svc-72nb2
Feb 13 15:05:41.313: INFO: Got endpoints: latency-svc-qfvm6 [751.002799ms]
Feb 13 15:05:41.329: INFO: Created: latency-svc-bmgdd
Feb 13 15:05:41.360: INFO: Got endpoints: latency-svc-lqshj [750.765778ms]
Feb 13 15:05:41.378: INFO: Created: latency-svc-g2vxj
Feb 13 15:05:41.415: INFO: Got endpoints: latency-svc-spcdr [751.271846ms]
Feb 13 15:05:41.441: INFO: Created: latency-svc-qhfst
Feb 13 15:05:41.460: INFO: Got endpoints: latency-svc-vcw9x [744.327526ms]
Feb 13 15:05:41.511: INFO: Created: latency-svc-75285
Feb 13 15:05:41.516: INFO: Got endpoints: latency-svc-x7dn4 [754.861152ms]
Feb 13 15:05:41.538: INFO: Created: latency-svc-25p8x
Feb 13 15:05:41.572: INFO: Got endpoints: latency-svc-66j5s [760.645271ms]
Feb 13 15:05:41.590: INFO: Created: latency-svc-kxczp
Feb 13 15:05:41.610: INFO: Got endpoints: latency-svc-fgz9l [748.440063ms]
Feb 13 15:05:41.624: INFO: Created: latency-svc-96xdc
Feb 13 15:05:41.665: INFO: Got endpoints: latency-svc-d5kml [746.016093ms]
Feb 13 15:05:41.681: INFO: Created: latency-svc-9bq4m
Feb 13 15:05:41.717: INFO: Got endpoints: latency-svc-fqmn6 [755.588827ms]
Feb 13 15:05:41.735: INFO: Created: latency-svc-jzkz5
Feb 13 15:05:41.767: INFO: Got endpoints: latency-svc-qm79b [756.445342ms]
Feb 13 15:05:41.783: INFO: Created: latency-svc-7gfxf
Feb 13 15:05:41.819: INFO: Got endpoints: latency-svc-dbd89 [755.584805ms]
Feb 13 15:05:41.840: INFO: Created: latency-svc-ppb8t
Feb 13 15:05:41.862: INFO: Got endpoints: latency-svc-v6f64 [751.44689ms]
Feb 13 15:05:41.894: INFO: Created: latency-svc-99tm9
Feb 13 15:05:41.912: INFO: Got endpoints: latency-svc-6h8h8 [751.406225ms]
Feb 13 15:05:41.932: INFO: Created: latency-svc-5fhzp
Feb 13 15:05:41.965: INFO: Got endpoints: latency-svc-zf8lz [751.985866ms]
Feb 13 15:05:41.990: INFO: Created: latency-svc-qd5qz
Feb 13 15:05:42.014: INFO: Got endpoints: latency-svc-72nb2 [753.523996ms]
Feb 13 15:05:42.032: INFO: Created: latency-svc-dx672
Feb 13 15:05:42.066: INFO: Got endpoints: latency-svc-bmgdd [753.178493ms]
Feb 13 15:05:42.081: INFO: Created: latency-svc-rm99x
Feb 13 15:05:42.111: INFO: Got endpoints: latency-svc-g2vxj [750.855382ms]
Feb 13 15:05:42.130: INFO: Created: latency-svc-dw8s4
Feb 13 15:05:42.162: INFO: Got endpoints: latency-svc-qhfst [745.984706ms]
Feb 13 15:05:42.182: INFO: Created: latency-svc-4vhvz
Feb 13 15:05:42.214: INFO: Got endpoints: latency-svc-75285 [753.568384ms]
Feb 13 15:05:42.230: INFO: Created: latency-svc-kpj4m
Feb 13 15:05:42.265: INFO: Got endpoints: latency-svc-25p8x [748.094629ms]
Feb 13 15:05:42.282: INFO: Created: latency-svc-mlkdb
Feb 13 15:05:42.315: INFO: Got endpoints: latency-svc-kxczp [741.970514ms]
Feb 13 15:05:42.332: INFO: Created: latency-svc-bt9n9
Feb 13 15:05:42.363: INFO: Got endpoints: latency-svc-96xdc [752.964517ms]
Feb 13 15:05:42.382: INFO: Created: latency-svc-5f7zm
Feb 13 15:05:42.424: INFO: Got endpoints: latency-svc-9bq4m [758.665051ms]
Feb 13 15:05:42.441: INFO: Created: latency-svc-7w6wv
Feb 13 15:05:42.460: INFO: Got endpoints: latency-svc-jzkz5 [742.918219ms]
Feb 13 15:05:42.477: INFO: Created: latency-svc-9vpsc
Feb 13 15:05:42.514: INFO: Got endpoints: latency-svc-7gfxf [747.069714ms]
Feb 13 15:05:42.537: INFO: Created: latency-svc-8s5f9
Feb 13 15:05:42.565: INFO: Got endpoints: latency-svc-ppb8t [745.648183ms]
Feb 13 15:05:42.587: INFO: Created: latency-svc-swvdd
Feb 13 15:05:42.611: INFO: Got endpoints: latency-svc-99tm9 [748.745803ms]
Feb 13 15:05:42.631: INFO: Created: latency-svc-9hjk9
Feb 13 15:05:42.660: INFO: Got endpoints: latency-svc-5fhzp [746.986065ms]
Feb 13 15:05:42.674: INFO: Created: latency-svc-5lkrd
Feb 13 15:05:42.711: INFO: Got endpoints: latency-svc-qd5qz [745.25176ms]
Feb 13 15:05:42.728: INFO: Created: latency-svc-h97kc
Feb 13 15:05:42.763: INFO: Got endpoints: latency-svc-dx672 [748.17961ms]
Feb 13 15:05:42.777: INFO: Created: latency-svc-xd9kz
Feb 13 15:05:42.811: INFO: Got endpoints: latency-svc-rm99x [744.881833ms]
Feb 13 15:05:42.842: INFO: Created: latency-svc-d5rg9
Feb 13 15:05:42.866: INFO: Got endpoints: latency-svc-dw8s4 [754.249118ms]
Feb 13 15:05:42.883: INFO: Created: latency-svc-kk2fq
Feb 13 15:05:42.910: INFO: Got endpoints: latency-svc-4vhvz [747.624916ms]
Feb 13 15:05:42.927: INFO: Created: latency-svc-jv99s
Feb 13 15:05:42.967: INFO: Got endpoints: latency-svc-kpj4m [752.511336ms]
Feb 13 15:05:42.986: INFO: Created: latency-svc-mzwfp
Feb 13 15:05:43.011: INFO: Got endpoints: latency-svc-mlkdb [746.459485ms]
Feb 13 15:05:43.030: INFO: Created: latency-svc-gpnhc
Feb 13 15:05:43.065: INFO: Got endpoints: latency-svc-bt9n9 [750.841371ms]
Feb 13 15:05:43.087: INFO: Created: latency-svc-hhgbr
Feb 13 15:05:43.113: INFO: Got endpoints: latency-svc-5f7zm [750.496236ms]
Feb 13 15:05:43.129: INFO: Created: latency-svc-d44tt
Feb 13 15:05:43.163: INFO: Got endpoints: latency-svc-7w6wv [738.750607ms]
Feb 13 15:05:43.185: INFO: Created: latency-svc-268bs
Feb 13 15:05:43.214: INFO: Got endpoints: latency-svc-9vpsc [752.9256ms]
Feb 13 15:05:43.234: INFO: Created: latency-svc-ds4w4
Feb 13 15:05:43.261: INFO: Got endpoints: latency-svc-8s5f9 [746.943246ms]
Feb 13 15:05:43.279: INFO: Created: latency-svc-vwfs6
Feb 13 15:05:43.311: INFO: Got endpoints: latency-svc-swvdd [745.793722ms]
Feb 13 15:05:43.329: INFO: Created: latency-svc-hqwjc
Feb 13 15:05:43.362: INFO: Got endpoints: latency-svc-9hjk9 [751.105778ms]
Feb 13 15:05:43.379: INFO: Created: latency-svc-pp9gz
Feb 13 15:05:43.414: INFO: Got endpoints: latency-svc-5lkrd [754.326805ms]
Feb 13 15:05:43.431: INFO: Created: latency-svc-249jm
Feb 13 15:05:43.465: INFO: Got endpoints: latency-svc-h97kc [753.975422ms]
Feb 13 15:05:43.485: INFO: Created: latency-svc-z7q6j
Feb 13 15:05:43.511: INFO: Got endpoints: latency-svc-xd9kz [747.767103ms]
Feb 13 15:05:43.527: INFO: Created: latency-svc-p5qhf
Feb 13 15:05:43.561: INFO: Got endpoints: latency-svc-d5rg9 [750.064688ms]
Feb 13 15:05:43.614: INFO: Got endpoints: latency-svc-kk2fq [748.277562ms]
Feb 13 15:05:43.661: INFO: Got endpoints: latency-svc-jv99s [750.393358ms]
Feb 13 15:05:43.718: INFO: Got endpoints: latency-svc-mzwfp [751.027421ms]
Feb 13 15:05:43.765: INFO: Got endpoints: latency-svc-gpnhc [753.692072ms]
Feb 13 15:05:43.836: INFO: Got endpoints: latency-svc-hhgbr [770.060166ms]
Feb 13 15:05:43.860: INFO: Got endpoints: latency-svc-d44tt [747.015107ms]
Feb 13 15:05:43.913: INFO: Got endpoints: latency-svc-268bs [749.754334ms]
Feb 13 15:05:43.963: INFO: Got endpoints: latency-svc-ds4w4 [748.695091ms]
Feb 13 15:05:44.017: INFO: Got endpoints: latency-svc-vwfs6 [754.995634ms]
Feb 13 15:05:44.060: INFO: Got endpoints: latency-svc-hqwjc [749.3064ms]
Feb 13 15:05:44.110: INFO: Got endpoints: latency-svc-pp9gz [748.458155ms]
Feb 13 15:05:44.161: INFO: Got endpoints: latency-svc-249jm [746.962144ms]
Feb 13 15:05:44.214: INFO: Got endpoints: latency-svc-z7q6j [748.848955ms]
Feb 13 15:05:44.263: INFO: Got endpoints: latency-svc-p5qhf [752.116808ms]
Feb 13 15:05:44.264: INFO: Latencies: [27.642905ms 45.496ms 70.533256ms 82.526238ms 103.617283ms 114.764071ms 116.398626ms 144.947689ms 146.882244ms 154.801935ms 156.893616ms 175.51146ms 178.562957ms 184.724892ms 192.028937ms 193.27519ms 196.322ms 203.681913ms 223.253548ms 242.530232ms 247.981788ms 248.441739ms 248.58626ms 254.299013ms 269.755143ms 273.288418ms 276.942755ms 277.316082ms 277.348647ms 278.473299ms 279.329946ms 284.561937ms 293.114697ms 293.81846ms 299.632786ms 299.882778ms 312.665905ms 319.67479ms 323.476722ms 331.228689ms 348.012343ms 353.721288ms 353.871442ms 357.793684ms 361.611214ms 361.615465ms 362.295494ms 368.148143ms 414.090626ms 460.734777ms 507.544165ms 534.282524ms 585.292058ms 629.977652ms 678.028088ms 729.366543ms 738.750607ms 741.785554ms 741.795949ms 741.970514ms 742.447795ms 742.918219ms 743.307497ms 743.554066ms 743.995416ms 744.279267ms 744.327526ms 744.587986ms 744.881833ms 745.1026ms 745.25176ms 745.272729ms 745.648183ms 745.793722ms 745.984706ms 746.016093ms 746.167102ms 746.459485ms 746.526149ms 746.566088ms 746.784868ms 746.836473ms 746.911691ms 746.926999ms 746.943246ms 746.962144ms 746.986065ms 747.015107ms 747.069714ms 747.20129ms 747.386831ms 747.47273ms 747.510762ms 747.624916ms 747.734497ms 747.767103ms 747.802665ms 747.824291ms 747.857428ms 748.094629ms 748.16869ms 748.17961ms 748.23325ms 748.235261ms 748.25799ms 748.277562ms 748.440063ms 748.458155ms 748.522543ms 748.645111ms 748.695091ms 748.705841ms 748.745803ms 748.767939ms 748.848955ms 748.869196ms 749.012765ms 749.028988ms 749.177085ms 749.239585ms 749.240274ms 749.3064ms 749.392029ms 749.433259ms 749.724837ms 749.754334ms 749.805959ms 749.845873ms 749.866524ms 749.881346ms 749.989467ms 750.021792ms 750.063753ms 750.064688ms 750.233106ms 750.25007ms 750.253525ms 750.332391ms 750.393358ms 750.496236ms 750.529937ms 750.700154ms 750.713816ms 750.761004ms 750.765778ms 750.793945ms 750.807236ms 750.8092ms 750.841371ms 750.846192ms 750.855382ms 750.915352ms 751.002799ms 751.003292ms 751.027421ms 751.105778ms 751.232647ms 751.271846ms 751.406225ms 751.44689ms 751.572351ms 751.863669ms 751.985866ms 752.021648ms 752.030642ms 752.031465ms 752.116808ms 752.238626ms 752.403088ms 752.511336ms 752.538467ms 752.881188ms 752.9256ms 752.964517ms 753.178493ms 753.246246ms 753.273647ms 753.326079ms 753.523996ms 753.568384ms 753.692072ms 753.740018ms 753.8532ms 753.975422ms 754.249118ms 754.326805ms 754.385127ms 754.861152ms 754.995634ms 755.128998ms 755.584805ms 755.588827ms 755.707816ms 756.128305ms 756.445342ms 758.665051ms 759.713262ms 759.733942ms 760.645271ms 770.060166ms]
Feb 13 15:05:44.264: INFO: 50 %ile: 748.16869ms
Feb 13 15:05:44.264: INFO: 90 %ile: 753.692072ms
Feb 13 15:05:44.264: INFO: 99 %ile: 760.645271ms
Feb 13 15:05:44.264: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Feb 13 15:05:44.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8502" for this suite. 02/13/23 15:05:44.273
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":357,"skipped":6621,"failed":0}
------------------------------
• [SLOW TEST] [10.870 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:33.412
    Feb 13 15:05:33.412: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename svc-latency 02/13/23 15:05:33.414
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:33.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:33.444
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Feb 13 15:05:33.447: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-8502 02/13/23 15:05:33.449
    W0213 15:05:33.459367      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "svc-latency-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "svc-latency-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "svc-latency-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "svc-latency-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    I0213 15:05:33.459932      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8502, replica count: 1
    I0213 15:05:34.510717      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0213 15:05:35.511865      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Feb 13 15:05:35.633: INFO: Created: latency-svc-h4dlj
    Feb 13 15:05:35.641: INFO: Got endpoints: latency-svc-h4dlj [29.031505ms]
    Feb 13 15:05:35.663: INFO: Created: latency-svc-2nnbk
    Feb 13 15:05:35.669: INFO: Got endpoints: latency-svc-2nnbk [27.642905ms]
    Feb 13 15:05:35.681: INFO: Created: latency-svc-mxwkl
    Feb 13 15:05:35.688: INFO: Got endpoints: latency-svc-mxwkl [45.496ms]
    Feb 13 15:05:35.854: INFO: Created: latency-svc-4b6rw
    Feb 13 15:05:35.861: INFO: Created: latency-svc-78rxg
    Feb 13 15:05:35.862: INFO: Created: latency-svc-22xsb
    Feb 13 15:05:35.862: INFO: Created: latency-svc-zv4tr
    Feb 13 15:05:35.863: INFO: Created: latency-svc-xjqpv
    Feb 13 15:05:35.863: INFO: Created: latency-svc-9plb2
    Feb 13 15:05:35.863: INFO: Created: latency-svc-8jj4x
    Feb 13 15:05:35.863: INFO: Created: latency-svc-skgzz
    Feb 13 15:05:35.862: INFO: Created: latency-svc-4b5hk
    Feb 13 15:05:35.863: INFO: Created: latency-svc-kznn2
    Feb 13 15:05:35.862: INFO: Created: latency-svc-t2mxp
    Feb 13 15:05:35.862: INFO: Created: latency-svc-l9dwp
    Feb 13 15:05:35.864: INFO: Created: latency-svc-557pg
    Feb 13 15:05:35.865: INFO: Created: latency-svc-kv5rk
    Feb 13 15:05:35.865: INFO: Created: latency-svc-d8zn2
    Feb 13 15:05:35.866: INFO: Got endpoints: latency-svc-4b6rw [196.322ms]
    Feb 13 15:05:35.885: INFO: Got endpoints: latency-svc-22xsb [242.530232ms]
    Feb 13 15:05:35.891: INFO: Got endpoints: latency-svc-9plb2 [248.441739ms]
    Feb 13 15:05:35.891: INFO: Got endpoints: latency-svc-l9dwp [248.58626ms]
    Feb 13 15:05:35.892: INFO: Got endpoints: latency-svc-zv4tr [203.681913ms]
    Feb 13 15:05:35.892: INFO: Got endpoints: latency-svc-t2mxp [247.981788ms]
    Feb 13 15:05:35.897: INFO: Got endpoints: latency-svc-d8zn2 [254.299013ms]
    Feb 13 15:05:35.905: INFO: Created: latency-svc-nx4cz
    Feb 13 15:05:35.912: INFO: Created: latency-svc-kxtdz
    Feb 13 15:05:35.913: INFO: Got endpoints: latency-svc-8jj4x [269.755143ms]
    Feb 13 15:05:35.921: INFO: Got endpoints: latency-svc-skgzz [277.316082ms]
    Feb 13 15:05:35.921: INFO: Got endpoints: latency-svc-xjqpv [276.942755ms]
    Feb 13 15:05:35.922: INFO: Got endpoints: latency-svc-kznn2 [278.473299ms]
    Feb 13 15:05:35.922: INFO: Got endpoints: latency-svc-557pg [277.348647ms]
    Feb 13 15:05:35.928: INFO: Got endpoints: latency-svc-kv5rk [284.561937ms]
    Feb 13 15:05:35.944: INFO: Got endpoints: latency-svc-4b5hk [299.632786ms]
    Feb 13 15:05:35.944: INFO: Got endpoints: latency-svc-78rxg [299.882778ms]
    Feb 13 15:05:35.949: INFO: Got endpoints: latency-svc-nx4cz [82.526238ms]
    Feb 13 15:05:35.956: INFO: Got endpoints: latency-svc-kxtdz [70.533256ms]
    Feb 13 15:05:35.964: INFO: Created: latency-svc-vwx5z
    Feb 13 15:05:35.982: INFO: Created: latency-svc-qhprw
    Feb 13 15:05:35.995: INFO: Got endpoints: latency-svc-vwx5z [103.617283ms]
    Feb 13 15:05:35.996: INFO: Created: latency-svc-9cdw9
    Feb 13 15:05:36.007: INFO: Got endpoints: latency-svc-qhprw [114.764071ms]
    Feb 13 15:05:36.008: INFO: Got endpoints: latency-svc-9cdw9 [116.398626ms]
    Feb 13 15:05:36.017: INFO: Created: latency-svc-lqzjz
    Feb 13 15:05:36.037: INFO: Created: latency-svc-4qtvd
    Feb 13 15:05:36.039: INFO: Got endpoints: latency-svc-lqzjz [146.882244ms]
    Feb 13 15:05:36.043: INFO: Created: latency-svc-v2xvm
    Feb 13 15:05:36.052: INFO: Got endpoints: latency-svc-4qtvd [154.801935ms]
    Feb 13 15:05:36.070: INFO: Got endpoints: latency-svc-v2xvm [156.893616ms]
    Feb 13 15:05:36.079: INFO: Created: latency-svc-cn48m
    Feb 13 15:05:36.094: INFO: Created: latency-svc-dr8cn
    Feb 13 15:05:36.113: INFO: Got endpoints: latency-svc-cn48m [192.028937ms]
    Feb 13 15:05:36.115: INFO: Got endpoints: latency-svc-dr8cn [193.27519ms]
    Feb 13 15:05:36.258: INFO: Created: latency-svc-scnj4
    Feb 13 15:05:36.268: INFO: Created: latency-svc-vxsbm
    Feb 13 15:05:36.270: INFO: Created: latency-svc-fjq6d
    Feb 13 15:05:36.272: INFO: Created: latency-svc-n94d9
    Feb 13 15:05:36.273: INFO: Created: latency-svc-kc722
    Feb 13 15:05:36.274: INFO: Created: latency-svc-vcpgn
    Feb 13 15:05:36.275: INFO: Created: latency-svc-nh9rp
    Feb 13 15:05:36.275: INFO: Got endpoints: latency-svc-scnj4 [353.721288ms]
    Feb 13 15:05:36.276: INFO: Created: latency-svc-fnlrc
    Feb 13 15:05:36.277: INFO: Created: latency-svc-dx4r9
    Feb 13 15:05:36.281: INFO: Created: latency-svc-z49rr
    Feb 13 15:05:36.281: INFO: Created: latency-svc-dwc2b
    Feb 13 15:05:36.281: INFO: Created: latency-svc-b4r2v
    Feb 13 15:05:36.282: INFO: Created: latency-svc-vqkcn
    Feb 13 15:05:36.282: INFO: Created: latency-svc-vzbmx
    Feb 13 15:05:36.282: INFO: Created: latency-svc-4jt9d
    Feb 13 15:05:36.290: INFO: Got endpoints: latency-svc-nh9rp [368.148143ms]
    Feb 13 15:05:36.290: INFO: Got endpoints: latency-svc-dx4r9 [361.615465ms]
    Feb 13 15:05:36.291: INFO: Got endpoints: latency-svc-n94d9 [175.51146ms]
    Feb 13 15:05:36.298: INFO: Got endpoints: latency-svc-4jt9d [184.724892ms]
    Feb 13 15:05:36.302: INFO: Got endpoints: latency-svc-b4r2v [357.793684ms]
    Feb 13 15:05:36.302: INFO: Created: latency-svc-kz5n7
    Feb 13 15:05:36.303: INFO: Got endpoints: latency-svc-vqkcn [353.871442ms]
    Feb 13 15:05:36.304: INFO: Got endpoints: latency-svc-kc722 [348.012343ms]
    Feb 13 15:05:36.307: INFO: Got endpoints: latency-svc-vxsbm [362.295494ms]
    Feb 13 15:05:36.323: INFO: Created: latency-svc-n9scz
    Feb 13 15:05:36.326: INFO: Got endpoints: latency-svc-vcpgn [331.228689ms]
    Feb 13 15:05:36.326: INFO: Got endpoints: latency-svc-fnlrc [319.67479ms]
    Feb 13 15:05:36.331: INFO: Got endpoints: latency-svc-z49rr [279.329946ms]
    Feb 13 15:05:36.332: INFO: Got endpoints: latency-svc-dwc2b [323.476722ms]
    Feb 13 15:05:36.332: INFO: Got endpoints: latency-svc-vzbmx [293.114697ms]
    Feb 13 15:05:36.340: INFO: Created: latency-svc-d7z7j
    Feb 13 15:05:36.349: INFO: Created: latency-svc-gd88j
    Feb 13 15:05:36.359: INFO: Created: latency-svc-tqwlq
    Feb 13 15:05:36.363: INFO: Got endpoints: latency-svc-fjq6d [293.81846ms]
    Feb 13 15:05:36.368: INFO: Created: latency-svc-cxxnm
    Feb 13 15:05:36.379: INFO: Created: latency-svc-fslw9
    Feb 13 15:05:36.396: INFO: Created: latency-svc-hp7g4
    Feb 13 15:05:36.403: INFO: Created: latency-svc-97zph
    Feb 13 15:05:36.412: INFO: Created: latency-svc-qv9hw
    Feb 13 15:05:36.420: INFO: Got endpoints: latency-svc-kz5n7 [144.947689ms]
    Feb 13 15:05:36.427: INFO: Created: latency-svc-dh6fd
    Feb 13 15:05:36.435: INFO: Created: latency-svc-hg4fx
    Feb 13 15:05:36.448: INFO: Created: latency-svc-84rlk
    Feb 13 15:05:36.464: INFO: Created: latency-svc-6zv9g
    Feb 13 15:05:36.469: INFO: Got endpoints: latency-svc-n9scz [178.562957ms]
    Feb 13 15:05:36.473: INFO: Created: latency-svc-2pcdp
    Feb 13 15:05:36.483: INFO: Created: latency-svc-vrd5j
    Feb 13 15:05:36.503: INFO: Created: latency-svc-z8w99
    Feb 13 15:05:36.513: INFO: Got endpoints: latency-svc-d7z7j [223.253548ms]
    Feb 13 15:05:36.532: INFO: Created: latency-svc-nb2k9
    Feb 13 15:05:36.564: INFO: Got endpoints: latency-svc-gd88j [273.288418ms]
    Feb 13 15:05:36.587: INFO: Created: latency-svc-7cts7
    Feb 13 15:05:36.611: INFO: Got endpoints: latency-svc-tqwlq [312.665905ms]
    Feb 13 15:05:36.629: INFO: Created: latency-svc-9xqks
    Feb 13 15:05:36.664: INFO: Got endpoints: latency-svc-cxxnm [361.611214ms]
    Feb 13 15:05:36.683: INFO: Created: latency-svc-7dv7b
    Feb 13 15:05:36.717: INFO: Got endpoints: latency-svc-fslw9 [414.090626ms]
    Feb 13 15:05:36.736: INFO: Created: latency-svc-n8qtz
    Feb 13 15:05:36.765: INFO: Got endpoints: latency-svc-hp7g4 [460.734777ms]
    Feb 13 15:05:36.794: INFO: Created: latency-svc-z229n
    Feb 13 15:05:36.814: INFO: Got endpoints: latency-svc-97zph [507.544165ms]
    Feb 13 15:05:36.840: INFO: Created: latency-svc-bdnqg
    Feb 13 15:05:36.861: INFO: Got endpoints: latency-svc-qv9hw [534.282524ms]
    Feb 13 15:05:36.878: INFO: Created: latency-svc-xfn2n
    Feb 13 15:05:36.912: INFO: Got endpoints: latency-svc-dh6fd [585.292058ms]
    Feb 13 15:05:36.936: INFO: Created: latency-svc-bpk5j
    Feb 13 15:05:36.962: INFO: Got endpoints: latency-svc-hg4fx [629.977652ms]
    Feb 13 15:05:36.980: INFO: Created: latency-svc-sgv76
    Feb 13 15:05:37.011: INFO: Got endpoints: latency-svc-84rlk [678.028088ms]
    Feb 13 15:05:37.032: INFO: Created: latency-svc-77cwc
    Feb 13 15:05:37.061: INFO: Got endpoints: latency-svc-6zv9g [729.366543ms]
    Feb 13 15:05:37.079: INFO: Created: latency-svc-xjd2x
    Feb 13 15:05:37.113: INFO: Got endpoints: latency-svc-2pcdp [749.028988ms]
    Feb 13 15:05:37.132: INFO: Created: latency-svc-7wj2j
    Feb 13 15:05:37.163: INFO: Got endpoints: latency-svc-vrd5j [742.447795ms]
    Feb 13 15:05:37.184: INFO: Created: latency-svc-46qjv
    Feb 13 15:05:37.211: INFO: Got endpoints: latency-svc-z8w99 [741.795949ms]
    Feb 13 15:05:37.231: INFO: Created: latency-svc-298w6
    Feb 13 15:05:37.270: INFO: Got endpoints: latency-svc-nb2k9 [756.128305ms]
    Feb 13 15:05:37.287: INFO: Created: latency-svc-7xxgm
    Feb 13 15:05:37.314: INFO: Got endpoints: latency-svc-7cts7 [749.240274ms]
    Feb 13 15:05:37.330: INFO: Created: latency-svc-shzsg
    Feb 13 15:05:37.363: INFO: Got endpoints: latency-svc-9xqks [752.538467ms]
    Feb 13 15:05:37.379: INFO: Created: latency-svc-mmwdg
    Feb 13 15:05:37.415: INFO: Got endpoints: latency-svc-7dv7b [750.807236ms]
    Feb 13 15:05:37.434: INFO: Created: latency-svc-hsjtf
    Feb 13 15:05:37.468: INFO: Got endpoints: latency-svc-n8qtz [751.003292ms]
    Feb 13 15:05:37.485: INFO: Created: latency-svc-n7fb8
    Feb 13 15:05:37.513: INFO: Got endpoints: latency-svc-z229n [748.522543ms]
    Feb 13 15:05:37.534: INFO: Created: latency-svc-jhhvx
    Feb 13 15:05:37.563: INFO: Got endpoints: latency-svc-bdnqg [747.824291ms]
    Feb 13 15:05:37.588: INFO: Created: latency-svc-dhx84
    Feb 13 15:05:37.612: INFO: Got endpoints: latency-svc-xfn2n [750.25007ms]
    Feb 13 15:05:37.628: INFO: Created: latency-svc-tgkf9
    Feb 13 15:05:37.663: INFO: Got endpoints: latency-svc-bpk5j [751.572351ms]
    Feb 13 15:05:37.685: INFO: Created: latency-svc-cgzzr
    Feb 13 15:05:37.713: INFO: Got endpoints: latency-svc-sgv76 [750.063753ms]
    Feb 13 15:05:37.730: INFO: Created: latency-svc-dsccf
    Feb 13 15:05:37.762: INFO: Got endpoints: latency-svc-77cwc [750.793945ms]
    Feb 13 15:05:37.780: INFO: Created: latency-svc-vrgtv
    Feb 13 15:05:37.810: INFO: Got endpoints: latency-svc-xjd2x [748.869196ms]
    Feb 13 15:05:37.828: INFO: Created: latency-svc-fssx5
    Feb 13 15:05:37.863: INFO: Got endpoints: latency-svc-7wj2j [750.529937ms]
    Feb 13 15:05:37.881: INFO: Created: latency-svc-pvc4f
    Feb 13 15:05:37.911: INFO: Got endpoints: latency-svc-46qjv [747.802665ms]
    Feb 13 15:05:37.927: INFO: Created: latency-svc-52b6c
    Feb 13 15:05:37.965: INFO: Got endpoints: latency-svc-298w6 [753.740018ms]
    Feb 13 15:05:37.980: INFO: Created: latency-svc-m8s45
    Feb 13 15:05:38.014: INFO: Got endpoints: latency-svc-7xxgm [744.587986ms]
    Feb 13 15:05:38.033: INFO: Created: latency-svc-lzs2x
    Feb 13 15:05:38.062: INFO: Got endpoints: latency-svc-shzsg [748.235261ms]
    Feb 13 15:05:38.084: INFO: Created: latency-svc-g7js7
    Feb 13 15:05:38.117: INFO: Got endpoints: latency-svc-mmwdg [753.246246ms]
    Feb 13 15:05:38.134: INFO: Created: latency-svc-wqftk
    Feb 13 15:05:38.161: INFO: Got endpoints: latency-svc-hsjtf [746.566088ms]
    Feb 13 15:05:38.178: INFO: Created: latency-svc-4mwgm
    Feb 13 15:05:38.212: INFO: Got endpoints: latency-svc-n7fb8 [743.307497ms]
    Feb 13 15:05:38.253: INFO: Created: latency-svc-9nmmg
    Feb 13 15:05:38.273: INFO: Got endpoints: latency-svc-jhhvx [759.713262ms]
    Feb 13 15:05:38.296: INFO: Created: latency-svc-2m4kl
    Feb 13 15:05:38.323: INFO: Got endpoints: latency-svc-dhx84 [759.733942ms]
    Feb 13 15:05:38.366: INFO: Got endpoints: latency-svc-tgkf9 [753.8532ms]
    Feb 13 15:05:38.366: INFO: Created: latency-svc-mqst4
    Feb 13 15:05:38.401: INFO: Created: latency-svc-hzvjc
    Feb 13 15:05:38.414: INFO: Got endpoints: latency-svc-cgzzr [750.761004ms]
    Feb 13 15:05:38.433: INFO: Created: latency-svc-mbpm8
    Feb 13 15:05:38.465: INFO: Got endpoints: latency-svc-dsccf [752.403088ms]
    Feb 13 15:05:38.496: INFO: Created: latency-svc-5mcb2
    Feb 13 15:05:38.516: INFO: Got endpoints: latency-svc-vrgtv [754.385127ms]
    Feb 13 15:05:38.537: INFO: Created: latency-svc-qkxl9
    Feb 13 15:05:38.564: INFO: Got endpoints: latency-svc-fssx5 [753.326079ms]
    Feb 13 15:05:38.592: INFO: Created: latency-svc-ck44v
    Feb 13 15:05:38.613: INFO: Got endpoints: latency-svc-pvc4f [749.433259ms]
    Feb 13 15:05:38.636: INFO: Created: latency-svc-8mwjk
    Feb 13 15:05:38.664: INFO: Got endpoints: latency-svc-52b6c [752.881188ms]
    Feb 13 15:05:38.679: INFO: Created: latency-svc-hzb8m
    Feb 13 15:05:38.710: INFO: Got endpoints: latency-svc-m8s45 [745.272729ms]
    Feb 13 15:05:38.725: INFO: Created: latency-svc-xwm6c
    Feb 13 15:05:38.764: INFO: Got endpoints: latency-svc-lzs2x [749.012765ms]
    Feb 13 15:05:38.781: INFO: Created: latency-svc-qqc7s
    Feb 13 15:05:38.812: INFO: Got endpoints: latency-svc-g7js7 [749.866524ms]
    Feb 13 15:05:38.827: INFO: Created: latency-svc-2rswn
    Feb 13 15:05:38.867: INFO: Got endpoints: latency-svc-wqftk [749.989467ms]
    Feb 13 15:05:38.888: INFO: Created: latency-svc-f84nr
    Feb 13 15:05:38.917: INFO: Got endpoints: latency-svc-4mwgm [755.128998ms]
    Feb 13 15:05:38.935: INFO: Created: latency-svc-v2xwb
    Feb 13 15:05:38.962: INFO: Got endpoints: latency-svc-9nmmg [749.881346ms]
    Feb 13 15:05:38.985: INFO: Created: latency-svc-d2b7h
    Feb 13 15:05:39.017: INFO: Got endpoints: latency-svc-2m4kl [743.554066ms]
    Feb 13 15:05:39.036: INFO: Created: latency-svc-fb5lr
    Feb 13 15:05:39.064: INFO: Got endpoints: latency-svc-mqst4 [741.785554ms]
    Feb 13 15:05:39.082: INFO: Created: latency-svc-vn2lj
    Feb 13 15:05:39.113: INFO: Got endpoints: latency-svc-hzvjc [747.20129ms]
    Feb 13 15:05:39.137: INFO: Created: latency-svc-ww54s
    Feb 13 15:05:39.164: INFO: Got endpoints: latency-svc-mbpm8 [749.724837ms]
    Feb 13 15:05:39.181: INFO: Created: latency-svc-nflb5
    Feb 13 15:05:39.212: INFO: Got endpoints: latency-svc-5mcb2 [746.167102ms]
    Feb 13 15:05:39.232: INFO: Created: latency-svc-rwv7g
    Feb 13 15:05:39.264: INFO: Got endpoints: latency-svc-qkxl9 [747.510762ms]
    Feb 13 15:05:39.282: INFO: Created: latency-svc-c2sms
    Feb 13 15:05:39.311: INFO: Got endpoints: latency-svc-ck44v [746.911691ms]
    Feb 13 15:05:39.328: INFO: Created: latency-svc-qxq2q
    Feb 13 15:05:39.363: INFO: Got endpoints: latency-svc-8mwjk [750.713816ms]
    Feb 13 15:05:39.379: INFO: Created: latency-svc-4hd6h
    Feb 13 15:05:39.415: INFO: Got endpoints: latency-svc-hzb8m [750.915352ms]
    Feb 13 15:05:39.433: INFO: Created: latency-svc-4v5xm
    Feb 13 15:05:39.461: INFO: Got endpoints: latency-svc-xwm6c [750.700154ms]
    Feb 13 15:05:39.485: INFO: Created: latency-svc-bj8vm
    Feb 13 15:05:39.512: INFO: Got endpoints: latency-svc-qqc7s [747.734497ms]
    Feb 13 15:05:39.534: INFO: Created: latency-svc-n9mhk
    Feb 13 15:05:39.561: INFO: Got endpoints: latency-svc-2rswn [748.767939ms]
    Feb 13 15:05:39.574: INFO: Created: latency-svc-87m8z
    Feb 13 15:05:39.611: INFO: Got endpoints: latency-svc-f84nr [743.995416ms]
    Feb 13 15:05:39.629: INFO: Created: latency-svc-brhq2
    Feb 13 15:05:39.662: INFO: Got endpoints: latency-svc-v2xwb [745.1026ms]
    Feb 13 15:05:39.682: INFO: Created: latency-svc-zbh9h
    Feb 13 15:05:39.716: INFO: Got endpoints: latency-svc-d2b7h [753.273647ms]
    Feb 13 15:05:39.741: INFO: Created: latency-svc-m2xcz
    Feb 13 15:05:39.765: INFO: Got endpoints: latency-svc-fb5lr [748.23325ms]
    Feb 13 15:05:39.781: INFO: Created: latency-svc-gt4l5
    Feb 13 15:05:39.815: INFO: Got endpoints: latency-svc-vn2lj [750.233106ms]
    Feb 13 15:05:39.843: INFO: Created: latency-svc-hf5rw
    Feb 13 15:05:39.865: INFO: Got endpoints: latency-svc-ww54s [752.021648ms]
    Feb 13 15:05:39.882: INFO: Created: latency-svc-f66lz
    Feb 13 15:05:39.916: INFO: Got endpoints: latency-svc-nflb5 [751.863669ms]
    Feb 13 15:05:39.934: INFO: Created: latency-svc-tzsgk
    Feb 13 15:05:39.964: INFO: Got endpoints: latency-svc-rwv7g [752.031465ms]
    Feb 13 15:05:39.977: INFO: Created: latency-svc-9w57s
    Feb 13 15:05:40.011: INFO: Got endpoints: latency-svc-c2sms [746.926999ms]
    Feb 13 15:05:40.037: INFO: Created: latency-svc-g65ps
    Feb 13 15:05:40.062: INFO: Got endpoints: latency-svc-qxq2q [750.846192ms]
    Feb 13 15:05:40.081: INFO: Created: latency-svc-pb62f
    Feb 13 15:05:40.114: INFO: Got endpoints: latency-svc-4hd6h [750.021792ms]
    Feb 13 15:05:40.141: INFO: Created: latency-svc-9d6sv
    Feb 13 15:05:40.163: INFO: Got endpoints: latency-svc-4v5xm [747.857428ms]
    Feb 13 15:05:40.182: INFO: Created: latency-svc-jflhn
    Feb 13 15:05:40.211: INFO: Got endpoints: latency-svc-bj8vm [749.845873ms]
    Feb 13 15:05:40.227: INFO: Created: latency-svc-zq729
    Feb 13 15:05:40.260: INFO: Got endpoints: latency-svc-n9mhk [748.705841ms]
    Feb 13 15:05:40.282: INFO: Created: latency-svc-x82v9
    Feb 13 15:05:40.312: INFO: Got endpoints: latency-svc-87m8z [750.8092ms]
    Feb 13 15:05:40.330: INFO: Created: latency-svc-9sccq
    Feb 13 15:05:40.361: INFO: Got endpoints: latency-svc-brhq2 [749.805959ms]
    Feb 13 15:05:40.381: INFO: Created: latency-svc-mj7rg
    Feb 13 15:05:40.414: INFO: Got endpoints: latency-svc-zbh9h [752.030642ms]
    Feb 13 15:05:40.431: INFO: Created: latency-svc-tmjwr
    Feb 13 15:05:40.467: INFO: Got endpoints: latency-svc-m2xcz [750.332391ms]
    Feb 13 15:05:40.489: INFO: Created: latency-svc-qpjdk
    Feb 13 15:05:40.513: INFO: Got endpoints: latency-svc-gt4l5 [748.16869ms]
    Feb 13 15:05:40.535: INFO: Created: latency-svc-xh2cp
    Feb 13 15:05:40.562: INFO: Got endpoints: latency-svc-hf5rw [746.784868ms]
    Feb 13 15:05:40.598: INFO: Created: latency-svc-qfvm6
    Feb 13 15:05:40.609: INFO: Got endpoints: latency-svc-f66lz [744.279267ms]
    Feb 13 15:05:40.630: INFO: Created: latency-svc-lqshj
    Feb 13 15:05:40.664: INFO: Got endpoints: latency-svc-tzsgk [748.25799ms]
    Feb 13 15:05:40.685: INFO: Created: latency-svc-spcdr
    Feb 13 15:05:40.716: INFO: Got endpoints: latency-svc-9w57s [752.238626ms]
    Feb 13 15:05:40.737: INFO: Created: latency-svc-vcw9x
    Feb 13 15:05:40.761: INFO: Got endpoints: latency-svc-g65ps [750.253525ms]
    Feb 13 15:05:40.782: INFO: Created: latency-svc-x7dn4
    Feb 13 15:05:40.811: INFO: Got endpoints: latency-svc-pb62f [748.645111ms]
    Feb 13 15:05:40.832: INFO: Created: latency-svc-66j5s
    Feb 13 15:05:40.861: INFO: Got endpoints: latency-svc-9d6sv [747.47273ms]
    Feb 13 15:05:40.884: INFO: Created: latency-svc-fgz9l
    Feb 13 15:05:40.919: INFO: Got endpoints: latency-svc-jflhn [755.707816ms]
    Feb 13 15:05:40.937: INFO: Created: latency-svc-d5kml
    Feb 13 15:05:40.961: INFO: Got endpoints: latency-svc-zq729 [749.177085ms]
    Feb 13 15:05:40.979: INFO: Created: latency-svc-fqmn6
    Feb 13 15:05:41.010: INFO: Got endpoints: latency-svc-x82v9 [749.392029ms]
    Feb 13 15:05:41.034: INFO: Created: latency-svc-qm79b
    Feb 13 15:05:41.063: INFO: Got endpoints: latency-svc-9sccq [751.232647ms]
    Feb 13 15:05:41.083: INFO: Created: latency-svc-dbd89
    Feb 13 15:05:41.110: INFO: Got endpoints: latency-svc-mj7rg [749.239585ms]
    Feb 13 15:05:41.131: INFO: Created: latency-svc-v6f64
    Feb 13 15:05:41.161: INFO: Got endpoints: latency-svc-tmjwr [746.526149ms]
    Feb 13 15:05:41.178: INFO: Created: latency-svc-6h8h8
    Feb 13 15:05:41.213: INFO: Got endpoints: latency-svc-qpjdk [746.836473ms]
    Feb 13 15:05:41.236: INFO: Created: latency-svc-zf8lz
    Feb 13 15:05:41.261: INFO: Got endpoints: latency-svc-xh2cp [747.386831ms]
    Feb 13 15:05:41.285: INFO: Created: latency-svc-72nb2
    Feb 13 15:05:41.313: INFO: Got endpoints: latency-svc-qfvm6 [751.002799ms]
    Feb 13 15:05:41.329: INFO: Created: latency-svc-bmgdd
    Feb 13 15:05:41.360: INFO: Got endpoints: latency-svc-lqshj [750.765778ms]
    Feb 13 15:05:41.378: INFO: Created: latency-svc-g2vxj
    Feb 13 15:05:41.415: INFO: Got endpoints: latency-svc-spcdr [751.271846ms]
    Feb 13 15:05:41.441: INFO: Created: latency-svc-qhfst
    Feb 13 15:05:41.460: INFO: Got endpoints: latency-svc-vcw9x [744.327526ms]
    Feb 13 15:05:41.511: INFO: Created: latency-svc-75285
    Feb 13 15:05:41.516: INFO: Got endpoints: latency-svc-x7dn4 [754.861152ms]
    Feb 13 15:05:41.538: INFO: Created: latency-svc-25p8x
    Feb 13 15:05:41.572: INFO: Got endpoints: latency-svc-66j5s [760.645271ms]
    Feb 13 15:05:41.590: INFO: Created: latency-svc-kxczp
    Feb 13 15:05:41.610: INFO: Got endpoints: latency-svc-fgz9l [748.440063ms]
    Feb 13 15:05:41.624: INFO: Created: latency-svc-96xdc
    Feb 13 15:05:41.665: INFO: Got endpoints: latency-svc-d5kml [746.016093ms]
    Feb 13 15:05:41.681: INFO: Created: latency-svc-9bq4m
    Feb 13 15:05:41.717: INFO: Got endpoints: latency-svc-fqmn6 [755.588827ms]
    Feb 13 15:05:41.735: INFO: Created: latency-svc-jzkz5
    Feb 13 15:05:41.767: INFO: Got endpoints: latency-svc-qm79b [756.445342ms]
    Feb 13 15:05:41.783: INFO: Created: latency-svc-7gfxf
    Feb 13 15:05:41.819: INFO: Got endpoints: latency-svc-dbd89 [755.584805ms]
    Feb 13 15:05:41.840: INFO: Created: latency-svc-ppb8t
    Feb 13 15:05:41.862: INFO: Got endpoints: latency-svc-v6f64 [751.44689ms]
    Feb 13 15:05:41.894: INFO: Created: latency-svc-99tm9
    Feb 13 15:05:41.912: INFO: Got endpoints: latency-svc-6h8h8 [751.406225ms]
    Feb 13 15:05:41.932: INFO: Created: latency-svc-5fhzp
    Feb 13 15:05:41.965: INFO: Got endpoints: latency-svc-zf8lz [751.985866ms]
    Feb 13 15:05:41.990: INFO: Created: latency-svc-qd5qz
    Feb 13 15:05:42.014: INFO: Got endpoints: latency-svc-72nb2 [753.523996ms]
    Feb 13 15:05:42.032: INFO: Created: latency-svc-dx672
    Feb 13 15:05:42.066: INFO: Got endpoints: latency-svc-bmgdd [753.178493ms]
    Feb 13 15:05:42.081: INFO: Created: latency-svc-rm99x
    Feb 13 15:05:42.111: INFO: Got endpoints: latency-svc-g2vxj [750.855382ms]
    Feb 13 15:05:42.130: INFO: Created: latency-svc-dw8s4
    Feb 13 15:05:42.162: INFO: Got endpoints: latency-svc-qhfst [745.984706ms]
    Feb 13 15:05:42.182: INFO: Created: latency-svc-4vhvz
    Feb 13 15:05:42.214: INFO: Got endpoints: latency-svc-75285 [753.568384ms]
    Feb 13 15:05:42.230: INFO: Created: latency-svc-kpj4m
    Feb 13 15:05:42.265: INFO: Got endpoints: latency-svc-25p8x [748.094629ms]
    Feb 13 15:05:42.282: INFO: Created: latency-svc-mlkdb
    Feb 13 15:05:42.315: INFO: Got endpoints: latency-svc-kxczp [741.970514ms]
    Feb 13 15:05:42.332: INFO: Created: latency-svc-bt9n9
    Feb 13 15:05:42.363: INFO: Got endpoints: latency-svc-96xdc [752.964517ms]
    Feb 13 15:05:42.382: INFO: Created: latency-svc-5f7zm
    Feb 13 15:05:42.424: INFO: Got endpoints: latency-svc-9bq4m [758.665051ms]
    Feb 13 15:05:42.441: INFO: Created: latency-svc-7w6wv
    Feb 13 15:05:42.460: INFO: Got endpoints: latency-svc-jzkz5 [742.918219ms]
    Feb 13 15:05:42.477: INFO: Created: latency-svc-9vpsc
    Feb 13 15:05:42.514: INFO: Got endpoints: latency-svc-7gfxf [747.069714ms]
    Feb 13 15:05:42.537: INFO: Created: latency-svc-8s5f9
    Feb 13 15:05:42.565: INFO: Got endpoints: latency-svc-ppb8t [745.648183ms]
    Feb 13 15:05:42.587: INFO: Created: latency-svc-swvdd
    Feb 13 15:05:42.611: INFO: Got endpoints: latency-svc-99tm9 [748.745803ms]
    Feb 13 15:05:42.631: INFO: Created: latency-svc-9hjk9
    Feb 13 15:05:42.660: INFO: Got endpoints: latency-svc-5fhzp [746.986065ms]
    Feb 13 15:05:42.674: INFO: Created: latency-svc-5lkrd
    Feb 13 15:05:42.711: INFO: Got endpoints: latency-svc-qd5qz [745.25176ms]
    Feb 13 15:05:42.728: INFO: Created: latency-svc-h97kc
    Feb 13 15:05:42.763: INFO: Got endpoints: latency-svc-dx672 [748.17961ms]
    Feb 13 15:05:42.777: INFO: Created: latency-svc-xd9kz
    Feb 13 15:05:42.811: INFO: Got endpoints: latency-svc-rm99x [744.881833ms]
    Feb 13 15:05:42.842: INFO: Created: latency-svc-d5rg9
    Feb 13 15:05:42.866: INFO: Got endpoints: latency-svc-dw8s4 [754.249118ms]
    Feb 13 15:05:42.883: INFO: Created: latency-svc-kk2fq
    Feb 13 15:05:42.910: INFO: Got endpoints: latency-svc-4vhvz [747.624916ms]
    Feb 13 15:05:42.927: INFO: Created: latency-svc-jv99s
    Feb 13 15:05:42.967: INFO: Got endpoints: latency-svc-kpj4m [752.511336ms]
    Feb 13 15:05:42.986: INFO: Created: latency-svc-mzwfp
    Feb 13 15:05:43.011: INFO: Got endpoints: latency-svc-mlkdb [746.459485ms]
    Feb 13 15:05:43.030: INFO: Created: latency-svc-gpnhc
    Feb 13 15:05:43.065: INFO: Got endpoints: latency-svc-bt9n9 [750.841371ms]
    Feb 13 15:05:43.087: INFO: Created: latency-svc-hhgbr
    Feb 13 15:05:43.113: INFO: Got endpoints: latency-svc-5f7zm [750.496236ms]
    Feb 13 15:05:43.129: INFO: Created: latency-svc-d44tt
    Feb 13 15:05:43.163: INFO: Got endpoints: latency-svc-7w6wv [738.750607ms]
    Feb 13 15:05:43.185: INFO: Created: latency-svc-268bs
    Feb 13 15:05:43.214: INFO: Got endpoints: latency-svc-9vpsc [752.9256ms]
    Feb 13 15:05:43.234: INFO: Created: latency-svc-ds4w4
    Feb 13 15:05:43.261: INFO: Got endpoints: latency-svc-8s5f9 [746.943246ms]
    Feb 13 15:05:43.279: INFO: Created: latency-svc-vwfs6
    Feb 13 15:05:43.311: INFO: Got endpoints: latency-svc-swvdd [745.793722ms]
    Feb 13 15:05:43.329: INFO: Created: latency-svc-hqwjc
    Feb 13 15:05:43.362: INFO: Got endpoints: latency-svc-9hjk9 [751.105778ms]
    Feb 13 15:05:43.379: INFO: Created: latency-svc-pp9gz
    Feb 13 15:05:43.414: INFO: Got endpoints: latency-svc-5lkrd [754.326805ms]
    Feb 13 15:05:43.431: INFO: Created: latency-svc-249jm
    Feb 13 15:05:43.465: INFO: Got endpoints: latency-svc-h97kc [753.975422ms]
    Feb 13 15:05:43.485: INFO: Created: latency-svc-z7q6j
    Feb 13 15:05:43.511: INFO: Got endpoints: latency-svc-xd9kz [747.767103ms]
    Feb 13 15:05:43.527: INFO: Created: latency-svc-p5qhf
    Feb 13 15:05:43.561: INFO: Got endpoints: latency-svc-d5rg9 [750.064688ms]
    Feb 13 15:05:43.614: INFO: Got endpoints: latency-svc-kk2fq [748.277562ms]
    Feb 13 15:05:43.661: INFO: Got endpoints: latency-svc-jv99s [750.393358ms]
    Feb 13 15:05:43.718: INFO: Got endpoints: latency-svc-mzwfp [751.027421ms]
    Feb 13 15:05:43.765: INFO: Got endpoints: latency-svc-gpnhc [753.692072ms]
    Feb 13 15:05:43.836: INFO: Got endpoints: latency-svc-hhgbr [770.060166ms]
    Feb 13 15:05:43.860: INFO: Got endpoints: latency-svc-d44tt [747.015107ms]
    Feb 13 15:05:43.913: INFO: Got endpoints: latency-svc-268bs [749.754334ms]
    Feb 13 15:05:43.963: INFO: Got endpoints: latency-svc-ds4w4 [748.695091ms]
    Feb 13 15:05:44.017: INFO: Got endpoints: latency-svc-vwfs6 [754.995634ms]
    Feb 13 15:05:44.060: INFO: Got endpoints: latency-svc-hqwjc [749.3064ms]
    Feb 13 15:05:44.110: INFO: Got endpoints: latency-svc-pp9gz [748.458155ms]
    Feb 13 15:05:44.161: INFO: Got endpoints: latency-svc-249jm [746.962144ms]
    Feb 13 15:05:44.214: INFO: Got endpoints: latency-svc-z7q6j [748.848955ms]
    Feb 13 15:05:44.263: INFO: Got endpoints: latency-svc-p5qhf [752.116808ms]
    Feb 13 15:05:44.264: INFO: Latencies: [27.642905ms 45.496ms 70.533256ms 82.526238ms 103.617283ms 114.764071ms 116.398626ms 144.947689ms 146.882244ms 154.801935ms 156.893616ms 175.51146ms 178.562957ms 184.724892ms 192.028937ms 193.27519ms 196.322ms 203.681913ms 223.253548ms 242.530232ms 247.981788ms 248.441739ms 248.58626ms 254.299013ms 269.755143ms 273.288418ms 276.942755ms 277.316082ms 277.348647ms 278.473299ms 279.329946ms 284.561937ms 293.114697ms 293.81846ms 299.632786ms 299.882778ms 312.665905ms 319.67479ms 323.476722ms 331.228689ms 348.012343ms 353.721288ms 353.871442ms 357.793684ms 361.611214ms 361.615465ms 362.295494ms 368.148143ms 414.090626ms 460.734777ms 507.544165ms 534.282524ms 585.292058ms 629.977652ms 678.028088ms 729.366543ms 738.750607ms 741.785554ms 741.795949ms 741.970514ms 742.447795ms 742.918219ms 743.307497ms 743.554066ms 743.995416ms 744.279267ms 744.327526ms 744.587986ms 744.881833ms 745.1026ms 745.25176ms 745.272729ms 745.648183ms 745.793722ms 745.984706ms 746.016093ms 746.167102ms 746.459485ms 746.526149ms 746.566088ms 746.784868ms 746.836473ms 746.911691ms 746.926999ms 746.943246ms 746.962144ms 746.986065ms 747.015107ms 747.069714ms 747.20129ms 747.386831ms 747.47273ms 747.510762ms 747.624916ms 747.734497ms 747.767103ms 747.802665ms 747.824291ms 747.857428ms 748.094629ms 748.16869ms 748.17961ms 748.23325ms 748.235261ms 748.25799ms 748.277562ms 748.440063ms 748.458155ms 748.522543ms 748.645111ms 748.695091ms 748.705841ms 748.745803ms 748.767939ms 748.848955ms 748.869196ms 749.012765ms 749.028988ms 749.177085ms 749.239585ms 749.240274ms 749.3064ms 749.392029ms 749.433259ms 749.724837ms 749.754334ms 749.805959ms 749.845873ms 749.866524ms 749.881346ms 749.989467ms 750.021792ms 750.063753ms 750.064688ms 750.233106ms 750.25007ms 750.253525ms 750.332391ms 750.393358ms 750.496236ms 750.529937ms 750.700154ms 750.713816ms 750.761004ms 750.765778ms 750.793945ms 750.807236ms 750.8092ms 750.841371ms 750.846192ms 750.855382ms 750.915352ms 751.002799ms 751.003292ms 751.027421ms 751.105778ms 751.232647ms 751.271846ms 751.406225ms 751.44689ms 751.572351ms 751.863669ms 751.985866ms 752.021648ms 752.030642ms 752.031465ms 752.116808ms 752.238626ms 752.403088ms 752.511336ms 752.538467ms 752.881188ms 752.9256ms 752.964517ms 753.178493ms 753.246246ms 753.273647ms 753.326079ms 753.523996ms 753.568384ms 753.692072ms 753.740018ms 753.8532ms 753.975422ms 754.249118ms 754.326805ms 754.385127ms 754.861152ms 754.995634ms 755.128998ms 755.584805ms 755.588827ms 755.707816ms 756.128305ms 756.445342ms 758.665051ms 759.713262ms 759.733942ms 760.645271ms 770.060166ms]
    Feb 13 15:05:44.264: INFO: 50 %ile: 748.16869ms
    Feb 13 15:05:44.264: INFO: 90 %ile: 753.692072ms
    Feb 13 15:05:44.264: INFO: 99 %ile: 760.645271ms
    Feb 13 15:05:44.264: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Feb 13 15:05:44.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-8502" for this suite. 02/13/23 15:05:44.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:44.284
Feb 13 15:05:44.285: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename webhook 02/13/23 15:05:44.286
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:44.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:44.309
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 02/13/23 15:05:44.325
STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:05:45.042
STEP: Deploying the webhook pod 02/13/23 15:05:45.05
W0213 15:05:45.065017      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Wait for the deployment to be ready 02/13/23 15:05:45.065
Feb 13 15:05:45.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 02/13/23 15:05:47.097
STEP: Verifying the service has paired with the endpoint 02/13/23 15:05:47.122
Feb 13 15:05:48.123: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 02/13/23 15:05:48.219
STEP: Creating a configMap that should be mutated 02/13/23 15:05:48.245
STEP: Deleting the collection of validation webhooks 02/13/23 15:05:48.307
STEP: Creating a configMap that should not be mutated 02/13/23 15:05:48.361
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Feb 13 15:05:48.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3633" for this suite. 02/13/23 15:05:48.404
STEP: Destroying namespace "webhook-3633-markers" for this suite. 02/13/23 15:05:48.424
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":358,"skipped":6632,"failed":0}
------------------------------
• [4.206 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:44.284
    Feb 13 15:05:44.285: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename webhook 02/13/23 15:05:44.286
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:44.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:44.309
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 02/13/23 15:05:44.325
    STEP: Create role binding to let webhook read extension-apiserver-authentication 02/13/23 15:05:45.042
    STEP: Deploying the webhook pod 02/13/23 15:05:45.05
    W0213 15:05:45.065017      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Wait for the deployment to be ready 02/13/23 15:05:45.065
    Feb 13 15:05:45.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 02/13/23 15:05:47.097
    STEP: Verifying the service has paired with the endpoint 02/13/23 15:05:47.122
    Feb 13 15:05:48.123: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 02/13/23 15:05:48.219
    STEP: Creating a configMap that should be mutated 02/13/23 15:05:48.245
    STEP: Deleting the collection of validation webhooks 02/13/23 15:05:48.307
    STEP: Creating a configMap that should not be mutated 02/13/23 15:05:48.361
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Feb 13 15:05:48.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3633" for this suite. 02/13/23 15:05:48.404
    STEP: Destroying namespace "webhook-3633-markers" for this suite. 02/13/23 15:05:48.424
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:48.497
Feb 13 15:05:48.497: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename gc 02/13/23 15:05:48.498
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:48.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:48.513
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
W0213 15:05:48.524240      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 15:05:48.532587      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
W0213 15:05:48.541700      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:05:48.551: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"43e4fde4-7805-4eac-913e-2dcd0dd8f302", Controller:(*bool)(0xc0050c7fe6), BlockOwnerDeletion:(*bool)(0xc0050c7fe7)}}
Feb 13 15:05:48.562: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b770351a-dabb-46ba-a869-c4fb2501710e", Controller:(*bool)(0xc003f8e49e), BlockOwnerDeletion:(*bool)(0xc003f8e49f)}}
Feb 13 15:05:48.570: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"42c4f1c0-aff2-4091-ac42-b72afc754fc8", Controller:(*bool)(0xc003f8e69a), BlockOwnerDeletion:(*bool)(0xc003f8e69b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Feb 13 15:05:53.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3471" for this suite. 02/13/23 15:05:53.604
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":359,"skipped":6639,"failed":0}
------------------------------
• [SLOW TEST] [5.120 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:48.497
    Feb 13 15:05:48.497: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename gc 02/13/23 15:05:48.498
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:48.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:48.513
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    W0213 15:05:48.524240      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 15:05:48.532587      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    W0213 15:05:48.541700      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:05:48.551: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"43e4fde4-7805-4eac-913e-2dcd0dd8f302", Controller:(*bool)(0xc0050c7fe6), BlockOwnerDeletion:(*bool)(0xc0050c7fe7)}}
    Feb 13 15:05:48.562: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b770351a-dabb-46ba-a869-c4fb2501710e", Controller:(*bool)(0xc003f8e49e), BlockOwnerDeletion:(*bool)(0xc003f8e49f)}}
    Feb 13 15:05:48.570: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"42c4f1c0-aff2-4091-ac42-b72afc754fc8", Controller:(*bool)(0xc003f8e69a), BlockOwnerDeletion:(*bool)(0xc003f8e69b)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Feb 13 15:05:53.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3471" for this suite. 02/13/23 15:05:53.604
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:53.624
Feb 13 15:05:53.625: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename secrets 02/13/23 15:05:53.626
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.664
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-271ba9cd-0af2-4f22-a1cd-943a9b582e3a 02/13/23 15:05:53.668
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Feb 13 15:05:53.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2433" for this suite. 02/13/23 15:05:53.68
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":360,"skipped":6658,"failed":0}
------------------------------
• [0.070 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:53.624
    Feb 13 15:05:53.625: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename secrets 02/13/23 15:05:53.626
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.664
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-271ba9cd-0af2-4f22-a1cd-943a9b582e3a 02/13/23 15:05:53.668
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Feb 13 15:05:53.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2433" for this suite. 02/13/23 15:05:53.68
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:53.699
Feb 13 15:05:53.699: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename services 02/13/23 15:05:53.7
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.747
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 02/13/23 15:05:53.753
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Feb 13 15:05:53.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5631" for this suite. 02/13/23 15:05:53.766
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":361,"skipped":6667,"failed":0}
------------------------------
• [0.087 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:53.699
    Feb 13 15:05:53.699: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename services 02/13/23 15:05:53.7
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.747
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 02/13/23 15:05:53.753
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Feb 13 15:05:53.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5631" for this suite. 02/13/23 15:05:53.766
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 02/13/23 15:05:53.79
Feb 13 15:05:53.790: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
STEP: Building a namespace api object, basename replication-controller 02/13/23 15:05:53.792
STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.823
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 02/13/23 15:05:53.829
W0213 15:05:53.841600      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
Feb 13 15:05:53.841: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5260" to be "running and ready"
Feb 13 15:05:53.853: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.729907ms
Feb 13 15:05:53.853: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Feb 13 15:05:55.860: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.018017605s
Feb 13 15:05:55.860: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Feb 13 15:05:55.860: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 02/13/23 15:05:55.864
W0213 15:05:55.873021      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
STEP: Then the orphan pod is adopted 02/13/23 15:05:55.873
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Feb 13 15:05:56.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5260" for this suite. 02/13/23 15:05:56.886
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":362,"skipped":6700,"failed":0}
------------------------------
• [3.102 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 02/13/23 15:05:53.79
    Feb 13 15:05:53.790: INFO: >>> kubeConfig: /tmp/kubeconfig-219335588
    STEP: Building a namespace api object, basename replication-controller 02/13/23 15:05:53.792
    STEP: Waiting for a default service account to be provisioned in namespace 02/13/23 15:05:53.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 02/13/23 15:05:53.823
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 02/13/23 15:05:53.829
    W0213 15:05:53.841600      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    Feb 13 15:05:53.841: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5260" to be "running and ready"
    Feb 13 15:05:53.853: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.729907ms
    Feb 13 15:05:53.853: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Feb 13 15:05:55.860: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.018017605s
    Feb 13 15:05:55.860: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Feb 13 15:05:55.860: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 02/13/23 15:05:55.864
    W0213 15:05:55.873021      19 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
    STEP: Then the orphan pod is adopted 02/13/23 15:05:55.873
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Feb 13 15:05:56.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5260" for this suite. 02/13/23 15:05:56.886
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6704,"failed":0}
Feb 13 15:05:56.894: INFO: Running AfterSuite actions on all nodes
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Feb 13 15:05:56.894: INFO: Running AfterSuite actions on node 1
Feb 13 15:05:56.894: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Feb 13 15:05:56.894: INFO: Running AfterSuite actions on all nodes
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Feb 13 15:05:56.894: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Feb 13 15:05:56.894: INFO: Running AfterSuite actions on node 1
    Feb 13 15:05:56.894: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.094 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7066 Specs in 5574.410 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6704 Skipped
PASS

Ginkgo ran 1 suite in 1h32m54.805935256s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

